<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Thu, 14 Mar 2024 17:12:58 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.4.3</generator>
	<item>
		<title>Reach for the Stars: Eight Out-of-This-World Games Join the Cloud</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-square-enix-titles/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 14 Mar 2024 13:00:59 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70299</guid>

					<description><![CDATA[The stars align this GFN Thursday as more top titles from Ubisoft and Square Enix join the cloud. Star Wars Outlaws will be coming to the GeForce NOW library at launch later this year, while STAR OCEAN THE SECOND STORY R and PARANORMASIGHT: The Seven Mysteries of Honjo are part of eight new titles joining		<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-square-enix-titles/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The stars align this GFN Thursday as more top titles from Ubisoft and Square Enix join the cloud.</p>
<p><i>Star Wars Outlaws </i>will be coming to the <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> library at launch later this year, while<i> STAR OCEAN THE SECOND STORY R </i>and <i>PARANORMASIGHT: The Seven Mysteries of Honjo </i>are part of eight new titles joining this week.</p>
<p>Additionally, <a href="https://www.nvidia.com/en-us/geforce/news/gdc-2024-dlss-rtx-full-ray-tracing-game-announcements">four other games</a> are getting <a href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA RTX</a> enhancements, all arriving at next week’s <a href="https://gdconf.com/">Game Developers Conference</a>.</p>
<p><i>NARAKA: BLADEPOINT</i> and <i>Portal with RTX</i> are adding full ray tracing and <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">NVIDIA DLSS</a> 3.5 Ray Reconstruction capabilities. This month’s <i>Diablo IV</i> update will add ray tracing. And <i>Sengoku Dynasty</i> — available to stream today — was recently updated with DLSS 3 Frame Generation.</p>
<h2><b>Coming Soon</b></h2>
<figure id="attachment_70303" aria-describedby="caption-attachment-70303" style="width: 672px" class="wp-caption aligncenter"><img fetchpriority="high" decoding="async" class="size-large wp-image-70303" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Star_Wars_Outlaws-672x336.jpg" alt="Star Wars Outlaws coming to GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Star_Wars_Outlaws-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Star_Wars_Outlaws-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Star_Wars_Outlaws-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Star_Wars_Outlaws-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Star_Wars_Outlaws-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Star_Wars_Outlaws-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Star_Wars_Outlaws-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Star_Wars_Outlaws-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Star_Wars_Outlaws.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70303" class="wp-caption-text"><em>A galaxy far, far away is coming to the cloud.</em></figcaption></figure>
<p>GeForce NOW members will be able to stream <i>Star Wars Outlaws</i>, the first open-world Star Wars game from Ubisoft, when it comes to the cloud at launch later this year.</p>
<p>Set between the events of <i>The Empire Strikes Back</i> and <i>Return of the Jedi</i>, explore distinct planets across the galaxy, both iconic and new. Risk it all as Kay Vess, a scoundrel seeking freedom and a fresh new start. Members will fight, steal and outwit their way through the galaxy’s crime syndicates to become the galaxy’s most wanted.</p>
<p>The game will launch with DLSS 3 and ray-traced effects, as well as NVIDIA RTX Direct Illumination (RTXDI) and ray-traced <a href="https://blogs.nvidia.com/blog/direct-indirect-lighting/">global illumination lighting</a>, taking visuals to the next level. Turn RTX ON, available to Ultimate and Priority members as well as Day Pass users. And both Ultimate members and <a href="https://blogs.nvidia.com/blog/geforce-now-thursday-day-pass-cygames/">Day Pass </a>users get the added benefit of <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">NVIDIA DLSS 3</a> and <a href="https://www.nvidia.com/en-us/geforce/technologies/reflex/">NVIDIA Reflex</a> for a streaming experience nearly indistinguishable from playing locally.</p>
<h2><b>Adventure Awaits</b></h2>
<figure id="attachment_70306" aria-describedby="caption-attachment-70306" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" class="size-large wp-image-70306" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/STAR-OCEAN-THE-SECOND-STORY-R_Vol1.2-672x378.jpg" alt="Star Ocean on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/STAR-OCEAN-THE-SECOND-STORY-R_Vol1.2-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/STAR-OCEAN-THE-SECOND-STORY-R_Vol1.2-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/STAR-OCEAN-THE-SECOND-STORY-R_Vol1.2-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/STAR-OCEAN-THE-SECOND-STORY-R_Vol1.2-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/STAR-OCEAN-THE-SECOND-STORY-R_Vol1.2-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/STAR-OCEAN-THE-SECOND-STORY-R_Vol1.2-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/03/STAR-OCEAN-THE-SECOND-STORY-R_Vol1.2-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/03/STAR-OCEAN-THE-SECOND-STORY-R_Vol1.2-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/03/STAR-OCEAN-THE-SECOND-STORY-R_Vol1.2-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70306" class="wp-caption-text"><em>Play two of Square Enix’s latest games, thanks to the cloud.</em></figcaption></figure>
<p>With GeForce NOW, there’s always something new to play. This week, Japan-based publisher Square Enix brings two of its latest role-playing adventures to the cloud.</p>
<p>Witness an awakened destiny in <i>STAR OCEAN THE SECOND STORY R</i>, the highly acclaimed remake of the <i>STAR OCEAN</i> series’ second installment. Brought to life with a unique 2.5D aesthetic, which fuses 2D pixel characters and 3D environments, the remake includes all the iconic aspects of the original release while adding fresh elements. Experience new battle mechanics, full Japanese and English voice-overs, original and rearranged music, fast-travel and more. Discover the modernized, classic Japanese role-playing game perfect for newcomers and long-time fans alike.</p>
<p>Members can also try <i>STAR OCEAN THE SECOND STORY R &#8211; DEMO</i> this week before purchasing the full game.</p>
<p>Plus, solve an century-old mystery in <i>PARANORMASIGHT: The Seven Mysteries of Honjo</i>, a horror-adventure visual novel surrounding a Japanese tale, in which a mysterious “Rite of Resurrection” leads to conflict between those who have the power to curse others. Players conduct investigations throughout immersive, ambient, 360-degree environments to unravel the mysteries of Honjo, including by conversing with many interesting — and suspicious — characters.</p>
<p>Ultimate members can stream these games at up to 4K resolution for amazing visual quality across nearly any device and access NVIDIA GeForce RTX 4080 servers for extended session lengths. <a href="http://geforcenow.com">Upgrade</a> today.</p>
<h2><b>Shine Bright Like a New Game</b></h2>
<figure id="attachment_70309" aria-describedby="caption-attachment-70309" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" class="size-large wp-image-70309" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Balatro-672x336.jpg" alt="Balatro on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Balatro-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Balatro-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Balatro-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Balatro-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Balatro-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Balatro-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Balatro-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Balatro-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Balatro.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70309" class="wp-caption-text"><em>Play crazy poker hands, discover game-changing jokers and trigger outrageous combos in Balatro, streaming this week.</em></figcaption></figure>
<p>Members can look for the following new games this week:</p>
<ul>
<li><i>Hellbreach: Vegas </i>(New release on <a href="https://store.steampowered.com/app/1691320?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, March 11)</li>
<li><i>Deus Ex: Mankind Divided</i> (New release on <a href="https://www.epicgames.com/store/p/deus-ex-mankind-divided-4c6370?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, Free March 14)</li>
<li><i>Outcast &#8211; A New Beginning </i>(New release on <a href="https://store.steampowered.com/app/1013140?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, March 15)</li>
<li><i>Balatro </i>(<a href="https://store.steampowered.com/app/2379780?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>PARANORMASIGHT: The Seven Mysteries of Honjo</i> (<a href="https://store.steampowered.com/app/2106840?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Space Engineers</i> (<a href="https://www.xbox.com/en-US/games/store/space-engineers/9NLV3X229LG1?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>STAR OCEAN THE SECOND STORY R</i> (<a href="https://store.steampowered.com/app/2238900?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>STAR OCEAN THE SECOND STORY R &#8211; DEMO</i> (<a href="https://store.steampowered.com/app/2441280?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Warhammer 40,000: Boltgun</i> (<a href="https://www.xbox.com/games/store/warhammer-40000-boltgun---windows/9N41VHRQ5X8N?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">How would your life look without video games? <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f914.png" alt="🤔" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1767943704470340088?ref_src=twsrc%5Etfw">March 13, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/gfn-thursday-3-14-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/gfn-thursday-3-14-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Reach for the Stars: Eight Out-of-This-World Games Join the Cloud]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA GTC 2024: A Glimpse Into the Future of AI With Jensen Huang</title>
		<link>https://blogs.nvidia.com/blog/gtc-2024-jensen-huang/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Thu, 14 Mar 2024 13:00:34 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70265</guid>

					<description><![CDATA[NVIDIA’s founder and CEO will discuss the future of AI at one of the world’s premier technology conferences.
]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><a href="https://www.nvidia.com/gtc/">NVIDIA&#8217;s GTC 2024</a> AI conference will set the stage for another leap forward in AI.</p>
<p>At the heart of this highly anticipated event: the opening keynote by <a href="http://nvidianews.nvidia.com/bios/jensen-huang">Jensen Huang</a>, NVIDIA’s visionary founder and CEO, who speaks on Monday, March 18, at 1 p.m. Pacific, at the SAP Center in San Jose, Calif.</p>
<p><iframe loading="lazy" title="YouTube video player" src="https://www.youtube.com/embed/n9R1ts_xfgc?si=HjAtzbGK20dewNM6" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<h2>Planning Your GTC Experience</h2>
<p>There are two ways to watch.</p>
<p><a href="https://www.nvidia.com/gtc/keynote/">Register to attend GTC</a> in person to secure a spot for an immersive experience at the SAP Center. The center is a short walk from the San Jose Convention Center, where the rest of the conference takes place. Doors open at 11 a.m., and badge pickup starts at 10:30 a.m.</p>
<p>The keynote will also be livestreamed at <a href="https://www.nvidia.com/gtc/keynote/">www.nvidia.com/gtc/keynote/</a>.</p>
<p>Whether attending in person or virtually, commit to joining us all week. GTC is more than just a conference. It’s a gateway to the next wave of AI innovations.</p>
<ul>
<li style="font-weight: 400;" aria-level="1"><b>Transforming AI:</b> Hear more from Huang as he discusses the origins and impact of transformer neural network architecture with its creators and industry pioneers. He’ll host a panel with all eight authors of the legendary 2017 paper that introduced the concept of transformers: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin.Wed., March 20, 11-11:50 a.m. Pacific.</li>
<li style="font-weight: 400;" aria-level="1"><b>Join Visionaries Transforming Our World:</b> Hear from leaders such as <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=Igor%20Babuschkin#/session/1706123152858001fNnT">xAI cofounder Igor Babuschkin</a>; <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=Sebastian%20Bubeck#/session/1691595634284001HXjJ">Microsoft Vice President of GenAI Sebastian Bubeck</a>, Stanford University’s <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=Fei-Fei%20Li#/session/1690423197613001jzhz">Fei-Fei Li</a>,  Meta Vice President of AI Research <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=%20Joelle%20Pineau#/session/1695673049743001rLIc">Joelle Pineau</a>; <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=brad%20lightcap#/session/1696214901866001OP1b">OpenAI Chief Operating Officer Brad LightCap</a>; Adept AI founder and CEO <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=David%20Luan#/session/1706747368510001RGVh">David Luan</a>; Waabi f<a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=%20Raquel%20Urtasu#/session/1696610170422001o3kU">ounder and CEO Raquel Urtasun</a>; Mistral CEO <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=Arthur%20Mensch#/">Arthur Mensch</a>; and many others at the forefront of AI across various industries.</li>
<li style="font-weight: 400;" aria-level="1"><b>Be Part of What Comes Next:</b> Engage from March 17-21 in <a href="https://www.nvidia.com/gtc/training/">workshops</a> and <a href="https://www.nvidia.com/gtc/networking/">peer networking</a> and connect<a href="https://www.nvidia.com/gtc/connect-with-experts/"> with the </a>experts. This year’s session catalog is packed with topics covering everything from robotics to generative AI, showcasing real-world applications and the latest in AI innovation.</li>
<li style="font-weight: 400;" aria-level="1"><b>Stay Connected:</b> Tune in online to engage with the event and fellow attendees using #GTC24 on social media.</li>
</ul>
<p>With visionary speakers and a comprehensive program covering the essentials of AI and computing, GTC promises to be an enlightening experience for all.</p>
<p>Don’t miss your chance to be at the forefront of AI’s evolution. <a href="https://www.nvidia.com/gtc/keynote/">Register now</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/jensen-headshot-1906-600x338-1.png"
			type="image/png"
			width="600"
			height="338"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/jensen-headshot-1906-600x338-1.png"
			width="600"
			height="338"
			/>
			<media:title type="html"><![CDATA[NVIDIA GTC 2024: A Glimpse Into the Future of AI With Jensen Huang]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI Decoded: Demystifying Large Language Models, the Brains Behind Chatbots</title>
		<link>https://blogs.nvidia.com/blog/ai-decoded-rtx-pc-llms-chatbots/</link>
		
		<dc:creator><![CDATA[Jesse Clayton]]></dc:creator>
		<pubDate>Wed, 13 Mar 2024 13:00:36 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[AI Decoded]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Conversational AI]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[generative AI]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70273</guid>

					<description><![CDATA[If AI is having its iPhone moment, then chatbots are one of its first popular apps.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our </i><a href="https://blogs.nvidia.com/blog/tag/ai-decoded/"><i>AI Decoded series</i></a><i>, which aims to demystify AI by making the technology more accessible, while showcasing new hardware, software, tools and accelerations for RTX PC and workstation users.</i></p>
<p>If AI is having its iPhone moment, then chatbots are one of its first popular apps.</p>
<p>They’re made possible thanks to <a href="https://blogs.nvidia.com/blog/what-are-large-language-models-used-for/">large language models</a>, deep learning algorithms pretrained on massive datasets — as expansive as the internet itself — that can recognize, summarize, translate, predict and generate text and other forms of content. They can run locally on PCs and workstations powered by <a href="https://www.nvidia.com/en-us/geforce/">NVIDIA GeForce</a> and <a href="https://www.nvidia.com/en-us/design-visualization/technologies/rtx/">RTX</a> GPUs.</p>
<p>LLMs excel at summarizing large volumes of text, classifying and mining data for insights, and generating new text in a user-specified style, tone or format. They can facilitate communication in any language, even beyond ones spoken by humans, such as computer code or protein and genetic sequences.</p>
<p>While the first LLMs dealt solely with text, later iterations were trained on other types of data. These multimodal LLMs can recognize and generate images, audio, videos and other content forms.</p>
<p>Chatbots like ChatGPT were among the first to bring LLMs to a consumer audience, with a familiar interface built to converse with and respond to natural-language prompts. LLMs have since been used to help developers write code and scientists to drive drug discovery and vaccine development.</p>
<p>But the AI models that power those functions are computationally intensive. Combining advanced optimization techniques and algorithms like quantization with RTX GPUs, which are purpose-built for AI, helps make LLMs compact enough and PCs powerful enough to run locally — no internet connection required. And a new breed of lightweight LLMs like Mistral — one of the LLMs powering <a href="https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/">Chat with RTX</a> — sets the stage for state-of-the-art performance with lower power and storage demands.</p>
<h2><strong>Why Do LLMs Matter?</strong></h2>
<p>LLMs can be adapted for a wide range of use cases, industries and workflows. This versatility, combined with their high-speed performance, offers performance and efficiency gains across virtually all language-based tasks.</p>
<figure id="attachment_70279" aria-describedby="caption-attachment-70279" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/03/DeepL_LLMs.png"><img loading="lazy" decoding="async" class="size-large wp-image-70279" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/DeepL_LLMs-672x433.png" alt="" width="672" height="433" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/DeepL_LLMs-672x433.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/DeepL_LLMs-400x258.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/DeepL_LLMs-768x495.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/DeepL_LLMs-698x450.png 698w, https://blogs.nvidia.com/wp-content/uploads/2024/03/DeepL_LLMs-333x215.png 333w, https://blogs.nvidia.com/wp-content/uploads/2024/03/DeepL_LLMs-155x100.png 155w, https://blogs.nvidia.com/wp-content/uploads/2024/03/DeepL_LLMs.png 1050w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-70279" class="wp-caption-text">DeepL, running on NVIDIA GPUs in the cloud, uses advanced AI to provide accurate text translations.</figcaption></figure>
<p>LLMs are widely used in language translation apps such as <a href="https://www.deepl.com/translator">DeepL</a>, which uses AI and machine learning to provide accurate outputs.</p>
<p>Medical researchers are training LLMs on textbooks and other medical data to enhance patient care. Retailers are leveraging LLM-powered chatbots to deliver stellar customer support experiences. Financial analysts are tapping LLMs to transcribe and summarize earning calls and other important meetings. And that’s just the tip of the iceberg.</p>
<p>Chatbots — like Chat with RTX — and writing assistants built atop LLMs are making their mark on every facet of knowledge work, from content marketing and copywriting to legal operations. Coding assistants were among the first LLM-powered applications to point toward the AI-assisted future of software development. Now, projects like ChatDev are combining LLMs with AI agents — smart bots that act autonomously to help answer questions or perform digital tasks — to spin up an on-demand, virtual software company. Just tell the system what kind of app is needed and watch it get to work.</p>
<p><a href="https://developer.nvidia.com/blog/introduction-to-llm-agents/">Learn more about LLM agents</a> on the NVIDIA developer blog.</p>
<h2><strong>Easy as Striking Up a Conversation </strong></h2>
<p>Many people’s first encounter with generative AI came by way of a chatbot such as ChatGPT, which simplifies the use of LLMs through natural language, making user action as simple as telling the model what to do.</p>
<p>LLM-powered chatbots can help generate a draft of marketing copy, offer ideas for a vacation, craft an email to customer service and even spin up original poetry.</p>
<p>Advances in image generation and multimodal LLMs have extended the chatbot’s realm to include analyzing and generating imagery — all while maintaining the wonderfully simple user experience. Just describe an image to the bot or upload a photo and ask the system to analyze it. It’s chatting, but now with visual aids.</p>
<div class="simplePullQuote right"></p>
<p>For more on how these bots are designed, check out the on-demand webinar on <a href="https://info.nvidia.com/building-intelligent-ai-chatbots-using-rag-webinar.html?ondemandrgt=yes#">Building Intelligent AI Chatbots Using RAG</a>.</p>
<p>
</div>
<p>Future advancements will help LLMs expand their capacity for logic, reasoning, math and more, giving them the ability to break complex requests into smaller subtasks.</p>
<p>Progress is also being made on AI agents, applications capable of taking a complex prompt, breaking it into smaller ones, and engaging autonomously with LLMs and other AI systems to complete them. ChatDev is an example of an AI agent framework, but agents aren’t limited to technical tasks.</p>
<p>For example, users could ask a personal AI travel agent to book a family vacation abroad. The agent would break that task into subtasks — itinerary planning, booking travel and lodging, creating packing lists, finding a dog walker — and independently execute them in order.</p>
<h2><strong>Unlock Personal Data With RAG</strong></h2>
<p>As powerful as LLMs and chatbots are for general use, they can become even more helpful when combined with an individual user’s data. By doing so, they can help analyze email inboxes to uncover trends, comb through dense user manuals to find the answer to a technical question about some hardware, or summarize years of bank and credit card statements.</p>
<p><a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">Retrieval-augmented generation</a>, or RAG, is one of the easiest and most effective ways to hone LLMs for a particular dataset.</p>
<figure id="attachment_70282" aria-describedby="caption-attachment-70282" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/03/RAG_Locally_LLMs.png"><img loading="lazy" decoding="async" class="size-large wp-image-70282" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/RAG_Locally_LLMs-672x369.png" alt="" width="672" height="369" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/RAG_Locally_LLMs-672x369.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/RAG_Locally_LLMs-400x220.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/RAG_Locally_LLMs-768x422.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/RAG_Locally_LLMs-819x450.png 819w, https://blogs.nvidia.com/wp-content/uploads/2024/03/RAG_Locally_LLMs-392x215.png 392w, https://blogs.nvidia.com/wp-content/uploads/2024/03/RAG_Locally_LLMs-182x100.png 182w, https://blogs.nvidia.com/wp-content/uploads/2024/03/RAG_Locally_LLMs.png 1200w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-70282" class="wp-caption-text">An example of RAG on a PC.</figcaption></figure>
<p>RAG enhances the accuracy and reliability of generative AI models with facts fetched from external sources. By connecting an LLM with practically any external resource, RAG lets users chat with data repositories while also giving the LLM the ability to cite its sources. The user experience is as simple as pointing the chatbot toward a file or directory.</p>
<p>For example, a standard LLM will have general knowledge about content strategy best practices, marketing tactics and basic insights into a particular industry or customer base. But connecting it via RAG to marketing assets supporting a product launch would allow it to analyze the content and help plan a tailored strategy.</p>
<p>RAG works with any LLM, as the application supports it. NVIDIA’s Chat with RTX tech demo is an example of RAG connecting an LLM to a personal dataset. It runs locally on systems with a GeForce RTX or NVIDIA RTX professional GPU.</p>
<p>To learn more about RAG and how it compares to fine-tuning an LLM, read the tech blog, <a href="https://developer.nvidia.com/blog/rag-101-retrieval-augmented-generation-questions-answered/">RAG 101: Retrieval-Augmented Generation Questions Answered</a>.</p>
<h2><strong>Experience the Speed and Privacy of Chat with RTX</strong></h2>
<p><a href="https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/">Chat with RTX</a> is a local, personalized chatbot demo that’s easy to use and <a href="https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/">free to download</a>. It’s built with RAG functionality and <a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-supercharges-large-language-model-inference-on-nvidia-h100-gpus/">TensorRT-LLM</a> and RTX acceleration. It supports multiple open-source LLMs, including Meta’s Llama 2 and Mistral’s Mistral. Support for Google’s Gemma is coming in a future update.</p>
<figure id="attachment_70285" aria-describedby="caption-attachment-70285" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/03/chat-wth-rtx.png"><img loading="lazy" decoding="async" class="wp-image-70285 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/chat-wth-rtx-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/chat-wth-rtx-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/chat-wth-rtx-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/chat-wth-rtx-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/chat-wth-rtx-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/chat-wth-rtx-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2024/03/chat-wth-rtx-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2024/03/chat-wth-rtx-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/03/chat-wth-rtx-1280x720.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/chat-wth-rtx.png 1999w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-70285" class="wp-caption-text">Chat with RTX connects users to their personal data through RAG.</figcaption></figure>
<p>Users can easily connect local files on a PC to a supported LLM simply by dropping files into a folder and pointing the demo to that location. Doing so enables it to answer queries with quick, contextually relevant answers.</p>
<p>Since Chat with RTX runs locally on Windows with GeForce RTX PCs and NVIDIA RTX workstations, results are fast — and the user’s data stays on the device. Rather than relying on cloud-based services, Chat with RTX lets users process sensitive data on a local PC without the need to share it with a third party or have an internet connection.</p>
<p><i>To learn more about how AI is shaping the future, tune in to </i><a href="https://www.nvidia.com/gtc/"><i>NVIDIA GTC</i></a><i>, a global AI developer conference running March 18-21 in San Jose, Calif., and online.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/nvidia-ai-decoded-week-2-nv-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/nvidia-ai-decoded-week-2-nv-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI Decoded: Demystifying Large Language Models, the Brains Behind Chatbots]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Currents of Change: ITIF&#8217;s Daniel Castro on Energy-Efficient AI and Climate Change</title>
		<link>https://blogs.nvidia.com/blog/itif-daniel-castro/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Wed, 13 Mar 2024 13:00:32 +0000</pubDate>
				<category><![CDATA[The AI Podcast]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70264</guid>

					<description><![CDATA[AI-driven change is in the air, as are concerns about the technology’s environmental impact. In this episode of NVIDIA’s AI Podcast, Daniel Castro, vice president of the Information Technology and Innovation Foundation and director of its Center for Data Innovation, speaks with host Noah Kravitz about the motivation behind his AI energy use report, which		<a class="read-more" href="https://blogs.nvidia.com/blog/itif-daniel-castro/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>AI-driven change is in the air, as are concerns about the technology’s environmental impact. In this episode of NVIDIA’s <a href="https://blogs.nvidia.com/ai-podcast/">AI Podcast</a>, Daniel Castro, vice president of the Information Technology and Innovation Foundation and director of its Center for Data Innovation, speaks with host Noah Kravitz about the motivation behind his <a href="https://datainnovation.org/2024/01/rethinking-concerns-about-ais-energy-use/">AI energy use report</a>, which addresses misconceptions about the technology’s energy consumption. Castro also touches on the need for policies and frameworks that encourage the development of energy-efficient technology. Tune in to discover the crucial role of GPU acceleration in enhancing sustainability and how AI can help address climate change challenges.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1772793834%3Fsecret_token%3Ds-MWFun29XaR3&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="ITIF President Daniel Castro on Energy-Efficient AI and Climate Change" href="https://soundcloud.com/theaipodcast/ai-daniel-castro-itif/s-MWFun29XaR3" target="_blank" rel="noopener">ITIF President Daniel Castro on Energy-Efficient AI and Climate Change</a></div>
<p>Register for <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>, a global AI developer conference running March 18-21 in San Jose, Calif., to explore sessions on <a href="https://www.nvidia.com/gtc/session-catalog/?search=&amp;tab.allsessions=1700692987788001F1cG&amp;search.industry=1624401800869002y16T#/">energy-efficient computing</a> and <a href="https://www.nvidia.com/gtc/session-catalog/?search=climate&amp;tab.allsessions=1700692987788001F1cG#/">using AI to combat climate change</a>.</p>
<h2>You Might Also Like…</h2>
<p><a href="https://soundcloud.com/theaipodcast/ai-overjet"><b>Overjet on Bringing AI to Dentistry &#8211; Ep. 179</b><b><br />
</b><br />
</a>Dentists get a bad rap. Dentists also get more people out of more aggravating pain than just about anyone, which is why the more technology dentists have, the better. Overjet, a member of the NVIDIA Inception program for startups, is moving fast to bring AI to dentists’ offices.</p>
<p><a href="https://soundcloud.com/theaipodcast/ai-wildfire"><b>DigitalPath’s Ethan Higgins on Using AI to Fight Wildires &#8211; Ep. 211</b></a></p>
<p>DigitalPath is igniting change in the golden state — using computer vision, generative adversarial networks and a network of thousands of cameras to detect signs of fire in real-time.</p>
<p><a href="https://soundcloud.com/theaipodcast/anima-anandkumar"><b>Anima Anandkumar on Using Generative AI to Tackle Global Challenges &#8211; Ep. 204</b></a></p>
<p>Anima Anandkumar, Bren Professor at Caltech and senior director of AI research at NVIDIA, speaks to generative AI’s potential to make splashes in the scientific community, from accelerating drug and vaccine research to predicting extreme weather events like hurricanes or heat waves.</p>
<p><a href="https://soundcloud.com/theaipodcast/everestlabs"><b>Doing the Best They Can: EverestLabs Ensures Fewer Recyclables Go to Landfills &#8211; Ep. 184</b></a></p>
<p>All of us recycle. Or, at least, all of us should. Now, AI is joining the effort. JD Ambati, founder and CEO of EverestLabs, developer of RecycleOS, discusses developing first AI-enabled operating system for recycling.</p>
<h2><b>Show Notes</b></h2>
<p>1:41: Context on and findings from the AI energy use report<br />
10:36: How GPU acceleration has transformed the energy efficiency of AI, particularly in weather and climate forecasting<br />
12:31: Examples of how GPU acceleration has improved the energy efficiency of AI operations<br />
15:51: Castro’s insights on sustainability and AI<br />
20:01: Policies and frameworks to encourage energy-efficient AI<br />
26:43: Castro’s outlook on the interplay among advancing AI technology, energy sustainability and climate change</p>
<h2><b>Subscribe to the AI Podcast</b></h2>
<p>Get the<a href="https://blogs.nvidia.com/ai-podcast/"> AI Podcast</a> through<a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439"> iTunes</a>,<a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjI2NDAzNDEzMy9zb3VuZHMucnNz"> Google Podcasts</a>,<a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm"> Google Play</a>, <a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">Amazon Music, </a><a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us">Castbox</a>, DoggCatcher,<a href="https://overcast.fm/itunes1186480811/the-ai-podcast"> Overcast</a>,<a href="https://player.fm/series/the-ai-podcast"> PlayerFM</a>, Pocket Casts,<a href="http://www.podbay.fm/show/1186480811"> Podbay</a>,<a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast"> PodBean</a>, PodCruncher, PodKicker,<a href="https://soundcloud.com/theaipodcast"> Soundcloud</a>,<a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L"> Spotify</a>,<a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr"> Stitcher</a> and<a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/"> TuneIn</a>.</p>
<p>Make the AI Podcast better: Have a few minutes to spare? Fill out<a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short"> this listener survey</a>.</p>
<p>&nbsp;</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2021/04/earth-pixabay-x1280.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2021/04/earth-pixabay-x1280-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Currents of Change: ITIF’s Daniel Castro on Energy-Efficient AI and Climate Change]]></media:title>
			<media:description type="html">Earth pixabay for &quot;I Am AI&quot; video</media:description>
			</media:content>
			</item>
		<item>
		<title>Head of the Class: Explore AI’s Potential in Higher Education and Research at GTC</title>
		<link>https://blogs.nvidia.com/blog/gtc-2024-ai-education-research-sessions/</link>
		
		<dc:creator><![CDATA[Max Starubinskiy]]></dc:creator>
		<pubDate>Tue, 12 Mar 2024 16:39:26 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Education]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70251</guid>

					<description><![CDATA[For students, researchers and educators eager to delve into AI, GTC — NVIDIA’s conference on AI and accelerated computing — is in a class of its own. Taking place from March 18-21 at the San Jose Convention Center, GTC features over 900 talks presented by world-renowned experts in fields such as generative AI, high performance		<a class="read-more" href="https://blogs.nvidia.com/blog/gtc-2024-ai-education-research-sessions/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>For students, researchers and educators eager to delve into AI, <a href="https://www.nvidia.com/gtc/">GTC</a> — NVIDIA’s conference on AI and accelerated computing — is in a class of its own.</p>
<p>Taking place from March 18-21 at the San Jose Convention Center, GTC features over 900 talks presented by world-renowned experts in fields such as <a href="https://www.nvidia.com/gtc/sessions/generative-ai/">generative AI</a>, <a href="https://www.nvidia.com/gtc/sessions/hpc/">high performance computing</a>, <a href="https://www.nvidia.com/gtc/sessions/healthcare/">healthcare</a>, <a href="https://www.nvidia.com/gtc/sessions/ai-in-environment-and-energy/">energy and environment</a> and <a href="https://www.nvidia.com/gtc/sessions/robotics/">robotics</a>.</p>
<p>See some of the top sessions for attendees in higher education below. And don’t miss NVIDIA founder and CEO <a href="https://www.nvidia.com/gtc/keynote/?regcode=pa-srch-goog-143845-prsp&amp;ncid=pa-srch-goog-143845-prsp">Jensen Huang’s GTC keynote</a> on how AI is transforming industries, on Monday, March 18, at 1 p.m. PT.</p>
<h2><b>For Researchers </b></h2>
<ul>
<li style="font-weight: 300;" aria-level="1"><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;ncid=em-even-602095-vt16&amp;mkt_tok=MTU2LU9GTi03NDIAAAGRTeopo5oXth7RUEHrzNOoN2_WgvKHfykfVuZUquqdLFinu7RrFMkREJQXGnQB0M-wRzoH5j4-a1L3WHqzhoTg#/session/1702594702652001JJhD">Transforming AI</a> is a panel featuring Huang and the eight authors of “Attention Is All You Need,” a groundbreaking paper that introduced the <a href="https://blogs.nvidia.com/blog/what-is-a-transformer-model/">transformer</a> neural network architecture.</li>
<li style="font-weight: 300;" aria-level="1"><a href="https://www.nvidia.com/gtc/session-catalog/?search=stanford%20university&amp;search=stanford+university&amp;tab.allsessions=1700692987788001F1cG#/session/1690423197613001jzhz">Fireside Chat With Fei-Fei Li and Bill Dally: The High-Speed Revolution in AI and Managing the Impact on Humanity</a>, featuring Dally, chief scientist and senior vice president of research at NVIDIA, and Li, Sequoia Professor of computer science at Stanford University.</li>
<li style="font-weight: 300;" aria-level="1"><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=bojan#/session/1705548169759001iR7s">Fireside Chat With Christian Szegedy and Bojan Tunguz: Automated Reasoning for More Advanced Software Synthesis and Verification</a>, featuring Szegedy, research scientist and founder of xAI, and Tunguz, data scientist at NVIDIA.</li>
</ul>
<p>See more <a href="https://www.nvidia.com/gtc/sessions/researcher-and-educator/">sessions for researchers</a>.</p>
<h2><b>For Educators</b></h2>
<ul>
<li style="font-weight: 300;" aria-level="1"><a href="https://register.nvidia.com/flow/nvidia/gtcs24/attendeeportaldigital/page/sessioncatalog?tab.allsessions=1700692987788001F1cG&amp;search=s61961">Priming Researchers and Students for AI and Accelerated Computing Breakthroughs With Self-Sustaining Training Programs</a>, featuring Israel Chaparro-Cruz, lecturer and co-investigator from Universidad Nacional Jorge Basadre Grohmann; Mohammad Mostafanejad, lead software scientist at the Molecular Sciences Software Institute at Virginia Tech; and Joe Bungo, <a href="https://www.nvidia.com/en-us/training/">Deep Learning Institute</a> program manager at NVIDIA.</li>
<li style="font-weight: 300;" aria-level="1"><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62100&amp;search=S62100&amp;tab.allsessions=1700692987788001F1cG#/session/1694460530363001n1EI">Learn How Educators Are Integrating Generative AI, Simulation and Design Into Their Curricula</a>, featuring Deepak Chetty, area head for virtual production and assistant professor of practice at the University of Texas, Austin; Barbara Mones, teaching professor in the Paul G. Allen School of Computer Science and Engineering at the University of Washington; and Laura Scholl, senior content developer for the NVIDIA Deep Learning Institute.</li>
<li style="font-weight: 300;" aria-level="1"><a href="https://register.nvidia.com/flow/nvidia/gtcs24/se62199">Omniverse Educator Summit</a>, an opportunity for educators to explore the <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> platform, connect with peers and discover practical resources for classrooms from NVIDIA, including the Deep Learning Institute’s <a href="https://www.nvidia.com/en-us/training/teaching-kits/">Teaching Kits</a> and <a href="https://www.nvidia.com/en-in/deep-learning-ai/education/ambassador-program/">University Ambassador Program</a>. <a href="https://register.nvidia.com/flow/nvidia/gtcs24/se62199">Register</a> to attend.</li>
</ul>
<p>Find more <a href="https://www.nvidia.com/gtc/sessions/researcher-and-educator/">sessions for educators</a>.</p>
<h2><b>For Students</b></h2>
<ul>
<li style="font-weight: 300;" aria-level="1"><a href="https://register.nvidia.com/flow/nvidia/gtcs24/attendeeportaldigital/page/sessioncatalog?tab.allsessions=1700692987788001F1cG&amp;search=s62690">AI Secrets I Wish I Knew</a>, featuring speakers from Stanford University, NVIDIA and education journalism initiative EdSurge.</li>
<li style="font-weight: 300;" aria-level="1"><a href="https://www.nvidia.com/gtc/session-catalog/?search=S61185&amp;tab.allsessions=1700692987788001F1cG#/">NVIDIA Graduate Fellowship Fast Forward Talks</a>, featuring Dally and fellowship recipients from Caltech, Cornell University, Stanford University and UC Berkeley.</li>
<li style="font-weight: 300;" aria-level="1"><a href="https://www.nvidia.com/gtc/session-catalog/?search=SE62899&amp;search=SE62899&amp;tab.allsessions=1700692987788001F1cG#/session/1700283593964001ZX54">Bridging the AI Divide: Expanding Access and Training to Nontraditional Talents and Underserved Communities</a>, featuring speakers from Black Women In Artificial Intelligence, Create Labs, Cortex Innovation District and NVIDIA.</li>
</ul>
<p>Discover more <a href="https://www.nvidia.com/gtc/sessions/student/">sessions for students</a> and apply to join the <a href="https://developer.nvidia.com/student-network">NVIDIA Student Network</a>.</p>
<p>To gain hands-on experience, check out <a href="https://www.nvidia.com/gtc/training/">training labs and full-day technical workshops</a> at GTC.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/GTC_Education.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/GTC_Education-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Head of the Class: Explore AI’s Potential in Higher Education and Research at GTC]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Eco-System Upgrade: AI Plants a Digital Forest at NVIDIA GTC</title>
		<link>https://blogs.nvidia.com/blog/ai-refik-anadol-gtc-2024/</link>
		
		<dc:creator><![CDATA[Heather Schoell]]></dc:creator>
		<pubDate>Mon, 11 Mar 2024 17:17:06 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[NVIDIA DGX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70234</guid>

					<description><![CDATA[The ecosystem around NVIDIA’s technologies has always been verdant — but this is absurd. After a stunning premiere at the World Economic Forum in Davos, immersive artworks based on Refik Anadol Studio’s Large Nature Model will come to the U.S. for the first time at NVIDIA GTC. Offering a deep dive into the synergy between		<a class="read-more" href="https://blogs.nvidia.com/blog/ai-refik-anadol-gtc-2024/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The ecosystem around NVIDIA’s technologies has always been verdant — but this is absurd.</p>
<p>After a stunning premiere at the World Economic Forum in Davos, immersive artworks based on Refik Anadol Studio’s Large Nature Model will come to the U.S. for the first time at <a href="https://www.nvidia.com/gtc/" target="_blank" rel="noopener">NVIDIA GTC</a>.</p>
<p>Offering a deep dive into the synergy between AI and the natural world, Anadol’s multisensory work, “Large Nature Model: A Living Archive,” will be situated prominently on the main concourse of the San Jose Convention Center, where the global AI event is taking place, from March 18-21.</p>
<p>Fueled by NVIDIA’s advanced AI technology, including powerful <a href="https://www.nvidia.com/en-us/data-center/dgx-a100/" target="_blank" rel="noopener">DGX A100</a> stations and high-performance GPUs, the exhibit offers a captivating journey through our planet’s ecosystems with stunning visuals, sounds and scents.</p>
<p>These scenes are rendered in breathtaking clarity across screens with a total output of 12.5 million pixels, immersing attendees in an unprecedented digital portrayal of Earth’s ecosystems.</p>
<p>Refik Anadol, recognized by The Economist as “the artist of the moment,” has emerged as a key figure in AI art. His work, notable for its use of data and machine learning, places him at the forefront of a generation pushing the boundaries between technology, interdisciplinary research and aesthetics. Anadol’s influence reflects a wider movement in the art world towards embracing digital innovation, setting new precedents in how art is created and experienced.</p>
<h2><strong>Exhibition Details</strong></h2>
<ul>
<li><strong>Location</strong>: Main concourse at the San Jose McEnery Convention Center, ensuring easy access for all GTC attendees.</li>
<li><strong>Total experience hours</strong>: Available from 5-7 p.m., providing a curated window to engage with the installation fully.</li>
<li><strong>Screen dimensions</strong>: The installation features two towering screens, each four meters high. The larger, four-by-12-meter screen displays the “Large Nature Model: Living Archive,” showcasing Anadol’s centerpiece. A second, four-by-six-meter screen offers a glimpse into the process of building the Large Nature Model.</li>
</ul>
<h2><strong>A Gateway to Digital Nature</strong></h2>
<p>Large Nature Model is a <a href="https://www.nvidia.com/en-us/glossary/generative-ai/" target="_blank" rel="noopener">generative AI</a> model focused exclusively on nature.</p>
<p>This installation exemplifies AI’s unique potential to capture nature’s inherent intelligence, aiming to redefine our engagement with and appreciation of Earth’s ecosystems.</p>
<p>Anadol has been working with nature-based datasets throughout his career, and began working with rainforest data years ago.</p>
<p>The Large Nature Model, on which the work being shown at GTC is based, continues to evolve. It represents the work of a team of 29 data scientists, graphic designers and AI specialists from around the world, all working under the umbrella of the <a href="https://refikanadolstudio.com/" target="_blank" rel="noopener">Refik Anadol Studio</a>.</p>
<p>The Large Nature Model showcased at GTC is fine-tuned using the Getty Images foundation model built using the <a href="https://www.nvidia.com/en-us/gpu-cloud/picasso/" target="_blank" rel="noopener">NVIDIA Edify architecture</a>. The model is fine-tuned on an extensive dataset of approximately 750,000 images, comprising 274,947 images of flora, 358,713 images of fauna and 130,282 images of fungi — showcasing the rich biodiversity of the Amazonian rainforest.</p>
<h2><strong>Insights Into the Making</strong></h2>
<p>Alongside the visual feast, a <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=refik#/session/1704749437740001oGfB" target="_blank" rel="noopener">panel discussion</a> featuring Anadol and colleagues from the Refik Anadol Studio will provide insights into their research and design processes.</p>
<p>Moderated by Brian Dowdy, a senior technical marketing engineer at NVIDIA, the discussion will explore the collaborative efforts, technical challenges and creative processes that make such pioneering art possible.</p>
<p>The creation of the Large Nature Model represents six months of rigorous development and collaboration with NVIDIA researchers, underscoring the dedication and interdisciplinary effort required to bring this innovative vision to life.</p>
<p><a href="https://www.nvidia.com/gtc/pricing/" target="_blank" rel="noopener">Register for GTC</a> today to join this immersive journey into the heart of nature, art and AI innovation.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/refikanadolgtc.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/refikanadolgtc-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Eco-System Upgrade: AI Plants a Digital Forest at NVIDIA GTC]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI Getting Green Light: City of Raleigh Taps NVIDIA Metropolis to Improve Traffic</title>
		<link>https://blogs.nvidia.com/blog/city-of-raleigh-metropolis-traffic/</link>
		
		<dc:creator><![CDATA[Scott Martin]]></dc:creator>
		<pubDate>Mon, 11 Mar 2024 16:00:06 +0000</pubDate>
				<category><![CDATA[Accelerated Analytics]]></category>
		<category><![CDATA[DeepStream]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[Metropolis]]></category>
		<category><![CDATA[NVIDIA Jetson]]></category>
		<category><![CDATA[TensorRT]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70205</guid>

					<description><![CDATA[You might say that James Alberque has a bird’s-eye view of the road congestion and challenges that come with a booming U.S. city. Alberque analyzes traffic data for Raleigh, North Carolina, which has seen its population more than double in the past three decades. The city has been working with NVIDIA and its partners to		<a class="read-more" href="https://blogs.nvidia.com/blog/city-of-raleigh-metropolis-traffic/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>You might say that James Alberque has a bird’s-eye view of the road congestion and challenges that come with a booming U.S. city.</p>
<p>Alberque analyzes traffic data for Raleigh, North Carolina, which has seen its population more than double in the past three decades. The city has been working with NVIDIA and its partners to analyze traffic on the roads and intersections to help reduce congestion and enhance pedestrian safety.</p>
<p>“We can now push traffic video into the <a href="https://developer.nvidia.com/deepstream-sdk">NVIDIA DeepStream</a> platform and can quantify in real time how many vehicles are entering and exiting intersections and visualize it for our engineers,” said Alberque, a geoinformation systems and emerging technology manager for the city.</p>
<p>Such information can be fed to vendors responsible for keeping traffic lights optimized, so population expansion doesn’t bring roadways to a crawl or increase the number of accidents.</p>
<p>Urban growth has slowed commutes as metropolitan regions across the nation turn to AI for assistance in optimizing traffic flow.</p>
<p>“We got great accuracy level using NVIDIA pre-trained AI computer vision models for traffic cameras right out of the box,” said Alberque. “And our engineers worked with an NVIDIA Metropolis partner, Quantiphi, to refine those models and got them up to an incredible 95% accuracy,” said Alberque.</p>
<p>The Raleigh system uses hundreds of cameras to enhance its model training, and the city has its sights set on everything from road flooding, license plate tracking and parking utilization to bus stop wait times and sanitation management.</p>
<h2><b>Federal Initiatives Support Intersection Safety</b></h2>
<p>Advances from the city of Raleigh and others looking to <a href="https://blogs.nvidia.com/blog/cvedia-ai-intersects-u-s-traffic-lights-better-flow-safety/">smooth the flow of traffic</a> come as the U.S. Department of Transportation continues to support AI efforts.</p>
<p>The DOT recently <a href="https://www.transportation.gov/briefing-room/us-dot-announces-winners-intersection-safety-challenge">announced winners</a> of the first phase of its <a href="https://its.dot.gov/isc/">Intersection Safety Challenge</a>, which aims to support innovation in intersection safety. Three of the DOT’s winning entrants are harnessing <a href="https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/">NVIDIA Metropolis</a> for smart intersections.</p>
<p>In this first stage, 15 participants who submitted design concept proposals for intersection safety systems out of 120 submissions were awarded $100,000 each and an invitation to participate further.</p>
<p>The next stage will focus on system assessment and virtual testing, with teams expected to develop, train and improve algorithms used for detection, localization and classification of vehicles and road users in a controlled test intersection.</p>
<h2><b>Enlisting NVIDIA AI for Smart Intersections</b></h2>
<p><a href="https://www2.deloitte.com/us/en/services/consulting.html?icid=top_consulting">Deloitte Consulting</a> is building a foundation for smart intersections, enlisting the NVIDIA Metropolis application framework, developer tools and partner ecosystem.</p>
<p><a href="https://en.derq.com/">Derq USA</a> is developing an intersection safety system that relies on NVIDIA Metropolis to help manage the deluge of sensor data for insights.</p>
<p>Metropolis partner, <a href="https://miovision.com/">Miovision</a>, which has traffic light safety systems deployed across the U.S., uses the <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/">NVIDIA Jetson edge AI platform</a> in its devices for processing video and <a href="https://developer.nvidia.com/tensorrt-getting-started">TensorRT</a> for inference.</p>
<p>“There are so many people moving into our city and surrounding areas, and our number one and number two concerns for citizens are around traffic — this is providing data to move the needle,” said Alberque, regarding Raleigh’s Metropolis and DeepStream development.</p>
<p>&nbsp;</p>
<p><a href="https://www.nvidia.com/gtc/?ncid=GTC-NVPK75EY"><i>Register for GTC24</i></a><i> to discover how AI is transforming smart cities. Some key sessions include: </i><i></i></p>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62372"><i>S62372 &#8211; Overcoming London’s Commuting Conditions With Computer Vision</i></a><i> &#8211; Vivacity</i></li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62436"><i>S62436 &#8211; Harnessing Computer Vision and Traffic Cameras for Urban Traffic Monitoring</i></a><i> &#8211; Quantiphi &amp; City of Raleigh</i></li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62402&amp;tab.allsessions=1700692987788001F1cG#/"><i>S62402 &#8211; How Cities and DOTs Can Implement Road Safety Technologies</i></a><i> &#8211; Derq &amp; Seattle Dept. of Transportation</i></li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62382"><i>[S62382] Paving the Way for a Safer, Smarter Future in Transportation</i></a><i> &#8211; Deloitte</i></li>
</ul>
<p><i></i><br />
<i>Explore more smart traffic solutions powered by NVIDIA Metropolis in this </i><a href="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fresources.nvidia.com%2Fen-us-smart-spaces&amp;data=05%7C02%7Cscmartin%40nvidia.com%7C5f248c24ad044462710108dc28fd7478%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638430316266963304%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=Nu7Nt6aJQh9rHARZ6iuWbvQaCUf6WuCNJUS3wNbjLZE%3D&amp;reserved=0"><i>Smart Roadways eBook</i></a><i>.</i></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/TrafficLight.jpg"
			type="image/jpeg"
			width="1183"
			height="766"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/TrafficLight-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI Getting Green Light: City of Raleigh Taps NVIDIA Metropolis to Improve Traffic]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>LLMs Land on Laptops: NVIDIA, HP CEOs Celebrate AI PCs</title>
		<link>https://blogs.nvidia.com/blog/llms-hp-laptops/</link>
		
		<dc:creator><![CDATA[Allen Bourgoyne]]></dc:creator>
		<pubDate>Thu, 07 Mar 2024 20:25:40 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Data Science]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[generative AI]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Mobile]]></category>
		<category><![CDATA[NGC]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[RTX Mobile Workstations]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70210</guid>

					<description><![CDATA[2024 will be the year generative AI gets personal, the CEOs of NVIDIA and HP said today in a fireside chat, unveiling new laptops that can build, test and run large language models. “This is a renaissance of the personal computer,” said NVIDIA founder and CEO Jensen Huang at HP Amplify, a gathering in Las		<a class="read-more" href="https://blogs.nvidia.com/blog/llms-hp-laptops/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>2024 will be the year generative AI gets personal, the CEOs of NVIDIA and HP said today in a fireside chat, unveiling new laptops that can build, test and run large language models.</p>
<p>“This is a renaissance of the personal computer,” said NVIDIA founder and CEO Jensen Huang at HP Amplify, a gathering in Las Vegas of about 1,500 resellers and distributors. “The work of creators, designers and data scientists is going to be revolutionized by these new workstations.”</p>
<p>“AI is the biggest thing to come to the PC in decades,” said HP’s Enrique Lores, in the runup to the announcement of what his company billed as “the industry’s largest portfolio of AI PCs and workstations.”</p>
<h2><b>Greater Speed and Security</b></h2>
<p>Compared to running their AI work in the cloud, the new systems will provide increased speed and security while reducing costs and energy, Lores said in a keynote at the event.</p>
<p>New HP ZBooks provide a portfolio of mobile AI workstations powered by a full range of <a href="https://www.nvidia.com/en-us/geforce/ada-lovelace-architecture/">NVIDIA RTX Ada Generation GPUs</a>.</p>
<p>Entry-level systems with the NVIDIA RTX 500 Ada Generation Laptop GPU let users run generative AI apps and tools wherever they go.</p>
<p>High-end models pack the RTX 5000 to deliver up to 682 TOPS, so they can create and run LLMs locally, using retrieval-augmented generation (<a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">RAG</a>) to connect to their content for results that are both personalized and private.</p>
<h2><b>Access to Accelerated Software</b></h2>
<p>The new workstations can tap into NVIDIA’s full-stack AI platform, including software that speeds the data science at the foundation of generative AI.</p>
<p>The systems’ Z by HP AI Studio platform — developed in collaboration with NVIDIA — links to <a href="https://catalog.ngc.nvidia.com/">NVIDIA NGC</a>, a catalog of GPU-accelerated software for AI and data science. NGC includes <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/">NVIDIA NeMo</a>, a framework to build, customize and deploy generative AI models.</p>
<p>In addition, HP and NVIDIA <a href="https://press.hp.com/us/en/press-releases/2024/hp-unveils-largest-portfolio-ai-pc.html">announced</a> that <a href="https://www.nvidia.com/en-us/technologies/cuda-x/">NVIDIA CUDA-X</a> libraries will be integrated with the systems to turbocharge the data preparation and processing that’s fundamental for generative AI.</p>
<h2><b>Speedups for Data Scientists</b></h2>
<p>The libraries include <a href="https://developer.nvidia.com/rapids">NVIDIA RAPIDS cuDF</a>, which accelerates pandas, software used by nearly 10 million data scientists.</p>
<p>“It used to take them hours and sometimes days to process data that now they can do in minutes,” Huang said.</p>
<p>“This pandas library is insanely complex,” he added, noting NVIDIA engineers worked for more than five years on reformulating the code so it can be accelerated with GPUs.</p>
<h2><b>Entering a New Era</b></h2>
<p>In tandem with the new systems, HP announced a partner training program developed in collaboration with NVIDIA. It will equip computer vendors to advise customers on the right AI products and solutions to meet their needs.</p>
<p>Such programs pave the way for an industry that’s entering an era where AI lets software write software.</p>
<p>“We’ve reinvented the computer. We’ve reinvented how software is written, and now we have to reinvent how software is used,” said Huang. “Large language models, connected into other LLMs, will help solve application problems — that’s the future.”</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/Huang-and-Lores-at-HP-Amplify-x-1280HP.jpg"
			type="image/jpeg"
			width="1451"
			height="769"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/Huang-and-Lores-at-HP-Amplify-x-1280HP-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[LLMs Land on Laptops: NVIDIA, HP CEOs Celebrate AI PCs]]></media:title>
			<media:description type="html">NVIDIA, HP CEOs at HP Amplify</media:description>
			</media:content>
			</item>
		<item>
		<title>First Class: NVIDIA Introduces Generative AI Professional Certification</title>
		<link>https://blogs.nvidia.com/blog/generative-ai-professional-certification/</link>
		
		<dc:creator><![CDATA[Craig Clawson]]></dc:creator>
		<pubDate>Thu, 07 Mar 2024 17:02:33 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Deep Learning Institute]]></category>
		<category><![CDATA[generative AI]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70154</guid>

					<description><![CDATA[NVIDIA is offering a new professional certification in generative AI to enable developers to establish technical credibility in this important domain. Generative AI is revolutionizing industries worldwide, yet there’s a critical skills gap and need to uplevel employees to more fully harness the technology. Available for the first time from NVIDIA, this new professional certification		<a class="read-more" href="https://blogs.nvidia.com/blog/generative-ai-professional-certification/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>NVIDIA is offering a new professional certification in generative AI to enable developers to establish technical credibility in this important domain.</p>
<p>Generative AI is revolutionizing industries worldwide, yet there’s a critical skills gap and need to uplevel employees to more fully harness the technology.</p>
<p>Available for the first time from NVIDIA, this new professional certification enables developers, career professionals, and others to validate and showcase their generative AI skills and expertise. Our new professional certification program introduces two associate-level generative AI certifications, focusing on proficiency in large language models and multimodal workflow skills.</p>
<p>“Generative AI has moved to center stage as governments, industries and organizations everywhere look to harness its transformative capabilities,” NVIDIA founder and CEO Jensen Huang recently said.</p>
<p>The certification will become available starting at GTC, where in-person attendees can also access recommended training to prepare for a certification exam.</p>
<p>“Organizations in every industry need to increase their expertise in this transformative technology,” said Greg Estes, VP of developer programs at NVIDIA. “Our goals are to assist in upskilling workforces, sharpen the skills of qualified professionals, and enable individuals to demonstrate their proficiency in order to gain a competitive advantage in the job market.”</p>
<h2><b>See AI’s Future. Learn How to Use It.  </b></h2>
<p>GTC 2024 — running March 18-21 in San Jose, Calif. — is the first in-person GTC event in five years, and more than 300,000 people are expected to register to attend in person or virtually.  There will be 900 sessions and more than 300 exhibitors showcasing how organizations are deploying NVIDIA platforms to achieve industry breakthroughs.</p>
<p>Attendees can choose from 20 full-day, hands-on <a href="https://www.nvidia.com/gtc/training/?ncid=prsy-896405">technical workshops</a>, with many sessions available virtually in EMEA and APAC time zones. Also, sign up for the GTC Conference + Training package for more than 40 complimentary onsite training labs.</p>
<p><a href="https://www.nvidia.com/gtc/"><i>Sign up</i></a><i> for GTC . Learn more about the generative AI course </i><a href="https://www.nvidia.com/en-us/training/instructor-led-workshops/generative-ai-with-diffusion-models/"><i>here</i></a><i> and </i><a href="https://www.nvidia.com/en-us/learn/certification/generative-ai-llm-associate/"><i>here</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/nvt-general-AI-certification-no-copy-social-1200x675-1.jpg"
			type="image/jpeg"
			width="1200"
			height="675"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/nvt-general-AI-certification-no-copy-social-1200x675-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[First Class: NVIDIA Introduces Generative AI Professional Certification]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Don’t Pass This Up: Day Passes Now Available on GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-day-pass-cygames/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 07 Mar 2024 14:00:51 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70190</guid>

					<description><![CDATA[Gamers can now seize the day with Day Passes, available to purchase for 24-hour continuous access to powerful cloud gaming with all the benefits of a GeForce NOW Ultimate or Priority membership — no commitment required. Publisher Cygames brings its next triple-A title to the cloud. Granblue Fantasy: Relink leads eight new games joining the		<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-day-pass-cygames/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Gamers can now seize the day with Day Passes, available to purchase for 24-hour continuous access to powerful cloud gaming with all the benefits of a GeForce NOW Ultimate or Priority membership — no commitment required.</p>
<p>Publisher Cygames brings its next triple-A title to the cloud. <i>Granblue Fantasy: Relink</i> leads eight new games joining the <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> library this week.</p>
<p>Plus, an update for GeForce NOW Windows and macOS adds support for <a href="https://nvidia.custhelp.com/app/answers/detail/a_id/5504">G-SYNC in the cloud</a>. By pairing it with new <a href="https://www.nvidia.com/en-us/geforce/technologies/reflex/">NVIDIA Reflex</a> support for 60 and 120 frames per second streaming options, Ultimate members can experience ultra-low-latency streaming that’s nearly indistinguishable from using a local PC.</p>
<h2><b>Seize the Day</b></h2>
<p>Day Passes offer access to 24 hours of <a href="https://www.nvidia.com/en-us/geforce/rtx/">GeForce RTX</a>-powered cloud gaming. Users can get all the benefits of <a href="https://www.nvidia.com/en-us/geforce-now/memberships/">Ultimate and Priority memberships</a> for a day without committing to longer-term monthly memberships, and choose how and when they access the cloud.</p>
<figure id="attachment_70194" aria-describedby="caption-attachment-70194" style="width: 605px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-70194" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Day_Pass-605x500.png" alt="Day Pass Matrix on GeForce NOW" width="605" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Day_Pass-605x500.png 605w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Day_Pass-400x331.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Day_Pass-768x635.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Day_Pass-544x450.png 544w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Day_Pass-260x215.png 260w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Day_Pass-121x100.png 121w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Day_Pass-1280x1058.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Day_Pass.png 1512w" sizes="(max-width: 605px) 100vw, 605px" /><figcaption id="caption-attachment-70194" class="wp-caption-text"><em>Play for a day.</em></figcaption></figure>
<p>Ultimate Day Pass users can stream at either 4K 120 fps, up to 240 fps, or with ultrawide resolutions. Plus, they can get all the same benefits as gamers using NVIDIA GeForce RTX 40 Series GPUs, with access to <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">NVIDIA DLSS 3</a> and NVIDIA Reflex technologies for the smoothest gameplay and lowest latency, even on underpowered devices. Both Ultimate and Priority Day Pass users can turn <a href="https://www.nvidia.com/en-us/geforce/rtx/">RTX ON</a> in supported games for immersive, cinematic gameplay.</p>
<p>The Ultimate Day Pass is available for $7.99 and the Priority Day Pass for $3.99. Twenty-four hours of continuous play begins at purchase. Day Passes are available in limited quantities each day, so grab one before the opportunity passes.</p>
<h2><b>Head in the Clouds</b></h2>
<figure id="attachment_70197" aria-describedby="caption-attachment-70197" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-70197" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Granblue_Fantasy_Relink-672x336.jpg" alt="Granblue Fantasy: Relink on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Granblue_Fantasy_Relink-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Granblue_Fantasy_Relink-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Granblue_Fantasy_Relink-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Granblue_Fantasy_Relink-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Granblue_Fantasy_Relink-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Granblue_Fantasy_Relink-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Granblue_Fantasy_Relink-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Granblue_Fantasy_Relink-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Granblue_Fantasy_Relink.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70197" class="wp-caption-text"><em>Going on a grand adventure.</em></figcaption></figure>
<p>Cygames, known for developing popular online game <i>Granblue Fantasy, </i>brings their full-fledged action role-playing game to GeForce NOW. <i>Granblue Fantasy: Relink</i> is now available for fans to stream across devices.</p>
<p>Set in the same universe as the web browser and mobile version of the title<i>, Granblue Fantasy: Relink</i> is an ARPG that features many of the beloved characters from the franchise in an all-new original story. Step into the shoes of a captain leading a Skyfaring crew, alongside a scrappy dragon named Vyrn and a mysterious girl named Lyria, as they navigate the Sky Realm, a world of islands drifting in the clouds.</p>
<p>Slash, shoot and hex treacherous foes with up to three other gaming buddies. GeForce NOW Priority and Ultimate members can become Skyfarers in the cloud with longer game sessions and faster access to GeForce RTX-class servers.</p>
<h2><b>Spring Into New Games</b></h2>
<figure id="attachment_70200" aria-describedby="caption-attachment-70200" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-70200" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Undisputed-672x336.jpg" alt="Undisputed on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Undisputed-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Undisputed-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Undisputed-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Undisputed-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Undisputed-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Undisputed-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Undisputed-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Undisputed-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Undisputed.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70200" class="wp-caption-text"><em>Pull no punches.</em></figcaption></figure>
<p>Step into the ring in <i>Undisputed</i>, an authentic boxing game from Steel City Interactive. Featuring bone-jarring action and more licensed boxers than ever, <i>Undisputed</i>, currently in early access<i>, </i>gives members unprecedented control to master every inch of the ring.</p>
<p>It’s available to stream from the cloud this week, along with the following games:</p>
<ul>
<li><i>The Thaumaturge</i> (New release on <a href="https://store.steampowered.com/app/1684350?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 4)</li>
<li><i>Classified: France ‘44 </i>(New release on <a href="https://store.steampowered.com/app/2085370?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 5)</li>
<li><i>Expeditions: A MudRunner Game </i>(New release on <a href="https://store.steampowered.com/app/2477340?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 5)</li>
<li><i>Winter Survival </i>(New release on <a href="https://store.steampowered.com/app/1394960?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 6)</li>
<li><i>Taxi Life: A City Driving Simulator </i>(New release on <a href="https://store.steampowered.com/app/1351240?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 7)</li>
<li><i>Zoria: Age of Shattering</i> (New release on <a href="https://store.steampowered.com/app/1159090?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 7)</li>
<li><i>Granblue Fantasy: Relink </i>(<a href="https://store.steampowered.com/app/881020?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Undisputed</i> (<a href="https://store.steampowered.com/app/1451190?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">One 𝘿𝙖𝙮 more&#8230; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/2600.png" alt="☀" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1765422088284782946?ref_src=twsrc%5Etfw">March 6, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/gfn-thursday-3-7-nv-blog-1280x680-no-cta.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/gfn-thursday-3-7-nv-blog-1280x680-no-cta-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Don’t Pass This Up: Day Passes Now Available on GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Bria Builds Responsible Generative AI for Enterprises Using NVIDIA NeMo, Picasso</title>
		<link>https://blogs.nvidia.com/blog/bria-builds-responsible-generative-ai-using-nemo-picasso/</link>
		
		<dc:creator><![CDATA[Arham Mehta]]></dc:creator>
		<pubDate>Wed, 06 Mar 2024 16:00:52 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cloud Services]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[Media and Entertainment]]></category>
		<category><![CDATA[Retail]]></category>
		<category><![CDATA[Trustworthy AI]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70173</guid>

					<description><![CDATA[As visual generative AI matures from research to the enterprise domain, businesses are seeking responsible ways to integrate the technology into their products. Bria, a startup based in Tel Aviv, is responding with an open platform for visual generative AI that emphasizes model transparency alongside fair attribution and copyright protections. Currently offering models that convert		<a class="read-more" href="https://blogs.nvidia.com/blog/bria-builds-responsible-generative-ai-using-nemo-picasso/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>As visual generative AI matures from research to the enterprise domain, businesses are seeking responsible ways to integrate the technology into their products.</p>
<p>Bria, a startup based in Tel Aviv, is responding with an open platform for visual generative AI that emphasizes model transparency alongside fair attribution and copyright protections. Currently offering models that convert text prompts to images or transform existing images, the company will this year add text-to-video and image-to-video AI.</p>
<p>“Creating generative AI models requires time and expertise,” said Yair Adato, co-founder and CEO of Bria. “We do the heavy lifting so product teams can adopt our models to achieve a technical edge and go to market quickly, without investing as many resources.”</p>
<p>Advertising agencies and retailers can use Bria’s tools to quickly generate visuals for marketing campaigns. And creative studios can adopt the models to develop stock imagery or edit visuals. Dozens of enterprise clients have integrated the startup’s pretrained models or use its application programming interfaces.</p>
<p>Bria develops its models with the <a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/index.html">NVIDIA NeMo</a> framework, which is <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nemo/tags">available on NGC</a>, NVIDIA’s hub for accelerated software. The company uses reference implementations from the <a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/multimodalmodels/index.html">NeMo Multimodal</a> collection, trained on <a href="https://www.nvidia.com/en-us/data-center/tensor-cores/">NVIDIA Tensor Core GPUs</a>, to enable high-throughput, low-latency image generation. It’s also adopting <a href="https://www.nvidia.com/en-us/gpu-cloud/picasso/">NVIDIA Picasso</a>, a foundry for visual generative AI models, to run inference.</p>
<p>“We were looking for a framework to train our models efficiently — one that would minimize compute cost while scaling AI training to more quickly reach model convergence,” said Misha Feinstein, vice president of research and development at Bria. “NeMo features optimization techniques that allow us to maximize the GPUs’ performance during both training and inference.”</p>
<h2><b>Creative Solutions to Creative Challenges</b></h2>
<p>Bria, founded in 2020, offers flexible options for enterprises adopting visual generative AI. By adopting Bria’s platform, its customers can gain a competitive edge by creating visual content at scale while retaining control of their data and technology. Developers can access its pretrained models through APIs or by directly licensing the source code and model weights for further fine-tuning.</p>
<p>“We want to build a company where we respect privacy, content ownership, data ownership and copyright,” said Adato. “To create a healthy, sustainable industry, it’s important to incentivize individuals to keep creating and innovating.”</p>
<p>Adato likens Bria’s <a href="https://bria.ai/fair-diffusion/">attribution program</a> to a music streaming service that pays artists each time one of their songs is played. It’s required for all customers who use Bria’s models — even if they further train and fine-tune the model on their own.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-large wp-image-70178" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-2-672x336.png" alt="" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-2-672x336.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-2-400x200.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-2-768x384.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-2-1536x768.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-2-842x421.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-2-406x203.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-2-188x94.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-2-1280x640.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-2.png 1920w" sizes="(max-width: 672px) 100vw, 672px" /></p>
<p>Using licensed datasets provides additional benefits: the Bria team doesn’t need to spend time cleaning the data or sorting out inappropriate content and misinformation.</p>
<h2><b>A Growing Suite of NVIDIA-Accelerated Models</b></h2>
<p>Bria offers two versions of its text-to-image model. One is latency-optimized to rapidly accomplish tasks like image background generation. The other offers higher image resolution. Additional foundation models enable super-resolution, object removal, object generation, inpainting and outpainting.</p>
<p>The company is working to continuously increase the resolution of its generated images, further reduce latency and develop domain-specific models for industries such as ecommerce and stock imagery. Inference is accelerated by the <a href="https://developer.nvidia.com/triton-inference-server">NVIDIA Triton Inference Server</a> software and the <a href="https://developer.nvidia.com/tensorrt">NVIDIA TensorRT</a> software development kit.</p>
<p>“We’re running on NVIDIA frameworks, hardware and software,” said Feinstein. “NVIDIA experts have helped us optimize these tools for our needs — we would probably run much slower without their help.”</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-large wp-image-70181" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-1-672x419.png" alt="" width="672" height="419" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-1-672x419.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-1-400x250.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-1-768x479.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-1-1536x958.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-1-721x450.png 721w, https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-1-345x215.png 345w, https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-1-160x100.png 160w, https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-1-1280x799.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/BRIA-AI-1.png 1920w" sizes="(max-width: 672px) 100vw, 672px" /></p>
<p>To keep up with the latest hardware and networking infrastructure, Bria uses cloud computing resources: <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100 Tensor Core GPUs</a> for AI training and a variety of <a href="https://www.nvidia.com/en-us/data-center/tensor-cores/">NVIDIA Tensor Core GPUs</a> for inference.</p>
<p>Bria is a member of <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a>, a program that provides startups with technological support and AI platform guidance. Visit Bria in the Inception Pavilion at <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>, running March 18-21 in San Jose and online.</p>
<p>To train optimized text-to-image models, check out the NeMo Multimodal <a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/multimodalmodels/index.html">user guide</a> and <a href="https://github.com/NVIDIA/NeMo/tree/main/examples/multimodal" target="_blank" rel="noopener">GitHub repository</a>. NeMo Multimodal is also available as part of the <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nemo">NeMo container on NGC</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/Bria_Blog_banner.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/Bria_Blog_banner-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Bria Builds Responsible Generative AI for Enterprises Using NVIDIA NeMo, Picasso]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI Decoded: Demystifying AI and the Hardware, Software and Tools That Power It</title>
		<link>https://blogs.nvidia.com/blog/ai-decoded-rtx-pc/</link>
		
		<dc:creator><![CDATA[Jesse Clayton]]></dc:creator>
		<pubDate>Wed, 06 Mar 2024 14:00:30 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Mobile]]></category>
		<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[AI Decoded]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Chat with RTX]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70162</guid>

					<description><![CDATA[With the 2018 launch of RTX technologies and the first consumer GPU built for AI — GeForce RTX — NVIDIA accelerated the shift to AI computing. Since then, AI on RTX PCs and workstations has grown into a thriving ecosystem with more than 100 million users and 500 AI applications. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>With the 2018 launch of <a href="https://www.nvidia.com/en-us/geforce/rtx/">RTX technologies</a> and the first consumer GPU built for AI — GeForce RTX — NVIDIA accelerated the shift to AI computing. Since then, <a href="https://www.nvidia.com/en-us/ai-on-rtx/">AI on RTX PCs and workstations</a> has grown into a thriving ecosystem with more than 100 million users and 500 AI applications.</p>
<p>Generative AI is now ushering in a new wave of capabilities from PC to cloud. And <a href="https://www.nvidia.com/en-us/about-nvidia/i-am-ai/">NVIDIA’s rich history and expertise in AI</a> is helping ensure all users have the performance to handle a wide range of AI features.</p>
<p>Users at home and in the office are already taking advantage of AI on RTX with productivity- and entertainment-enhancing software. Gamers feel the benefits of AI on <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/">GeForce RTX GPUs</a> with higher frame rates at stunning resolutions in their favorite titles. Creators can focus on creativity, instead of watching spinning wheels or repeating mundane tasks. And developers can streamline workflows using generative AI for prototyping and to automate debugging.</p>
<p>The field of AI is moving fast. As research advances, AI will tackle more complex tasks. And the demanding performance needs will be handled by RTX.</p>
<h2><b>What Is AI?</b></h2>
<p>In its most fundamental form, <a href="https://blogs.nvidia.com/blog/what-is-ai-computing/#:~:text=AI%20computing%20is%20the%20work,Email0">artificial intelligence</a> is a smarter type of computing. It’s the capability of a computer program or a machine to think, learn and take actions without being explicitly coded with commands to do so, or a user having to control each command.</p>
<p>AI can be thought of as the ability for a device to perform tasks autonomously, by ingesting and analyzing enormous amounts of data, then recognizing patterns in that data — often referred to as being “trained.”</p>
<p>AI development is always oriented around developing systems that perform tasks that would otherwise require human intelligence, and often significant levels of input, to complete — only at speeds beyond any individual’s or group’s capabilities. For this reason, AI is broadly seen as both disruptive and highly transformational.</p>
<p>A key benefit of AI systems is the ability to learn from experiences or patterns inside data, adjusting conclusions on their own when fed new inputs or data. This self-learning allows AI systems to accomplish a stunning variety of tasks, including image recognition, speech recognition, language translation, medical diagnostics, car navigation, image and video enhancement, and hundreds of other use cases.</p>
<p>The next step in the evolution of AI is content generation — referred to as <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a>. It enables users to quickly create new content, and iterate on it, based on a variety of inputs, which can include text, images, sounds, animation, 3D models or other types of data. It then generates new content in the same or a new form.</p>
<p>Popular language applications, like the cloud-based ChatGPT, allow users to generate long-form copy based on a short text request. Image generators like Stable Diffusion turn descriptive text inputs into the desired image. New applications are turning text into video and 2D images into 3D renderings.</p>
<h2><b>GeForce RTX AI PCs and NVIDIA RTX Workstations</b></h2>
<p>AI PCs are computers with dedicated hardware designed to help AI run faster. It’s the difference between sitting around waiting for a 3D image to load, and seeing it update instantaneously with an AI denoiser.</p>
<p><iframe loading="lazy" title="NVIDIA Studio | Arnold for Maya" width="500" height="281" src="https://www.youtube.com/embed/N5PBActlYJw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>On RTX GPUs, these specialized AI accelerators are called <a href="https://nvidianews.nvidia.com/news/generative-ai-rtx-pcs-and-workstations#:~:text=NVIDIA%20RTX%20GPUs%20%E2%80%94%20capable%20of,applications%20for%20work%20and%20play.">Tensor Cores</a>. And they dramatically speed up AI performance across the most demanding applications for work and play.</p>
<p>One way that AI performance is measured is in teraops, or trillion operations per second (TOPS). Similar to an engine’s horsepower rating, TOPS can give users a sense of a PC’s AI performance with a single metric. The current generation of GeForce RTX GPUs offers performance options that range from roughly 200 AI TOPS all the way to over 1,300 TOPS, with many options across laptops and desktops in between. Professionals get even higher AI performance with the <a href="https://www.nvidia.com/en-us/design-visualization/rtx-6000/">NVIDIA RTX 6000 Ada Generation GPU</a>.</p>
<p>To put this in perspective, the current generation of AI PCs without GPUs range from 10 to 45 TOPS.</p>
<p>More and more types of AI applications will require the benefits of having a PC capable of performing certain AI tasks locally — meaning on the device rather than running in the cloud. Benefits of running on an AI PC include that computing is always available, even without an internet connection; systems offer low latency for high responsiveness; and increased privacy so that users don’t have to upload sensitive materials to an online database before it becomes usable by an AI.</p>
<h2><b>AI for Everyone</b></h2>
<p>RTX GPUs bring more than just performance. They introduce capabilities only possible with RTX technology. Many of these AI features are accessible — and impactful — to millions, regardless of the individual’s skill level.</p>
<p>From AI upscaling to improved video conferencing to intelligent, personalizable chatbots, there are tools to benefit all types of users.</p>
<p><iframe loading="lazy" title="Introducing RTX Video HDR: AI-Upscale Video to HDR Quality" width="500" height="281" src="https://www.youtube.com/embed/FHAjydnpos8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p><a href="https://blogs.nvidia.com/blog/rtx-video-hdr-remix-studio-driver/">RTX Video</a> uses AI to upscale streaming video and display it in HDR. Bringing lower-resolution video in standard dynamic range to vivid, up to 4K high-resolution high dynamic range. RTX users can enjoy the feature with one-time, one-click enablement on nearly any video streamed in a Chrome or Edge browser.</p>
<p><iframe loading="lazy" title="NVIDIA Broadcast 1.4 Update Featuring Eye Contact" width="500" height="281" src="https://www.youtube.com/embed/nR-vP_7XFHE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p><a href="https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/">NVIDIA Broadcast</a>, a free app for RTX users with a straightforward user interface, has a host of AI features that improve video conferencing and livestreaming. It removes unwanted background sounds like clicky keyboards, vacuum cleaners and screaming children with Noise and Echo Removal. It can replace or blur backgrounds with better edge detection using Virtual Background. It smooths low-quality camera images with Video Noise Removal. And it can stay centered on the screen with eyes looking at the camera no matter where the user moves, using Auto Frame and Eye Contact.</p>
<p><a href="https://blogs.nvidia.com/blog/chat-with-rtx-available-now/">Chat with RTX</a> is a local, personalized AI chatbot demo that’s easy to use and <a href="https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/">free to download</a>.</p>
<figure id="attachment_70166" aria-describedby="caption-attachment-70166" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/03/Chat-with-RTX.png"><img loading="lazy" decoding="async" class="size-large wp-image-70166" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/Chat-with-RTX-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/Chat-with-RTX-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Chat-with-RTX-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Chat-with-RTX-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Chat-with-RTX-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Chat-with-RTX-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Chat-with-RTX-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Chat-with-RTX-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Chat-with-RTX-1280x720.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Chat-with-RTX.png 1999w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-70166" class="wp-caption-text">The tech demo, originally released in January, will get an update with Google’s Gemma soon.</figcaption></figure>
<p>Users can easily connect local files on a PC to a supported large language model simply by dropping files into a single folder and pointing the demo to the location. It enables queries for quick, contextually relevant answers.</p>
<p>Since Chat with RTX runs locally on Windows with GeForce RTX PCs and <a href="https://www.nvidia.com/en-us/design-visualization/workstations/">NVIDIA RTX workstations</a>, results are fast — and the user’s data stays on the device. Rather than relying on cloud-based services, Chat with RTX lets users process sensitive data on a local PC without the need to share it with a third party or have an internet connection.</p>
<h2><b>AI for Gamers</b></h2>
<p>Over the past six years, game performance has seen the greatest leaps with AI acceleration. Gamers have been turning <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">NVIDIA DLSS</a> on since 2019, boosting frame rates and improving image quality. It’s a technique that uses AI to generate pixels in video games automatically. With ongoing improvements, it now increases frame rates by up to 4x.</p>
<p><iframe loading="lazy" title="NVIDIA DLSS 3.5 | New Ray Reconstruction Enhances Ray Tracing with AI" width="500" height="281" src="https://www.youtube.com/embed/sGKCrcNsVzo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>And with the introduction of Ray Reconstruction in the latest version, DLSS 3.5, visual quality is further enhanced in some of the world’s top titles, setting a new standard for visually richer and more immersive gameplay.</p>
<p>There are now over 500 games and applications that have revolutionized the ways people play and create with ray tracing, DLSS and AI-powered technologies.</p>
<p>Beyond frames, AI is set to improve the way gamers interact with characters and remaster classic games.</p>
<p><iframe loading="lazy" title="NVIDIA ACE Brings Digital Characters to Life with Generative AI ft. Convai" width="500" height="281" src="https://www.youtube.com/embed/psrXGPh80UM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p><a href="https://nvidianews.nvidia.com/news/ace-avatar-cloud-engine-microservices">NVIDIA ACE microservices</a> — including generative AI-powered speech and animation models — are enabling developers to add intelligent, dynamic digital avatars to games. Demonstrated at CES, ACE won multiple awards for its ability to bring game characters to life as a glimpse into the future of PC gaming.</p>
<p><a href="https://www.nvidia.com/en-us/geforce/rtx-remix/">NVIDIA RTX Remix</a>, a platform for modders to create stunning RTX remasters of classic games, delivers generative AI tools that can transform basic textures from classic games into modern, 4K-resolution, physically based rendering materials. Several projects have already been released or are in the works, including <i>Half-Life 2 RTX</i> and <i>Portal with RTX</i>.</p>
<h2><b>AI for Creators</b></h2>
<p>AI is unlocking creative potential by reducing or automating tedious tasks, freeing up time for pure creativity. These features run fastest or solely on PCs with NVIDIA RTX or GeForce RTX GPUs.</p>
<figure id="attachment_70169" aria-describedby="caption-attachment-70169" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/03/Adobe-enhance-speech.png"><img loading="lazy" decoding="async" class="size-large wp-image-70169" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/Adobe-enhance-speech-672x445.png" alt="" width="672" height="445" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/Adobe-enhance-speech-672x445.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Adobe-enhance-speech-400x265.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Adobe-enhance-speech-768x508.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Adobe-enhance-speech-1536x1017.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Adobe-enhance-speech-680x450.png 680w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Adobe-enhance-speech-325x215.png 325w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Adobe-enhance-speech-151x100.png 151w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Adobe-enhance-speech-1280x847.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Adobe-enhance-speech.png 1999w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-70169" class="wp-caption-text">Adobe Premiere Pro’s AI-powered Enhance Speech tool removes unwanted noise and improves dialogue quality.</figcaption></figure>
<p>Adobe Premiere Pro’s <a href="https://blogs.nvidia.com/blog/studio-driver-app-rtx-ai-adobe-premiere-pro/">Enhance Speech tool is accelerated by RTX</a>, using AI to remove unwanted noise and improve the quality of dialogue clips so they sound professionally recorded. It’s up to 4.5x faster on RTX vs. Mac. Another Premiere feature, Auto Reframe, uses GPU acceleration to identify and track the most relevant elements in a video and intelligently reframes video content for different aspect ratios.</p>
<p><iframe loading="lazy" title="The DaVinci Resolve Effect I&#039;ve been Waiting For!" width="500" height="281" src="https://www.youtube.com/embed/NM6PGGXiBeE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Another time-saving AI feature for video editors is DaVinci Resolve’s Magic Mask. Previously, if editors needed to adjust the color/brightness of a subject in one shot or remove an unwanted object, they’d have to use a combination of rotoscoping techniques or basic power windows and masks to isolate the subject from the background.</p>
<p>Magic Mask has completely changed that workflow. With it, simply draw a line over the subject and the AI will process for a moment before revealing the selection. And GeForce RTX laptops can run the feature 2.5x faster than the fastest non-RTX laptops.</p>
<p>This is just a sample of the ways that AI is increasing the speed of creativity. There are now more than 125 AI applications accelerated by RTX.</p>
<h2><b>AI for Developers</b></h2>
<p>AI is enhancing the way developers build software applications through scalable environments, hardware and software optimizations, and new APIs.</p>
<p><a href="https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/workbench/">NVIDIA AI Workbench</a> helps developers quickly create, test and customize pretrained generative AI models and LLMs using PC-class performance and memory footprint. It’s a unified, easy-to-use toolkit that can scale from running locally on RTX PCs to virtually any data center, public cloud or <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a>.</p>
<p>After building AI models for PC use cases, developers can optimize them using <a href="https://developer.nvidia.com/tensorrt">NVIDIA TensorRT</a> — the software that helps developers take full advantage of the Tensor Cores in RTX GPUs.</p>
<p>TensorRT acceleration is now available in text-based applications with <a href="https://blogs.nvidia.com/blog/ignite-rtx-ai-tensorrt-llm-chat-api/">TensorRT-LLM for Windows</a>. The open-source library increases LLM performance and includes pre-optimized checkpoints for popular models, including <a href="https://blogs.nvidia.com/blog/google-gemma-llm-rtx-ai-pc/">Google’s Gemma</a>, Meta Llama 2, Mistral and Microsoft Phi-2.</p>
<p>Developers also have access to a TensorRT-LLM wrapper for the OpenAI Chat API. With just one line of code change, <a href="https://continue.dev/docs/intro">continue.dev</a> — an open-source autopilot for VS Code and JetBrains that taps into an LLM — can use TensorRT-LLM locally on an RTX PC for fast, local LLM inference using this popular tool.</p>
<p>Every week, we’ll demystify AI by making the technology more accessible, and we’ll showcase new hardware, software, tools and accelerations for RTX AI PC users.</p>
<p>The iPhone moment of AI is here, and it’s just the beginning. Welcome to AI Decoded.</p>
<p><i>Get weekly updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/ai-on-rtx/?modal=subscribe-ai"><i>AI Decoded newsletter</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/ai-decoded-nv-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/ai-decoded-nv-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI Decoded: Demystifying AI and the Hardware, Software and Tools That Power It]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>The Magic Behind the Screen: Celebrating the 96th Academy Awards Nominees for Best Visual Effects</title>
		<link>https://blogs.nvidia.com/blog/academy-awards-vfx-openusd/</link>
		
		<dc:creator><![CDATA[Rick Champagne]]></dc:creator>
		<pubDate>Tue, 05 Mar 2024 17:00:50 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[Media and Entertainment]]></category>
		<category><![CDATA[Universal Scene Description]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70139</guid>

					<description><![CDATA[The 96th Academy Awards nominees for Best Visual Effects are a testament to the incredible technological advancements pushing the boundaries of what’s possible in film. Whether showcasing colossal destruction scenes, heart-pumping action sequences or interstellar adventures, each nominee demonstrates unique contributions in visual effects, or VFX — and they all used cutting-edge NVIDIA technologies in		<a class="read-more" href="https://blogs.nvidia.com/blog/academy-awards-vfx-openusd/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The 96th Academy Awards nominees for Best Visual Effects are a testament to the incredible technological advancements pushing the boundaries of what’s possible in film.</p>
<p>Whether showcasing colossal destruction scenes, heart-pumping action sequences or interstellar adventures, each nominee demonstrates unique contributions in visual effects, or VFX — and they all used cutting-edge NVIDIA technologies in their workflows to bring their magic to the screen.</p>
<p>This year’s nominees include:</p>
<ul>
<li><b><i>The Creator</i></b> (20th Century Studios) — Jay Cooper, Ian Comley, Andrew Roberts and Neil Corbould</li>
<li><b><i>Godzilla: Minus One</i></b> (Toho) — Takashi Yamazaki, Kiyoko Shibuya, Masaki Takahashi and Tatsuji Nojima</li>
<li><b><i>Guardians of the Galaxy Vol. 3</i></b> (Marvel Studios) — Stephane Ceretti, Alexis Wajsbrot, Guy Williams and Theo Bialek</li>
<li><b><i>Napoleon</i></b> (Apple Original Films/Sony Pictures) — Charley Henley, Luc-Ewen Martin-Fenouillet, Simone Coco and Neil Corbould</li>
<li><b><i>Mission: Impossible – Dead Reckoning Part One</i></b> (Paramount Pictures) — Alex Wuttke, Simone Coco, Jeff Sutherland and Neil Corbould</li>
</ul>
<h2><b>Reinventing the Monster Movie</b></h2>
<p><i>Godzilla: Minus One</i> presented a unique challenge: making a well-known giant monster, or kaijū, feel terrifying anew.</p>
<p>With a budget under $15 million, small by today’s standards, the film’s VFX team relied on rapid iterations with the director to eliminate long review cycles, along with a heavily detailed computer-generated imagery (CGI) model to bring Godzilla to life.</p>
<p>Godzilla was ready for its closeup, the monster’s head alone containing over 200 million polygons. The animators injected nuanced, lifelike behaviors into the creature to round out its performance.</p>
<p>In addition, the film’s destruction scenes used a sophisticated, memory-intensive physics engine, allowing for realistic simulations of crumbling buildings and landscapes under destruction to further immerse audiences in the chaos.</p>
<h2><b>A Cosmic Spectacle</b></h2>
<p><i>Guardians of the Galaxy Vol. 3</i> continued the series’s tradition of blending humor with breathtaking cosmic visuals. This installment pushed the envelope with its use of real-time rendering, enabling its artists to visualize complex space environments and characters on set.</p>
<p>The film brought together Wētā FX, Framestore and Sony Pictures Imageworks, among others, to create a whopping 3,000+ VFX shots. The dense, immersive 3D environments allowed for a seamless integration of live-action and CGI elements and characters, resulting in a visually stunning space opera that maintained the series’ signature style while exploring new visual territories.</p>
<p>One of <i>Guardians</i>’s greatest achievements is the hallway fight scene filmed at 120 frames per second and delivered as a single continuous shot with variable speed ramps and nonstop action.</p>
<h2><b>Epic Storytelling Through Detailed VFX</b></h2>
<p>The historical epic <i>Napoleon </i>was brought to life with meticulous attention to detail and scale. The film used various set extensions and practical effects to recreate the vast battlefields and period-specific architecture of early 19th-century Europe.</p>
<p>Advanced crowd simulation was used to depict the massive armies of Napoleon’s time, each soldier animated with individual behaviors to enhance the battle scenes’ realism. These touches, combined with high-resolution textures and dynamic lighting, created a visually compelling narrative grounded in reality.</p>
<h2><b>Exploring AI’s Boundaries</b></h2>
<p><i>The Creator</i> explored the themes of AI and virtual reality, requiring VFX that could realistically depict advanced technology and digital worlds.</p>
<p>The film made significant use of CG animation and visual effects to create environments both futuristic and plausible. Director Gareth Edwards, also known for <i>Rogue One</i> and <i>Godzilla (2014),</i> has been widely applauded for delivering a film with the look of an expensive summer blockbuster using a fraction of the typical budget.</p>
<p>The portrayal of AI entities involved a combination of motion-capture and procedural animation to create characters that moved and interacted with complexity and fluidity at human level. The VFX team developed custom software to simulate the intricate patterns of digital consciousness, blurring the lines between the virtual and the real.</p>
<h2><b>High-Octane Action Meets Precision VFX</b></h2>
<p>For <i>Mission: Impossible &#8211; Dead Reckoning Part One</i>, the visual effects team faced the challenge of enhancing the film’s signature action sequences without detracting from the series’s reputation for practical stunts. To achieve this, they took a hybrid approach, using CGI to seamlessly augment practical effects.</p>
<p>High-speed drone footage integrated with CG elements created breathtaking chase scenes, while advanced compositing techniques added layers of detail and depth to explosions and hand-to-hand combat scenes, elevating the film’s action to new heights.</p>
<h2><b>NVIDIANs at the SciTech Awards</b></h2>
<figure id="attachment_70149" aria-describedby="caption-attachment-70149" style="width: 352px" class="wp-caption alignright"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/03/Oscars-Blog-Copy-2.jpg"><img loading="lazy" decoding="async" class="wp-image-70149 size-medium" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/Oscars-Blog-Copy-2-352x400.jpg" alt="" width="352" height="400" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/Oscars-Blog-Copy-2-352x400.jpg 352w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Oscars-Blog-Copy-2-440x500.jpg 440w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Oscars-Blog-Copy-2-396x450.jpg 396w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Oscars-Blog-Copy-2-189x215.jpg 189w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Oscars-Blog-Copy-2-88x100.jpg 88w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Oscars-Blog-Copy-2.jpg 599w" sizes="(max-width: 352px) 100vw, 352px" /></a><figcaption id="caption-attachment-70149" class="wp-caption-text">NVIDIA’s Christopher Jon Horvath, joined by Steve LaVietes and Joe Ardent, on stage to accept their award.</figcaption></figure>
<p><i></i>The Academy Awards for Scientific and Technical Achievements highlight technical contributions that have significantly affected the way movies are made, as well as the brilliant inventors behind them.</p>
<p><a href="https://aousd.org/blog/explainer-series-what-is-openusd/">OpenUSD</a> was <a href="https://aousd.org/blog/openusd-wins-academy-award-for-scientific-and-technical-achievement/">honored in the science and engineering subcategory</a> for its importance as the first open-source scene description framework that streamlines the entire production workflow. Its innovative layering system and efficient crate file format have established it as the de facto standard for 3D scene interchange, facilitating unparalleled collaboration across the industry.<b> </b></p>
<p>The science and engineering subcategory also celebrated other remarkable technologies, including the <a href="https://www.openvdb.org/">OpenVDB</a> open-source library, for sparse 3D volumes, which has become an industry standard for visual-effects simulations and renderings of water, fire, smoke and clouds.</p>
<p>Initially created in 2009 by Ken Museth, senior director of physics research at NVIDIA, OpenVDB has been further developed by Museth, Peter Cucka and Mihai Aldén. Learn more about the latest advancements in OpenVDB including <a href="https://developer.nvidia.com/nanovdb">NanoVDB</a> and <a href="https://developer.nvidia.com/rendering-technologies/neuralvdb">NeuralVDB</a>.</p>
<p>In addition, the <a href="https://www.alembic.io/index.html">Alembic</a> Caching and Interchange system, developed by Lucas Miller, NVIDIA’s Christopher Jon Horvath, Steve LaVietes and Joe Ardent, received recognition for its efficient algorithms in storing and retrieving baked, time-sampled data, facilitating high-efficiency caching and scene sharing across the digital production pipeline.</p>
<p>OpenVDB and Alembic are both interoperable with OpenUSD, enhancing their utility and integration within the industry’s production workflows.</p>
<h2><b>See How Oscar-Nominated VFX Are Created at GTC</b></h2>
<p>Learn more about visual effects, AI, virtual production and animation at <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>, a global AI conference taking place March 18-21 at the San Jose Convention Center and online. Register to hear from <a href="https://www.nvidia.com/gtc/sessions/media-and-entertainment/">industry luminaries creating stunning visuals in film and TV</a>.</p>
<p>Academy Award-winner Ken Museth will present a session, <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=museth#/session/1697498197036001JVKp">Open-Source Software for Visual Effects: OpenUSD and OpenVDB</a>, on Monday, March 18, at 9 a.m. PT.</p>
<p>And join us for <a href="https://www.nvidia.com/gtc/sessions/openusd-day/">OpenUSD Day</a> to learn how to build generative AI-enabled 3D pipelines and tools using Universal Scene Description. Browse the full list of <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search.industry=option_1559593250529#/">media and entertainment sessions</a> at GTC.</p>
<p><i>Featured image courtesy of Toho Co., Ltd. TOHO CO., LTD.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/Oscars-Blog-Header.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/Oscars-Blog-Header-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[The Magic Behind the Screen: Celebrating the 96th Academy Awards Nominees for Best Visual Effects]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Robo Rendezvous: Robotics Innovators and AI Leaders to Converge at NVIDIA GTC</title>
		<link>https://blogs.nvidia.com/blog/robotics-innovators-ai-gtc-2024/</link>
		
		<dc:creator><![CDATA[Jason Black]]></dc:creator>
		<pubDate>Mon, 04 Mar 2024 18:55:55 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Digital Twin]]></category>
		<category><![CDATA[Embedded Computing]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[Isaac]]></category>
		<category><![CDATA[Jetson]]></category>
		<category><![CDATA[Metaverse]]></category>
		<category><![CDATA[Metropolis]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70141</guid>

					<description><![CDATA[Bringing together pioneers in robotics and AI, NVIDIA GTC will be a state-of-the-art showcase of applied AI for autonomous machines. The conference, running March 18-21 at the San Jose Convention Center and online, boasts a star-studded lineup. This includes a fireside chat with Marc Raibert, executive director of The AI Institute, and Dieter Fox, senior		<a class="read-more" href="https://blogs.nvidia.com/blog/robotics-innovators-ai-gtc-2024/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Bringing together pioneers in robotics and AI, <a href="https://www.nvidia.com/gtc/" target="_blank" rel="noopener">NVIDIA GTC</a> will be a state-of-the-art showcase of applied AI for autonomous machines.</p>
<p>The conference, running March 18-21 at the San Jose Convention Center and online, boasts a star-studded lineup. This includes a fireside chat with Marc Raibert, executive director of The AI Institute, and Dieter Fox, senior director of robotics research at NVIDIA, as well as panels featuring heavyweights like Disney, Google DeepMind and Amazon, alongside insights from NVIDIA stalwarts like Senior Research Scientist Jim Fan.</p>
<p>With over 77 ecosystem partners and more than 25 partner robots, from industrial giants to entertainment bots, GTC is where the future of robotics unfolds.</p>
<p>Attendees will be able to explore the convergence of AI and robotics through dynamic displays in the <a href="https://www.nvidia.com/gtc/sponsors/?search.pavilion=1640012882104005N6Ek#/">AI at the Edge pavilion,</a> the <a href="https://www.nvidia.com/gtc/sponsors/?search.pavilion=1640012882104006NO4J#/">Metropolis pavilion</a>, the <a href="https://www.nvidia.com/gtc/sponsors/?search.pavilion=1640012882104003Nbgl#/">Healthcare and Life Sciences</a> pavilion and demo areas, featuring the latest robot arms, robotic vision systems and high-accuracy 3D scanning systems. They can also explore the <a href="https://www.nvidia.com/gtc/sponsors/?search.pavilion=option_1695660050270#/">Industrial Digitalization pavilion</a> to dive deeper into robotics within the industrial sector, seeing how industry leaders use digital technologies to enable new levels of innovation, automation and efficiency across industrial workflows.</p>
<p>These demonstrations provide compelling examples of how AI seamlessly enhances human capabilities across diverse industries. Groundbreaking demos using large language models for real-world applications will push the boundaries of human-machine interaction.</p>
<p>Here are a few of the conference’s <a href="https://www.nvidia.com/gtc/sessions/robotics/" target="_blank" rel="noopener">must-see robotics events</a>:</p>
<ul>
<li><b>AI’s Impact on Robotics:</b> In a fireside chat, <a href="https://www.nvidia.com/gtc/sessions/robotics/" target="_blank" rel="noopener">Raibert and Fox discuss AI’s transformative role in robotics</a>, moving from traditional controls to AI-driven technologies.</li>
<li><b>Generative AI in Robotics:</b> A panel led by NVIDIA Senior Strategic Partnerships Manager Sandra Skaff and featuring leaders from Ambi Robotics, Covariant, Vayu Robotics and Scaled Foundations discusses the <a href="https://www.nvidia.com/gtc/session-catalog/?search=S63034&amp;tab.allsessions=1700692987788001F1cG#/session/1702515738340001PgCL" target="_blank" rel="noopener">impact of generative AI in robotics</a>, focusing on its potential to advance reasoning, planning and perception.</li>
<li><b>Generative AI Revolution:</b> Google DeepMind unveils the next frontier in robotics, powered by generative AI’s advancements in perception and interaction, in the session “<a href="https://www.nvidia.com/gtc/session-catalog/?search=S61182&amp;tab.allsessions=1700692987788001F1cG#/session/1691430991280001dyB0" target="_blank" rel="noopener">Robotics in the Age of Generative AI</a>.”</li>
<li><b>Metaverse Meets Automation:</b> SICK AG offers a vision of the metaverse revolutionizing the automation industry, in the session “<a href="https://www.nvidia.com/gtc/session-catalog/?search=S62461&amp;tab.allsessions=1700692987788001F1cG#/session/1696266185804001uSBw" target="_blank" rel="noopener">Exploring Tomorrow’s Industrial Automation</a>.”</li>
<li><b>Robots and AI Vision:</b> The session “<a href="https://www.nvidia.com/gtc/session-catalog/?search=S62409&amp;tab.allsessions=1700692987788001F1cG#/" target="_blank" rel="noopener">Empowering Collaborative Robots: The Future of AI Vision With Digital Twins</a>” shows how AI vision is setting new standards for robot-human collaboration.</li>
<li><b>Robots With Character:</b> Walt Disney Imagineering will show how it’s enabling the rapid design of legged robotic characters that learn to imitate artist-specified animations, in the session “<a href="https://www.nvidia.com/gtc/session-catalog/?search=s63374&amp;tab.allsessions=1700692987788001F1cG#/" target="_blank" rel="noopener">Breathing Life Into Disney’s Robotic Characters With Deep Reinforcement Learning</a>.”</li>
<li><b>Boosting Humanoid Performance:</b> Sanctuary AI explores the role of synthetic data in enhancing humanoid robot performance for complex tasks, in the session “<a href="https://www.nvidia.com/gtc/session-catalog/?search=S61276&amp;tab.allsessions=1700692987788001F1cG#/" target="_blank" rel="noopener">Using Omniverse to Generate First-Person Experiential Data for Humanoid Robots</a>.”</li>
</ul>
<p>Plus, a special session with Deepu Talla, vice president of robotics and edge computing at NVIDIA, about “<a href="https://www.nvidia.com/gtc/session-catalog/?search=S63287&amp;tab.allsessions=1700692987788001F1cG#/" target="_blank" rel="noopener">AI Robotics: Driving Innovation for the Future of Automation</a>” was just added to the GTC catalog.</p>
<p>This year’s GTC also offers <a href="https://www.nvidia.com/gtc/session-catalog/?search=&amp;tab.allsessions=1700692987788001F1cG&amp;search.sessiontype=16573103299710016qZX#/">40 hands-on labs</a>, providing attendees with an immersive experience of the practical applications of these technologies.</p>
<p>A <a href="https://www.nvidia.com/gtc/sessions/jetson-and-robotics-developer-day/">Jetson and Robotics Developer Day</a> will be held on Thursday, March 21, featuring a full day of sessions and panels that dive deep into building next-gen AI-powered robotics and edge applications on the <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/">NVIDIA Jetson</a>, <a href="https://developer.nvidia.com/isaac">Isaac</a> and <a href="https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/">Metropolis</a> platforms.</p>
<p>Over the past decade, GTC has been where advances in computer graphics, deep learning and generative AI were launched. As industries from agriculture to manufacturing are transformed by these technologies, this year’s event will offer a glimpse into the innovations that will soon define our daily lives.</p>
<p><a href="https://www.nvidia.com/gtc/"><i>Register for GTC </i></a><i> to secure your spot at the forefront of technology’s next leap. </i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/nvidia-robotics.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/nvidia-robotics-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Robo Rendezvous: Robotics Innovators and AI Leaders to Converge at NVIDIA GTC]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Automakers Electrify Geneva International Motor Show</title>
		<link>https://blogs.nvidia.com/blog/automakers-geneva-motor-show/</link>
		
		<dc:creator><![CDATA[Danny Shapiro]]></dc:creator>
		<pubDate>Fri, 01 Mar 2024 19:13:33 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70113</guid>

					<description><![CDATA[The Geneva International Motor Show, one of the most important and long-standing global auto exhibitions, opened this week, with the spotlight on several China and U.S. EV makers building on NVIDIA DRIVE that are expanding their presence in Europe. BYD One of the key reveals is BYD’s Yangweng U8 plug-in hybrid large SUV, built on		<a class="read-more" href="https://blogs.nvidia.com/blog/automakers-geneva-motor-show/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The Geneva International Motor Show, one of the most important and long-standing global auto exhibitions, opened this week, with the spotlight on several China and U.S. EV makers building on <a href="https://www.nvidia.com/en-us/self-driving-cars/" target="_blank" rel="noopener">NVIDIA DRIVE</a> that are expanding their presence in Europe.</p>
<h2><b>BYD</b></h2>
<p>One of the key reveals is <b>BYD’s</b> Yangweng U8 plug-in hybrid large SUV, built on the <a href="https://www.nvidia.com/en-us/self-driving-cars/hardware/" target="_blank" rel="noopener">NVIDIA DRIVE Orin</a> platform. It features an electric drivetrain with a range of up to 1,000 kilometers, or 621 miles, thanks to its 49 kilowatt-hour battery and range-extender gasoline engine.</p>
<h2><b>IM Motors</b></h2>
<p>The premium EV brand by SAIC and Alibaba, <b>IM Motors</b>, unveiled its IM L6 mid-size electric  saloon (aka sedan), which will soon be available to the European market.</p>
<p>The L6 features IM’s proprietary Intelligent Mobility Autonomous Driving System, powered by NVIDIA DRIVE Orin. The advanced system uses a comprehensive sensor suite, including one lidar, three radars, 11 cameras and 12 ultrasonic sensors. IM reports that the L6 is capable of highway navigation on autopilot, marking a milestone in the company’s mission to bring advanced self-driving vehicles to market.</p>
<p><a href="https://blogs.nvidia.com/blog/auto-shanghai-nvidia-drive/" target="_blank" rel="noopener">IM Motors</a> has been working with NVIDIA since 2021, using NVIDIA DRIVE Orin as the AI brain for its flagship LS7 SUV and L7 sedan.</p>
<figure id="attachment_70125" aria-describedby="caption-attachment-70125" style="width: 672px" class="wp-caption alignnone"><img loading="lazy" decoding="async" class="wp-image-70125 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/IM_L6_NEW-IMAGE-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/IM_L6_NEW-IMAGE-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/IM_L6_NEW-IMAGE-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/IM_L6_NEW-IMAGE-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/IM_L6_NEW-IMAGE-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/IM_L6_NEW-IMAGE-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/IM_L6_NEW-IMAGE-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/03/IM_L6_NEW-IMAGE-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/03/IM_L6_NEW-IMAGE-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/03/IM_L6_NEW-IMAGE-1280x853.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70125" class="wp-caption-text">IM Motors IM L6</figcaption></figure>
<h2><b>Lucid </b></h2>
<p>The Geneva Motor Show marks the European debut of Lucid’s Gravity SUV.</p>
<p>The Gravity aims to set fresh benchmarks for sustainability and technological innovation when its production commences in late 2024. Powered by NVIDIA DRIVE, the luxury SUV features supercar levels of performance and an impressive battery range to mitigate range anxiety.</p>
<figure id="attachment_70121" aria-describedby="caption-attachment-70121" style="width: 672px" class="wp-caption alignnone"><img loading="lazy" decoding="async" class="wp-image-70121 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/Lucid_Gravity-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/Lucid_Gravity-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Lucid_Gravity-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Lucid_Gravity-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Lucid_Gravity-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Lucid_Gravity-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Lucid_Gravity-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Lucid_Gravity-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Lucid_Gravity-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Lucid_Gravity-1280x853.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70121" class="wp-caption-text">Lucid Gravity SUV</figcaption></figure>
<p>Explore the latest developments in mobility and meet NVIDIA DRIVE ecosystem partners showcasing their next-gen vehicles at <a href="https://www.nvidia.com/gtc/" target="_blank" rel="noopener">GTC</a>, the conference for the era of AI, running from March 18-21 at the San Jose Convention Center and online.</p>
<p>Find additional details on <a href="https://images.nvidia.com/nvimages/gtc/pdf/GTC24_March_Automotive_Brochure.pdf" target="_blank" rel="noopener">automotive-specific programming at GTC</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/byd8suv.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/byd8suv-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Automakers Electrify Geneva International Motor Show]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>No Noobs Here: Top Pro Gamers Bolster Software Quality Assurance Testing</title>
		<link>https://blogs.nvidia.com/blog/nvidia-life-pro-gamers/</link>
		
		<dc:creator><![CDATA[Samantha Zee]]></dc:creator>
		<pubDate>Fri, 01 Mar 2024 17:14:58 +0000</pubDate>
				<category><![CDATA[NVIDIA Life]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70004</guid>

					<description><![CDATA[For some NVIDIANs, it’s always game day. Our Santa Clara-based software quality assurance team boasts some of the world’s top gamers, whose search for bugs and errors is as strategic as their battle plans for toppling top-tier opponents in video games. Two team members of the QA team — friendly colleagues in the office but		<a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-life-pro-gamers/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>For some NVIDIANs, it’s always game day.</p>
<p>Our Santa Clara-based software quality assurance team boasts some of the world’s top gamers, whose search for bugs and errors is as strategic as their battle plans for toppling top-tier opponents in video games.</p>
<p>Two team members of the QA team — friendly colleagues in the office but fierce rivals in the esports arena — recently competed against one another at the finals of the Guildhouse Fighters tournament, a local circuit in Northern California.</p>
<p>Eduardo “PR Balrog” Perez-Frangie, a veteran <i>Street Fighter</i> player, fought his way to the Grand Final to face Miky “Samurai” Chea.</p>
<p>Perez-Frangie came out on top, but there was a twist: he’d brought to the contest his two-year-old son, who fell asleep on his father’s chest mid-match. “I played the rest of the game with a deadweight in my lap,” he said.</p>
<figure id="attachment_70005" aria-describedby="caption-attachment-70005" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-70005" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4730_L-1-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4730_L-1-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4730_L-1-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4730_L-1-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4730_L-1-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4730_L-1-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4730_L-1-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4730_L-1-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4730_L-1-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4730_L-1-1280x853.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70005" class="wp-caption-text">Perez-Frangie and Chea play at work — guess who won? QA team members Alyssa Ruiz and DaJuan McDaniel cheer them on.</figcaption></figure>
<h2><b>A Competitive Spirit</b></h2>
<p>Perez-Frangie has competed for 15 years in a series of fighting game titles, including <i>Marvel vs. Capcom</i>, <i>Killer Instinct</i> and <i>Mortal Kombat</i>. He was part of the Evil Geniuses esports organization when he joined NVIDIA almost a decade ago but now plays without a sponsor so he can enjoy more family time.</p>
<p>He’s played against Chea in esports events for years, and they’re just as competitive in the office as in the stadiums.</p>
<p>“Even when we’re in the test environment, when we’re looking for bugs, we are competitive,” Perez-Frangie said. “But Miky stays calm — he was a teacher, so he can put everyone in their place.”</p>
<p>Chea’s days teaching kindergarten through eighth grade in Fresno, California, are behind him, but the coaching aspect of his current gaming-related role reminds him of the classroom — a place to share insights and takeaways.</p>
<p>As new games are released and older ones updated, “the hardware and software stack needs to work in harmony,” Chea said. “Our pro gaming team is the last line of defense to ensure our customers have the best gaming experience possible.”</p>
<figure id="attachment_70008" aria-describedby="caption-attachment-70008" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-70008" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/NZ9_4939_L-1-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/NZ9_4939_L-1-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/NZ9_4939_L-1-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/NZ9_4939_L-1-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/NZ9_4939_L-1-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/NZ9_4939_L-1-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/02/NZ9_4939_L-1-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/02/NZ9_4939_L-1-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/02/NZ9_4939_L-1-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/02/NZ9_4939_L-1-1280x853.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70008" class="wp-caption-text">The QA team gathers to check out a new game.</figcaption></figure>
<p>QA team member DaJuan “Shroomed” McDaniel is a top-ranked <i>Super Smash Bros. Melee</i> player whose signature characters are Sheik and Marth. He’s also widely considered to be the best <i>Dr. Mario</i> player of all time.</p>
<p>“Being a competitive gamer, visual fidelity is so important,” McDaniel said. “We can see and feel visual anomalies, frame discrepancies, general latency and anything that’s off in ways that others won’t see.”</p>
<figure id="attachment_70011" aria-describedby="caption-attachment-70011" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-70011" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4554_L-1-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4554_L-1-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4554_L-1-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4554_L-1-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4554_L-1-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4554_L-1-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4554_L-1-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4554_L-1-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4554_L-1-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-NZ9_4554_L-1-1280x853.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70011" class="wp-caption-text">McDaniel playing “Cyberpunk 2077.”</figcaption></figure>
<h2><b>A Winning Formula</b></h2>
<p>Alyssa Ruiz joined the QA team a year ago, initially testing drivers as part of the pro gaming team before switching to testing <a href="https://developer.nvidia.com/rtx/dlss">NVIDIA DLSS</a>, a suite of neural rendering techniques that use deep learning to improve image quality and performance.</p>
<p>Introduced to gaming by her brothers through <i>Halo 3</i>, she later dedicated hours to <i>Fortnite</i> before deciding to stream the gameplay directly from her console. She posted the content to TikTok and began playing in online tournaments. By then, her game of choice was Riot Games’ <i>Valorant</i>.</p>
<p>“The game has a large female player base with visually appealing graphics and an engrossing storyline,” she said. “It can be more complex than a fighting game because it relies on a combination of abilities with strategies. It’s also a team game, so if someone isn’t pulling their weight, it’s a loss for all of us.”</p>
<p>That’s not unlike the team dynamic in the office.</p>
<figure id="attachment_70014" aria-describedby="caption-attachment-70014" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-70014" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/Team-crop1-672x378.jpg" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/Team-crop1-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Team-crop1-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Team-crop1-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Team-crop1-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Team-crop1-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Team-crop1-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Team-crop1-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Team-crop1-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Team-crop1-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70014" class="wp-caption-text">Perez-Frangie, Ruiz, Chea and McDaniel.</figcaption></figure>
<p>Each member brings their own specialties to the testing environment, where they’re using their keen eyes to scrutinize DLSS technologies.</p>
<p>Their acute awareness of game latency and image fidelity — honed through hundreds of hours of gameplay — means the team can achieve better test coverage all around.</p>
<p>“We’re all very competitive, but there’s a real diversity that contributes to a stronger team,” Ruiz said. “And we all get along really well.”</p>
<p><i>Learn more about </i><a href="https://www.nvidia.com/en-us/about-nvidia/careers/life-at-nvidia/"><i>NVIDIA life, culture and careers</i></a><i>. </i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/Pro-Gamers-Featured-Photo.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/Pro-Gamers-Featured-Photo-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[No Noobs Here: Top Pro Gamers Bolster Software Quality Assurance Testing]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>What Is Trustworthy AI?</title>
		<link>https://blogs.nvidia.com/blog/what-is-trustworthy-ai/</link>
		
		<dc:creator><![CDATA[Nikki Pope]]></dc:creator>
		<pubDate>Fri, 01 Mar 2024 17:00:24 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Corporate Responsibility]]></category>
		<category><![CDATA[Social Impact]]></category>
		<category><![CDATA[Trustworthy AI]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70030</guid>

					<description><![CDATA[Artificial intelligence, like any transformative technology, is a work in progress — continually growing in its capabilities and its societal impact. Trustworthy AI initiatives recognize the real-world effects that AI can have on people and society, and aim to channel that power responsibly for positive change. What Is Trustworthy AI? Trustworthy AI is an approach		<a class="read-more" href="https://blogs.nvidia.com/blog/what-is-trustworthy-ai/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p dir="ltr">Artificial intelligence, like any transformative technology, is a work in progress — continually growing in its capabilities and its societal impact. <a href="https://blogs.nvidia.com/blog/tag/trustworthy-ai/">Trustworthy AI initiatives</a> recognize the real-world effects that AI can have on people and society, and aim to channel that power responsibly for positive change.</p>
<h2 dir="ltr">What Is Trustworthy AI?</h2>
<p dir="ltr">Trustworthy AI is an approach to AI development that prioritizes safety and transparency for those who interact with it. <a href="https://developer.nvidia.com/blog/tag/trustworthy-ai/">Developers of trustworthy AI</a> understand that no model is perfect, and take steps to help customers and the general public understand how the technology was built, its intended use cases and its limitations.</p>
<p dir="ltr">In addition to complying with privacy and consumer protection laws, trustworthy AI models are tested for safety, security and mitigation of unwanted bias. They’re also transparent — providing information such as accuracy benchmarks or a description of the training dataset — to various audiences including regulatory authorities, developers and consumers.</p>
<h2 dir="ltr">Principles of Trustworthy AI</h2>
<p dir="ltr"><a href="https://www.nvidia.com/en-us/ai-data-science/trustworthy-ai/">Trustworthy AI principles</a> are foundational to NVIDIA’s end-to-end AI development. They have a simple goal: to enable trust and transparency in AI and support the work of partners, customers and developers.</p>
<h3 dir="ltr">Privacy: Complying With Regulations, Safeguarding Data</h3>
<p dir="ltr">AI is often described as data hungry. Often, the more data an algorithm is trained on, the more accurate its predictions.</p>
<p dir="ltr">But data has to come from somewhere. To develop trustworthy AI, it’s key to consider not just what data is legally available to use, but what data is socially responsible to use.</p>
<p dir="ltr">Developers of AI models that rely on data such as a person’s image, voice, artistic work or health records should evaluate whether individuals have provided appropriate consent for their personal information to be used in this way.</p>
<p dir="ltr">For institutions like hospitals and banks, building AI models means balancing the responsibility of keeping patient or customer data private while training a robust algorithm. NVIDIA has created technology that enables <a href="https://blogs.nvidia.com/blog/what-is-federated-learning/">federated learning</a>, where researchers develop AI models trained on data from multiple institutions without confidential information leaving a company’s private servers.</p>
<p dir="ltr"><a href="https://www.nvidia.com/en-gb/data-center/dgx-systems/">NVIDIA DGX systems</a> and <a href="https://developer.nvidia.com/flare">NVIDIA FLARE</a> software have enabled several federated learning projects in <a href="https://blogs.nvidia.com/blog/federated-learning-nature-medicine/">healthcare</a> and <a href="https://developer.nvidia.com/blog/using-federated-learning-to-bridge-data-silos-in-financial-services/">financial services</a>, facilitating secure collaboration by multiple data providers on more accurate, generalizable AI models for <a href="https://blogs.nvidia.com/blog/israel-medical-center-ai-startups-radiology/">medical image analysis</a> and <a href="https://blogs.nvidia.com/blog/ai-fraud-detection-rapids-triton-tensorrt-nemo/">fraud detection</a>.</p>
<h3 dir="ltr">Safety and Security: Avoiding Unintended Harm, Malicious Threats</h3>
<p dir="ltr">Once deployed, AI systems have real-world impact, so it’s essential they perform as intended to preserve user safety.</p>
<p dir="ltr">The freedom to use publicly available AI algorithms creates immense possibilities for positive applications, but also means the technology can be used for unintended purposes.</p>
<p dir="ltr">To help mitigate risks, <a href="https://blogs.nvidia.com/blog/ai-chatbot-guardrails-nemo/">NVIDIA NeMo Guardrails</a> keeps AI language models on track by allowing enterprise developers to set boundaries for their applications. Topical guardrails ensure that chatbots stick to specific subjects. Safety guardrails set limits on the language and data sources the apps use in their responses. Security guardrails seek to prevent malicious use of a large language model that’s connected to third-party applications or application programming interfaces.</p>
<p dir="ltr">NVIDIA Research is working with the DARPA-run SemaFor program to <a href="https://github.com/NVlabs/stylegan3-detector" target="_blank" rel="noopener">help digital forensics experts identify AI-generated images</a>. Last year, researchers published a novel method for <a href="https://arxiv.org/pdf/2302.07371.pdf" target="_blank" rel="noopener">addressing social bias using ChatGPT</a>. They’re also creating methods for <a href="https://research.nvidia.com/labs/nxp/avatar-fingerprinting/">avatar fingerprinting</a> — a way to detect if someone is using an AI-animated likeness of another individual without their consent.</p>
<p dir="ltr">To protect data and AI applications from security threats, <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100</a> and <a href="https://www.nvidia.com/en-us/data-center/h200/">H200 Tensor Core GPUs</a> are built with <a href="https://blogs.nvidia.com/blog/what-is-confidential-computing/">confidential computing</a>, which ensures sensitive data is protected while in use, whether deployed on premises, in the cloud or at the edge. <a href="https://www.nvidia.com/en-us/data-center/solutions/confidential-computing/">NVIDIA Confidential Computing</a> uses hardware-based security methods to ensure unauthorized entities can’t view or modify data or applications while they’re running — traditionally a time when data is left vulnerable.</p>
<h3 dir="ltr">Transparency: Making AI Explainable</h3>
<p dir="ltr">To create a trustworthy AI model, the algorithm can’t be a black box — its creators, users and stakeholders must be able to understand how the AI works to trust its results.</p>
<p dir="ltr">Transparency in AI is a set of best practices, tools and design principles that helps users and other stakeholders understand how an AI model was trained and how it works. <a href="https://blogs.nvidia.com/blog/what-is-explainable-ai/">Explainable AI</a>, or XAI, is a subset of transparency covering tools that inform stakeholders how an AI model makes certain predictions and decisions.</p>
<p dir="ltr">Transparency and XAI are crucial to establishing trust in AI systems, but there’s no universal solution to fit every kind of AI model and stakeholder. Finding the right solution involves a systematic approach to identify who the AI affects, analyze the associated risks and implement effective mechanisms to provide information about the AI system.</p>
<p dir="ltr"><a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">Retrieval-augmented generation</a>, or RAG, is a technique that advances AI transparency by connecting generative AI services to authoritative external databases, enabling models to cite their sources and provide more accurate answers. NVIDIA is helping developers get started with a <a href="https://www.nvidia.com/en-us/ai-data-science/ai-workflows/generative-ai-chatbots/">RAG workflow</a> that uses the <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/">NVIDIA NeMo</a> framework for developing and customizing generative AI models.</p>
<p dir="ltr">NVIDIA is also part of the National Institute of Standards and Technology’s U.S. Artificial Intelligence Safety Institute Consortium, or AISIC, to <a href="https://blogs.nvidia.com/blog/aisic-trustworthy-ai/">help create tools and standards for responsible AI development</a> and deployment. As a consortium member, NVIDIA will promote trustworthy AI by leveraging best practices for implementing AI model transparency.</p>
<p dir="ltr">And on NVIDIA’s hub for accelerated software, <a href="https://www.nvidia.com/en-us/gpu-cloud/">NGC</a>, <a href="https://developer.nvidia.com/blog/enhancing-ai-transparency-and-ethical-considerations-with-model-card/">model cards</a> offer detailed information about how each AI model works and was built. NVIDIA’s Model Card ++ format describes the datasets, training methods and performance measures used, licensing information, as well as specific ethical considerations.</p>
<h3 dir="ltr">Nondiscrimination: Minimizing Bias</h3>
<p dir="ltr">AI models are trained by humans, often using data that is limited by size, scope and diversity. To ensure that all people and communities have the opportunity to benefit from this technology, it’s important to reduce unwanted bias in AI systems.</p>
<p dir="ltr">Beyond following government guidelines and antidiscrimination laws, trustworthy AI developers mitigate potential unwanted bias by looking for clues and patterns that suggest an algorithm is discriminatory, or involves the inappropriate use of certain characteristics. Racial and gender bias in data are well-known, but other considerations include cultural bias and bias introduced during data labeling. To reduce unwanted bias, developers might incorporate different variables into their models.</p>
<p dir="ltr">Synthetic datasets offer one solution to reduce unwanted bias in training data used to develop AI for <a href="https://www.nvidia.com/en-us/self-driving-cars/">autonomous vehicles</a> and <a href="https://developer.nvidia.com/isaac-sim">robotics</a>. If data used to train self-driving cars underrepresents uncommon scenes such as extreme weather conditions or traffic accidents, synthetic data can help augment the diversity of these datasets to better represent the real world, helping improve AI accuracy.</p>
<p dir="ltr"><a href="https://developer.nvidia.com/omniverse/replicator">NVIDIA Omniverse Replicator</a>, a framework built on the <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> platform for creating and operating 3D pipelines and virtual worlds, helps developers set up custom pipelines for synthetic data generation. And by integrating the <a href="https://developer.nvidia.com/tao-toolkit">NVIDIA TAO Toolkit</a> for <a href="https://blogs.nvidia.com/blog/what-is-transfer-learning/">transfer learning</a> with Innotescus, a web platform for curating unbiased datasets for computer vision, developers can better <a href="https://developer.nvidia.com/blog/curating-data-for-transfer-learning-with-the-nvidia-tao-toolkit-and-innotescus/">understand dataset patterns and biases to help address statistical imbalances</a>.</p>
<p dir="ltr">Learn more about trustworthy AI on <a href="https://www.nvidia.com/en-us/ai-data-science/trustworthy-ai/">NVIDIA.com</a> and the <a href="https://blogs.nvidia.com/blog/tag/trustworthy-ai/">NVIDIA Blog</a>. For more on tackling unwanted bias in AI, <a href="https://www.nvidia.com/en-us/on-demand/session/gtcspring22-se2696/">watch this talk</a> from <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a> and attend the <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=S62411%2C%20S62221%2C%20S62594%2C%20S62292%2C%20S62300#/">trustworthy AI track</a> at the <a href="https://www.nvidia.com/gtc/pricing/">upcoming conference</a>, taking place March 18-21 in San Jose, Calif, and online.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/model-cards.png"
			type="image/png"
			width="1280"
			height="720"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/model-cards-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[What Is Trustworthy AI?]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Live at GTC: Hear From Industry Leaders Using AI to Drive Innovation and Agility</title>
		<link>https://blogs.nvidia.com/blog/industry-leaders-ai-innovation-gtc-2024/</link>
		
		<dc:creator><![CDATA[Ben Oliveri]]></dc:creator>
		<pubDate>Fri, 01 Mar 2024 16:00:28 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Driving]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Energy]]></category>
		<category><![CDATA[Financial Services]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[Industrial and Manufacturing]]></category>
		<category><![CDATA[Media and Entertainment]]></category>
		<category><![CDATA[Public Sector]]></category>
		<category><![CDATA[Retail]]></category>
		<category><![CDATA[Telecommunications]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70083</guid>

					<description><![CDATA[Enterprise execs across broad sectors to share their AI strategies and success stories.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Interest in new AI applications reached a fever pitch last year as business leaders began exploring AI pilot programs. This year, they’re focused on strategically implementing these programs to create new value and sharpen their competitive advantage.</p>
<p><a href="https://www.nvidia.com/gtc/?ncid=pa-srch-goog-789978-prsp&amp;_bt=690120344873&amp;_bk=nvidia%20gtc&amp;_bm=p&amp;_bn=g&amp;_bg=157308081494&amp;gad_source=1&amp;gclid=EAIaIQobChMI8ITYoOy6hAMVmZxaBR2EhQB-EAAYASAAEgKOmfD_BwE">GTC</a>, NVIDIA’s conference on AI and accelerated computing, set for March 18-21 at the San Jose Convention Center, will feature leaders across a broad swath of industries discussing how they’re charting the path to AI-driven innovation.</p>
<p>Execs from Bentley Systems, Lowe’s, Siemens and Verizon are among those sharing their companies’ AI journeys.</p>
<p><i>Don’t miss NVIDIA founder and CEO </i><a href="https://www.nvidia.com/gtc/keynote/?regcode=pa-srch-goog-143845-prsp&amp;ncid=pa-srch-goog-143845-prsp"><i>Jensen Huang’s GTC keynote on Monday, March 18</i></a><i>, at 1 p.m. PT.</i></p>
<h2><strong>AI Takes Center Stage in Enterprise Technology Priorities</strong></h2>
<p>Nearly three-quarters of C-suite executives plan to increase their company’s tech investments this year, according to a <a href="https://www.bcg.com/publications/2024/from-potential-to-profit-with-genai">BCG survey of C-suite executives</a>, and 89% rank AI and generative AI among their top three priorities. More than half expect AI to deliver cost savings, primarily through productivity gains, improved customer service and IT efficiencies.</p>
<p>However, challenges to driving value with AI remain, including reskilling workers, prioritizing the right AI use cases and developing a strategy to implement responsible AI.</p>
<p>Join us in person or online to learn how industry leaders are overcoming these challenges to thrive with AI.</p>
<p>Here’s a preview of top industry sessions:</p>
<h2><strong>Financial Services</strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search.industry=option_1559593199335&amp;search=Navigating%20the%20Opportunity%20for%20GenAI%20in%20Financial%20Services#/session/1696518068816001oKTP">Navigating the Opportunity for Generative AI in Financial Services</a>, featuring speakers from NVIDIA, MasterCard, Capital One and Goldman Sachs.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62357">Enterprise AI in Banking: How One Leader Is Investing in “AI First,”</a> featuring Alexandra V. Mousavizadeh, CEO of Evident, and Chintan Mehta, chief information officer and head of digital technology and innovation at Wells Fargo.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62506">How PayPal Reduced Cloud Costs by up to 70% With Spark RAPIDS</a>, featuring Illay Chen, software engineer at PayPal.</p>
<h2><strong>Public Sector</strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62730&amp;tab.allsessions=1700692987788001F1cG#/session/1697653098220001o65m">Generative AI Adoption and Operational Challenges in Government</a>, featuring speakers from Microsoft, NVIDIA and the U.S. Army.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62173&amp;tab.allsessions=1700692987788001F1cG#/session/1695253323624001BtLZ">How to Apply Generative AI to Improve Cybersecurity</a>, featuring Bartley Richardson, director of cybersecurity engineering at NVIDIA.</p>
<h2><strong>Healthcare</strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=Generative%20AI%20is%20Accelerating%20Healthcare%20into%20One%20of%20the%20Largest%20Technology%20Industries&amp;tab.allsessions=1700692987788001F1cG&amp;search.industry=option_1559593230294#/session/1696538040602001SPK9">Healthcare Is Adopting Generative AI, Becoming One of the Largest Tech Industries</a>, featuring Kimberly Powell, vice president of healthcare and life sciences at NVIDIA.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=kimberly%20#/session/1698191176989001uYJy">The Role of Generative AI in Modern Medicine</a>, featuring speakers from ARK Investment Management, NVIDIA, Microsoft and Scripps Research.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=priscilla#/session/1695916048653001DMnh">How Artificial Intelligence Is Powering the Future of Biomedicine</a>, featuring Priscilla Chan, cofounder and co-CEO of the Chan Zuckerberg Initiative, and Mona Flores, global head of medical AI at NVIDIA.</p>
<h2><strong>Retail and Consumer Packaged Goods</strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62335&amp;tab.allsessions=1700692987788001F1cG#/session/1695974018770001Nx65">Augmented Marketing in Beauty With Generative AI</a>, featuring Asmita Dubey, chief digital and marketing officer at L’Oréal.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S63057&amp;tab.allsessions=1700692987788001F1cG#/session/1702686433551001kArq">AI and the Radical Transformation of Marketing</a>, featuring Stephan Pretorius, chief technology officer at WPP.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62711&amp;tab.allsessions=1700692987788001F1cG#/session/1697478061549001Siwq">How Lowe’s Is Driving Innovation and Agility With AI</a>, featuring Azita Martin, vice president of artificial intelligence for retail and consumer packaged goods at NVIDIA, and Seemantini Godbole, executive vice president and chief digital and information officer at Lowe’s.</p>
<h2><strong>Telecommunications</strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search.industry=option_1559593261405#/session/1701877391479001i8Xl">Special Address: Three Ways Artificial Intelligence Is Transforming Telecommunications</a>, featuring Ronnie Vasishta, senior vice president of telecom at NVIDIA.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=Generative%20AI%20as%20an%20Innovative%20Accelerator%20in%20Telcos&amp;tab.allsessions=1700692987788001F1cG&amp;search.industry=option_1559593261405#/session/1696276835489001KIp8">Generative AI as an Innovative Accelerator in Telcos</a>, featuring Asif Hasan, cofounder of Quantiphi; Lilach Ilan, global head of business development, telco operations at NVIDIA; and Chris Halton, vice president of product strategy and innovation at Verizon.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62491&amp;tab.allsessions=1700692987788001F1cG#/session/1696278201820001fGOk">How Telcos Are Enabling National AI Infrastructure and Platforms</a>, featuring speakers from Indosat, NVIDIA, Singtel and Telconet.</p>
<h2><strong>Manufacturing</strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62159&amp;tab.allsessions=1700692987788001F1cG#/session/1695154321196001N4qD">Accelerating Aerodynamics Analysis at Mercedes-Benz</a>, featuring Liam McManus, technical product manager at Siemens; Erich Jehle-Graf of Mercedes Benz; and Ian Pegler, global business development, computer-aided design at NVIDIA.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62610&amp;tab.allsessions=1700692987788001F1cG#/session/1696547477246001wBZh">Omniverse-Based Fab Digital Twin Platform for Semiconductor Industry</a>, featuring Seokjin Youn, corporate vice president and head of the management information systems team at Samsung Electronics.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62613&amp;tab.allsessions=1700692987788001F1cG#/session/1696557359747001pzFS">Digitalizing Global Manufacturing Supply Chains With Digital Twins, Powered by OpenUSD</a>, featuring Kirk Fleischhaue, senior vice president at Foxconn.</p>
<h2><strong>Automotive</strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62645&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/session/1696634065530001aPuZ">Applying AI &amp; LLMs to Transform the Luxury Automotive Experience</a>, featuring Chrissie Kemp, chief data and digital product officer at Jaguar Land Rover.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62804&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/session/1699240468937001wa2p">Accelerating Automotive Workflows With Large Language Models</a>, featuring Bryan Goodman, director of artificial intelligence at Ford Motor Co.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62464&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/session/1696269758904001tFR9">How LLMs and Generative AI Will Enhance the Way We Experience Self-Driving Cars</a>, featuring Alex Kendall, cofounder and CEO of Wayve.</p>
<h2><strong>Robotics </strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62315&amp;tab.allsessions=1700692987788001F1cG#/session/1695934955725001WSFM">Robotics and the Role of AI: Past, Present and Future</a>, featuring Marc Raibert, executive director at The AI Institute, and Dieter Fox, senior director of robotics research at NVIDIA.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=S63374#/session/1707740763445001P6MR">Breathing Life into Disney’s Robotic Characters With Deep Reinforcement Learning</a>, featuring Mortiz Bächer, associate lab director of robotics at Disney Research.</p>
<h2><strong>Media and Entertainment </strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62681&amp;tab.allsessions=1700692987788001F1cG#/session/1697058319445001UuNS">Unlocking Creative Potential: The Synergy of AI and Human Creativity</a>, featuring Andrea Gagliano, senior director of data science, AI/ML at Getty Images.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S63212&amp;tab.allsessions=1700692987788001F1cG#/session/1705543534428001emzA">Beyond the Screen: Unraveling the Impact of AI in the Film Industry</a>, featuring Nikola Todorovic, cofounder and CEO at Wonder Dynamics; Chris Jacquemin, head of digital strategy at WME; and Sanja Fidler, vice president of AI research at NVIDIA.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=media.monks#/session/1695842420299001v3xv">Revolutionizing Fan Engagement: Unleashing the Power of AI in Software-Defined Production</a>, featuring ​​Lewis Smithingham, senior vice president of innovation and creative solutions at Media.Monks.</p>
<h2><strong>Energy</strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search.industry=1624401800869002y16T#/session/1694550684312001N8Iy">Panel: Building a Lower-Carbon Future With HPC and AI in Energy</a>, featuring speakers from NVIDIA, Shell, ExxonMobil, Schlumberger and Petrobas.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search.industry=1624401800869002y16T#/session/1694200404853001wkzy">The Increasing Complexity of the Electric Grid Demands Edge Computing</a>, featuring Marissa Hummon, chief technology officer at Utilidata.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search.industry=1624401800869002y16T#/session/1707787199510001WW9X">Advancing the Energy Transition With AI-Powered Innovation</a>, featuring Nefeli Moridis, developer relationship manager of subsurface, global energy team at NVIDIA; Owen O&#8217;Connell, senior vice president and chief information officer, services and operations at Shell; and Marc Spieler, senior managing director of energy at NVIDIA.</p>
<p><i>Browse a </i><a href="https://www.nvidia.com/gtc/sessions/business-insights/"><i>curated list</i><i> of GTC</i></a><i><a href="https://www.nvidia.com/gtc/sessions/business-insights/"> sessions</a> for business leaders of every technical level and area of interest.  </i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/industries-corp-blog-gtc24-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/industries-corp-blog-gtc24-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Live at GTC: Hear From Industry Leaders Using AI to Drive Innovation and Agility]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
	</channel>
</rss>
