<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Fri, 01 Mar 2024 17:04:28 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.4.3</generator>
	<item>
		<title>What Is Trustworthy AI?</title>
		<link>https://blogs.nvidia.com/blog/what-is-trustworthy-ai/</link>
		
		<dc:creator><![CDATA[Nikki Pope]]></dc:creator>
		<pubDate>Fri, 01 Mar 2024 17:00:24 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Corporate Responsibility]]></category>
		<category><![CDATA[Social Impact]]></category>
		<category><![CDATA[Trustworthy AI]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70030</guid>

					<description><![CDATA[Artificial intelligence, like any transformative technology, is a work in progress — continually growing in its capabilities and its societal impact. Trustworthy AI initiatives recognize the real-world effects that AI can have on people and society, and aim to channel that power responsibly for positive change. What Is Trustworthy AI? Trustworthy AI is an approach		<a class="read-more" href="https://blogs.nvidia.com/blog/what-is-trustworthy-ai/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p dir="ltr">Artificial intelligence, like any transformative technology, is a work in progress — continually growing in its capabilities and its societal impact. <a href="https://blogs.nvidia.com/blog/tag/trustworthy-ai/">Trustworthy AI initiatives</a> recognize the real-world effects that AI can have on people and society, and aim to channel that power responsibly for positive change.</p>
<h2 dir="ltr">What Is Trustworthy AI?</h2>
<p dir="ltr">Trustworthy AI is an approach to AI development that prioritizes safety and transparency for those who interact with it. <a href="https://developer.nvidia.com/blog/tag/trustworthy-ai/">Developers of trustworthy AI</a> understand that no model is perfect, and take steps to help customers and the general public understand how the technology was built, its intended use cases and its limitations.</p>
<p dir="ltr">In addition to complying with privacy and consumer protection laws, trustworthy AI models are tested for safety, security and mitigation of unwanted bias. They’re also transparent — providing information such as accuracy benchmarks or a description of the training dataset — to various audiences including regulatory authorities, developers and consumers.</p>
<h2 dir="ltr">Principles of Trustworthy AI</h2>
<p dir="ltr"><a href="https://www.nvidia.com/en-us/ai-data-science/trustworthy-ai/">Trustworthy AI principles</a> are foundational to NVIDIA’s end-to-end AI development. They have a simple goal: to enable trust and transparency in AI and support the work of partners, customers and developers.</p>
<h3 dir="ltr">Privacy: Complying With Regulations, Safeguarding Data</h3>
<p dir="ltr">AI is often described as data hungry. Often, the more data an algorithm is trained on, the more accurate its predictions.</p>
<p dir="ltr">But data has to come from somewhere. To develop trustworthy AI, it’s key to consider not just what data is legally available to use, but what data is socially responsible to use.</p>
<p dir="ltr">Developers of AI models that rely on data such as a person’s image, voice, artistic work or health records should evaluate whether individuals have provided appropriate consent for their personal information to be used in this way.</p>
<p dir="ltr">For institutions like hospitals and banks, building AI models means balancing the responsibility of keeping patient or customer data private while training a robust algorithm. NVIDIA has created technology that enables <a href="https://blogs.nvidia.com/blog/what-is-federated-learning/">federated learning</a>, where researchers develop AI models trained on data from multiple institutions without confidential information leaving a company’s private servers.</p>
<p dir="ltr"><a href="https://www.nvidia.com/en-gb/data-center/dgx-systems/">NVIDIA DGX systems</a> and <a href="https://developer.nvidia.com/flare">NVIDIA FLARE</a> software have enabled several federated learning projects in <a href="https://blogs.nvidia.com/blog/federated-learning-nature-medicine/">healthcare</a> and <a href="https://developer.nvidia.com/blog/using-federated-learning-to-bridge-data-silos-in-financial-services/">financial services</a>, facilitating secure collaboration by multiple data providers on more accurate, generalizable AI models for <a href="https://blogs.nvidia.com/blog/israel-medical-center-ai-startups-radiology/">medical image analysis</a> and <a href="https://blogs.nvidia.com/blog/ai-fraud-detection-rapids-triton-tensorrt-nemo/">fraud detection</a>.</p>
<h3 dir="ltr">Safety and Security: Avoiding Unintended Harm, Malicious Threats</h3>
<p dir="ltr">Once deployed, AI systems have real-world impact, so it’s essential they perform as intended to preserve user safety.</p>
<p dir="ltr">The freedom to use publicly available AI algorithms creates immense possibilities for positive applications, but also means the technology can be used for unintended purposes.</p>
<p dir="ltr">To help mitigate risks, <a href="https://blogs.nvidia.com/blog/ai-chatbot-guardrails-nemo/">NVIDIA NeMo Guardrails</a> keeps AI language models on track by allowing enterprise developers to set boundaries for their applications. Topical guardrails ensure that chatbots stick to specific subjects. Safety guardrails set limits on the language and data sources the apps use in their responses. Security guardrails seek to prevent malicious use of a large language model that’s connected to third-party applications or application programming interfaces.</p>
<p dir="ltr">NVIDIA Research is working with the DARPA-run SemaFor program to <a href="https://github.com/NVlabs/stylegan3-detector" target="_blank" rel="noopener">help digital forensics experts identify AI-generated images</a>. Last year, researchers published a novel method for <a href="https://arxiv.org/pdf/2302.07371.pdf" target="_blank" rel="noopener">addressing social bias using ChatGPT</a>. They’re also creating methods for <a href="https://research.nvidia.com/labs/nxp/avatar-fingerprinting/">avatar fingerprinting</a> — a way to detect if someone is using an AI-animated likeness of another individual without their consent.</p>
<p dir="ltr">To protect data and AI applications from security threats, <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100</a> and <a href="https://www.nvidia.com/en-us/data-center/h200/">H200 Tensor Core GPUs</a> are built with <a href="https://blogs.nvidia.com/blog/what-is-confidential-computing/">confidential computing</a>, which ensures sensitive data is protected while in use, whether deployed on premises, in the cloud or at the edge. <a href="https://www.nvidia.com/en-us/data-center/solutions/confidential-computing/">NVIDIA Confidential Computing</a> uses hardware-based security methods to ensure unauthorized entities can’t view or modify data or applications while they’re running — traditionally a time when data is left vulnerable.</p>
<h3 dir="ltr">Transparency: Making AI Explainable</h3>
<p dir="ltr">To create a trustworthy AI model, the algorithm can’t be a black box — its creators, users and stakeholders must be able to understand how the AI works to trust its results.</p>
<p dir="ltr">Transparency in AI is a set of best practices, tools and design principles that helps users and other stakeholders understand how an AI model was trained and how it works. <a href="https://blogs.nvidia.com/blog/what-is-explainable-ai/">Explainable AI</a>, or XAI, is a subset of transparency covering tools that inform stakeholders how an AI model makes certain predictions and decisions.</p>
<p dir="ltr">Transparency and XAI are crucial to establishing trust in AI systems, but there’s no universal solution to fit every kind of AI model and stakeholder. Finding the right solution involves a systematic approach to identify who the AI affects, analyze the associated risks and implement effective mechanisms to provide information about the AI system.</p>
<p dir="ltr"><a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">Retrieval-augmented generation</a>, or RAG, is a technique that advances AI transparency by connecting generative AI services to authoritative external databases, enabling models to cite their sources and provide more accurate answers. NVIDIA is helping developers get started with a <a href="https://www.nvidia.com/en-us/ai-data-science/ai-workflows/generative-ai-chatbots/">RAG workflow</a> that uses the <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/">NVIDIA NeMo</a> framework for developing and customizing generative AI models.</p>
<p dir="ltr">NVIDIA is also part of the National Institute of Standards and Technology’s U.S. Artificial Intelligence Safety Institute Consortium, or AISIC, to <a href="https://blogs.nvidia.com/blog/aisic-trustworthy-ai/">help create tools and standards for responsible AI development</a> and deployment. As a consortium member, NVIDIA will promote trustworthy AI by leveraging best practices for implementing AI model transparency.</p>
<p dir="ltr">And on NVIDIA’s hub for accelerated software, <a href="https://www.nvidia.com/en-us/gpu-cloud/">NGC</a>, <a href="https://developer.nvidia.com/blog/enhancing-ai-transparency-and-ethical-considerations-with-model-card/">model cards</a> offer detailed information about how each AI model works and was built. NVIDIA’s Model Card ++ format describes the datasets, training methods and performance measures used, licensing information, as well as specific ethical considerations.</p>
<h3 dir="ltr">Nondiscrimination: Minimizing Bias</h3>
<p dir="ltr">AI models are trained by humans, often using data that is limited by size, scope and diversity. To ensure that all people and communities have the opportunity to benefit from this technology, it’s important to reduce unwanted bias in AI systems.</p>
<p dir="ltr">Beyond following government guidelines and antidiscrimination laws, trustworthy AI developers mitigate potential unwanted bias by looking for clues and patterns that suggest an algorithm is discriminatory, or involves the inappropriate use of certain characteristics. Racial and gender bias in data are well-known, but other considerations include cultural bias and bias introduced during data labeling. To reduce unwanted bias, developers might incorporate different variables into their models.</p>
<p dir="ltr">Synthetic datasets offer one solution to reduce unwanted bias in training data used to develop AI for <a href="https://www.nvidia.com/en-us/self-driving-cars/">autonomous vehicles</a> and <a href="https://developer.nvidia.com/isaac-sim">robotics</a>. If data used to train self-driving cars underrepresents uncommon scenes such as extreme weather conditions or traffic accidents, synthetic data can help augment the diversity of these datasets to better represent the real world, helping improve AI accuracy.</p>
<p dir="ltr"><a href="https://developer.nvidia.com/omniverse/replicator">NVIDIA Omniverse Replicator</a>, a framework built on the <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> platform for creating and operating 3D pipelines and virtual worlds, helps developers set up custom pipelines for synthetic data generation. And by integrating the <a href="https://developer.nvidia.com/tao-toolkit">NVIDIA TAO Toolkit</a> for <a href="https://blogs.nvidia.com/blog/what-is-transfer-learning/">transfer learning</a> with Innotescus, a web platform for curating unbiased datasets for computer vision, developers can better <a href="https://developer.nvidia.com/blog/curating-data-for-transfer-learning-with-the-nvidia-tao-toolkit-and-innotescus/">understand dataset patterns and biases to help address statistical imbalances</a>.</p>
<p dir="ltr">Learn more about trustworthy AI on <a href="https://www.nvidia.com/en-us/ai-data-science/trustworthy-ai/">NVIDIA.com</a> and the <a href="https://blogs.nvidia.com/blog/tag/trustworthy-ai/">NVIDIA Blog</a>. For more on tackling unwanted bias in AI, <a href="https://www.nvidia.com/en-us/on-demand/session/gtcspring22-se2696/">watch this talk</a> from <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a> and attend the <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=S62411%2C%20S62221%2C%20S62594%2C%20S62292%2C%20S62300#/">trustworthy AI track</a> at the <a href="https://www.nvidia.com/gtc/pricing/">upcoming conference</a>, taking place March 18-21 in San Jose, Calif, and online.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/model-cards.png"
			type="image/png"
			width="1280"
			height="720"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/model-cards-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[What Is Trustworthy AI?]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Live at GTC: Hear From Industry Leaders Using AI to Drive Innovation and Agility</title>
		<link>https://blogs.nvidia.com/blog/industry-leaders-ai-innovation-gtc-2024/</link>
		
		<dc:creator><![CDATA[Ben Oliveri]]></dc:creator>
		<pubDate>Fri, 01 Mar 2024 16:00:28 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Driving]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Energy]]></category>
		<category><![CDATA[Financial Services]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[Industrial and Manufacturing]]></category>
		<category><![CDATA[Media and Entertainment]]></category>
		<category><![CDATA[Public Sector]]></category>
		<category><![CDATA[Retail]]></category>
		<category><![CDATA[Telecommunications]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70083</guid>

					<description><![CDATA[Enterprise execs across broad sectors to share their AI strategies and success stories.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Interest in new AI applications reached a fever pitch last year as business leaders began exploring AI pilot programs. This year, they’re focused on strategically implementing these programs to create new value and sharpen their competitive advantage.</p>
<p><a href="https://www.nvidia.com/gtc/?ncid=pa-srch-goog-789978-prsp&amp;_bt=690120344873&amp;_bk=nvidia%20gtc&amp;_bm=p&amp;_bn=g&amp;_bg=157308081494&amp;gad_source=1&amp;gclid=EAIaIQobChMI8ITYoOy6hAMVmZxaBR2EhQB-EAAYASAAEgKOmfD_BwE">GTC</a>, NVIDIA’s conference on AI and accelerated computing, set for March 18-21 at the San Jose Convention Center, will feature leaders across a broad swath of industries discussing how they’re charting the path to AI-driven innovation.</p>
<p>Execs from Bentley Systems, Lowe’s, Siemens and Verizon are among those sharing their companies’ AI journeys.</p>
<p><i>Don’t miss NVIDIA founder and CEO </i><a href="https://www.nvidia.com/gtc/keynote/?regcode=pa-srch-goog-143845-prsp&amp;ncid=pa-srch-goog-143845-prsp"><i>Jensen Huang’s GTC keynote on Monday, March 18</i></a><i>, at 1 p.m. PT.</i></p>
<h2><strong>AI Takes Center Stage in Enterprise Technology Priorities</strong></h2>
<p>Nearly three-quarters of C-suite executives plan to increase their company’s tech investments this year, according to a <a href="https://www.bcg.com/publications/2024/from-potential-to-profit-with-genai">BCG survey of C-suite executives</a>, and 89% rank AI and generative AI among their top three priorities. More than half expect AI to deliver cost savings, primarily through productivity gains, improved customer service and IT efficiencies.</p>
<p>However, challenges to driving value with AI remain, including reskilling workers, prioritizing the right AI use cases and developing a strategy to implement responsible AI.</p>
<p>Join us in person or online to learn how industry leaders are overcoming these challenges to thrive with AI.</p>
<p>Here’s a preview of top industry sessions:</p>
<h2><strong>Financial Services</strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search.industry=option_1559593199335&amp;search=Navigating%20the%20Opportunity%20for%20GenAI%20in%20Financial%20Services#/session/1696518068816001oKTP"><i>Navigating the Opportunity for Generative AI in Financial Services</i></a>, featuring speakers from NVIDIA, MasterCard, Capital One and Goldman Sachs.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62357"><i>Enterprise AI in Banking: How One Leader Is Investing in “AI First,”</i></a> featuring Alexandra V. Mousavizadeh, CEO of Evident, and Chintan Mehta, chief information officer and head of digital technology and innovation at Wells Fargo.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62506"><i>How PayPal Reduced Cloud Costs by up to 70% With Spark RAPIDS</i></a>, featuring Illay Chen, software engineer at PayPal.</p>
<h2><strong>Public Sector</strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62730&amp;tab.allsessions=1700692987788001F1cG#/session/1697653098220001o65m"><i>Generative AI Adoption and Operational Challenges in Government</i></a>, featuring speakers from Microsoft, NVIDIA and the U.S. Army.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62173&amp;tab.allsessions=1700692987788001F1cG#/session/1695253323624001BtLZ"><i>How to Apply Generative AI to Improve Cybersecurity</i></a>, featuring Bartley Richardson, director of cybersecurity engineering at NVIDIA.</p>
<h2><strong>Healthcare</strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=Generative%20AI%20is%20Accelerating%20Healthcare%20into%20One%20of%20the%20Largest%20Technology%20Industries&amp;tab.allsessions=1700692987788001F1cG&amp;search.industry=option_1559593230294#/session/1696538040602001SPK9"><i>Healthcare Is Adopting Generative AI, Becoming One of the Largest Tech Industries</i></a>, featuring Kimberly Powell, vice president of healthcare and life sciences at NVIDIA.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=kimberly%20#/session/1698191176989001uYJy"><i>The Role of Generative AI in Modern Medicine</i></a>, featuring speakers from ARK Investment Management, NVIDIA, Microsoft and Scripps Research.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=priscilla#/session/1695916048653001DMnh"><i>How Artificial Intelligence Is Powering the Future of Biomedicine</i></a>, featuring Priscilla Chan, cofounder and co-CEO of the Chan Zuckerberg Initiative, and Mona Flores, global head of medical AI at NVIDIA.</p>
<h2><strong>Retail and Consumer Packaged Goods</strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62335&amp;tab.allsessions=1700692987788001F1cG#/session/1695974018770001Nx65"><i>Augmented Marketing in Beauty With Generative AI</i></a>, featuring Asmita Dubey, chief digital and marketing officer at L’Oréal.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S63057&amp;tab.allsessions=1700692987788001F1cG#/session/1702686433551001kArq"><i>AI and the Radical Transformation of Marketing</i></a>, featuring Stephan Pretorius, chief technology officer at WPP.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62711&amp;tab.allsessions=1700692987788001F1cG#/session/1697478061549001Siwq"><i>How Lowe’s Is Driving Innovation and Agility With AI</i></a>, featuring Azita Martin, vice president of artificial intelligence for retail and consumer packaged goods at NVIDIA, and Seemantini Godbole, executive vice president and chief digital and information officer at Lowe’s.</p>
<h2><strong>Telecommunications</strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search.industry=option_1559593261405#/session/1701877391479001i8Xl"><i>Special Address: Three Ways Artificial Intelligence Is Transforming Telecommunications</i></a><i>, </i>featuring Ronnie Vasishta, senior vice president of telecom at NVIDIA.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=Generative%20AI%20as%20an%20Innovative%20Accelerator%20in%20Telcos&amp;tab.allsessions=1700692987788001F1cG&amp;search.industry=option_1559593261405#/session/1696276835489001KIp8"><i>Generative AI as an Innovative Accelerator in Telcos</i></a>, featuring Asif Hasan, cofounder of Quantiphi; Lilach Ilan, global head of business development, telco operations at NVIDIA; and Chris Halton, vice president of product strategy and innovation at Verizon.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62491&amp;tab.allsessions=1700692987788001F1cG#/session/1696278201820001fGOk"><i>How Telcos Are Enabling National AI Infrastructure and Platforms</i></a>, featuring speakers from Indosat, NVIDIA, Singtel and Telconet.</p>
<h2><strong>Manufacturing</strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62159&amp;tab.allsessions=1700692987788001F1cG#/session/1695154321196001N4qD"><i>Accelerating Aerodynamics Analysis at Mercedes-Benz</i></a>, featuring Liam McManus, technical product manager at Siemens; Erich Jehle-Graf of Mercedes Benz; and Ian Pegler, global business development, computer-aided design at NVIDIA.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62610&amp;tab.allsessions=1700692987788001F1cG#/session/1696547477246001wBZh"><i>Omniverse-Based Fab Digital Twin Platform for Semiconductor Industry</i></a>, featuring Seokjin Youn, corporate vice president and head of the management information systems team at Samsung Electronics.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62613&amp;tab.allsessions=1700692987788001F1cG#/session/1696557359747001pzFS"><i>Digitalizing Global Manufacturing Supply Chains With Digital Twins, Powered by OpenUSD</i></a>, featuring Kirk Fleischhaue, senior vice president at Foxconn.</p>
<h2><strong>Automotive</strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62645&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/session/1696634065530001aPuZ"><i>Applying AI &amp; LLMs to Transform the Luxury Automotive Experience</i></a>, featuring Chrissie Kemp, chief data and digital product officer at JLR (Jaguar Land Rover).</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62804&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/session/1699240468937001wa2p"><i>Accelerating Automotive Workflows With Large Language Models</i></a>, featuring Bryan Goodman, director of artificial intelligence at Ford Motor Co.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62464&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/session/1696269758904001tFR9"><i>How LLMs and Generative AI Will Enhance the Way We Experience Self-Driving Cars</i></a>, featuring Alex Kendall, cofounder and CEO of Wayve.</p>
<h2><strong>Robotics </strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62315&amp;tab.allsessions=1700692987788001F1cG#/session/1695934955725001WSFM"><i>Robotics and the Role of AI: Past, Present and Future</i></a>, featuring Marc Raibert, executive director at The AI Institute, and Dieter Fox, senior director of robotics research at NVIDIA.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=S63374#/session/1707740763445001P6MR"><i>Breathing Life into Disney’s Robotic Characters With Deep Reinforcement Learning</i></a>, featuring Mortiz Bächer, associate lab director of robotics at Disney Research.</p>
<h2><strong>Media and Entertainment </strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62681&amp;tab.allsessions=1700692987788001F1cG#/session/1697058319445001UuNS"><i>Unlocking Creative Potential: The Synergy of AI and Human Creativity</i></a>, featuring Andrea Gagliano, senior director of data science, AI/ML at Getty Images.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=S63212&amp;tab.allsessions=1700692987788001F1cG#/session/1705543534428001emzA">Beyond the Screen: Unraveling the Impact of AI in the Film Industry</a>, featuring Nikola Todorovic, cofounder and CEO at Wonder Dynamics; Chris Jacquemin, head of digital strategy at WME; and Sanja Fidler, vice president of AI research at NVIDIA.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=media.monks#/session/1695842420299001v3xv"><i>Revolutionizing Fan Engagement: Unleashing the Power of AI in Software-Defined Production</i></a>, featuring ​​Lewis Smithingham, senior vice president of innovation and creative solutions at Media.Monks.</p>
<h2><strong>Energy</strong></h2>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search.industry=1624401800869002y16T#/session/1694550684312001N8Iy"><i>Panel: Building a Lower-Carbon Future With HPC and AI in Energy</i></a>, featuring speakers from NVIDIA, Shell, ExxonMobil, Schlumberger and Petrobas.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search.industry=1624401800869002y16T#/session/1694200404853001wkzy"><i>The Increasing Complexity of the Electric Grid Demands Edge Computing</i></a>, featuring Marissa Hummon, chief technology officer at Utilidata.</p>
<p><i>Browse a </i><a href="https://www.nvidia.com/gtc/sessions/business-insights/"><i>curated list</i><i> of GTC</i></a><i><a href="https://www.nvidia.com/gtc/sessions/business-insights/"> sessions</a> for business leaders of every technical level and area of interest.  </i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/industries-corp-blog-gtc24-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/industries-corp-blog-gtc24-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Live at GTC: Hear From Industry Leaders Using AI to Drive Innovation and Agility]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Battle.net Leaps Into the Cloud With GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-battlenet-march-games-list/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 29 Feb 2024 14:00:55 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70064</guid>

					<description><![CDATA[GFN Thursday celebrates this leap day with the addition of a popular game store to the cloud. Stream the first titles from Blizzard Entertainment’s Battle.net, including Diablo IV, Overwatch 2, Call of Duty HQ and Hearthstone, now playable across more devices than ever. They’re all part of the 30 new games coming to GeForce NOW		<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-battlenet-march-games-list/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>GFN Thursday celebrates this leap day with the addition of a popular game store to the cloud.</p>
<p>Stream the first titles from Blizzard Entertainment’s Battle.net, including <i>Diablo IV, Overwatch 2, Call of Duty HQ </i>and <i>Hearthstone</i>, now playable across more devices than ever.</p>
<p>They’re all part of the 30 new games coming to <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> in March, with eight available this week.</p>
<p>Plus, Day Passes, <a href="https://blogs.nvidia.com/blog/ces-2024-geforce-now-activision-blizzard-day-passes-g-sync/">announced at CES</a>, are coming to the cloud next week, enabling gamers to experience the benefits of GeForce NOW <a href="https://www.nvidia.com/en-us/geforce-now/memberships/">Ultimate and Priority memberships</a> for 24 hours at a time.</p>
<h2><b>Welcome to the Cloud</b></h2>
<figure id="attachment_70075" aria-describedby="caption-attachment-70075" style="width: 672px" class="wp-caption aligncenter"><img fetchpriority="high" decoding="async" class="size-large wp-image-70075" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/Diablo.IV_.-Screenshot-672x378.jpg" alt="Diablo IV on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/Diablo.IV_.-Screenshot-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Diablo.IV_.-Screenshot-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Diablo.IV_.-Screenshot-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Diablo.IV_.-Screenshot-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Diablo.IV_.-Screenshot-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Diablo.IV_.-Screenshot-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Diablo.IV_.-Screenshot-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Diablo.IV_.-Screenshot-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Diablo.IV_.-Screenshot-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70075" class="wp-caption-text"><em>More cloud gaming friends.</em></figcaption></figure>
<p>Battle.net is Blizzard’s digital storefront, a gateway to adventures in the Blizzard universe and home to a vibrant gaming community.</p>
<p>Members who own <i>Diablo IV, Overwatch 2, Call of Duty HQ </i>and <i>Hearthstone </i>on Battle.net can now stream these triple-A titles from <a href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA GeForce RTX</a>-powered servers in the cloud without worrying about hardware specs or long download times.</p>
<figure id="attachment_70065" aria-describedby="caption-attachment-70065" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" class="size-large wp-image-70065" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/01_Screenshot-1-672x378.jpg" alt="Hearthstone on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/01_Screenshot-1-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/01_Screenshot-1-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/01_Screenshot-1-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/01_Screenshot-1-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/01_Screenshot-1-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/02/01_Screenshot-1-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/02/01_Screenshot-1-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/01_Screenshot-1-1280x720.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/02/01_Screenshot-1.jpg 1920w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70065" class="wp-caption-text"><em>Cloud gamers have heart.</em></figcaption></figure>
<p>Battle the forces of evil in the dark, treacherous world of <i>Diablo IV</i>’s Sanctuary at up to 4K resolution and 120 frames per second with an <a href="http://www.geforcenow.com">Ultimate membership</a>, even on under-powered devices. Assemble a deck to cast legendary spells in <i>Hearthstone</i>, and engage in epic firefights in <i>Overwatch 2 </i>and <i>Call of Duty HQ</i> at ultra-low latency thanks to the power of <a href="https://www.nvidia.com/en-us/geforce/technologies/reflex/">NVIDIA Reflex</a> technology. Read this <a href="https://nvidia.custhelp.com/app/answers/detail/a_id/5462">article</a> and search for <i>Hearthstone</i> for more details on supported devices for this title.</p>
<p>Get ready to play Blizzard and Activision’s top-quality games anytime, anywhere. Battle.net joins supported platforms on GeForce NOW, including Steam, Epic Games Store, Xbox, Ubisoft Connect and GOG.com.</p>
<h2><b>Not Mad at March</b></h2>
<figure id="attachment_70068" aria-describedby="caption-attachment-70068" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" class="size-large wp-image-70068" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-welcome-to-paradize-tw-li-2048x1024-1-672x336.jpg" alt="Welcome to ParadiZe on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-welcome-to-paradize-tw-li-2048x1024-1-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-welcome-to-paradize-tw-li-2048x1024-1-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-welcome-to-paradize-tw-li-2048x1024-1-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-welcome-to-paradize-tw-li-2048x1024-1-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-welcome-to-paradize-tw-li-2048x1024-1-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-welcome-to-paradize-tw-li-2048x1024-1-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-welcome-to-paradize-tw-li-2048x1024-1-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-welcome-to-paradize-tw-li-2048x1024-1-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-welcome-to-paradize-tw-li-2048x1024-1.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70068" class="wp-caption-text"><em>“A wasteland I like to call my home.”</em></figcaption></figure>
<p>Imagine a paradise … infested with zombies! In <i>Welcome to ParadiZe</i> — now available for members to stream — capture, control and teach zombies to farm or fight in the beautiful country of ParadiZe. Explore the world’s unique flora and fauna while using the zombies to defend the camp and do the dirty work.</p>
<p>In addition, members can look for the following this week:<i></i></p>
<ul>
<li><i>STAR WARS: Dark Forces Remaster </i>(New release on <a href="https://store.steampowered.com/app/2292260?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb. 28)</li>
<li><i>Space Engineers </i>(New release on <a href="https://www.xbox.com/games/store/space-engineers/9NLV3X229LG1?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass, Feb. 29)</li>
<li><i>Welcome to ParadiZe </i>(New release on <a href="https://store.steampowered.com/app/1519090?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb. 29)</li>
<li><i>Call of Duty HQ </i>(<a href="https://shop.battle.net/family/call-of-duty?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
<li><i>Diablo IV </i>(<a href="https://shop.battle.net/product/diablo-iv?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
<li><i>Fort Solis</i> (<a href="https://store.steampowered.com/app/1931730?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Hearthstone </i>(<a href="https://shop.battle.net/product/hearthstone?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
<li><i>Overwatch 2 </i>(<a href="https://shop.battle.net/product/overwatch?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
</ul>
<p>Plus, check out what the rest of March looks like:</p>
<ul>
<li><i>The Thaumaturge</i> (New release on <a href="https://store.steampowered.com/app/1684350?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 4)</li>
<li><i>Classified: France &#8217;44 </i>(New release on <a href="https://store.steampowered.com/app/2085370?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 5)</li>
<li><i>Expeditions: A MudRunner Game </i>(New release on <a href="https://store.steampowered.com/app/2477340?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 5)</li>
<li><i>Warhammer 40,000: Boltgun</i> (New release on Xbox, available on PC Game Pass, Mar. 5)</li>
<li><i>Winter Survival </i>(New release on <a href="https://store.steampowered.com/app/1394960?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 6)</li>
<li><i>Taxi Life: A City Driving Simulator </i>(New release on <a href="https://store.steampowered.com/app/1351240?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 7)</li>
<li><i>Hellbreach: Vegas </i>(New release on <a href="https://store.steampowered.com/app/1691320?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 11)</li>
<li><i>Crown Wars: The Black Prince </i>(New release on <a href="https://store.steampowered.com/app/1658920?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 14)</li>
<li><i>Outcast &#8211; A New Beginning </i>(New release on <a href="https://store.steampowered.com/app/1013140?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 15)</li>
<li><i>Alone in the Dark </i>(New release on <a href="https://store.steampowered.com/app/1310410?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 20)</li>
<li><i>Breachway </i>(New release on <a href="https://store.steampowered.com/app/2118810?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 22)</li>
<li><i>Palia </i>(New release on <a href="https://store.steampowered.com/app/2707930?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 25)</li>
<li><i>Bulwark: Falconeer Chronicles </i>(New release on <a href="https://store.steampowered.com/app/290100?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 26)</li>
<li><i>Millennia </i>(New release on <a href="https://store.steampowered.com/app/1268590?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 26)</li>
<li><i>Outpost: Infinity Siege </i>(New release on <a href="https://store.steampowered.com/app/1566690?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 26)</li>
<li><i>SOUTH PARK: SNOW DAY! </i>(New release on <a href="https://store.steampowered.com/app/1214650?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Mar. 26)</li>
<li><i>Balatro</i> (<a href="https://store.steampowered.com/app/2379780?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>PARANORMASIGHT: The Seven Mysteries of Honjo</i> (<a href="https://store.steampowered.com/app/2106840?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Portal: Revolution</i> (<a href="https://store.steampowered.com/app/601360?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>STAR OCEAN THE SECOND STORY R</i> (<a href="https://store.steampowered.com/app/2238900?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>STAR OCEAN THE SECOND STORY R &#8211; DEMO</i> (<a href="https://store.steampowered.com/app/2441280?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Undisputed</i> (<a href="https://store.steampowered.com/app/1451190?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<h2><b>Fantastic February</b></h2>
<p>In addition to the 27 games announced last month, five more joined the <a href="http://play.geforcenow.com">GeForce NOW library</a>:<i></i></p>
<ul>
<li><i>Deep Rock Galactic: Survivor</i> (New release on <a href="https://store.steampowered.com/app/2321470?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb. 14)</li>
<li><i>Goat Simulator 3</i> (New release on <a href="https://store.steampowered.com/app/850190?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb. 15)</li>
<li><i>Le Mans Ultimate</i> (New release on <a href="https://store.steampowered.com/app/2399420?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb. 20)</li>
<li><i>art of rally </i>(<a href="https://www.xbox.com/games/store/art-of-rally/9P6JQDDZ2MQB?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Halo Infinite </i>(<a href="https://store.steampowered.com/app/1240440?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.xbox.com/en-US/games/store/halo-infinite/9PP5G1F0C2B6/0010?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
</ul>
<p><i>The Thaumaturge</i> didn’t make it in February due to a shift in its launch date, and is included in the March games list.</p>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Wait for it&#8230;. <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f440.png" alt="👀" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="https://t.co/tXdyoeuQSP">pic.twitter.com/tXdyoeuQSP</a></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1762885451029864804?ref_src=twsrc%5Etfw">February 28, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-thursday-2-29-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-thursday-2-29-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Battle.net Leaps Into the Cloud With GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>What Is Sovereign AI?</title>
		<link>https://blogs.nvidia.com/blog/what-is-sovereign-ai/</link>
		
		<dc:creator><![CDATA[Keith Strier]]></dc:creator>
		<pubDate>Wed, 28 Feb 2024 20:31:53 +0000</pubDate>
				<category><![CDATA[Explainer]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[5G]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Energy]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70078</guid>

					<description><![CDATA[Nations have long invested in domestic infrastructure to advance their economies, control their own data and take advantage of technology opportunities in areas such as transportation, communications, commerce, entertainment and healthcare. AI, the most important technology of our time, is turbocharging innovation across every facet of society. It’s expected to generate trillions of dollars in		<a class="read-more" href="https://blogs.nvidia.com/blog/what-is-sovereign-ai/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Nations have long invested in domestic infrastructure to advance their economies, control their own data and take advantage of technology opportunities in areas such as transportation, communications, commerce, entertainment and healthcare.</p>
<p>AI, the most important technology of our time, is turbocharging innovation across every facet of society. It’s expected to generate trillions of dollars in economic dividends and productivity gains.</p>
<p>Countries are investing in sovereign AI to develop and harness such benefits on their own. Sovereign AI refers to a nation’s capabilities to produce artificial intelligence using its own infrastructure, data, workforce and business networks.</p>
<h2><b>Why Sovereign AI Is Important</b></h2>
<p>The global imperative for nations to invest in sovereign AI capabilities has grown since the rise of <a href="https://www.nvidia.com/en-us/glossary/generative-ai/" target="_blank" rel="noopener">generative AI</a>, which is reshaping markets, challenging governance models, inspiring new industries and transforming others — from gaming to biopharma. It’s also rewriting the nature of work, as people in many fields start using AI-powered “copilots.”</p>
<p>Sovereign AI encompasses both physical and data infrastructures. The latter includes sovereign foundation models, such as <a href="https://www.nvidia.com/en-us/glossary/large-language-models/" target="_blank" rel="noopener">large language models</a>, developed by local teams and trained on local datasets to promote inclusiveness with specific dialects, cultures and practices.</p>
<p>For example, speech AI models can help <a href="https://blogs.nvidia.com/blog/te-hiku-media-maori-speech-ai/" target="_blank" rel="noopener">preserve, promote and revitalize indigenous languages</a>. And <a href="https://blogs.nvidia.com/blog/what-are-large-language-models-used-for/" target="_blank" rel="noopener">LLMs</a> aren’t just for teaching AIs human languages, but for writing software code, protecting consumers from financial fraud, teaching robots physical skills and much more.</p>
<p>In addition, as artificial intelligence and <a href="https://blogs.nvidia.com/blog/what-is-accelerated-computing/" target="_blank" rel="noopener">accelerated computing</a> become increasingly critical tools for <a href="https://blogs.nvidia.com/blog/ai-energy-study/" target="_blank" rel="noopener">combating climate change</a>, <a href="https://blogs.nvidia.com/blog/energy-efficient-ai-industries/" target="_blank" rel="noopener">boosting energy efficiency</a> and <a href="https://blogs.nvidia.com/blog/generative-ai-cybersecurity/" target="_blank" rel="noopener">protecting against cybersecurity threats</a>, sovereign AI has a pivotal role to play in equipping every nation to bolster its sustainability efforts.</p>
<h2><b>Factoring In AI Factories</b></h2>
<p>Comprising new, essential infrastructure for AI production are “AI factories,” where data comes in and intelligence comes out. These are next-generation data centers that host advanced, full-stack accelerated computing platforms for the most computationally intensive tasks.</p>
<p>Nations are building up domestic computing capacity through various models. Some are procuring and operating sovereign AI clouds in collaboration with state-owned <a href="https://www.nvidia.com/en-us/industries/telecommunications/ai-factories/">telecommunications providers</a> or utilities. Others are sponsoring local cloud partners to provide a shared AI computing platform for public- and private-sector use.</p>
<p>“The AI factory will become the bedrock of modern economies across the world,” NVIDIA founder and CEO Jensen Huang said in a recent media Q&amp;A.</p>
<h2><b>Sovereign AI Efforts Underway</b></h2>
<p>Nations around the world are already investing in sovereign AI.</p>
<p>Since 2019, NVIDIA’s <a href="https://www.nvidia.com/en-us/industries/global-public-sector/">AI Nations initiative</a> has helped countries spanning every region of the globe to build sovereign AI capabilities, including ecosystem enablement and workforce development, creating the conditions for engineers, developers, scientists, entrepreneurs, creators and public sector officials to pursue their AI ambitions at home.</p>
<p>France-based <a href="https://s3.fr-par.scw.cloud/iliad-strapi/DP_iliad_AI_260923_Eng_462ff3265c.pdf" target="_blank" rel="noopener">Scaleway</a>, a subsidiary of the iliad Group, is building Europe’s most powerful cloud-native AI supercomputer. The <a href="https://www.nvidia.com/en-us/data-center/dgx-superpod/" target="_blank" rel="noopener">NVIDIA DGX SuperPOD</a> comprises 127 DGX H100 systems, representing 1,016 <a href="https://www.nvidia.com/en-us/data-center/h100/" target="_blank" rel="noopener">NVIDIA H100 Tensor Core GPUs</a> interconnected by <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener">NVIDIA NVLink technology</a> and the <a href="https://www.nvidia.com/en-us/networking/quantum2/" target="_blank" rel="noopener">NVIDIA Quantum-2 InfiniBand platform</a>. NVIDIA DGX systems also include <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/" target="_blank" rel="noopener">NVIDIA AI Enterprise</a> software for secure, supported and stable AI development and deployment.</p>
<p>Swisscom Group, majority-owned by the Swiss government, recently announced its Italian subsidiary, <a href="https://www.thefastmode.com/technology-solutions/34250-fastweb-leverages-nvidia-dgx-supercomputer-to-develop-italian-genai-platform" target="_blank" rel="noopener">Fastweb</a>, will build Italy’s first and most powerful NVIDIA DGX-powered supercomputer — also using NVIDIA AI Enterprise software — to develop the first LLM natively trained in the Italian language.</p>
<p>With these NVIDIA technologies and its own cloud and cybersecurity infrastructures, Fastweb plans to launch an end-to-end system with which Italian companies, public-administration organizations and startups can develop generative AI applications for any industry.</p>
<p>The government of India has also announced sovereign AI initiatives promoting workforce development, sustainable computing and private-sector investment in domestic compute capacity. India-based <a href="https://nvidianews.nvidia.com/news/tata-partners-with-nvidia-to-build-large-scale-ai-infrastructure" target="_blank" rel="noopener">Tata Group</a>, for example, is building a large-scale AI infrastructure powered by the <a href="https://www.nvidia.com/en-us/data-center/grace-hopper-superchip/" target="_blank" rel="noopener">NVIDIA GH200 Grace Hopper Superchip</a>, while <a href="https://nvidianews.nvidia.com/news/reliance-and-nvidia-partner-to-advance-ai-in-india-for-india" target="_blank" rel="noopener">Reliance Industries</a> will develop a foundation LLM tailored for generative AI and trained on the diverse languages of the world’s most populous nation. NVIDIA is also working with India’s top universities to support and expand local researcher and developer communities.</p>
<p>Japan is going all in with sovereign AI, collaborating with NVIDIA to upskill its workforce, support Japanese language model development, and expand AI adoption for natural disaster response and climate resilience. These efforts include public-private partnerships that are incentivizing leaders like <a href="https://nvidianews.nvidia.com/news/softbank-telecom-data-centers-grace-hopper" target="_blank" rel="noopener">SoftBank Corp.</a> to collaborate with NVIDIA on building a generative AI platform for 5G and 6G applications as well as a network of distributed AI factories.</p>
<p>Finally, Singapore is fostering a range of sovereign AI programs, including by partnering with NVIDIA to upgrade its National Super Computer Center, or NSCC, with NVIDIA H100 GPUs. In addition, <a href="https://blogs.nvidia.com/blog/singtel-sovereign-ai/" target="_blank" rel="noopener">Singtel</a>, a leading communications services provider building energy-efficient AI factories across Southeast Asia, is accelerated by <a href="https://www.nvidia.com/en-us/data-center/technologies/hopper-architecture/" target="_blank" rel="noopener">NVIDIA Hopper architecture GPUs</a> and NVIDIA AI reference architectures.</p>
<p><i>Read more about </i><a href="https://blogs.nvidia.com/blog/world-governments-summit/" target="_blank" rel="noopener"><i>sovereign AI and its transformative potential</i></a><i>.</i></p>
<p><em>Explore <a title="Original URL: https://www.nvidia.com/gtc/sessions/generative-ai/?nvid=nv-int-txtad-141445 Click to follow link." href="https://www.nvidia.com/gtc/sessions/generative-ai/?nvid=nv-int-txtad-141445" data-outlook-id="97194cbf-406f-48c7-a83a-cd48b46329c6">generative AI</a> sessions and experiences at <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>, the global conference on AI and accelerated computing, running March 18-21 in San Jose, Calif., and online.</em></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/sovereign-ai-explainer-1280x680-1-scaled.jpeg"
			type="image/jpeg"
			width="2048"
			height="1024"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/sovereign-ai-explainer-1280x680-1-842x450.jpeg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[What Is Sovereign AI?]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>And … Action! Cuebric CEO Provides Insights Into Filmmaking Using AI</title>
		<link>https://blogs.nvidia.com/blog/pinar-demirdag-cuebric/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Wed, 28 Feb 2024 14:00:55 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[The AI Podcast]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70034</guid>

					<description><![CDATA[These days, just about everyone is a content creator. But can generative AI help make people create high-quality films and other content affordably? Find out from Pinar Seyhan Demirdag, cofounder and CEO of Cuebric, during his conversation with NVIDIA AI Podcast host Noah Kravitz. Cuebric is on a mission to offer new solutions in filmmaking		<a class="read-more" href="https://blogs.nvidia.com/blog/pinar-demirdag-cuebric/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>These days, just about everyone is a content creator. But can generative AI help make people create high-quality films and other content affordably? Find out from Pinar Seyhan Demirdag, cofounder and CEO of <a href="https://cuebric.com/">Cuebric</a>, during his conversation with NVIDIA <a href="https://blogs.nvidia.com/ai-podcast/">AI Podcast</a> host Noah Kravitz.</p>
<p>Cuebric is on a mission to offer new solutions in filmmaking and content creation through immersive, two-and-a-half-dimensional cinematic environments. Its AI-powered application aims to help creators quickly bring their ideas to life, making high-quality production more accessible.</p>
<p>Demirdag discusses how Cuebric uses <a href="https://courses.nvidia.com/courses/course-v1:DLI+S-FX-07+V1">generative AI</a> to enable the creation of engaging environments affordably. Listen in to find out about the current landscape of content creation, the role of AI in simplifying the creative process, and Cuebric’s participation in NVIDIA’s <a href="https://www.nvidia.com/gtc/">GTC technology conference</a>.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1759544883%3Fsecret_token%3Ds-4wmCp5pXKIv&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="Exploring Filmmaking with Cuebric's AI: Insights from Pinar Seyhan Demirdag - Ep. 314" href="https://soundcloud.com/theaipodcast/pinar-demirdag-cuebric/s-4wmCp5pXKIv" target="_blank" rel="noopener">Exploring Filmmaking with Cuebric&#8217;s AI: Insights from Pinar Seyhan Demirdag &#8211; Ep. 314</a></div>
<p><em>Explore <a title="Original URL: https://www.nvidia.com/gtc/sessions/generative-ai/?nvid=nv-int-txtad-141445 Click to follow link." href="https://www.nvidia.com/gtc/sessions/generative-ai/?nvid=nv-int-txtad-141445" data-outlook-id="97194cbf-406f-48c7-a83a-cd48b46329c6">generative AI</a> sessions and experiences at <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>, the global conference on AI and accelerated computing, running March 18-21 in San Jose, Calif., and online.</em></p>
<h2><strong>Time Stamps:</strong></h2>
<p>1:15: Getting to know Pinar Seyhan Demirdag and Cuebric<br />
2:30: The beginnings and goals of Cuebric<br />
4:45: How Cuebric’s AI application works for filmmakers<br />
9:00: Advantages of AI in content creation<br />
13:20: Making high-quality production budget-friendly<br />
17:35: The future of AI in creative endeavors<br />
22:00: Cuebric at NVIDIA GTC</p>
<h2>You Might Also Like…</h2>
<h3><a href="https://soundcloud.com/theaipodcast/edtech">MIT’s Anant Agarwal on AI in Education – Ep. 197</a></h3>
<p>AI could help students work smarter, not harder. Anant Agarwal, founder of edX and chief platform officer at 2U, shares his vision for the future of online education and the impact of AI in revolutionizing the learning experience.</p>
<h3><a href="https://soundcloud.com/theaipodcast/university-of-florida-ai">UF Provost Joe Glover on Building a Leading AI University – Ep. 186</a></h3>
<p>Joe Glover, provost and senior vice president of academic affairs at the University of Florida, discusses the university’s efforts to implement AI across all aspects of higher education, including a public-private partnership with NVIDIA that has helped transform UF into one of the leading AI universities in the country.</p>
<h3><a href="https://soundcloud.com/theaipodcast/nvidias-marc-hamilton-on-building-the-cambridge-1-supercomputer-during-a-pandemic">NVIDIA’s Marc Hamilton on Building the Cambridge-1 Supercomputer During a Pandemic – Ep. 137</a></h3>
<p>Cambridge-1, the U.K.’s most powerful supercomputer, ranks among the world’s top 3 most energy-efficient supercomputers and was built to help healthcare researchers make new discoveries. Marc Hamilton, vice president of solutions architecture and engineering at NVIDIA, speaks on how he remotely oversaw its construction.</p>
<h2><strong>Subscribe to the AI Podcast</strong></h2>
<p>Get the <a href="https://blogs.nvidia.com/ai-podcast/">AI Podcast</a> through <a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439">iTunes</a>, <a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjI2NDAzNDEzMy9zb3VuZHMucnNz">Google Podcasts</a>, <a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm">Google Play</a>, <a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">Amazon Music</a>, <a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us">Castbox</a>, DoggCatcher, <a href="https://overcast.fm/itunes1186480811/the-ai-podcast">Overcast</a>, <a href="https://player.fm/series/the-ai-podcast">PlayerFM</a>, Pocket Casts, <a href="http://www.podbay.fm/show/1186480811">Podbay</a>, <a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast">PodBean</a>, PodCruncher, PodKicker, <a href="https://soundcloud.com/theaipodcast">Soundcloud</a>, <a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L">Spotify</a>, <a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr">Stitcher</a> and <a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/">TuneIn</a>.</p>
<h4>Make the AI Podcast better: Have a few minutes to spare? Fill out <a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short">this listener survey</a>.</h4>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/Cuebric-App-3.png"
			type="image/png"
			width="1920"
			height="1080"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/Cuebric-App-3-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[And … Action! Cuebric CEO Provides Insights Into Filmmaking Using AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Time to Skill Up: Game Reviewer Ralph Panebianco Wields NVIDIA RTX for the Win</title>
		<link>https://blogs.nvidia.com/blog/skillup-adobe-premiere-pro-photoshop/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Wed, 28 Feb 2024 14:00:13 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70040</guid>

					<description><![CDATA[YouTube content creator Ralph Panebianco really, really loves video games. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/" target="_blank" rel="noopener"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. We’re also deep diving on new </i><a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/"><i>GeForce RTX 40 Series GPU</i></a><i> features, technologies and resources, and how they dramatically accelerate content creation.</i></p>
<p>YouTube content creator Ralph Panebianco really, <i>really</i> loves video games.</p>
<p>Since getting an original Nintendo Entertainment System at the age of four, Panebianco, this week’s featured <i>In the NVIDIA Studio</i> creator, has spent much of his free time playing video games. He pursued a career in gaming in his native country of Australia before pivoting to content creation, opening a YouTube channel called <a href="https://www.youtube.com/c/SkillUp">Skill Up</a>, where he reviews the latest video games.</p>
<p>“When I wasn’t playing video games, I was reading about them, and now I get to talk about them for a living,” he said.</p>
<p>And calling all art fans: the latest Studio Standouts video features film noir-themed artwork brought to life with dramatic, monochromatic flair.</p>
<p><iframe loading="lazy" title="Film Noir: A Community Digital Art Showcase | NVIDIA Studio Standouts" width="500" height="281" src="https://www.youtube.com/embed/Uzp-5r8DluY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Video Editing Skillz</b></h2>
<p>Panebianco works with his partner to create in-depth, insightful reviews of the latest video games on his Skill Up YouTube channel, which has garnered nearly 1 million subscribers. Below is a recent video reviewing <i>Pacific Drive, </i>a title available on the <a href="https://www.nvidia.com/en-us/geforce-now/">NVIDIA GeForce NOW</a> cloud gaming service, powered by GeForce RTX GPUs.</p>
<p><iframe loading="lazy" title="I strongly recommend: Pacific Drive (Review)" width="500" height="281" src="https://www.youtube.com/embed/WXxJ_66ksD4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>“Creatively, we don’t view game reviews as functional buying guides with a list of pros and cons,” said Panebianco. “We view reviews as a chance to crack a game open and really show the audience what makes it tick. They’re sort of mini-essays on game design, delving deep into why specific game mechanics do or don’t work.”</p>
<p>The content creation process begins with booting up the game on his PC, powered by the recently launched <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4080-family/">GeForce RTX 4080 SUPER</a> graphics card. This allows the Skill Up team to tap <a href="https://www.nvidia.com/en-us/geforce/rtx/">RTX ray tracing</a> and <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">NVIDIA DLSS</a> — breakthrough technologies that use AI to create additional frames and improve image quality.</p>
<p>He records video footage primarily using <a href="https://www.nvidia.com/en-us/geforce/geforce-experience/">GeForce Experience</a>, a companion to NVIDIA GeForce GPUs that enables users to capture assets, optimize game settings and keep drivers up to date, among other features.</p>
<p>When footage requires high-dynamic range, the team uses the OBS Studio open-source software with AV1 hardware encoding to achieve <a href="https://blogs.nvidia.com/blog/av1-obs29-youtube/">40% more efficient encoding</a> on average than H.264 and deliver higher quality than competing GPUs.</p>
<p>“The AV1 encoder is ridiculously efficient in terms of file size,” he said.</p>
<figure id="attachment_70041" aria-describedby="caption-attachment-70041" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-obs-1280w.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-70041" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-obs-1280w-672x475.jpg" alt="" width="672" height="475" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-obs-1280w-672x475.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-obs-1280w-400x283.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-obs-1280w-768x543.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-obs-1280w-636x450.jpg 636w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-obs-1280w-304x215.jpg 304w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-obs-1280w-141x100.jpg 141w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-obs-1280w.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-70041" class="wp-caption-text">NVIDIA GPUs and OBS Studio software work in synergy.</figcaption></figure>
<p>Once the footage is ready, Panebianco writes a video script in Microsoft Word and then records himself, using Audacity. He uses the AI-powered <a href="https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/">NVIDIA Broadcast</a> app, free for RTX GPU owners, to eliminate background noise and achieve professional studio quality.</p>
<p>Panebianco then hands off the files to his editor for production in Adobe Premiere Pro, where a number of GPU-accelerated, AI-powered features such as Enhance Speech, Auto Reframe and Unsharp Mask help speed the video editing process.</p>
<figure id="attachment_70047" aria-describedby="caption-attachment-70047" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-nvdec-1280w.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-70047" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-nvdec-1280w-672x359.jpg" alt="" width="672" height="359" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-nvdec-1280w-672x359.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-nvdec-1280w-400x213.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-nvdec-1280w-768x410.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-nvdec-1280w-842x450.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-nvdec-1280w-403x215.jpg 403w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-nvdec-1280w-188x100.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-nvdec-1280w.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-70047" class="wp-caption-text">NVIDIA’s GPU-accelerated video decoder (NVDEC) enables smooth playback and scrubbing of high-resolution videos.</figcaption></figure>
<p>Next, Panebianco exports the final files twice as fast thanks to the dual AV1 encoders in his RTX GPU. Lastly, his editor creates a YouTube thumbnail in Adobe Photoshop, and then the video is ready for publishing.</p>
<figure id="attachment_70050" aria-describedby="caption-attachment-70050" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-photoshop-1280w.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-70050" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-photoshop-1280w-672x359.jpg" alt="" width="672" height="359" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-photoshop-1280w-672x359.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-photoshop-1280w-400x213.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-photoshop-1280w-768x410.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-photoshop-1280w-842x450.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-photoshop-1280w-403x215.jpg 403w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-photoshop-1280w-188x100.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-photoshop-1280w.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-70050" class="wp-caption-text">Adobe Photoshop has over 30 GPU-accelerated features that help modify and adjust images smoothly and quickly.</figcaption></figure>
<p>“Almost my entire workflow was enhanced by NVIDIA’s hardware,” Panebianco shared. “It’s not just about the hardware making for efficient encoding or lightning-fast, hardware-enabled rendering — it’s about the end-to-end toolset.”</p>
<p>Panebianco has words of wisdom for aspiring content creators.</p>
<p>“Worry less about the numbers and more about the quality,” he said. “The metrics grind pays little in the way of dividends, but putting out truly excellent content is an almost failure-proof path to growth.”</p>
<figure id="attachment_70053" aria-describedby="caption-attachment-70053" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-featured-setup-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-70053" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-featured-setup-1280w-672x248.png" alt="" width="672" height="248" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-featured-setup-1280w-672x248.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-featured-setup-1280w-400x148.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-featured-setup-1280w-768x284.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-featured-setup-1280w-842x311.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-featured-setup-1280w-406x150.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-featured-setup-1280w-188x69.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-ralph-panebianco-wk98-featured-setup-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-70053" class="wp-caption-text">Video game content creator Ralph Panebianco.</figcaption></figure>
<p>Catch Panebianco’s video game reviews on the <a href="https://www.youtube.com/@SkillUp/featured">Skill Up YouTube channel</a>.</p>
<p><i>Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/skill-up-nv-blog-header-preview-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/skill-up-nv-blog-header-preview-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Time to Skill Up: Game Reviewer Ralph Panebianco Wields NVIDIA RTX for the Win]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Rack ‘n’ Roll: NVIDIA Grace Hopper Systems Gather at GTC</title>
		<link>https://blogs.nvidia.com/blog/mgx-accelerated-systems-gtc/</link>
		
		<dc:creator><![CDATA[Ivan Goldwasser]]></dc:creator>
		<pubDate>Tue, 27 Feb 2024 16:00:36 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[generative AI]]></category>
		<category><![CDATA[GPU Computing]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[NVIDIA Hopper Architecture]]></category>
		<category><![CDATA[NVIDIA Quantum-2]]></category>
		<category><![CDATA[NVLink]]></category>
		<category><![CDATA[Recommender Systems]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70025</guid>

					<description><![CDATA[The spirit of software legend Grace Hopper will live on at NVIDIA GTC. Accelerated systems using powerful processors — named in honor of the pioneer of programming — will be on display at the global AI conference running March 18-21, ready to take computing to the next level. System makers will show more than 500		<a class="read-more" href="https://blogs.nvidia.com/blog/mgx-accelerated-systems-gtc/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The spirit of software legend Grace Hopper will live on at <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>.</p>
<p>Accelerated systems using powerful processors — named in honor of the pioneer of programming — will be on display at the global AI conference running March 18-21, ready to take computing to the next level.</p>
<p>System makers will show more than 500 servers in multiple configurations across 18 racks, all packing <a href="https://www.nvidia.com/en-us/data-center/grace-hopper-superchip/">NVIDIA GH200 Grace Hopper Superchips</a>. They’ll form the largest display at NVIDIA’s booth in the San Jose Convention Center, filling the MGX Pavilion.</p>
<h2><b>MGX Speeds Time to Market</b></h2>
<p><a href="https://www.nvidia.com/en-us/data-center/products/mgx/">NVIDIA MGX</a> is a blueprint for building accelerated servers with any combination of GPUs, CPUs and data processing units (<a href="https://blogs.nvidia.com/blog/whats-a-dpu-data-processing-unit/">DPUs</a>) for a wide range of AI, high performance computing and <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> applications. It’s a modular reference architecture for use across multiple product generations and workloads.</p>
<p>GTC attendees can get an up-close look at MGX models tailored for enterprise, cloud and telco-edge uses, such as <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> inference, <a href="https://blogs.nvidia.com/blog/whats-a-recommender-system/">recommenders</a> and data analytics.</p>
<p>The pavilion will showcase accelerated systems packing single and dual GH200 Superchips in 1U and 2U chassis, linked via <a href="https://www.nvidia.com/en-us/networking/products/data-processing-unit/">NVIDIA BlueField-3 DPUs</a> and <a href="https://www.nvidia.com/en-us/networking/quantum2/">NVIDIA Quantum-2</a> 400Gb/s InfiniBand networks over <a href="https://www.nvidia.com/en-us/networking/interconnect/">LinkX</a> cables and transceivers.</p>
<p>The systems support industry standards for 19- and 21-inch rack enclosures, and many provide E1.S bays for nonvolatile storage.</p>
<h2><b>Grace Hopper in the Spotlight</b></h2>
<p>Here’s a sampler of MGX systems now available:</p>
<ul>
<li>ASRock RACK’s MECAI, measuring 450 x 445 x 87mm, accelerates AI and 5G services in constrained spaces at the edge of telco networks.</li>
<li>ASUS’s MGX server, the ESC NM2N-E1, slides into a rack that holds up to 32 GH200 processors and supports air- and water-cooled nodes.</li>
<li>Foxconn provides a suite of MGX systems, including a 4U model that accommodates up to eight NVIDIA H100 NVL PCIe Tensor Core GPUs.</li>
<li>GIGABYTE’s <a href="https://www.gigabyte.com/Enterprise/Server/XH23-VG0-rev-AAJ1">XH23-VG0-MGX</a> can accommodate plenty of storage in its six 2.5-inch Gen5 NVMe hot-swappable bays and two M.2 slots.</li>
<li>Inventec’s systems can slot into 19- and 21-inch racks and use three different implementations of liquid cooling.</li>
<li>Lenovo supplies a range of 1U, 2U and 4U MGX servers, including models that support direct liquid cooling.</li>
<li>Pegatron’s air-cooled AS201-1N0 server packs a BlueField-3 DPU for software-defined, hardware-accelerated networking.</li>
<li>QCT can stack 16 of its QuantaGrid D74S-IU systems, each with two GH200 Superchips, into a single QCT QoolRack.</li>
<li>Supermicro’s ARS-111GL-NHR with nine hot-swappable fans is part of a portfolio of air- and liquid-cooled GH200 and <a href="https://www.nvidia.com/en-us/data-center/grace-cpu/">NVIDIA Grace CPU</a> systems.</li>
<li>Wiwynn’s SV7200H, a 1U dual GH200 system, supports a BlueField-3 DPU and a liquid-cooling subsystem that can be remotely managed.</li>
<li>Wistron’s MGX servers are 4U GPU systems for AI inference and mixed workloads, supporting up to eight accelerators in one system.</li>
</ul>
<p>The new servers are in addition to three accelerated systems using MGX<a href="https://blogs.nvidia.com/blog/computex-keynote-generative-ai/"> announced at COMPUTEX</a> last May — Supermicro’s ARS-221GL-NR using the Grace CPU and QCT’s QuantaGrid S74G-2U and S74GM-2U powered by the GH200.</p>
<h2><b>Grace Hopper Packs Two in One</b></h2>
<p>System builders are adopting the hybrid processor because it packs a punch.</p>
<p>GH200 Superchips combine a high-performance, power-efficient Grace CPU with a muscular <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100 GPU</a>. They share hundreds of gigabytes of memory over a fast <a href="https://www.nvidia.com/en-us/data-center/nvlink-c2c/">NVIDIA NVLink-C2C</a> interconnect.</p>
<p>The result is a processor and memory complex well-suited to take on today’s most demanding jobs, such as running <a href="https://www.nvidia.com/en-us/glossary/large-language-models/">large language models</a>. They have the memory and speed needed to link generative AI models to data sources that can improve their accuracy using <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">retrieval-augmented generation</a>, aka RAG.</p>
<h2><b>Recommenders Run 4x Faster</b></h2>
<p>In addition, the GH200 Superchip delivers greater efficiency and <a href="https://blogs.nvidia.com/blog/grace-hopper-recommender-systems/">up to 4x more performance</a> than using the H100 GPU with traditional CPUs for tasks like making recommendations for online shopping or media streaming.</p>
<p>In its <a href="https://blogs.nvidia.com/blog/grace-hopper-inference-mlperf/">debut</a> on the <a href="https://www.nvidia.com/en-us/data-center/resources/mlperf-benchmarks/">MLPerf</a> industry benchmarks last November, GH200 systems ran all data center inference tests, extending the already leading performance of H100 GPUs.</p>
<p>In all these ways, GH200 systems are taking to new heights a computing revolution their namesake helped start on the first mainframe computers more than seven decades ago.</p>
<p><em>Explore <a title="Original URL: https://www.nvidia.com/gtc/sessions/generative-ai/?nvid=nv-int-txtad-141445 Click to follow link." href="https://www.nvidia.com/gtc/sessions/generative-ai/?nvid=nv-int-txtad-141445" data-outlook-id="97194cbf-406f-48c7-a83a-cd48b46329c6">generative AI</a> sessions and experiences at <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>, the global conference on AI and accelerated computing, running March 18-21 in San Jose, Calif., and online.</em></p>
<p><i>And get the 30,000-foot view from NVIDIA CEO and founder Jensen Huang in his GTC<a href="https://www.nvidia.com/gtc/keynote/"> keynote</a>. </i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/MGX-modular-server-KV.png"
			type="image/png"
			width="1919"
			height="1020"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/MGX-modular-server-KV-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Rack ‘n’ Roll: NVIDIA Grace Hopper Systems Gather at GTC]]></media:title>
			<media:description type="html">Picture of MGX modular servers</media:description>
			</media:content>
			</item>
		<item>
		<title>Meet the Omnivore: Mode Maison Harnesses OpenUSD to Drive Innovations in Retail With High-Fidelity Digital Twins</title>
		<link>https://blogs.nvidia.com/blog/mode-maison-openusd-omniverse/</link>
		
		<dc:creator><![CDATA[Nicole Castro]]></dc:creator>
		<pubDate>Tue, 27 Feb 2024 16:00:34 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Meet the Omnivore]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Rendering]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<category><![CDATA[Universal Scene Description]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69980</guid>

					<description><![CDATA[Editor’s note: This post is a part of our Meet the Omnivore series, which features individual creators and developers who use OpenUSD to build tools, applications and services for 3D workflows and physically accurate virtual worlds. A failed furniture-shopping trip turned into a business idea for Steven Gay, cofounder and CEO of company Mode Maison.		<a class="read-more" href="https://blogs.nvidia.com/blog/mode-maison-openusd-omniverse/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is a part of our </i><a href="https://blogs.nvidia.com/blog/tag/meet-the-omnivore/"><i>Meet the Omnivore</i></a><i> series, which features individual creators and developers who use </i><a href="https://www.nvidia.com/en-us/omniverse/usd/"><i>OpenUSD</i></a><i> to build tools, applications and services for 3D workflows and physically accurate virtual worlds.</i></p>
<p>A failed furniture-shopping trip turned into a business idea for Steven Gay, cofounder and CEO of company <a href="https://www.modemaisonlabs.com/" target="_blank" rel="noopener">Mode Maison</a>.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/Steven_Gay_photo.jpg"><img loading="lazy" decoding="async" class="alignright wp-image-69984 size-thumbnail" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/Steven_Gay_photo-150x150.jpg" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/Steven_Gay_photo-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Steven_Gay_photo-400x400.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Steven_Gay_photo-450x450.jpg 450w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Steven_Gay_photo-215x215.jpg 215w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Steven_Gay_photo-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Steven_Gay_photo.jpg 495w" sizes="(max-width: 150px) 100vw, 150px" /></a></p>
<p>Gay grew up in Houston and studied at the University of Texas before working in New York as one of the youngest concept designers at Ralph Lauren. He was inspired to start his own company after a long day of trying — and failing — to pick out a sofa.</p>
<p>The experience illuminated how the luxury home-goods industry has traditionally lagged in adopting digital technologies, especially those for creating immersive, interactive experiences for consumers.</p>
<p>Gay founded Mode Maison in 2018 with the goal of solving this challenge and paving the way for scalability, creativity and a generative future in retail. Using the Universal Scene Description framework, aka <a href="https://www.nvidia.com/en-us/omniverse/usd/">OpenUSD</a>, and the <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> platform, Gay, along with Mode Maison Chief Technology Officer Jakub Cech and the Mode Maison team, are helping enhance and digitalize entire product lifecycle processes — from design and manufacturing to consumer experiences.</p>
<hr />
<p style="padding-left: 40px;"><em>Register for <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>, which takes place March 17-21, to hear how leading companies are using the latest innovations in AI and graphics. </em><em>And join us for <a href="https://www.nvidia.com/gtc/sessions/openusd-day/">OpenUSD Day</a> to learn how to build generative AI-enabled 3D pipelines and tools using Universal Scene Description.</em></p>
<hr />
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/12-rio-manso-scaled.jpg"><img loading="lazy" decoding="async" class="aligncenter wp-image-69981 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/12-rio-manso-672x378.jpg" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/12-rio-manso-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/12-rio-manso-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/12-rio-manso-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/12-rio-manso-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/12-rio-manso-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/02/12-rio-manso-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/02/12-rio-manso-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/02/12-rio-manso-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/12-rio-manso-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<p>They developed a photometric scanning system, called <a href="https://www.tmac.dev/about" target="_blank" rel="noopener">Total Material Appearance Capture</a>, which offers an unbiased, physically based approach to digitizing the material world that’s enabled by real-world embedded sensors.</p>
<p>TMAC captures proprietary data and the composition of any material, then turns it into input that serves as a single source of truth, which can be used for creating a fully digitized retail model. Using the system, along with OpenUSD and NVIDIA Omniverse, Mode Maison customers can create highly accurate <a href="https://www.nvidia.com/en-us/omniverse/solutions/digital-twins/">digital twins</a> of any material or product.</p>
<p>“By enabling this, we’re effectively collapsing and fostering a complete integration across the entire product lifecycle process — from design and production to manufacturing to consumer experiences and beyond,” said Gay.</p>
<figure id="attachment_69987" aria-describedby="caption-attachment-69987" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/dsc_4290_3-copy2-scaled.jpg"><img loading="lazy" decoding="async" class="wp-image-69987 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/dsc_4290_3-copy2-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/dsc_4290_3-copy2-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/dsc_4290_3-copy2-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/dsc_4290_3-copy2-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/dsc_4290_3-copy2-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/dsc_4290_3-copy2-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/02/dsc_4290_3-copy2-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/02/dsc_4290_3-copy2-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/02/dsc_4290_3-copy2-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/02/dsc_4290_3-copy2-1280x853.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69987" class="wp-caption-text">Mode Maison developed a photometric scanning system called Total Material Appearance Capture.</figcaption></figure>
<h2><b>Streamlining Workflows and Enhancing Productivity With Digital Twins</b></h2>
<p>Previously, Mode Maison faced significant challenges in creating physically based, highly flexible and scalable digital materials. The limitations were particularly noticeable when rendering complex materials and textures, or integrating digital models into cohesive, multilayered environments.</p>
<p>Using Omniverse helped Gay and his team overcome these challenges by offering advanced rendering capabilities, physics simulations and extensibility for AI training that unlock new possibilities in digital retail.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/random-page3-scaled.jpg"><img loading="lazy" decoding="async" class="aligncenter wp-image-69990 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/random-page3-672x378.jpg" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/random-page3-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/random-page3-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/random-page3-768x431.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/random-page3-1536x863.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/random-page3-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/02/random-page3-801x450.jpg 801w, https://blogs.nvidia.com/wp-content/uploads/2024/02/random-page3-383x215.jpg 383w, https://blogs.nvidia.com/wp-content/uploads/2024/02/random-page3-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/random-page3-1280x719.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<p>Before using Omniverse and OpenUSD, Mode Maison used disjointed processes for digital material capture, modeling and rendering, often leading to inconsistencies, the inability to scale and minimal interoperability. After integrating Omniverse, the company experienced a streamlined, coherent workflow where high-fidelity digital twins can be created with greater efficiency and interoperability.</p>
<p>The team primarily uses Autodesk 3ds Max for design, and they import the 3D data using Omniverse Connectors. Gay says OpenUSD is playing an increasingly critical role in its workflows, especially when developing composable, flexible, interoperable capabilities across asset creation.</p>
<p>This enhanced pipeline starts with capturing high-fidelity material data using TMAC. The data is then processed and formatted into OpenUSD for the creation of physically based, scientifically accurate, high-fidelity digital twins.</p>
<p>“OpenUSD allows for an unprecedented level of collaboration and interoperability in creating complex, multi-layered capabilities and advanced digital materials,” Gay said. “Its ability to seamlessly integrate diverse digital assets and maintain their fidelity across various applications is instrumental in creating realistic, interactive digital twins for retail.”</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/Detail_602-scaled.jpg"><img loading="lazy" decoding="async" class="aligncenter wp-image-69993 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/Detail_602-672x378.jpg" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/Detail_602-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Detail_602-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Detail_602-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Detail_602-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Detail_602-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Detail_602-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Detail_602-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Detail_602-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Detail_602-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<p>OpenUSD and Omniverse have sped Mode Maison and their clients’ ability to bring products to market, reduced costs associated with building and modifying digital twins, and enhanced productivity through streamlined creation.</p>
<p>“Our work represents a major step toward a future where digital and physical realities will be seamlessly integrated,” said Gay. “This shift enhances consumer engagement and paves the way for more sustainable business practices by reducing the need for physical prototyping while enabling more precise manufacturing.”</p>
<p>As for emerging technological advancements in digital retail, Gay says AI will play a central role in creating hyper-personalized design, production, sourcing and front-end consumer experiences — all while reducing carbon footprints and paving the way for a more sustainable future in retail.</p>
<h2><b>Join In on the Creation</b></h2>
<p>Anyone can build their own <a href="https://developer.nvidia.com/omniverse">Omniverse extension or Connector</a> to enhance 3D workflows and tools.</p>
<p>Learn more about how OpenUSD and NVIDIA Omniverse are transforming industries at <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG#/">NVIDIA GTC</a>, a global AI conference running March 18-21, online and at the San Jose Convention Center.</p>
<p>Join <a href="https://www.nvidia.com/gtc/sessions/openusd-day/">OpenUSD Day</a> at GTC on Tuesday, March 19, to learn more about building generative AI-enabled 3D pipelines and tools using USD.</p>
<p><i>Get started with NVIDIA Omniverse by downloading the standard license </i><a href="https://www.nvidia.com/en-us/omniverse/download/"><i>free</i></a><i>, access </i><a href="https://developer.nvidia.com/usd"><i>OpenUSD</i></a><i> resources, and learn how </i><a href="https://www.nvidia.com/en-us/omniverse/enterprise/"><i>Omniverse Enterprise</i><i> can connect your team</i></a><i>. Stay up to date on </i><a href="https://www.instagram.com/nvidiaomniverse/"><i>Instagram</i></a><i>, </i><a href="https://medium.com/@nvidiaomniverse"><i>Medium</i></a><i> and </i><a href="https://twitter.com/nvidiaomniverse"><i>X</i></a><i>. For more, join the </i><a href="https://www.nvidia.com/en-us/omniverse/community/"><i>Omniverse community</i></a><i> on the  </i><a href="https://forums.developer.nvidia.com/c/omniverse/300"><i>forums</i></a><i>, </i><a href="https://discord.com/invite/XWQNJDNuaC"><i>Discord server</i></a><i>, </i><a href="https://www.twitch.tv/nvidiaomniverse"><i>Twitch</i></a><i> and </i><a href="https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA"><i>YouTube</i></a><i> channels. </i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/Detail_602-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1152"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/Detail_602-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Meet the Omnivore: Mode Maison Harnesses OpenUSD to Drive Innovations in Retail With High-Fidelity Digital Twins]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA RTX 500 and 1000 Professional Ada Generation Laptop GPUs Drive AI-Enhanced Workflows From Anywhere</title>
		<link>https://blogs.nvidia.com/blog/rtx-ada-ai-workflows/</link>
		
		<dc:creator><![CDATA[John Della Bona]]></dc:creator>
		<pubDate>Mon, 26 Feb 2024 08:00:23 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69967</guid>

					<description><![CDATA[With generative AI and hybrid work environments becoming the new standard, nearly every professional, whether a content creator, researcher or engineer, needs a powerful, AI-accelerated laptop to help users tackle their industry’s toughest challenges — even on the go. The new NVIDIA RTX 500 and 1000 Ada Generation Laptop GPUs will be available in new,		<a class="read-more" href="https://blogs.nvidia.com/blog/rtx-ada-ai-workflows/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>With <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> and hybrid work environments becoming the new standard, nearly every professional, whether a content creator, researcher or engineer, needs a powerful, AI-accelerated laptop to help users tackle their industry’s toughest challenges — even on the go.</p>
<p>The new NVIDIA RTX 500 and 1000 Ada Generation Laptop GPUs will be available in new, highly portable mobile workstations, expanding the <a href="https://www.nvidia.com/en-us/geforce/ada-lovelace-architecture/">NVIDIA Ada Lovelace architecture</a>-based lineup, which includes the RTX 2000, 3000, 3500, 4000 and 5000 Ada Generation Laptop GPUs.</p>
<p>AI is rapidly being adopted to drive efficiencies across professional design and content creation workflows and everyday productivity applications, underscoring the importance of having powerful local AI acceleration and sufficient processing power in systems.</p>
<p>The next generation of mobile workstations with Ada Generation GPUs, including the RTX 500 and 1000 GPUs, will include both a neural processing unit (NPU), a component of the CPU, and an <a href="https://www.nvidia.com/en-us/design-visualization/technologies/rtx/">NVIDIA RTX</a> GPU, which includes Tensor Cores for AI processing. The NPU helps offload light AI tasks, while the GPU provides up to an additional 682 TOPS of AI performance for more demanding day-to-day AI workflows.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/rtx500-1000-table.png"><img loading="lazy" decoding="async" class="aligncenter size-large wp-image-69976" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/rtx500-1000-table-672x200.png" alt="" width="672" height="200" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/rtx500-1000-table-672x200.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/rtx500-1000-table-400x119.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/rtx500-1000-table-406x121.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/02/rtx500-1000-table-188x56.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/02/rtx500-1000-table.png 675w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<p>The higher level of AI acceleration delivered by the GPU is useful for tackling a wide range of AI-based tasks, such as video conferencing with high-quality AI effects, streaming videos with AI upscaling, or working faster with generative AI and content creation applications.</p>
<p>The new RTX 500 GPU delivers up to 14x the generative AI performance for models like Stable Diffusion, up to 3x faster photo editing with AI and up to 10x the graphics performance for 3D rendering compared with a CPU-only configuration — bringing massive leaps in productivity for traditional and emerging workflows.</p>
<h2><b>Enhancing Professional Workflows Across Industries</b></h2>
<p>The RTX 500 and 1000 GPUs elevate workflows with AI for laptop users everywhere in compact designs. Video editors can streamline tasks such as removing background noise with AI. Graphic designers can bring blurry images to life with AI upscaling. Professionals can work on the go while using AI for higher-quality <a href="https://www.nvidia.com/en-us/design-visualization/software/broadcast-app/">video conferencing</a> and <a href="https://www.youtube.com/watch?v=VkKsamTPk7g">streaming</a> experiences.</p>
<p>For users looking to tap AI for advanced rendering, data science and deep learning workflows, NVIDIA also offers the RTX 2000, 3000, 3500, 4000 and 5000 Ada Generation Laptop GPUs. 3D creators can use AI denoising and deep learning super sampling (DLSS) to visualize photorealistic renders in real time. Businesses can query their internal knowledge base with chatbot-like interfaces using <a href="https://www.youtube.com/watch?v=gdsRJZT3IJw">local large language models</a>. And researchers and scientists can experiment with data science, AI model training and tuning, and development projects.</p>
<h2><b>Performance and Portability With NVIDIA RTX</b></h2>
<p>The RTX 500 and 1000 GPUs, based on the NVIDIA Ada Lovelace architecture, bring the latest advancements to thin and light laptops, including:</p>
<ul>
<li><b>Third-generation RT Cores: </b>Up to 2x the ray tracing performance of the previous generation for high-fidelity, photorealistic rendering.</li>
<li><b>Fourth-generation Tensor Cores:</b> Up to 2x the throughput of the previous generation, accelerating deep learning training, inferencing and AI-based creative workloads.</li>
<li><b>Ada Generation CUDA cores: </b>Up to 30% the single-precision floating point (FP32) throughput compared to the previous generation for significant performance improvements in graphics and compute workloads.</li>
<li><b>Dedicated GPU memory:</b> 4GB GPU memory with the RTX 500 GPU and 6GB with the RTX 1000 GPU allows users to run demanding 3D and AI-based applications, as well as tackle larger projects, datasets and multi-app workflows.</li>
<li><b>DLSS 3</b>: Delivers a breakthrough in AI-powered graphics, significantly boosting performance by generating additional high-quality frames.</li>
<li><b>AV1 encoder:</b> Eighth-generation NVIDIA encoder, aka <a href="https://developer.nvidia.com/video-codec-sdk">NVENC</a>, with AV1 support is up to 40% more efficient than H.264, enabling new possibilities for broadcasting, streaming and video calling.</li>
</ul>
<h2><b>Availability</b></h2>
<p>The new NVIDIA RTX 500 and 1000 Ada Generation Laptop GPUs will be available this spring in mobile workstations from global manufacturing partners including <a href="https://www.dell.com/en-us/dt/corporate/newsroom/announcements/detailpage.press-releases~usa~2024~02~20240226-dell-technologies-helps-organizations-create-a-modern-workplace-with-new-ai-experiences.htm#/filter-on/Country:en-us">Dell Technologies</a>, HP, Lenovo and MSI.</p>
<p><i>Learn more about the latest </i><a href="https://www.nvidia.com/en-us/design-visualization/rtx-professional-laptops/"><i>NVIDIA RTX Laptop GPUs</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/RTX-500_1000-Blog-Header.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/RTX-500_1000-Blog-Header-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA RTX 500 and 1000 Professional Ada Generation Laptop GPUs Drive AI-Enhanced Workflows From Anywhere]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Add It to the Toolkit: February Studio Driver and NVIDIA App Beta Now Available</title>
		<link>https://blogs.nvidia.com/blog/studio-driver-app-rtx-ai-adobe-premiere-pro/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Thu, 22 Feb 2024 14:00:51 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio Driver]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69909</guid>

					<description><![CDATA[The February NVIDIA Studio Driver, designed specifically to optimize creative apps, is now available for download.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. We’re also deep diving on new </i><a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/"><i>GeForce RTX 40 Series GPU</i></a><i> features, technologies and resources, and how they dramatically accelerate content creation.</i></p>
<p>The February NVIDIA Studio Driver, designed specifically to optimize creative apps, is now available for download. Developed in collaboration with app developers, Studio Drivers undergo extensive testing to ensure seamless compatibility with creative apps while enhancing features, automating processes and speeding workflows.</p>
<p>Creators can download the latest driver on the public beta of the <a href="https://www.nvidia.com/en-us/software/nvidia-app/">new NVIDIA app</a>, the essential companion for creators and gamers with NVIDIA GPUs in their PCs and laptops. The NVIDIA app beta is a first step to modernize and unify the NVIDIA Control Panel, GeForce Experience and RTX Experience apps.</p>
<figure id="attachment_69910" aria-describedby="caption-attachment-69910" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-image5-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69910" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-image5-1280w-672x377.png" alt="" width="672" height="377" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-image5-1280w-672x377.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-image5-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-image5-1280w-768x431.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-image5-1280w-801x450.png 801w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-image5-1280w-383x215.png 383w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-image5-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-image5-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69910" class="wp-caption-text">The NVIDIA App offers easy access to the latest Studio Drivers, a suite of AI-powered Studio apps, games and more.</figcaption></figure>
<p>The NVIDIA app simplifies the process of keeping PCs updated with the latest NVIDIA drivers, enables quick discovery and installation of NVIDIA apps like NVIDIA Broadcast and NVIDIA Omniverse, unifies the GPU control center, and introduces a redesigned in-app overlay for convenient access to powerful recording tools. Download the <a href="https://www.nvidia.com/en-us/software/nvidia-app/">NVIDIA app beta</a> today.</p>
<p>Adobe Premiere Pro’s AI-powered <a href="https://blogs.nvidia.com/blog/studio-rtx-ai-adobe-premiere-pro-photoshop-lightroom/">Enhance Speech tool</a> is <a href="https://blog.adobe.com/en/publish/2024/02/22/enhance-your-video-editing-workflows-power-adobe-video-ecosystem">now available in general release</a>. Accelerated by <a href="https://www.nvidia.com/en-us/design-visualization/technologies/rtx/">NVIDIA RTX</a>, the new feature removes unwanted noise and improves the quality of dialogue clips so they sound professionally recorded. It’s 75% faster on a <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4090/">GeForce RTX 4090</a> laptop GPU compared with an RTX 3080 Ti.</p>
<figure id="attachment_69962" aria-describedby="caption-attachment-69962" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/processed-272475C9-9758-4893-B8E7-6C5C45840F70-scaled.jpeg"><img loading="lazy" decoding="async" class="size-large wp-image-69962" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/processed-272475C9-9758-4893-B8E7-6C5C45840F70-672x445.jpeg" alt="" width="672" height="445" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/processed-272475C9-9758-4893-B8E7-6C5C45840F70-672x445.jpeg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/processed-272475C9-9758-4893-B8E7-6C5C45840F70-400x265.jpeg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/processed-272475C9-9758-4893-B8E7-6C5C45840F70-768x508.jpeg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/processed-272475C9-9758-4893-B8E7-6C5C45840F70-1536x1016.jpeg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/processed-272475C9-9758-4893-B8E7-6C5C45840F70-scaled.jpeg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/02/processed-272475C9-9758-4893-B8E7-6C5C45840F70-680x450.jpeg 680w, https://blogs.nvidia.com/wp-content/uploads/2024/02/processed-272475C9-9758-4893-B8E7-6C5C45840F70-325x215.jpeg 325w, https://blogs.nvidia.com/wp-content/uploads/2024/02/processed-272475C9-9758-4893-B8E7-6C5C45840F70-151x100.jpeg 151w, https://blogs.nvidia.com/wp-content/uploads/2024/02/processed-272475C9-9758-4893-B8E7-6C5C45840F70-1280x847.jpeg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69962" class="wp-caption-text">Adobe Premiere Pro’s AI-powered Enhance Speech tool removes unwanted noise and improves dialogue quality.</figcaption></figure>
<p>Have a <a href="https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/">Chat with RTX</a>, the tech demo app that lets <a href="https://www.nvidia.com/en-us/geforce/rtx/">GeForce RTX</a> owners personalize a <a href="https://www.nvidia.com/en-us/glossary/large-language-models/#:~:text=Large%20language%20models%20(LLMs)%20are,content%20using%20very%20large%20datasets.">large language model</a> connected to their own content. Results are fast and secure since it runs locally on a Windows RTX PC or workstation. <a href="https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/">Download</a> Chat with RTX today.</p>
<p><iframe loading="lazy" title="Create A Personalized AI Chatbot with Chat With RTX" width="500" height="281" src="https://www.youtube.com/embed/gdsRJZT3IJw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>And this week <i>In the NVIDIA Studio</i>, filmmaker James Matthews shares his short film, <i>Dive</i>, which was created with an Adobe Premiere Pro-powered workflow supercharged by his ASUS ZenBook Pro <a href="https://www.nvidia.com/en-us/studio/laptops-desktops/">NVIDIA Studio</a> laptop with a GeForce RTX 4070 graphics card.</p>
<h2><b>Going With the Flow</b></h2>
<p>Matthews’ goal with <i>Dive</i> was to create a visual and auditory representation of what it feels like to get swallowed up in the creative editing process.</p>
<figure id="attachment_69919" aria-describedby="caption-attachment-69919" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-nice-view-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69919" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-nice-view-1280w-672x250.png" alt="" width="672" height="250" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-nice-view-1280w-672x250.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-nice-view-1280w-400x149.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-nice-view-1280w-768x286.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-nice-view-1280w-842x314.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-nice-view-1280w-406x151.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-nice-view-1280w-188x70.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-james-matthews-wk97-nice-view-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69919" class="wp-caption-text">Talk about a dream content creation location.</figcaption></figure>
<p>“When I’m really deep into an edit, I sometimes feel like I’m fully immersed into the film and the editing process itself,” he said. “It’s almost like a flow state, where time stands still and you are one with your own creativity.”</p>
<p>To capture and visualize that feeling, Matthews used the power of his ASUS ZenBook Pro NVIDIA Studio laptop equipped with a GeForce RTX 4070 graphics card.</p>
<p>He started by brainstorming — listening to music and sketching conceptual images with pencil and paper. Then, Matthews added a song to his Adobe Premiere Pro timeline and created a shot list, complete with cuts and descriptions of focal range, speed, camera movement, lighting and other details.</p>
<p>Next, he planned location and shooting times, paying special attention to lighting conditions.</p>
<p>“I always have my Premiere Pro timeline up so I can really see and feel what I need to create from the images I originally drew while building the concept in my head,” Matthews said. “This helps get the pacing of each shot right, by watching it back and possibly adding it into the timeline for a test.”</p>
<p>Then, Matthews started editing the footage in Premiere Pro, aided by his Studio laptop. His dedicated GPU-based NVIDIA video encoder (<a href="https://developer.nvidia.com/video-codec-sdk">NVENC</a>) enabled buttery-smooth playback and scrubbing of his high-resolution and multi-stream footage, saving countless hours.</p>
<p><iframe loading="lazy" title="NVIDIA Studio | RTX Accelerates Adobe Premiere Pro" width="500" height="281" src="https://www.youtube.com/embed/poTeo7Ft3xk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Matthews’ RTX GPU accelerated a variety of <a href="https://www.adobe.com/products/premiere/ai-video-editing.html">AI-powered Adobe video editing tools</a>, such as Enhance Speech, Scene Edit Detection and Auto Color, which applies color corrections with just a few clicks.</p>
<p><iframe loading="lazy" title="Real-Time Video Editing and Faster Rendering in Adobe Premiere Pro with NVIDIA RTX" width="500" height="281" src="https://www.youtube.com/embed/MnVsfZT1wHU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Finally, Matthews added sound design before exporting the final files twice as fast thanks to NVENC’s dual AV1 encoders.</p>
<p>“The entire edit used GPU acceleration,” he shared. “Effects in Premiere Pro, along with the NVENC video encoders on the GPU, unlocked a seamless workflow and essentially allowed me to get into my flow state faster.”</p>
<figure id="attachment_69922" aria-describedby="caption-attachment-69922" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-james-matthews-wk97-artist-feature-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69922" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-james-matthews-wk97-artist-feature-1280w-672x218.png" alt="" width="672" height="218" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-james-matthews-wk97-artist-feature-1280w-672x218.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-james-matthews-wk97-artist-feature-1280w-400x130.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-james-matthews-wk97-artist-feature-1280w-768x249.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-james-matthews-wk97-artist-feature-1280w-842x273.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-james-matthews-wk97-artist-feature-1280w-406x132.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-james-matthews-wk97-artist-feature-1280w-188x61.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-james-matthews-wk97-artist-feature-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69922" class="wp-caption-text">Filmmaker James Matthews.</figcaption></figure>
<p>Watch Matthews’ content on <a href="http://youtube.com/JamesMatthews">YouTube</a>.</p>
<p><i>Follow NVIDIA Studio on <a href="https://www.facebook.com/NVIDIAStudio/">Facebook, </a></i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram </i></a><i>and </i><i></i><i><a href="https://twitter.com/NVIDIAStudio">X</a> </i><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/nv-blog-header-preview-1280x680-3.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/nv-blog-header-preview-1280x680-3-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Add It to the Toolkit: February Studio Driver and NVIDIA App Beta Now Available]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Into the Omniverse: Rhino 3D Launches OpenUSD Features to Enhance 3D Modeling and Development</title>
		<link>https://blogs.nvidia.com/blog/rhino-launches-openusd-features/</link>
		
		<dc:creator><![CDATA[George Matos]]></dc:creator>
		<pubDate>Thu, 22 Feb 2024 14:00:51 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[Into the Omniverse]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Universal Scene Description]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69937</guid>

					<description><![CDATA[Editor’s note: This post is part of Into the Omniverse, a series focused on how artists, developers and enterprises can transform their workflows using the latest advances in OpenUSD and NVIDIA Omniverse. The combination of powerful 3D tools and groundbreaking technologies can transform the way designers bring their visions to life — and Universal Scene		<a class="read-more" href="https://blogs.nvidia.com/blog/rhino-launches-openusd-features/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of </i><a href="https://www.nvidia.com/en-us/omniverse/news/"><i>Into the Omniverse</i></a><i>, a series focused on how artists, developers and enterprises can transform their workflows using the latest advances in </i><a href="https://www.nvidia.com/en-us/omniverse/usd/"><i>OpenUSD</i></a><i> and </i><a href="https://www.nvidia.com/en-us/omniverse/usd/"><i>NVIDIA Omniverse</i></a><i>.</i></p>
<p>The combination of powerful 3D tools and groundbreaking technologies can transform the way designers bring their visions to life — and Universal Scene Description, or <a href="https://www.nvidia.com/en-us/omniverse/usd/">OpenUSD</a>, is helping enable that synergy. It’s the framework on which the <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> platform that enables the development of OpenUSD-based tools and 3D workflows is based.</p>
<p><a href="https://www.rhino3d.com/" target="_blank" rel="noopener">Rhinoceros</a>, commonly known as Rhino, or Rhino 3D, is a powerful computer-aided design (CAD) and 3D modeling software used across industries — from education and jewelry design to architecture and marine modeling. The most recent software release includes support for OpenUSD export, among other updates, establishing it among the many applications embracing the new 3D standard.</p>
<h2><b>Turning Creativity Into CAD Reality</b></h2>
<p><a href="https://www.instagram.com/tanjalanggner/" target="_blank" rel="noopener">Tanja Langgner</a>, 3D artist and illustrator, grew up in Austria and now lives in a converted pigsty in the English countryside. With a background in industrial design, she’s had the opportunity to work with a slew of design agencies across Europe.</p>
<p>For the past decade, she’s undertaken freelance work in production and visualization, helping clients with tasks ranging from concept design and ideation to CAD and 3D modeling. Often doing industrial design work, Langgner relies on Rhino to construct CAD models,  whether for production evaluation or rendering purposes.</p>
<p>When faced with designs requiring intricate surface patterns, “Rhino’s Grasshopper, a parametric modeler, is excellent in creating complex parametric shapes,” she said.</p>
<p>Langgner is no stranger to OpenUSD. She uses it to transfer assets easily from one application to another, allowing her to visualize her work more efficiently. With the new Rhino update, she can now export OpenUSD files from Rhino, further streamlining her design workflow.</p>
<p><img loading="lazy" decoding="async" class="wp-image-69941 aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/rhino_screenshot02-1.png" alt="" width="690" height="370" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/rhino_screenshot02-1.png 1917w, https://blogs.nvidia.com/wp-content/uploads/2024/02/rhino_screenshot02-1-400x215.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/rhino_screenshot02-1-672x361.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/rhino_screenshot02-1-768x412.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/rhino_screenshot02-1-1536x824.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/rhino_screenshot02-1-838x450.png 838w, https://blogs.nvidia.com/wp-content/uploads/2024/02/rhino_screenshot02-1-401x215.png 401w, https://blogs.nvidia.com/wp-content/uploads/2024/02/rhino_screenshot02-1-186x100.png 186w, https://blogs.nvidia.com/wp-content/uploads/2024/02/rhino_screenshot02-1-1280x687.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/02/rhino_screenshot02-1-842x450.png 842w" sizes="(max-width: 690px) 100vw, 690px" /></p>
<p><a href="https://blogs.nvidia.com/blog/mathew-schwartz-openusd-omniverse/">Mathew Schwartz</a>, an assistant professor in architecture and design at the New Jersey Institute of Technology, also uses Rhino and OpenUSD in his 3D workflows. Schwartz’s research and design lab, <a href="https://www.siborglab.com/" target="_blank" rel="noopener">SiBORG</a>, focuses on understanding and improving design workflows, especially with regard to accessibility, human factors and automation.</p>
<p>With OpenUSD, he can combine his research, Python code, 3D environments and renders, with his favorite tools in Omniverse.</p>
<p>Schwartz, along with Langgner, recently joined a community livestream, where he shared more details about his research — including how he&#8217;s made navigation graphs that show how someone can move in a space if they’re using a wheelchair or crutches in real-time. With his industrial design experience, he demonstrated computation using Rhino 3D and the use of generative AI for a seamless design process.</p>
<p>“With OpenUSD and Omniverse, we’ve been able to expand the scope of our research, as we can easily combine data analysis and visualization with the design process,” he said.</p>
<p><img loading="lazy" decoding="async" class=" wp-image-69945 aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/Pathloop-ezgif.com-video-to-gif-converter.gif" alt="" width="651" height="367" /></p>
<p>Learn more by watching the replay of the community livestream:</p>
<p><iframe loading="lazy" title="Getting Started with Rhino and OpenUSD" width="500" height="281" src="https://www.youtube.com/embed/QoRf-XOMbeU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Rhino 3D Updates Simplify 3D Collaboration</b></h2>
<p><a href="https://www.rhino3d.com/e-news/1223u1/" target="_blank" rel="noopener">Rhino 8</a>, available now, brings significant enhancements to the 3D modeling experience. It enables the export of meshes, mesh vertex colors, physically based rendering materials and textures so users can seamlessly share and collaborate on 3D designs with enhanced visual elements.</p>
<p>The latest <a href="https://www.rhino3d.com/8/new/" target="_blank" rel="noopener">Rhino 8</a> release also includes <a href="https://youtu.be/n-JNwmO61jY?si=VUYAoZUbOSPqtqmH" target="_blank" rel="noopener">improvements</a> to:</p>
<ul>
<li><b>Modeling</b>: New features, including PushPull direct editing, a <a href="https://www.rhino3d.com/features/shrinkwrap/" target="_blank" rel="noopener">ShrinkWrap</a> function for creating water-tight meshes around various geometries, enhanced control over subdivision surfaces with the SubD Crease control tool, and improved functionality for smoother surface fillets.</li>
<li><b>Drawing and illustration</b>: Precision-boosting enhancements to clipping and sectioning operations, a new feature for creating reflected ceiling plans, major improvements to linetype options and enhanced UV mapping for better texture coordination.</li>
<li><b>Operating systems</b>: A faster-than-ever experience for Mac users thanks to Apple silicon processors and Apple Metal display technology, along with significantly accelerated rendering with the updated Cycles engine.</li>
<li><b>Development</b>: New Grasshopper components covering annotations, blocks, materials and user data, accompanied by a new, enhanced script editor.</li>
</ul>
<p>Future Rhino updates will feature an expansion of export capabilities to include NURBS curves and surfaces, subdivision modeling and the option to <a href="https://github.com/mcneel/RhinoUSD/tree/rhino-8.x/import_USD" target="_blank" rel="noopener">import OpenUSD</a> content.</p>
<p>The Rhino team actively seeks user feedback on desired import platforms and applications, continually working to make OpenUSD files widely accessible and adaptable across 3D environments.</p>
<h2><b>Get Plugged Into the World of OpenUSD</b></h2>
<p>Learn more about OpenUSD and meet experts at <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>, the conference for the era of AI, taking place March 18-21 at the San Jose Convention Center. Don’t miss:</p>
<ul>
<li style="font-weight: 400;">Members of the <a href="https://aousd.org/" target="_blank" rel="noopener">Alliance for OpenUSD (AOUSD)</a> speaking on <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=s62782#/session/1698243138347001uvVR">Monday, March 18</a>, about the power of OpenUSD as a standard for the 3D internet.</li>
<li style="font-weight: 400;"><a href="https://www.nvidia.com/gtc/sessions/openusd-day/">OpenUSD Day</a> on Tuesday, March 19,  to learn how to build generative AI-enabled 3D pipelines and tools for industrial digitalization.</li>
<li style="font-weight: 400;"><a href="https://www.nvidia.com/gtc/sessions/openusd-training/">Hands-on OpenUSD training</a> for all skill levels, from learning the fundamentals to building OpenUSD-based applications.</li>
</ul>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr"><a href="https://twitter.com/hashtag/OpenUSD?src=hash&amp;ref_src=twsrc%5Etfw">#OpenUSD</a> Day will be at <a href="https://twitter.com/hashtag/GTC24?src=hash&amp;ref_src=twsrc%5Etfw">#GTC24</a>. <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f440.png" alt="👀" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>You won&#39;t want to miss this full day of sessions on building <a href="https://twitter.com/hashtag/genAI?src=hash&amp;ref_src=twsrc%5Etfw">#genAI</a>-enabled 3D pipelines &amp; tools.</p>
<p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f449.png" alt="👉" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="https://t.co/AqUmID7sRo">https://t.co/AqUmID7sRo</a> <a href="https://t.co/VHq7TiR1NF">pic.twitter.com/VHq7TiR1NF</a></p>
<p>&mdash; NVIDIA Omniverse (@nvidiaomniverse) <a href="https://twitter.com/nvidiaomniverse/status/1752018554457600257?ref_src=twsrc%5Etfw">January 29, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p><i>Get started with NVIDIA Omniverse by downloading the standard license </i><a href="https://www.nvidia.com/en-us/omniverse/download/"><i>free</i></a><i>, access </i><a href="https://developer.nvidia.com/usd"><i>OpenUSD</i></a><i> resources, and learn how </i><a href="https://www.nvidia.com/en-us/omniverse/enterprise/"><i>Omniverse Enterprise</i><i> can connect your team</i></a><i>. Stay up to date on </i><a href="https://www.instagram.com/nvidiaomniverse/"><i>Instagram</i></a><i>, </i><a href="https://medium.com/@nvidiaomniverse"><i>Medium</i></a><i> and </i><a href="https://twitter.com/nvidiaomniverse"><i>X</i></a><i>. For more, join the </i><a href="https://www.nvidia.com/en-us/omniverse/community/"><i>Omniverse community</i></a><i> on the  </i><a href="https://forums.developer.nvidia.com/c/omniverse/300"><i>forums</i></a><i>, </i><a href="https://discord.com/invite/XWQNJDNuaC"><i>Discord server</i></a><i>, </i><a href="https://www.twitch.tv/nvidiaomniverse"><i>Twitch</i></a><i> and </i><a href="https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA"><i>YouTube</i></a><i> channels. </i></p>
<p><i>Featured image courtesy of Tanja Langgner.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-nv-ov-ito-1280x680_02_2024_rhino.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/Copy-of-nv-ov-ito-1280x680_02_2024_rhino-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Into the Omniverse: Rhino 3D Launches OpenUSD Features to Enhance 3D Modeling and Development]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Time to Play: GeForce NOW Now Offers 1,800 Games to Stream</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-four-year-anniversary-nightingale-bandai-namco/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 22 Feb 2024 14:00:13 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69888</guid>

					<description><![CDATA[Top-tier games from publishing partners Bandai Namco Entertainment and Inflexion Games are joining GeForce NOW this week as the cloud streaming service’s fourth-anniversary celebrations continue. Eleven new titles join the over 1,800 supported games in the GeForce NOW library, including Nightingale from Inflexion Games and Bandai Namco Entertainment’s Tales of Arise, Katamari Damacy REROLL and		<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-four-year-anniversary-nightingale-bandai-namco/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Top-tier games from publishing partners Bandai Namco Entertainment and Inflexion Games are joining <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> this week as the cloud streaming service’s fourth-anniversary celebrations continue.</p>
<p>Eleven new titles join the over 1,800 supported games in the GeForce NOW library, including <i>Nightingale</i> from Inflexion Games and Bandai Namco Entertainment’s <i>Tales of Arise</i>, <i>Katamari Damacy REROLL</i> and <i>Klonoa Phantasy Reverie Series.</i></p>
<p>“Happy fourth anniversary, GeForce NOW!” cheered Jarrett Lee, head of publishing at Inflexion Games. “The platform’s ease of access and seamless performance comprise a winning combination, and we’re excited to see how cloud gaming evolves.”</p>
<h2><b>Bigger Than Your Gaming Backlog</b></h2>
<figure id="attachment_69892" aria-describedby="caption-attachment-69892" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-69892" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-GeForce_NOW_Library-672x376.jpg" alt="GeForce NOW Library" width="672" height="376" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-GeForce_NOW_Library-672x376.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-GeForce_NOW_Library-400x224.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-GeForce_NOW_Library-768x430.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-GeForce_NOW_Library-1536x860.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-GeForce_NOW_Library-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-GeForce_NOW_Library-804x450.jpg 804w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-GeForce_NOW_Library-384x215.jpg 384w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-GeForce_NOW_Library-179x100.jpg 179w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-GeForce_NOW_Library-1280x716.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69892" class="wp-caption-text"><em>Games galore.</em></figcaption></figure>
<p>GeForce NOW offers over 1,800 games supported in the cloud, including over 100 free-to-play titles. That’s more than enough to play a different game every day for nearly five years.</p>
<p>The expansive GeForce NOW library supports games from popular digital stores Steam, Xbox — including supported PC Game Pass titles — Epic Games Store, Ubisoft Connect and GOG.com. From indie games to triple-A titles, there’s something for everyone to play.</p>
<figure id="attachment_69895" aria-describedby="caption-attachment-69895" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-69895" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/Cyberpunk2077_Phantom_Liberty_PC_4K_RGB_EN_Police_Chase-1-672x378.jpg" alt="Cyberpunk 2077 on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/Cyberpunk2077_Phantom_Liberty_PC_4K_RGB_EN_Police_Chase-1-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Cyberpunk2077_Phantom_Liberty_PC_4K_RGB_EN_Police_Chase-1-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Cyberpunk2077_Phantom_Liberty_PC_4K_RGB_EN_Police_Chase-1-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Cyberpunk2077_Phantom_Liberty_PC_4K_RGB_EN_Police_Chase-1-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Cyberpunk2077_Phantom_Liberty_PC_4K_RGB_EN_Police_Chase-1-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Cyberpunk2077_Phantom_Liberty_PC_4K_RGB_EN_Police_Chase-1-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Cyberpunk2077_Phantom_Liberty_PC_4K_RGB_EN_Police_Chase-1-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Cyberpunk2077_Phantom_Liberty_PC_4K_RGB_EN_Police_Chase-1-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Cyberpunk2077_Phantom_Liberty_PC_4K_RGB_EN_Police_Chase-1-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69895" class="wp-caption-text"><em>The city of the future is in the cloud.</em></figcaption></figure>
<p>Explore sprawling open worlds in the neon-drenched streets of Night City in <i>Cyberpunk 2077</i>, or unearth ancient secrets in the vast landscapes of <i>Assassin’s Creed Valhalla</i>. Test skills against friends in the high-octane action of <i>Apex Legends</i> or <i>Fortnite</i>, strategize on the battlefield in <i>Age of Empires IV</i> or gather the ultimate party in <i>Baldur’s Gate 3.</i></p>
<p>Build a dream farm in <i>Stardew Valley</i>, explore charming worlds in <i>Hollow Knight</i> or build a thriving metropolis in <i>Cities: Skylines II.</i></p>
<p>Members can also catch the latest titles in the cloud, including the newly launched dark-fantasy adventure game <a href="https://blogs.nvidia.com/blog/geforce-now-thursday-four-year-anniversary-the-inquisitor/"><i>The Inquisitor</i></a> and Ubisoft’s <a href="https://blogs.nvidia.com/blog/geforce-now-thursday-skull-and-bones-halo-infinite/"><i>Skull and Bones</i></a><i>.</i></p>
<p>Dedicated rows in the GeForce NOW app help members find the perfect game to stream, and tags indicate when sales or downloadable content are available. GeForce NOW even has game-library syncing capabilities for Steam, Xbox and Ubisoft Connect so that supported games automatically sync to members’ cloud gaming libraries for easy access.</p>
<p>Access titles without waiting for them to download or worrying about system specs. Plus, <a href="http://geforcenow.com">Ultimate members</a> gain exclusive access to gaming servers to get to their games faster.</p>
<h2><b>Let’s Get Crafty</b></h2>
<figure id="attachment_69898" aria-describedby="caption-attachment-69898" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-69898" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/Nightingale-9-672x378.png" alt="Nightingale on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/Nightingale-9-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Nightingale-9-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Nightingale-9-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Nightingale-9-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Nightingale-9.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Nightingale-9-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Nightingale-9-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Nightingale-9-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Nightingale-9-1280x720.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69898" class="wp-caption-text"><em>Entering new dimensions in the cloud.</em></figcaption></figure>
<p>Set out on an adventure into the mysterious and dangerous Fae Realms of <i>Nightingale,</i> the highly anticipated shared-world survival crafting game from Inflexion Games. Become an intrepid Realmwalker and explore, craft, build and fight across a visually stunning magical fantasy world inspired by the Victorian era.</p>
<p>Venture forth alone or with up to six other players in an online, shared world. The game features epic action, a variety of fantastical creatures and a Realm Card system that allows players to travel between realms and reshape landscapes.</p>
<p>Experience the magic of the Fae Realms in stunning resolution with <a href="https://www.nvidia.com/en-us/geforce/rtx/">RTX ON</a>.</p>
<h2><b>Roll On Over to the Cloud</b></h2>
<figure id="attachment_69901" aria-describedby="caption-attachment-69901" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-69901" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/Arise_Screenshot_01-672x378.jpg" alt="Tales of Arise on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/Arise_Screenshot_01-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Arise_Screenshot_01-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Arise_Screenshot_01-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Arise_Screenshot_01-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Arise_Screenshot_01-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Arise_Screenshot_01-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Arise_Screenshot_01-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Arise_Screenshot_01-1280x720.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Arise_Screenshot_01.jpg 1920w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69901" class="wp-caption-text"><em>Arise to the cloud and battle for the fate of two worlds.</em></figcaption></figure>
<p>Get ready for more fantasy, a touch of royalty and even some nostalgia with the latest Bandai Namco Entertainment titles coming to the cloud. <i>Tales of Arise</i>,<i> Katamari Damacy REROLL</i>,<i> Klonoa Phantasy Reverie Series</i>,<i> PAC-MAN MUSEUM+ </i>and <i>PAC-MAN WORLD Re-PAC</i> are now available for members to stream.</p>
<p>Embark on a mesmerizing journey in the fantastical world of <i>Tales of Arise</i> and unravel a gripping narrative that transcends the boundaries of imagination. Or roll into the whimsical, charming world of <i>Katamari Damacy REROLL —</i> control a sticky ball and roll up everything in its path to create colorful, celestial bodies.</p>
<p>Indulge in a nostalgic gaming feast with <i>Klonoa Phantasy Reverie Series</i>,<i> PAC-MAN MUSEUM+ </i>and <i>PAC-MAN WORLD Re-PAC. </i>The <i>Klonoa </i>series revitalizes dreamlike adventures, blending fantasy and reality for a captivating experience. Meanwhile, PAC-MAN MUSEUM+ invites players to munch through PAC-MAN’s iconic history, showcasing the timeless charm of the beloved yellow icon. For those seeking a classic world with a modern twist, <i>PAC-MAN WORLD Re-PAC</i> delivers an adventure packed with excitement and familiar ghosts.</p>
<h2><b>Face Your Fate</b></h2>
<figure id="attachment_69904" aria-describedby="caption-attachment-69904" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-69904" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-terminator-dark-fate-defiance-tw-li-2048x1024-1-672x336.jpg" alt="Terminator Dark Fate Defiance on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-terminator-dark-fate-defiance-tw-li-2048x1024-1-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-terminator-dark-fate-defiance-tw-li-2048x1024-1-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-terminator-dark-fate-defiance-tw-li-2048x1024-1-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-terminator-dark-fate-defiance-tw-li-2048x1024-1-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-terminator-dark-fate-defiance-tw-li-2048x1024-1-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-terminator-dark-fate-defiance-tw-li-2048x1024-1-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-terminator-dark-fate-defiance-tw-li-2048x1024-1-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-terminator-dark-fate-defiance-tw-li-2048x1024-1-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-spotlight-terminator-dark-fate-defiance-tw-li-2048x1024-1.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69904" class="wp-caption-text"><em>The fate of mankind is in the cloud.</em></figcaption></figure>
<p>Dive into an adrenaline-fueled journey with <i>Terminator: Dark Fate &#8211; Defiance</i>, where strategic prowess decides the fate of mankind against machines. In a world taken over by machines, the greatest threats remaining may come not from the machines themselves but from other human survivors.</p>
<p>It’s part of 11 new games this week:</p>
<ul>
<li><i>Le Mans Ultimate</i> (New release on <a href="https://store.steampowered.com/app/2399420?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb. 20)</li>
<li><i>Nightingale </i>(New release on <a href="https://store.steampowered.com/app/1928980?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb. 20)</li>
<li><i>Terminator: Dark Fate &#8211; Defiance </i>(New release on <a href="https://store.steampowered.com/app/1839950?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb. 21)</li>
<li><i>Garden Life: A Cozy Simulator </i>(New release on <a href="https://store.steampowered.com/app/1915380?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb. 22)</li>
<li><i>Pacific Drive </i>(New release on <a href="https://store.steampowered.com/app/1458140?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb. 22)</li>
<li><i>Solium Infernum </i>(New release on <a href="https://store.steampowered.com/app/1893810?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb. 22)</li>
<li><i>Katamari Damacy REROLL </i>(<a href="https://store.steampowered.com/app/848350?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Klonoa Phantasy Reverie Series </i>(<a href="https://store.steampowered.com/app/1730680?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>PAC-MAN MUSEUM+ </i>(<a href="https://store.steampowered.com/app/1665130?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>PAC-MAN WORLD Re-PAC </i>(<a href="https://store.steampowered.com/app/1859470?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Tales of Arise </i>(<a href="https://store.steampowered.com/app/740130?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<p>And several titles in the GeForce NOW library that were in early access are launching full releases this week:<i></i></p>
<ul>
<li><i>Last Epoch</i> (New 1.0 release on <a href="https://store.steampowered.com/app/899770?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb. 21)</li>
<li><i>Myth of Empires </i>(New 1.0 release on <a href="https://store.steampowered.com/app/1371580?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb. 21)</li>
<li><i>Sons of the Forest</i> (New 1.0 release on <a href="https://store.steampowered.com/app/1326470?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb. 22)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Off to the cloud&#8230; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/2601.png" alt="☁" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>Who&#39;s coming with? <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f680.png" alt="🚀" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1759990886182601117?ref_src=twsrc%5Etfw">February 20, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-thursday-2-22-nv-blog-1280x680-no-cta-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-thursday-2-22-nv-blog-1280x680-no-cta-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Time to Play: GeForce NOW Now Offers 1,800 Games to Stream]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>FOMO Alert: Discover 7 Unmissable Reasons to Attend GTC 2024</title>
		<link>https://blogs.nvidia.com/blog/do-not-miss-gtc-2024/</link>
		
		<dc:creator><![CDATA[Claudia Cook]]></dc:creator>
		<pubDate>Thu, 22 Feb 2024 14:00:07 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69950</guid>

					<description><![CDATA[“I just got back from GTC and ….” In four weeks, those will be among the most powerful words in your industry. But you won’t be able to use them if you haven’t been here. NVIDIA’s GTC 2024 transforms the San Jose Convention Center into a crucible of innovation, learning and community from March 18-21,		<a class="read-more" href="https://blogs.nvidia.com/blog/do-not-miss-gtc-2024/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>“I just got back from GTC and ….”</p>
<p>In four weeks, those will be among the most powerful words in your industry. But you won’t be able to use them if you haven’t been here.</p>
<p><a href="https://www.nvidia.com/gtc/">NVIDIA’s GTC 2024</a> transforms the San Jose Convention Center into a crucible of innovation, learning and community from March 18-21, marking a return to in-person gatherings that can’t be missed.</p>
<p>Tech enthusiasts, industry leaders and innovators from around the world are set to present and explore over 900 sessions and close to 300 exhibits.</p>
<p>They’ll dive into the future of AI, computing and beyond, with contributions from some of the brightest minds at companies such as Amazon, Amgen, Character.AI, Ford Motor Co., Genentech, L&#8217;Oréal, Lowe’s, Lucasfilm and Industrial Light &amp; Magic, Mercedes-Benz, Pixar, Siemens, Shutterstock, xAI and many more.</p>
<p>Among the most anticipated events is the Transforming AI Panel, featuring the original architects behind the concept that revolutionized the way we approach AI today: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin.</p>
<p>All eight authors of &#8220;<a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a>,&#8221; the seminal 2017 NeurIPS paper that introduced the trailblazing transformer neural network architecture will appear in person at GTC on a panel hosted by NVIDIA Founder and CEO Jensen Huang.</p>
<p>Located in the vibrant heart of Silicon Valley, GTC stands as a pivotal gathering where the convergence of technology and community shapes the future. This conference offers more than just presentations; it&#8217;s a collaborative platform for sharing knowledge and sparking innovation.</p>
<ol>
<li style="font-weight: 400;" aria-level="1"><strong>Exclusive Insights:</strong> <a href="https://blogs.nvidia.com/blog/gtc-keynote-spring-2023/">Last year, Huang announced a “lightspeed” leap in computing</a> and partnerships with giants like Microsoft to set the stage. This year, anticipate more innovations at the SAP Center, giving attendees a first look at the next transformative breakthroughs.</li>
<li style="font-weight: 400;" aria-level="1"><strong>Networking Opportunities:</strong> GTC’s networking events are designed to transform casual encounters into pivotal career opportunities. Connect directly with industry leaders and innovators, making every conversation a potential gateway to your next big role or project.</li>
<li style="font-weight: 400;" aria-level="1"><strong>Cutting-Edge Exhibits: </strong>Step into the future with exhibits that showcase the latest in AI and robotics. Beyond mere displays, these exhibits offer hands-on learning experiences, providing attendees with invaluable knowledge to stay ahead.
<p><figure id="attachment_69951" aria-describedby="caption-attachment-69951" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-69951 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/WEF_Press_Stills_LED.0001-1-672x354.png" alt="" width="672" height="354" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/WEF_Press_Stills_LED.0001-1-672x354.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/WEF_Press_Stills_LED.0001-1-400x211.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/WEF_Press_Stills_LED.0001-1-768x405.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/WEF_Press_Stills_LED.0001-1-1536x810.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/WEF_Press_Stills_LED.0001-1.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/02/WEF_Press_Stills_LED.0001-1-842x444.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/02/WEF_Press_Stills_LED.0001-1-406x215.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/02/WEF_Press_Stills_LED.0001-1-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/02/WEF_Press_Stills_LED.0001-1-1280x675.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69951" class="wp-caption-text">AI is spilling out in all directions, and GTC is the best way to capture it all. Pictured: The latest installation from AI artist Refik Anadol, whose work will be featured at GTC.</figcaption></figure></li>
<li style="font-weight: 400;" aria-level="1"><strong>Diversity and Innovation:</strong> Begin your day at the Women In Tech breakfast. This, combined with unique experiences like generative AI art installations and street food showcases, feeds creativity and fosters innovation in a relaxed setting.</li>
<li style="font-weight: 400;" aria-level="1"><strong>Learn From the Best:</strong> Engage with sessions led by visionaries from organizations such as Disney Research, Google DeepMind, Johnson &amp; Johnson Innovative Medicine, Stanford University and beyond. These aren’t just lectures but opportunities to question, engage and turn insights into actionable knowledge that can shape your career trajectory.</li>
<li style="font-weight: 400;" aria-level="1"><strong>Silicon Valley Experience: </strong>Embrace the energy of the world’s foremost tech hub. Inside the conference, GTC connects attendees with the latest technologies and minds. Beyond the show floor, it’s a gateway to building lasting relationships with leaders and thinkers across industries.</li>
<li style="font-weight: 400;" aria-level="1"><strong>Seize the Future Now:</strong> Don’t just join a story — write one. Be part of this moment in AI. <a href="https://www.nvidia.com/gtc/pricing/?regcode=no-ncid&amp;ncid=no-ncid">Register now for GTC</a> to write your own story in the epicenter of technological advancement. Be part of this transformative moment in AI.</li>
</ol>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/gtc24-spring-web-browser-notification-sjcc-1280x680-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/gtc24-spring-web-browser-notification-sjcc-1280x680-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[FOMO Alert: Discover 7 Unmissable Reasons to Attend GTC 2024]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Shining Brighter Together: Google’s Gemma Optimized to Run on NVIDIA GPUs</title>
		<link>https://blogs.nvidia.com/blog/google-gemma-llm-rtx-ai-pc/</link>
		
		<dc:creator><![CDATA[Ankit Patel]]></dc:creator>
		<pubDate>Wed, 21 Feb 2024 13:00:31 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[TensorRT]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69874</guid>

					<description><![CDATA[NVIDIA, in collaboration with Google, today launched optimizations across all NVIDIA AI platforms for Gemma — Google’s state-of-the-art new lightweight 2 billion&#8211; and 7 billion-parameter open language models that can be run anywhere, reducing costs and speeding innovative work for domain-specific use cases. Teams from the companies worked closely together to accelerate the performance of		<a class="read-more" href="https://blogs.nvidia.com/blog/google-gemma-llm-rtx-ai-pc/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>NVIDIA, in collaboration with Google, today launched optimizations across all NVIDIA AI platforms for <a href="https://blog.google/technology/developers/gemma-open-models/">Gemma</a> — Google’s state-of-the-art new lightweight <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-foundation/models/gemma-2b">2 billion</a>&#8211; and <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-foundation/models/gemma-7b">7 billion</a>-parameter open language models that can be run anywhere, reducing costs and speeding innovative work for domain-specific use cases.</p>
<p>Teams from the companies worked closely together to accelerate the performance of Gemma — built from the same research and technology used to create the Gemini models — with <a href="https://github.com/NVIDIA/TensorRT-LLM">NVIDIA TensorRT-LLM</a>, an open-source library for optimizing large language model inference, when running on NVIDIA GPUs in the data center, in the cloud, and locally on workstations with <a href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA RTX</a> GPUs or PCs with <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/">GeForce RTX</a> GPUs.</p>
<p>This allows developers to target the installed base of over 100 million NVIDIA RTX GPUs available in high-performance AI PCs globally.</p>
<p>Developers can also run Gemma on NVIDIA GPUs in the cloud, including on Google Cloud’s A3 instances based on the H100 Tensor Core GPU and soon, NVIDIA’s <a href="https://nvidianews.nvidia.com/news/nvidia-supercharges-hopper-the-worlds-leading-ai-computing-platform">H200 Tensor Core GPUs</a> — featuring 141GB of HBM3e memory at 4.8 terabytes per second — which Google will deploy this year.</p>
<p>Enterprise developers can additionally take advantage of NVIDIA’s rich ecosystem of tools — including <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> with the <a href="https://github.com/NVIDIA/NeMo">NeMo framework</a> and <a href="https://github.com/NVIDIA/TensorRT-LLM">TensorRT-LLM</a> — to fine-tune Gemma and deploy the optimized model in their production applications.</p>
<p>Learn more about how <a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-revs-up-inference-for-google-gemma/">TensorRT-LLM is revving up inference for Gemma</a>, along with additional information for developers. This includes several model checkpoints of Gemma and the FP8-quantized version of the model, all optimized with TensorRT-LLM.</p>
<p>Experience <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-foundation/models/gemma-2b">Gemma 2B</a> and <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-foundation/models/gemma-7b">Gemma 7B</a> directly from your browser on the NVIDIA AI Playground.</p>
<h2><b>Gemma Coming to Chat With RTX</b></h2>
<p>Adding support for Gemma soon is <a href="https://blogs.nvidia.com/blog/chat-with-rtx-available-now/">Chat with RTX</a>, an NVIDIA tech demo that uses <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">retrieval-augmented generation</a> and TensorRT-LLM software to give users generative AI capabilities on their local, RTX-powered Windows PCs.</p>
<p><iframe loading="lazy" title="Create A Personalized AI Chatbot with Chat With RTX" width="500" height="281" src="https://www.youtube.com/embed/gdsRJZT3IJw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>The Chat with RTX lets users personalize a chatbot with their own data by easily connecting local files on an RTX PC to a large language model.</p>
<p>Since the model runs locally, it provides results fast, and user data stays on the device. Rather than relying on cloud-based LLM services, Chat with RTX lets users process sensitive data on a local PC without the need to share it with a third party or have an internet connection.</p>
<p><em>Explore <a title="Original URL: https://www.nvidia.com/gtc/sessions/generative-ai/?nvid=nv-int-txtad-141445 Click to follow link." href="https://www.nvidia.com/gtc/sessions/generative-ai/?nvid=nv-int-txtad-141445" data-outlook-id="97194cbf-406f-48c7-a83a-cd48b46329c6">generative AI</a> sessions and experiences at <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>, the global conference on AI and accelerated computing, running March 18-21 in San Jose, Calif., and online.</em></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/nv-google-blog-header-preview-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/nv-google-blog-header-preview-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Shining Brighter Together: Google’s Gemma Optimized to Run on NVIDIA GPUs]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI’s Hottest Ticket: NVIDIA GTC Brings Together Automotive Leaders and Visionaries Transforming the Future of Transportation</title>
		<link>https://blogs.nvidia.com/blog/gtc-2024-auto-sessions/</link>
		
		<dc:creator><![CDATA[Marie Labrie]]></dc:creator>
		<pubDate>Fri, 16 Feb 2024 19:17:57 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69865</guid>

					<description><![CDATA[Generative AI and software-defined computing are transforming the automotive landscape — making the journey behind the wheel safer, smarter and more enjoyable. Dozens of automakers and NVIDIA DRIVE ecosystem partners will be demonstrating their developments in mobility, along with showcasing their next-gen vehicles at GTC, the conference for the era of AI, running from March		<a class="read-more" href="https://blogs.nvidia.com/blog/gtc-2024-auto-sessions/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Generative AI and software-defined computing are transforming the automotive landscape — making the journey behind the wheel safer, smarter and more enjoyable.</p>
<p>Dozens of automakers and <a href="https://www.nvidia.com/en-us/self-driving-cars/">NVIDIA DRIVE</a> ecosystem <a href="https://www.nvidia.com/en-us/self-driving-cars/partners/">partners</a> will be demonstrating their developments in mobility, along with showcasing their next-gen vehicles at GTC, the conference for the era of AI, running from March 18-21 in San Jose, Calif., and online. These include the Mercedes-Benz Concept CLA Class, the new Volvo EX90, Polestar 3, WeRide Robobus, Nuro R3 autonomous delivery vehicle and more.</p>
<p>Explore myriad sessions to learn about the latest developments in mobility — from highly automated and autonomous driving, <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> and <a href="https://www.nvidia.com/en-us/glossary/large-language-models/#:~:text=Large%20language%20models%20(LLMs)%20are,content%20using%20very%20large%20datasets.">large language models</a> to simulation, safety, design and manufacturing.</p>
<p>Featured sessions include:<b><i></i></b></p>
<ul>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62464&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>How LLMs and Generative AI Will Enhance the Way We Experience Self-Driving Cars</b></a><br />
Alex Kendall, cofounder and CEO, Wayve<br />
<em>Tuesday, March 19, 9 a.m. PT</em></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=s62621&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>Accelerating the New Era of Autonomous Vehicles With Generative AI</b></a><br />
Raquel Urtasun, founder and CEO, Waabi<br />
<em>Tuesday, March 19, 10 a.m. PT</em></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62645&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>Applying AI &amp; LLMs to Transform the Luxury Automotive Experience</b></a><br />
Chrissie Kemp, chief data and digital product officer, Jaguar Land Rover<br />
<em>Tuesday, March 19, 11 a.m. PT</em></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62380&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>Generative AI and Industrial Digitalization in the Automotive Industry</b></a><br />
Alex Kendall, cofounder and CEO, Wayve<br />
Raquel Urtasun, founder and CEO, Waabi<br />
Chrissie Kemp, chief data and digital product officer, Jaguar Land Rover<br />
Norm Marks, vice president, automotive enterprise, NVIDIA<br />
<em>Tuesday, March 19, 2 p.m. PT</em></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62804&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>Accelerating Automotive Workflows With Large Language Models</b></a><br />
Bryan Goodman, director, artificial intelligence, Ford Motor Co.<br />
<em>Tuesday, March 19, 3 p.m. PT</em></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62472&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>Infusing the Car’s Cockpit With AI</b></a><br />
Dr. Ephrem Chemaly, vice president and general manager, automotive business unit, MediaTek<br />
<em>Wednesday, March 20, 9 a.m. PT</em></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=S63294&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>The Nuro Driver: An AI-First Autonomous Driving System</b></a><br />
Albert Meixner, head of Software, Nuro<br />
<em>Wednesday, March 20, 3 p.m. PT</em></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=SE63001&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>Accelerating the Shift to AI-Defined Vehicles</b></a><br />
Xinzhou Wu, vice president, automotive, NVIDIA<br />
<em>Thursday, March 21, 8 a.m. PT</em></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62919&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>Transforming Factory Planning and Manufacturing Operations Within Digital Mega Plants</b><b><br />
</b></a>Benjamin Huber, head of advanced automation and digitalization – business area UX, Continental<br />
<em>Wednesday, March 20, 10 a.m. PT</em></li>
</ul>
<p>Rounding out the week will be <a href="https://www.nvidia.com/gtc/sessions/drive-developer-day/">DRIVE Developer Day</a> on Thursday, March 21 — featuring a series of deep-dive sessions on how to build safe and robust self-driving systems. Led by NVIDIA’s engineering experts, these talks will highlight the latest DRIVE features and developments.</p>
<p>Find additional details on <a href="https://images.nvidia.com/nvimages/gtc/pdf/GTC24_March_Automotive_Brochure.pdf">automotive-specific programming at GTC</a>.</p>
<p>Don’t stall — <a href="http://www.nvidia.com/gtc/?ncid=GTC-NVHWQQGN">register</a> today to learn how generative AI and software-defined computing are transforming the auto industry.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/autosessionsgtc24.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/autosessionsgtc24-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI’s Hottest Ticket: NVIDIA GTC Brings Together Automotive Leaders and Visionaries Transforming the Future of Transportation]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Telco GPT: Survey Shows Scale of Industry’s Enthusiasm and Adoption of Generative AI</title>
		<link>https://blogs.nvidia.com/blog/ai-telecommunications-survey/</link>
		
		<dc:creator><![CDATA[Ronnie Vasishta]]></dc:creator>
		<pubDate>Thu, 15 Feb 2024 16:37:33 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Telecommunications]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69852</guid>

					<description><![CDATA[It’s been five years since the telecommunications industry first deployed 5G networks to drive new performance levels for customers and unlock new value for telcos. But that industry milestone has been overshadowed by the emergence of generative AI and the swift pace at which telcos are embracing large language models as they seek to transform		<a class="read-more" href="https://blogs.nvidia.com/blog/ai-telecommunications-survey/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>It’s been five years since the telecommunications industry first deployed 5G networks to drive new performance levels for customers and unlock new value for telcos.</p>
<p>But that industry milestone has been overshadowed by the emergence of <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> and the swift pace at which telcos are embracing <a href="https://www.nvidia.com/en-us/glossary/large-language-models/">large language models</a> as they seek to transform all parts of their business.</p>
<p>A recent survey of more than 400 telecommunications industry professionals from around the world showed that generative AI is the breakout technology of the year and that enthusiasm and adoption for both generative AI, and AI in general, is booming. In addition, the survey showed that, among respondents, AI is improving both revenues and cost savings.</p>
<p>The generative AI insight is the main highlight in the second edition of NVIDIA’s “State of AI in Telecommunications” survey, which included questions covering a range of AI topics, including infrastructure spending, top use cases, biggest challenges and deployment models.</p>
<p>Survey respondents included C-suite leaders, managers, developers and IT architects from mobile telecoms, fixed and cable companies. The survey was conducted over eight weeks between October and December.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x.jpg"><img loading="lazy" decoding="async" class="aligncenter size-large wp-image-69853" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x-672x378.jpg" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<h2><b>Ramping Up on Generative AI</b></h2>
<p>The survey results show how generative AI went from relative obscurity in 2022 to a key solution within a year. Forty-three percent of respondents reported they were investing in it, showing clear evidence that the telecom industry is enthusiastically embracing the generative AI wave to address a wide variety of business goals.</p>
<p>More broadly, there was a marked increase in interest in adopting AI and growing expectations of success from the technology, especially among industry executives. In the survey, 53% of respondents agreed or strongly agreed that adopting AI will be a source of competitive advantage, compared to 39% who reported the same in 2022. For management respondents, the figure was 56%.</p>
<p>The primary reason for this sustained engagement is because many industry stakeholders expect AI to contribute to their company’s success. Overall, 56% of respondents agreed or strongly agreed that “AI is important to my company’s future success,” with the figure rising to 61% among decision-making management respondents. The overall figure is a 14-point boost over the 42% result from the 2022 survey.</p>
<h2><b>Customer Experience Remains Key Driver of AI Investment </b></h2>
<p>Telcos are adopting AI and generative AI to address a wide variety of business needs. Overall, 31% of respondents said they invested in at least six AI use cases in 2023, while 40% are planning to scale to six or more use cases in 2024.</p>
<p>But enhancing customer experiences remains the biggest AI opportunity for the telecom industry, with 48% of survey respondents selecting it as their main goal for using the technology. Likewise, some 35% of respondents identified customer experiences as their key AI success story.</p>
<p>For generative AI, 57% are using it to improve customer service and support, 57% to improve employee productivity, 48% for network operations and management, 40% for network planning and design, and 32% for marketing content generation.</p>
<h2><b>Early Phase of AI Investment Cycle</b></h2>
<p>The focus on customer experience is influencing investments. Investing in customer-experience optimization remains the most popular AI use case for 2023 (49% of respondents) and for generative AI investments (57% of respondents).</p>
<p>Telcos are also investing in other AI use cases: security (42%), network predictive maintenance (37%), network planning and operations (34%) and field operations (34%) are notable examples. However, using AI for fraud detection in transactions and payments had the biggest jump in popularity between 2022 and 2023, rising 14 points to 28% of respondents.</p>
<p>Overall, investments in AI are still in an early phase of the investment cycle, although growing strongly. In the survey, 43% of respondents reported an investment of over $1 million in AI in their previous year, 52% reported the same for the current year, and 66% reported their budget for AI infrastructure will increase in the next year.</p>
<p>For those who are already investing in AI, 67% reported that AI adoption has helped them increase revenues, with 19% of respondents noting that this revenue growth is more than 10% in specific business areas. Likewise, 63% reported that AI adoption has helped them reduce costs in specific business areas, with 14% noting that this cost reduction is more than 10%.</p>
<h2><b>Innovation With Partners</b></h2>
<p>While telcos are increasing their investments to improve their internal AI capabilities, partnerships remain critical for the adoption of AI solutions in the industry. This is applicable both for AI models and AI hardware infrastructure.</p>
<p>In the survey, 44% of respondents reported that co-development with partners is their company’s preferred approach to building AI solutions. Some 28% of respondents prefer to use open-source tools, while 25% take an AI-as-a-service approach. For generative AI, 29% of respondents built or customized models with a partner, an understandable conservative approach for the telecom industry with its stringent data protection rules.</p>
<p>For infrastructure, increasingly, many telcos are opting for cloud hosting, although the hybrid model still remains dominant. In the survey, 31% of respondents reported that they run most of their AI workloads in the cloud (44% for hybrid), compared to 21% of respondents in the previous survey (56% for hybrid). This is helping to fuel the growing need for more localized cloud infrastructure.</p>
<p><i>Download the “</i><a href="https://www.nvidia.com/en-us/lp/industries/telecommunications/state-of-ai-in-telecom-survey-report/?nvid=nv-int-tblg-284455-vt26"><i>State of AI in Telecommunications: 2024 Trends</i></a><i>” report for in-depth results and insights.</i></p>
<p><i>Explore how </i><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search.industry=option_1559593261405#/"><i>AI is transforming telecommunications at NVIDIA GTC</i></a><i>, featuring industry leaders including Amdocs, Indosat, KT, Samsung Research, ServiceNow, Singtel, SoftBank, Telconet and Verizon.</i></p>
<p><i>Learn more about </i><a href="https://www.nvidia.com/en-us/industries/telecommunications/"><i>NVIDIA solutions for telecommunications</i></a><i> across customer experience, network operations, sovereign AI factories and more.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/telco-towers.jpg"
			type="image/jpeg"
			width="1200"
			height="628"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/telco-towers-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Telco GPT: Survey Shows Scale of Industry’s Enthusiasm and Adoption of Generative AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Artistry With Adobe: Creator Esteban Toro Delivers Inspirational Master Class Powered by AI and RTX</title>
		<link>https://blogs.nvidia.com/blog/studio-rtx-ai-adobe-premiere-pro-photoshop-lightroom/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Thu, 15 Feb 2024 14:00:44 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69821</guid>

					<description><![CDATA[Adobe is putting generative AI into the hands of creators with Adobe Firefly — powered by NVIDIA in the cloud — and adding to its impressive app lineup with exciting new features. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Adobe is putting generative AI into the hands of creators with <a href="https://www.adobe.com/products/firefly.html">Adobe Firefly</a> — powered by NVIDIA in the cloud — and adding to its impressive app lineup with exciting new features.</p>
<p>The AI-powered Enhance Speech tool, available soon in Adobe Premiere Pro, is accelerated by <a href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA RTX</a>. This new feature removes unwanted noise and improves the quality of dialogue clips so they sound professionally recorded.</p>
<p>Esteban Toro, senior community relationship manager at Adobe and this week’s featured <i>In the NVIDIA Studio </i>artist, expertly wields AI-powered features in Adobe Photoshop and Lightroom to create his emotionally moving <i>Cinematic Portraits </i>series.</p>
<figure id="attachment_69822" aria-describedby="caption-attachment-69822" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69822" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w-672x446.png" alt="" width="672" height="446" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w-672x446.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w-400x266.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w-768x510.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w-678x450.png 678w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w-324x215.png 324w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w-151x100.png 151w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69822" class="wp-caption-text">A sneak peek of Toro’s work.</figcaption></figure>
<p>Have a <a href="https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/">Chat with RTX</a> — the tech demo app that lets GeForce RTX owners personalize a generative pretrained transformer <a href="https://www.nvidia.com/en-us/glossary/large-language-models/#:~:text=Large%20language%20models%20(LLMs)%20are,content%20using%20very%20large%20datasets.">large language model</a> connected to their own content, whether in documents, notes, videos or other data formats. Since it runs locally on a Windows RTX PC or workstation, results are fast and secure. <a href="https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/">Download</a> Chat with RTX today.</p>
<p><iframe loading="lazy" title="Create A Personalized AI Chatbot with Chat With RTX" width="500" height="281" src="https://www.youtube.com/embed/gdsRJZT3IJw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Don’t forget <a href="https://www.nvidia.com/gtc/pricing/">GTC registration is open</a> for virtual or in-person attendance. Running March 18-21 in San Jose, Calif., the event delivers something for every technical level and interest area, including <a href="https://www.nvidia.com/gtc/session-catalog/">sessions</a> on how to power content creation using OpenUSD and generative AI.</p>
<p>And Omniverse OpenUSD month rolls on, spotlighting the open and extensible ecosystem for describing, composing, simulating and collaborating within 3D worlds. Follow NVIDIA Studio on <a href="https://www.instagram.com/nvidiastudio/">Instagram</a>, <a href="https://twitter.com/NVIDIAStudio">X</a> and <a href="https://www.facebook.com/NVIDIAStudio/">Facebook</a> to learn more.</p>
<h2><b>Storytelling With Adobe AI and RTX </b></h2>
<p>The talented Toro is driven by stories.</p>
<figure id="attachment_69825" aria-describedby="caption-attachment-69825" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69825" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w-672x446.png" alt="" width="672" height="446" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w-672x446.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w-400x266.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w-768x510.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w-678x450.png 678w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w-324x215.png 324w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w-151x100.png 151w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69825" class="wp-caption-text">Stories fuel Toro’s creative process.</figcaption></figure>
<p>“Understanding how every person has a different upbringing and how the decisions they made took them to different places is absolutely inspiring,” said Toro. “When I discover a story worth telling, I just feel a necessity to tell it — and tell it right.”</p>
<p>It’s those stories that gave rise to <i>Cinematic Portraits</i>, a photo and video collection of people Toro’s befriended, such as Korean painter Kim Nam Soon, age 81, who impressively learned how to paint at 65.</p>
<div style="width: 1280px;" class="wp-video"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video class="wp-video-shortcode" id="video-69821-1" width="1280" height="720" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-kim-cinematic-1280w.mp4?_=1" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-kim-cinematic-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-kim-cinematic-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>Toro’s planning process is long and thorough — he can only retell stories by first having a conversation with each subject, making sure that they understand what the project is about and building a relationship with them so they feel comfortable enough to authentically share.</p>
<p>He captures video and photos of his subjects using Hasselblad and Sony camera gear. Then, he uses Adobe apps, accelerated by GeForce RTX and NVIDIA RTX technology, in post-production.</p>
<p>Toro deployed the Enhance Speech tool to boost the clarity and quality of voice recordings and adjusted enhancement levels with the Mix Amount setting — all powered by AI. The feature is 75% faster on a GeForce RTX 4090 laptop GPU compared with an RTX 3080 Ti.</p>
<p>“Without AI, the footage, filmed in challenging, noisy conditions, would be unusable,” he said.</p>
<p>The Text-Based Editing tool in Premiere Pro allowed Toro to use speech-to-text AI capabilities to automatically create captions, supported in 18 languages, for video footage — speeding the editing process.</p>
<figure id="attachment_69837" aria-describedby="caption-attachment-69837" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w.png"><img loading="lazy" decoding="async" class="wp-image-69837 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w-672x419.png" alt="" width="672" height="419" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w-672x419.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w-400x249.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w-768x479.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w-722x450.png 722w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w-345x215.png 345w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w-160x100.png 160w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69837" class="wp-caption-text">The Text-Based Editing tool can create a transcription of a video sequence and add captions.</figcaption></figure>
<p>Toro also used the Filler Word Detection feature, which detects and deletes filler words and pauses, to achieve cleaner, more accurate transcripts. Filler words are language agnostic, so the feature works in all 18 languages supported in Text-Based Editing.</p>
<figure id="attachment_69840" aria-describedby="caption-attachment-69840" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69840" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w-672x446.png" alt="" width="672" height="446" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w-672x446.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w-400x266.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w-768x510.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w-678x450.png 678w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w-324x215.png 324w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w-151x100.png 151w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69840" class="wp-caption-text">Adobe expert Esteban Toro hard at work.</figcaption></figure>
<p>Adobe offers a wide variety of time-saving features, such as the AI-powered Auto Reframe tool for automated editing in multiple size formats for social media with <a href="https://helpx.adobe.com/premiere-pro-next/organize-media/import-files/use-project-templates.html">project templates</a>. Toro’s <a href="https://www.nvidia.com/en-us/studio/">NVIDIA Studio laptop</a> with the <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4070-family/">GeForce RTX 4070 graphics card</a> accelerates all of these powerful tools.</p>
<p>Final file exports were achieved 4x faster than with a CPU alone thanks to the GPU-accelerated NVIDIA video encoder (<a href="https://developer.nvidia.com/video-codec-sdk">NVENC</a>). Toro quickly and easily added finishing touches in Photoshop Lightroom, using the RTX-accelerated, AI-powered Raw Details feature to refine the color detail of his high-resolution RAW images, and the Super Resolution feature to upscale images with higher quality than traditional methods.</p>
<p>“Having a dedicated GPU for video projects when filming high-quality video is almost mandatory,” said Toro. “Using NVIDIA GPUs allows me to render and process my projects faster, so the post-processing tools are serving my creative ideas, and I’m not limited by what the computer can do, but exactly what I want to create.&#8221;</p>
<figure id="attachment_69843" aria-describedby="caption-attachment-69843" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69843" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w-672x263.png" alt="" width="672" height="263" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w-672x263.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w-400x156.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w-768x300.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w-842x329.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w-406x159.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w-188x73.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69843" class="wp-caption-text">Artist and Adobe expert Esteban Toro.</figcaption></figure>
<p>Follow Esteban Toro on <a href="https://www.instagram.com/estebantorom">Instagram</a>.</p>
</div>]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-kim-cinematic-1280w.mp4" length="1764083" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/adobe-nv-blog-header-preview-1280x680-2.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/adobe-nv-blog-header-preview-1280x680-2-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Artistry With Adobe: Creator Esteban Toro Delivers Inspirational Master Class Powered by AI and RTX]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Eos Revealed: Peek Into Operations of a Top 10 Supercomputer</title>
		<link>https://blogs.nvidia.com/blog/eos/</link>
		
		<dc:creator><![CDATA[Charlie Boyle]]></dc:creator>
		<pubDate>Thu, 15 Feb 2024 14:00:16 +0000</pubDate>
				<category><![CDATA[Supercomputing]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69717</guid>

					<description><![CDATA[Providing a peek at the architecture powering advanced AI factories, NVIDIA Thursday released a video that offers the first public look at Eos, its latest data-center-scale supercomputer. An extremely large-scale NVIDIA DGX SuperPOD, Eos is where NVIDIA developers create their AI breakthroughs using accelerated computing infrastructure and fully optimized software. Eos is built with 576		<a class="read-more" href="https://blogs.nvidia.com/blog/eos/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Providing a peek at the architecture powering advanced AI factories, NVIDIA Thursday released a video that offers the first public look at Eos, its latest data-center-scale supercomputer.</p>
<p>An extremely large-scale <a href="https://www.nvidia.com/en-us/data-center/dgx-superpod/">NVIDIA DGX SuperPOD</a>, Eos is where NVIDIA developers create their AI breakthroughs using accelerated computing infrastructure and fully optimized software.</p>
<p>Eos is built with 576 <a href="https://www.nvidia.com/en-us/data-center/dgx-h100/">NVIDIA DGX H100</a> systems, <a href="https://www.nvidia.com/en-us/networking/quantum2/">NVIDIA Quantum-2 InfiniBand networking</a> and software, providing a total of 18.4 exaflops of FP8 AI performance. This system is a sister to a <a href="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fblogs.nvidia.com%2Fblog%2Fscaling-ai-training-mlperf%2F&amp;data=05%7C02%7Cgrainville%40nvidia.com%7Cc7f631fdf68a4870460808dc3174aac0%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638439624354202777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=t8JYd63NQeTU341PEhKkonuqdW7wsCTU%2FP7Fm8AR7Jo%3D&amp;reserved=0" data-auth="NotApplicable">separate Eos DGX SuperPOD with 10,752 NVIDIA H100 GPUs</a>, used for MLPerf training in November.</p>
<p>Revealed in November at the Supercomputing 2023 trade show, Eos — named for the Greek goddess said to open the gates of dawn each day — reflects NVIDIA’s commitment to advancing AI technology.</p>
<h2>Eos Supercomputer Fuels Innovation</h2>
<p>Each DGX H100 system is equipped with eight <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100 Tensor Core GPUs</a>. Eos features a total of 4,608 H100 GPUs.</p>
<p>As a result, Eos can handle the largest AI workloads to train <a href="https://blogs.nvidia.com/blog/kt-large-language-models/">large language models</a>, recommender systems, quantum simulations and more.</p>
<p>It’s a showcase of what NVIDIA’s technologies can do, when working at scale.</p>
<p>Eos is arriving at the perfect time. People are changing the world with <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a>, from drug discovery to chatbots to autonomous machines and beyond.</p>
<p>To achieve these breakthroughs, they need more than AI expertise and development skills. They need an AI factory — a purpose-built AI engine that’s always available and can help ramp their capacity to build AI models at scale</p>
<p>Eos delivers. <a href="https://www.top500.org/lists/top500/2023/11/">Ranked No. 9 in the TOP500</a> list of the world’s fastest supercomputers, Eos pushes the boundaries of AI technology and infrastructure.</p>
<p>It includes NVIDIA’s advanced accelerated computing and networking alongside sophisticated software offerings such as <a href="https://www.nvidia.com/en-us/data-center/base-command/">NVIDIA Base Command</a> and <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a>.</p>
<p><iframe loading="lazy" title="YouTube video player" src="https://www.youtube.com/embed/J8-CgG5ewJQ?si=Ke2AmFde1VPZS2Jf" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe><i></i><br />
Eos’s architecture is optimized for AI workloads demanding ultra-low-latency and high-throughput interconnectivity across a large cluster of accelerated computing nodes, making it an ideal solution for enterprises looking to scale their AI capabilities.</p>
<p>Based on NVIDIA Quantum-2 InfiniBand with In-Network Computing technology, its network architecture supports data transfer speeds of up to 400Gb/s, facilitating the rapid movement of large datasets essential for training complex AI models.</p>
<p>At the heart of Eos lies the groundbreaking DGX SuperPOD architecture powered by NVIDIA’s DGX H100 systems.</p>
<p>The architecture is built to provide the AI and computing fields with tightly integrated full-stack systems capable of computing at an enormous scale.</p>
<p>As enterprises and developers worldwide seek to harness the power of AI, Eos stands as a pivotal resource, promising to accelerate the journey towards AI-infused applications that fuel every organization.</p>
<p><em>Editor’s note: This post was updated on Feb. 19, 2024, to clarify that there are two Eos systems.</em></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/NVIDIA-Eos-Image.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/NVIDIA-Eos-Image-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Eos Revealed: Peek Into Operations of a Top 10 Supercomputer]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
	</channel>
</rss>
