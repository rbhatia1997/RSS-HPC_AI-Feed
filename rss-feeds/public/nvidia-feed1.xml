<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Tue, 26 Dec 2023 21:59:41 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.4.2</generator>
	<item>
		<title>Tune In to the Top 5 NVIDIA Videos of 2023</title>
		<link>https://blogs.nvidia.com/blog/top-5-nvidia-videos-2023/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Wed, 27 Dec 2023 16:00:22 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Climate]]></category>
		<category><![CDATA[Energy]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[GTC]]></category>
		<category><![CDATA[NVIDIA DGX]]></category>
		<category><![CDATA[NVIDIA Modulus]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68938</guid>

					<description><![CDATA[2023 was marked by the generative AI boom, representing a new era for how artificial intelligence can be used across industries. The year’s top videos from the NVIDIA YouTube channel reflect this focus, with popular videos highlighting the technology powering large language models, new platforms for building generative AI applications and how accelerated computing and <a class="read-more" href="https://blogs.nvidia.com/blog/top-5-nvidia-videos-2023/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>2023 was marked by the <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/" target="_blank" rel="noopener">generative AI</a> boom, representing a new era for how artificial intelligence can be used across industries.</p>
<p>The year’s top videos from the <a href="https://www.youtube.com/@NVIDIA" target="_blank" rel="noopener">NVIDIA YouTube channel</a> reflect this focus, with popular videos highlighting the technology powering <a href="https://www.nvidia.com/en-us/glossary/data-science/large-language-models/" target="_blank" rel="noopener">large language models</a>, new platforms for building generative AI applications and how accelerated computing and AI can advance climate science.</p>
<p>And don’t miss replays of NVIDIA founder and CEO Jensen Huang’s event appearances — his <a href="https://www.youtube.com/watch?v=DiGB5uAYKAg" target="_blank" rel="noopener">GTC keynote</a> in March has garnered 22 million views, making it by far the most-viewed video on the channel.</p>
<p>Tune in to NVIDIA’s top five videos of the year:</p>
<h2><strong>Predicting Extreme Weather Risk — Weeks in Advance</strong></h2>
<p>Explore in colorful detail how running FourCastNet — an AI framework developed by researchers at NVIDIA, Caltech and Lawrence Berkeley Lab — on NVIDIA GPUs enables quicker, more accurate extreme weather predictions.</p>
<p><iframe title="Predicting Extreme Weather Risk Three Weeks in Advance With FourCastNet" width="500" height="281" src="https://www.youtube.com/embed/FUUT6IrQjo4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Accelerating Carbon Capture and Storage</b></h2>
<p>Buckle up — learn how reservoir engineers are using <a href="https://www.nvidia.com/en-us/omniverse/" target="_blank" rel="noopener">NVIDIA Omniverse</a>, <a href="https://developer.nvidia.com/modulus" target="_blank" rel="noopener">NVIDIA Modulus</a> and <a href="https://blogs.nvidia.com/blog/what-is-accelerated-computing/#:~:text=Accelerated%20computing%20uses%20parallel%20processing,analytics%20to%20simulations%20and%20visualizations." target="_blank" rel="noopener">accelerated computing</a> to optimize carbon capture, ensuring long-term storage and safer operations.</p>
<p><iframe title="Accelerating Carbon Capture and Storage With Fourier Neural Operator and NVIDIA Modulus" width="500" height="281" src="https://www.youtube.com/embed/u-M5LQvx1cQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Visualizing Global-Scale Climate Data</b></h2>
<p>Seeing is achieving with this stunning demo of the <a href="https://www.nvidia.com/en-us/high-performance-computing/earth-2/" target="_blank" rel="noopener">NVIDIA Earth-2 platform</a>, which offers high-resolution climate visualizations for scientists, as well as breathtakingly detailed urban airflow information for architects and city planners.</p>
<p><iframe title="Interactive Visualization of High-Resolution, Global-Scale Climate Data in the Cloud" width="500" height="281" src="https://www.youtube.com/embed/8cQoYcbUG_M?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p><b>A Tour of the NVIDIA DGX H100</b></p>
<p>Presenting the engine behind the large language model breakthrough — the <a href="https://www.nvidia.com/en-us/data-center/dgx-h100/" target="_blank" rel="noopener">NVIDIA DGX H100</a>. Hear from Huang on why DGX is “the essential instrument of AI.”</p>
<p><iframe loading="lazy" title="Quick Tour of NVIDIA DGX H100" width="500" height="281" src="https://www.youtube.com/embed/a_tXcmEeGxo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p><b>Fine-Tuning Generative AI With NVIDIA AI Workbench </b></p>
<p>Check out this demo — featuring a multitude of Toy Jensens — to learn how <a href="https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/workbench/" target="_blank" rel="noopener">NVIDIA AI Workbench</a> streamlines selecting <a href="https://blogs.nvidia.com/blog/what-are-foundation-models/" target="_blank" rel="noopener">foundation models</a>, building project environments and fine-tuning models with domain-specific data.</p>
<p><iframe loading="lazy" title="NVIDIA AI Workbench | Fine Tuning Generative AI" width="500" height="281" src="https://www.youtube.com/embed/ntMRzPzSvM4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2022/07/digital-twin-earth.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2022/07/digital-twin-earth-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Tune In to the Top 5 NVIDIA Videos of 2023]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>5 Ways AI Created Smarter Spaces in 2023</title>
		<link>https://blogs.nvidia.com/blog/ai-metropolis-omniverse/</link>
		
		<dc:creator><![CDATA[Scott Martin]]></dc:creator>
		<pubDate>Tue, 26 Dec 2023 16:00:20 +0000</pubDate>
				<category><![CDATA[Accelerated Analytics]]></category>
		<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Metropolis]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Smart Spaces]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68831</guid>

					<description><![CDATA[With all the talk of how generative AI is going to change the world, it’s worth looking back on how AI’s already enabled leaps and bounds. NVIDIA helped automate airport operations, vehicle manufacturing, industrial inspections and more with AI to create smarter spaces in 2023. Airport AI Takes Off Toronto Pearson International Airport in June <a class="read-more" href="https://blogs.nvidia.com/blog/ai-metropolis-omniverse/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>With all the talk of how generative AI is going to change the world, it’s worth looking back on how AI’s already enabled leaps and bounds.</p>
<p>NVIDIA helped automate airport operations, vehicle manufacturing, industrial inspections and more with AI to create smarter spaces in 2023.</p>
<h2><b>Airport AI Takes Off</b></h2>
<p>Toronto Pearson International Airport <a href="https://blogs.nvidia.com/blog/zensors-visual-ai/">in June deployed</a> the Zensors AI platform, which uses security cameras to generate spatial data to help optimize operations. <a href="https://www.zensors.com/">Zensors</a> is a member of <a href="https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/">NVIDIA Metropolis</a>, a partner program for improving operations with visual data and AI, and <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a>, a free program that nurtures cutting-edge startups.</p>
<p>The Zensors platform uses anonymized data to count travelers in lines, identify congested areas and predict passenger wait times — and it can send alerts to help speed operations. Other startups <a href="https://blogs.nvidia.com/blog/airplane-turnarounds-gpu-ai-assaia/">have landed in this space</a> to reduce flight delays.</p>
<p>“Zensors is making visual AI easy for all to use,” said Anuraag Jain, the company’s cofounder and head of product and technology.</p>
<h2><b>Inspect Your Gadget</b></h2>
<p>Taiwanese manufacturers like Foxconn Industrial Internet, Pegatron, Quanta and Wistron <a href="https://blogs.nvidia.com/blog/electronics-giants-industrial-automation-nvidia-metropolis-for-factories/">are embracing</a> NVIDIA Metropolis for Factories to enable automated optical inspections.</p>
<p>Pegatron makes motherboards, smartphones, laptops, game consoles and much more. <a href="https://developer.nvidia.com/metropolis-for-factories">It uses Metropolis for Factories</a> to support its printed circuit board factories, achieving 99.8% accuracy on its automated optical inspection systems.</p>
<p>How’s that for a smarter workspace.</p>
<h2><b>PepsiCo’s AI Pop</b></h2>
<p>Beverage giant PepsiCo has deployed vision AI from KoiReader Technologies, an NVIDIA Metropolis partner, for efficiency gains in reading warehouse labels.</p>
<p>The startup’s technology <a href="https://blogs.nvidia.com/blog/pepsi-koivision/">is being tapped</a> to train and run the deep learning models behind PepsiCo’s AI label and barcode scanning system.</p>
<p>“If you find the right lever, you could dramatically improve our throughput,” said Greg Bellon, senior director of digital supply chain at PepsiCo.</p>
<h2><b>Driving Digital Production</b></h2>
<p>With NVIDIA Omniverse — a collaborative platform for developing <a href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description</a> applications to design, plan and operate manufacturing and assembly facilities — Mercedes-Benz is using <a href="https://blogs.nvidia.com/blog/what-is-a-digital-twin">digital twins</a> for production.</p>
<p>Harnessing Omniverse, Mercedes-Benz can interact directly with its suppliers, reducing coordination processes by 50%.</p>
<p>“Using NVIDIA Omniverse and AI, Mercedes-Benz is building a connected, digital-first approach to optimize its manufacturing processes, ultimately reducing construction time and production costs,” said Rev Lebaredian, vice president of Omniverse and simulation technology at NVIDIA.</p>
<h2><b>Juicing AI for Batteries</b></h2>
<p>Smart spaces often begin in the virtual world.</p>
<p><a href="https://blogs.nvidia.com/blog/siemens-nvidia-freyr/">Siemens showcased</a> an immersive digital model for a look into future FREYR Battery factories, powered by <a href="https://www.nvidia.com/en-us/omniverse/">Omniverse</a>.</p>
<p>The industrial giant demoed a blueprint for how teams can harness comprehensive digital twins virtually using models of existing and future plants. The technologies aim to help FREYR meet surging demand for high-density, cost-effective battery cells.</p>
<p>That’s AI to get charged up about.</p>
<p><i>Learn about building smart spaces with </i><a href="https://www.nvidia.com/en-us/industries/smart-cities-and-spaces/"><i>NVIDIA Metropolis</i></a><i>. Learn about connecting and developing OpenUSD applications with </i><a href="https://www.nvidia.com/en-us/omniverse/"><i>NVIDIA Omniverse</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/Top5_2023.png"
			type="image/png"
			width="1724"
			height="942"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/Top5_2023-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[5 Ways AI Created Smarter Spaces in 2023]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Ear-resistible: 5 AI Podcast Episodes That Perked Up Listeners in 2023</title>
		<link>https://blogs.nvidia.com/blog/ai-podcast-2023-wrap/</link>
		
		<dc:creator><![CDATA[Angie Lee]]></dc:creator>
		<pubDate>Tue, 26 Dec 2023 16:00:10 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[The AI Podcast]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Education]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Science]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68928</guid>

					<description><![CDATA[NVIDIA’s AI Podcast had its best year yet — with a record-breaking 1.2 million plays in 2023 and each biweekly episode now drawing more than 30,000 listens. Among tech’s top podcasts, the AI Podcast has racked up more than 200 episodes and nearly 5 million total plays since its debut in 2016. Listeners across the <a class="read-more" href="https://blogs.nvidia.com/blog/ai-podcast-2023-wrap/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><a href="https://soundcloud.com/theaipodcast">NVIDIA’s AI Podcast</a> had its best year yet — with a record-breaking 1.2 million plays in 2023 and each biweekly episode now drawing more than 30,000 listens.</p>
<p>Among tech’s top podcasts, the AI Podcast has racked up more than 200 episodes and nearly 5 million total plays since its debut in 2016.</p>
<p>Listeners across the globe tune in for smart interviews on <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/">generative AI</a>, <a href="https://blogs.nvidia.com/blog/what-are-large-language-models-used-for/">large language models</a>, as well as more offbeat topics like how AI is tackling challenges like <a href="https://soundcloud.com/theaipodcast/ai-stroller">building a self-driving baby stroller</a> or <a href="https://soundcloud.com/theaipodcast/peter-ma-ai-technosignatures">discovering alien signals</a>.</p>
<p>Here are five episodes that drew tens of thousands of listeners in 2023:</p>
<p><a href="https://soundcloud.com/theaipodcast/anima-anandkumar"><b>Gen AI Enables Scientific Leaps</b></a></p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1613940966&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="Anima Anandkumar on Using Generative AI to Tackle Global Challenges - Ep. 203" href="https://soundcloud.com/theaipodcast/anima-anandkumar" target="_blank" rel="noopener">Anima Anandkumar on Using Generative AI to Tackle Global Challenges &#8211; Ep. 203</a></div>
<p>Caltech’s Anima Anandkumar discusses generative AI’s potential to make splashes in the scientific community. The technology can, for example, be fed DNA, RNA, viral and bacterial data to craft a model that understands the language of genomes, or predict extreme-weather events like hurricanes and heat waves.</p>
<p><a href="https://soundcloud.com/theaipodcast/edtech"><b>Class in Session: AI for Learning</b></a></p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1532657599&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="MIT's Anant Agarwal on AI in Education - Ep. 197" href="https://soundcloud.com/theaipodcast/edtech" target="_blank" rel="noopener">MIT&#8217;s Anant Agarwal on AI in Education &#8211; Ep. 197</a></div>
<p>The future of online education and the revolutionary impact of AI on the learning experience were the central themes discussed by Anant Agarwal, founder of edX and chief platform officer at 2U. The MIT professor and edtech pioneer also highlighted the implementation of AI-powered features in the edX platform, including a ChatGPT plug-in.</p>
<p><a href="https://soundcloud.com/theaipodcast/codeiums"><b>AI Gets Coding</b></a></p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1574497063&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="Codeium’s Varun Mohan and Jeff Wang on Unleashing the Power of AI in Software Development - Ep. 200" href="https://soundcloud.com/theaipodcast/codeiums" target="_blank" rel="noopener">Codeium’s Varun Mohan and Jeff Wang on Unleashing the Power of AI in Software Development &#8211; Ep. 200</a></div>
<p>The world increasingly runs on code. Accelerating the work of those who create that code will boost their productivity — and that’s just what AI startup Codeium, a member of the <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a> program for startups, aims to do. The company’s leaders Varun Mohan and Jeff Wang talk about AI’s transformational role in software development.</p>
<p><a href="https://soundcloud.com/theaipodcast/making-machines-mindful"><b>Mindful Machine-Making</b></a></p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1643145072&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="Making Machines Mindful: NYU Professor Talks Responsible AI - Ep. 205" href="https://soundcloud.com/theaipodcast/making-machines-mindful" target="_blank" rel="noopener">Making Machines Mindful: NYU Professor Talks Responsible AI &#8211; Ep. 205</a></div>
<p>Julia Stoyanovich, associate professor of computer science and engineering at NYU and director of the university’s Center for Responsible AI, discusses how to make the terms “AI” and “responsible AI” synonymous.</p>
<p><a href="https://soundcloud.com/theaipodcast/matice"><b>AI for Regeneration, Scar Prevention</b></a></p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1550643253&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="Matice Founder Jessica Whited on Harnessing Regenerative Species for Medical Breakthroughs - Ep. 198" href="https://soundcloud.com/theaipodcast/matice" target="_blank" rel="noopener">Matice Founder Jessica Whited on Harnessing Regenerative Species for Medical Breakthroughs &#8211; Ep. 198</a></div>
<p>Scientists at Matice Biosciences are applying AI to study the regeneration of tissues in animals known as super-regenerators, such as salamanders and planarians. Cofounder Jessica Whited, a regenerative biologist at Harvard University, discusses how the research could unlock new treatments to help humans heal from injuries without scarring.</p>
<h2><b>Subscribe to the AI Podcast</b></h2>
<p>Get the<a href="https://blogs.nvidia.com/ai-podcast/"> AI Podcast</a> through <a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">Amazon Music</a>, <a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439">iTunes</a>, <a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjI2NDAzNDEzMy9zb3VuZHMucnNz">Google Podcasts</a>, <a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm">Google Play</a>, <a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us">Castbox</a>, DoggCatcher, <a href="https://overcast.fm/itunes1186480811/the-ai-podcast">Overcast</a>, <a href="https://player.fm/series/the-ai-podcast">PlayerFM</a>, Pocket Casts, <a href="http://www.podbay.fm/show/1186480811">Podbay</a>, <a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast">PodBean</a>, PodCruncher, PodKicker,<a href="https://soundcloud.com/theaipodcast"> Soundcloud</a>, <a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L">Spotify</a>, <a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr">Stitcher</a> and <a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/">TuneIn</a>.</p>
<p>Make the AI Podcast better by filling out <a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short">this listener survey</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast.jpg"
			type="image/jpeg"
			width="1400"
			height="931"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Ear-resistible: 5 AI Podcast Episodes That Perked Up Listeners in 2023]]></media:title>
			<media:description type="html">NVIDIA AI Podcast</media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Holiday Card Glows Gold and Green on Cold Winter’s Eve</title>
		<link>https://blogs.nvidia.com/blog/studio-holiday-autodesk-adobe-omniverse-usd/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 26 Dec 2023 14:00:37 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68901</guid>

					<description><![CDATA[NVIDIA’s holiday card — enchanting viewers from the perspective of snuggled-up family members on a couch — warmly depicts a crackling fireplace and an NVIDIA robo-dog by the hearth, all framed by a string of sparkling lights. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. We’re also deep diving on new </i><a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/"><i>GeForce RTX 40 Series GPU</i></a><i> features, technologies and resources, and how they dramatically accelerate content creation.</i></p>
<p>NVIDIA’s holiday card — enchanting viewers from the perspective of snuggled-up family members on a couch — warmly depicts a crackling fireplace and an NVIDIA robo-dog by the hearth, all framed by a string of sparkling lights.</p>
<p>In the scene, shown above, characters are decked out in NVIDIA-themed socks and under blankets with the pattern from a custom NVIDIA holiday sweater. Detail-oriented viewers can discover hidden treasures: a virtual toy model of NVIDIA founder and CEO Jensen Huang — aka <a href="https://blogs.nvidia.com/blog/toy-jensen-jingle-bells/">Toy Jensen</a> — NVIDIA iconography in the woodwork and an NVIDIA-branded mug.</p>
<p>Members of NVIDIA’s creative team who are featured in this week’s special <i>In the NVIDIA Studio</i> beat — Alessandro Baldasseroni, Michael Johnson and Rini Sugianto — collaborated to build this 3D scene. They combined 60 years of creative experience, AI-powered features and NVIDIA RTX GPU acceleration in their favorite creative apps to incredible effect.</p>
<p>Plus, the latest version of Reallusion iClone, a real-time 3D animation software, offers a crowd-creation system for populating large worlds in <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, a platform that interconnects 3D workflows for live-sync creation.</p>
<h2><b>Populate Virtual Worlds in NVIDIA Omniverse</b></h2>
<p>Reallusion iClone helps artists bring lifelike movement and realistic facial expressions to 3D models.</p>
<p>iClone version 8.4 builds on these capabilities with a simulation system that provides real-time, customizable crowd animations using Motion Director, a cutting-edge motion-matching and trigger-animation technology.</p>
<p><iframe loading="lazy" title="iClone 8.4 - Crowd Simulation | Motion Director Editor | FREE UPDATE" width="500" height="281" src="https://www.youtube.com/embed/oA8fzC47A7s?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>With it, artists can effortlessly spawn lifelike characters complete with facial expressions, accessories and diverse animation styles. The characters can then be directed to intelligently navigate 3D spaces while avoiding collisions and obstacles.</p>
<p><iframe loading="lazy" title="Crowd Sim: Actor Groups | iClone 8 Tutorial" width="500" height="281" src="https://www.youtube.com/embed/2VMJ9HyqrpI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>iClone supports live sync with <a href="https://docs.omniverse.nvidia.com/dev-guide/latest/kit-architecture.html">NVIDIA Omniverse Kit</a>-based apps, allowing users to more seamlessly tap its vast libraries of characters and motions.</p>
<p>iClone version 8.4 is free to download. Learn more about the <a href="https://www.reallusion.com/iclone/crowd-sim/">release details</a>.</p>
<h2><b>Averkin’s at It Again</b></h2>
<p>Seasoned <i>In the NVIDIA Studio </i>artist <a href="https://blogs.nvidia.com/blog/siggraph-studio-rtx-omniverse-openusd/">Andrew Averkin</a> can’t help but spread holiday cheer.</p>
<p>His 3D scene <i>Keep Me Warm </i>seamlessly transitions between the immaculately detailed parts of a holiday-themed room. The Christmas trees, bright lights and children’s toys all feature photorealistic detail sure to move viewers, and calming music adds to the scene’s coziness.</p>
<p><iframe loading="lazy" title="Keep Me Warm" width="500" height="281" src="https://www.youtube.com/embed/iK1V_UX8b_Q?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Averkin built <i>Keep Me Warm</i> in NVIDIA Omniverse, which is based on the Universal Scene Description framework, aka <a href="https://www.nvidia.com/en-us/omniverse/usd/">OpenUSD</a>.</p>
<p>Such inspirational, winter-themed content is just what the NVIDIA Studio team is looking for in the <a href="https://forums.developer.nvidia.com/t/get-creative-and-sleigh-the-2nd-annual-winterartchallenge/274994">#WinterArtChallenge</a>. Don’t forget to share winter-themed art with the hashtag on Facebook, Instagram or X for a chance to be featured on NVIDIA Studio and NVIDIA Omniverse social media channels.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Imagine coming across this incredible winter berry on a walk in the snow&#8230;<img src="https://s.w.org/images/core/emoji/14.0.0/72x72/2744.png" alt="❄" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>Incredible <a href="https://twitter.com/hashtag/WinterArtChallenge?src=hash&amp;ref_src=twsrc%5Etfw">#WinterArtChallenge</a> submission by <a href="https://twitter.com/blendeered?ref_src=twsrc%5Etfw">@Blendeered</a> (inspired by <a href="https://twitter.com/wildberrymore?ref_src=twsrc%5Etfw">@wildberrymore</a>&#39;s music). <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/26c4.png" alt="⛄" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>Share your winter-themed art using the hashtag for a chance to be featured on our social channels! <a href="https://t.co/yfPf6HTRrg">pic.twitter.com/yfPf6HTRrg</a></p>
<p>&mdash; NVIDIA Studio (@NVIDIAStudio) <a href="https://twitter.com/NVIDIAStudio/status/1734311782968156173?ref_src=twsrc%5Etfw">December 11, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p>And check out Averkin’s <a href="https://www.instagram.com/andrewaverkin/?hl=en">Instagram</a> for more engaging content.</p>
<h2><b>Deck the Halls With Tons of Renders</b></h2>
<p>“The goal was to create something that invoked warmth, joy and holiday spirit,” said Johnson on ideating for this year’s NVIDIA holiday card. “There’s nothing better than being with family, cuddled up on the couch, enjoying each other’s time while wearing something really cozy and relaxing.”</p>
<p>The NVIDIA artists created foreground characters starting with basic elements from the trio’s collective asset library.</p>
<p>Baldasseroni took the lead on modeling and tweaking the characters in ZBrush, working closely with Johnson on the right composition, and even provided preliminary posing to help guide the character feel for a relaxed family portrait.</p>
<div style="width: 1280px;" class="wp-video"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video class="wp-video-shortcode" id="video-68901-1" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-christmas-wk89-zbrush-1280w.mp4?_=1" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-christmas-wk89-zbrush-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-christmas-wk89-zbrush-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>Moving to Adobe Substance 3D Painter, Baldasseroni created and applied custom textures to the models. His <a href="https://www.nvidia.com/en-us/design-visualization/rtx-a6000/">NVIDIA RTX A6000 GPU</a> accelerated <a href="https://blogs.nvidia.com/blog/direct-indirect-lighting/">light and ambient occlusion</a>, baking optimized assets in mere seconds.</p>
<div class="simplePullQuote right"><p>“I used GPU acceleration in Adobe Substance Painter and worked with preliminary lookdev renders in the NVIDIA Iray engine.” — Alessandro Baldasseroni</p>
</div>
<p>Sugianto took on animation work, opening Autodesk Maya where her NVIDIA RTX A6000 GPU provided several key advantages.</p>
<p>RTX-accelerated ray tracing and AI-powered denoising with the Autodesk Arnold renderer resulted in highly interactive and photorealistic modeling.</p>
<p>Autodesk Maya also supports third-party GPU-accelerated renderers, such as V-Ray, OctaneRender and Redshift, which gave Sugianto more options to animate the scene.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-68901-2" width="1280" height="696" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-christmas-wk89-maya-1280w.mp4?_=2" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-christmas-wk89-maya-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-christmas-wk89-maya-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>With the assets beautifully modeled, textured and animated, Johnson imported all files into the <a href="https://www.nvidia.com/en-us/omniverse/apps/usd-composer/">NVIDIA Omniverse USD Composer</a> app to add physically accurate properties for the realistic fire, candle lighting and smoke.</p>
<p>“NVIDIA RTX GPU rendering in USD Composer is so fast at enabling quick iterations and different looks,” said Johnson.</p>
<p>Johnson used OpenUSD files in USD Composer, allowing Baldasseroni and Sugianto to review Johnson’s edits in real time with fully ray-traced details. This eliminated the need to download, upload and reformat files to share and consolidate feedback from other stakeholders, saving valuable time and resources.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-68901-3" width="1280" height="532" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-christmas-wk89-composer2-1280w.mp4?_=3" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-christmas-wk89-composer2-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-christmas-wk89-composer2-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>Johnson then rendered out still images into Adobe Photoshop for final color grading. He further improved visual quality by upscaling the image using the AI-powered, RTX-accelerated <a href="https://blogs.nvidia.com/blog/rtx-video-super-resolution/">Super Resolution</a> feature — which is significantly faster than traditional methods. Throughout his workflow, Johnson could choose from more than 30 GPU-accelerated features, including blur gallery, object selection, liquify, smart sharpen and perspective.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-68901-4" width="1280" height="532" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-christmas-wk89-photoshop-1280w.mp4?_=4" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-christmas-wk89-photoshop-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-christmas-wk89-photoshop-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>He then uploaded files into Nuke, a visual-effects and video-editing software, for final GPU-accelerated compositing of all the scene’s elements.</p>
<figure id="attachment_68917" aria-describedby="caption-attachment-68917" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-christmas-wk89-artist-feature-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68917" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-christmas-wk89-artist-feature-1280w-672x347.png" alt="" width="672" height="347" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-christmas-wk89-artist-feature-1280w-672x347.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-christmas-wk89-artist-feature-1280w-400x206.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-christmas-wk89-artist-feature-1280w-768x396.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-christmas-wk89-artist-feature-1280w-842x434.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-christmas-wk89-artist-feature-1280w-406x209.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-christmas-wk89-artist-feature-1280w-188x97.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-christmas-wk89-artist-feature-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68917" class="wp-caption-text">NVIDIA artists Alessandro Baldasseroni, Michael Johnson and Rini Sugianto.</figcaption></figure>
<p>Check out <a href="https://www.instagram.com/alessandrobaldasseroni/">Baldasseroni</a>, <a href="https://www.instagram.com/mike_johnson_art/">Johnson</a> and <a href="https://www.instagram.com/rinisugianto/">Sugianto</a> on Instagram.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>, </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i> and </i><a href="https://twitter.com/NVIDIAStudio"><i>X</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-christmas-wk89-zbrush-1280w.mp4" length="1968140" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-christmas-wk89-maya-1280w.mp4" length="1957434" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-christmas-wk89-composer2-1280w.mp4" length="1935814" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-christmas-wk89-photoshop-1280w.mp4" length="1728084" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/nv-blog-preview-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/nv-blog-preview-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Holiday Card Glows Gold and Green on Cold Winter’s Eve]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>11 Ways AI Made the World Better in 2023</title>
		<link>https://blogs.nvidia.com/blog/ai-better-world-omniverse-jetson/</link>
		
		<dc:creator><![CDATA[Scott Martin]]></dc:creator>
		<pubDate>Thu, 21 Dec 2023 16:00:30 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Corporate Sustainability]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[NVIDIA Jetson]]></category>
		<category><![CDATA[Omniverse Enterprise]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68826</guid>

					<description><![CDATA[AI made a splash this year — from Wall Street to the U.S. Congress — driven by a wave of developers aiming to make the world better. Here’s a look at AI in 2023 across agriculture, natural disasters, medicine and other areas worthy of a cocktail party conversation. This AI Is on Fire California has <a class="read-more" href="https://blogs.nvidia.com/blog/ai-better-world-omniverse-jetson/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>AI made a splash this year — from Wall Street to the U.S. Congress — driven by a wave of developers aiming to make the world better.</p>
<p>Here’s a look at AI in 2023 across agriculture, natural disasters, medicine and other areas worthy of a <a href="https://blogs.nvidia.com/blog/music-youtube-cocktail-party-problem-ai-artificial-intelligence-deep-learning/">cocktail party</a> conversation.</p>
<h2><b>This AI Is on Fire</b></h2>
<p>California has recently seen record wildfires. With scorching heat late into the summer, the state’s crispy foliage becomes a tinderbox that can ignite and quickly blaze out of control. Burning for solutions, developers are embracing AI for early detection.</p>
<p>DigitalPath, based in Chico, California, has refined a <a href="https://blogs.nvidia.com/blog/whats-the-difference-between-a-cnn-and-an-rnn/">convolutional neural network</a> to spot wildfires. The model, run on NVIDIA GPUs, enables thousands of cameras across the state to detect wildfires in real time for the ALERTCalifornia initiative, a collaboration between the University of California, San Diego, and the CAL FIRE wildfire agency.</p>
<p><a href="https://blogs.nvidia.com/blog/ai-wildfires-california/">The mission</a> is near and dear to DigitalPath employees, whose office sits not far from the town of Paradise, where California’s deadliest wildfire killed 85 people in 2018.</p>
<p>“It’s one of the main reasons we’re doing this,” said CEO Jim Higgins. “We don’t want people to lose their lives.”</p>
<h2><b>Earth-Shaking Research</b></h2>
<p>A team from the University of California, Santa Cruz; University of California, Berkeley; and the Technical University of Munich <a href="https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023GL103909">released a paper</a> this year on a new deep learning model for earthquake forecasts.</p>
<p>Shaking up the status quo around the ETAS model standard, developed in 1988, <a href="https://blogs.nvidia.com/blog/quakes-deep-learning-forecasts/">the new RECAST model</a>, trained on NVIDIA GPUs, is capable of using larger datasets and holds promise for making better predictions during earthquake sequences.</p>
<p>“There’s a ton of room for improvement within the forecasting side of things,” said Kelian Dascher-Cousineau, one of the paper’s authors.</p>
<h2><b>AI’s Day in the Sun</b></h2>
<p>Verdant, based in the San Francisco Bay Area, <a href="https://blogs.nvidia.com/blog/verdant-farm-organics-jetson-orin/">is supporting organic farming</a>. The startup develops AI for <a href="https://blogs.nvidia.com/blog/mondavi-monarch-smart-electric-jetson-tractor/">tractor</a> implements that can weed, fertilize and spray, providing labor support while lowering production costs for farmers and boosting yields.</p>
<p>The <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">NVIDIA Jetson Orin</a>-based robots-as-a-service business provides farmers with metrics on yield gains and chemical reduction. “We wanted to do something meaningful to help the environment,” said Lawrence Ibarria, chief operating officer at Verdant.</p>
<p><iframe loading="lazy" title="Sniper robot treats 500k plants per hour with 95% less chemicals | Challengers" width="500" height="281" src="https://www.youtube.com/embed/sV0cR_Nhac0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Living the Dream </b></h2>
<p>Ge Dong is living out her childhood dream, following in her mother’s footsteps by pursuing physics. She cofounded <a href="https://www.energysingularity.cn/en/">Energy Singularity</a>, a startup that aims to lower the cost of building a commercial tokamak — which can cost billions of dollars —for fusion energy development.</p>
<p>It brings the promise of cleaner energy.</p>
<p>“We’ve been using NVIDIA GPUs for all our research — they’re one of the most important tools in plasma physics these days,” <a href="https://blogs.nvidia.com/blog/ai-hpc-energy-fusion/">she said</a>.</p>
<h2><b>Gimme Shelter</b></h2>
<p>Chaofeng Wang, a University of Florida assistant professor of artificial intelligence, is enlisting deep learning and images from Google Street View to evaluate urban buildings. By automating the process, the work is intended to assist governments in supporting building structures and post-disaster recovery.</p>
<p>“Without NVIDIA GPUs, we wouldn’t have been able to do this,” <a href="https://blogs.nvidia.com/blog/street-view-image-deep-learning-research-urban-building/">Wang said</a>. “They significantly accelerate the process, ensuring timely results.”</p>
<h2><b>AI Predicts Covid Variants</b></h2>
<p><a href="https://blogs.nvidia.com/blog/genomic-large-language-model-predicts-covid-variants/">A Gordon Bell prize-winning model</a>, GenSLMs has shown it can generate gene sequences closely resembling real-world variants of SARS-CoV-2, the virus behind COVID-19. Researchers trained the model using <a href="https://www.nvidia.com/en-us/data-center/tensor-cores/">NVIDIA A100 Tensor Core GPU</a>-powered supercomputers, including NVIDIA’s <a href="https://blogs.nvidia.com/blog/making-selene-pandemic-ai/">Selene</a>, the U.S. Department of Energy’s <a href="https://blogs.nvidia.com/blog/nersc-perlmutter-ai-supercomputer/">Perlmutter</a> and Argonne’s <a href="https://nvidianews.nvidia.com/news/nvidia-turbocharges-extreme-scale-ai-for-argonne-national-laboratorys-polaris-supercomputer">Polaris</a> system.</p>
<p>“The AI’s ability to predict the kinds of gene mutations present in recent COVID strains — despite having only seen the Alpha and Beta variants during training — is a strong validation of its capabilities,” said Arvind Ramanathan, lead researcher on the project and a computational biologist at Argonne.</p>
<h2><b>Jetson-Enabled Autonomous Wheelchair</b></h2>
<p>Kabilan KB, an undergraduate student from the Karunya Institute of Technology and Sciences in Coimbatore, India, is developing an <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/">NVIDIA Jetson</a>-enabled autonomous wheelchair. To help boost development, he’s been using <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, a platform for building and operating 3D tools and applications based on the <a href="https://www.nvidia.com/en-us/omniverse/usd/">OpenUSD</a> framework.</p>
<p>“Using Omniverse for simulation, I don’t need to invest heavily in prototyping models for my robots, because I can use <a href="https://blogs.nvidia.com/blog/what-is-synthetic-data/">synthetic data</a> generation instead,” <a href="https://blogs.nvidia.com/blog/kabilan-kb-autonomous-wheelchair/">he said</a>. “It’s the software of the future.”</p>
<h2><b>Digital Twins for Brain Surgery</b></h2>
<p>Atlas Meditech is using the <a href="https://docs.nvidia.com/monai/index.html">MONAI</a> medical imaging framework and the <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> 3D development platform to help build AI-powered decision support and high-fidelity surgery rehearsal platforms — all in an effort to improve surgical outcomes and patient safety.</p>
<p>“With accelerated computing and digital twins, we want to transform this mental rehearsal into a highly realistic rehearsal in simulation,” <a href="https://blogs.nvidia.com/blog/atlas-meditech-brain-surgery-ai-digital-twins/">said Dr. Aaron Cohen-Gadol</a>, founder of the company.</p>
<h2><b>Keeping AI on Energy </b></h2>
<p>Artificial intelligence is helping optimize solar and wind farms, <a href="https://blogs.nvidia.com/blog/climate-research-next-wave/">simulate climate and weather</a>, and support power grid reliability and other areas of the energy market.</p>
<p>Check out this installment of the <a href="https://youtu.be/zrcxLZmOyNA?feature=shared">I AM AI video series</a> to learn about how NVIDIA is enabling these technologies and working with energy-conscious collaborators to drive breakthroughs for a cleaner, safer, more <a href="https://resources.nvidia.com/l/en-us-sustainable-computing">sustainable future</a>.</p>
<p><iframe loading="lazy" title="Powering the Future of Clean Energy | I AM AI" width="500" height="281" src="https://www.youtube.com/embed/zrcxLZmOyNA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>AI Can See Clearly Now</b></h2>
<p>Many patients in lower- and middle-income countries lack access to cataract surgery because of a shortage of ophthalmologists. But more than 2,000 doctors a year in lower-income countries can now treat cataract blindness — the world’s <a href="https://academic.oup.com/inthealth/article/14/Supplement_1/i68/6563812">leading cause of blindness</a> —using GPU-powered surgical simulation with the help of nonprofit HelpMeSee.</p>
<p>“We’re lowering the barrier for healthcare practitioners to learn these specific skills that can have a profound impact on patients,” <a href="https://blogs.nvidia.com/blog/helpmesee-nonprofit-training-simulator-for-cataract-surgery/">said Bonnie An Henderson</a>, CEO of the New York-based nonprofit.</p>
<h2><b>Waste Not, Want Not</b></h2>
<p>Afresh, based in San Francisco, helps stores reduce food waste. The startup has developed machine learning and AI models using data on fresh produce to help grocers make informed inventory-purchasing decisions. It has also launched software that enables grocers to save time and increase data accuracy with inventory tracking.</p>
<p>“The most impactful thing we can do is reduce food waste to mitigate climate change,” said Nathan Fenner, cofounder and president of Afresh, on the <a href="https://blogs.nvidia.com/ai-podcast/">NVIDIA AI podcast</a>.</p>
<p><iframe loading="lazy" title="Afresh Co-Founder Nathan Fenner On How AI Can Help Grocers Manage Supply Chains - Ep. 208 by The AI Podcast" width="500" height="400" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?visual=true&#038;url=https%3A%2F%2Fapi.soundcloud.com%2Ftracks%2F1671268662&#038;show_artwork=true&#038;maxheight=750&#038;maxwidth=500"></iframe></p>
<p>&nbsp;</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/ElevenWays-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1365"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/ElevenWays-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[11 Ways AI Made the World Better in 2023]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Explore a Whole New ‘Monster Hunter: World’ on GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-monster-hunter-world/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 21 Dec 2023 14:00:36 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68890</guid>

					<description><![CDATA[Time to gear up, hunters — Capcom’s Monster Hunter: World joins the GeForce NOW library, bringing members the ultimate hunting experience on any device. It’s all part of an adventurous week, with nearly a dozen new games joining the cloud gaming service. A Whole New World Join the Fifth Fleet on an epic adventure to <a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-monster-hunter-world/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Time to gear up, hunters — Capcom’s <i>Monster Hunter: World</i> joins the <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> library, bringing members the ultimate hunting experience on any device.</p>
<p>It’s all part of an adventurous week, with nearly a dozen new games joining the cloud gaming service.</p>
<h2><b>A Whole New World</b></h2>
<figure id="attachment_68898" aria-describedby="caption-attachment-68898" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-68898" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Monster_Hunter_World-672x378.jpg" alt="Monster Hunter World on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Monster_Hunter_World-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Monster_Hunter_World-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Monster_Hunter_World-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Monster_Hunter_World-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Monster_Hunter_World-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Monster_Hunter_World-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Monster_Hunter_World-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Monster_Hunter_World-1280x720.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Monster_Hunter_World.jpg 1920w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68898" class="wp-caption-text"><em>Hunt or be hunted.</em></figcaption></figure>
<p>Join the Fifth Fleet on an epic adventure to the New World, a land full of monstrous creatures, in the acclaimed action role-playing game (RPG) <i>Monster Hunter: World</i>. It’s the latest in the series to join the cloud, following <a href="https://blogs.nvidia.com/blog/geforce-now-thursday-feb-16/"><i>Monster Hunter Rise</i></a>.</p>
<p>Members can unleash their inner hunter and slay ferocious monsters in a living, breathing ecosystem. Explore the unique landscape and encounter diverse monster inhabitants in ferocious hunting battles. Hunt alone or with up to three other players, and use materials collected from fallen foes to craft new gear and take on bigger, badder beasts.</p>
<p>Step up to the Quest Board and hunt monsters in the cloud at up to 4K resolution and 120 frames per second as an <a href="http://geforcenow.com">Ultimate member</a> — or discover the New World at ultrawide resolutions. Members don’t need to wait for downloads or worry about storage space, and can take the action with them across nearly all devices.</p>
<h2><b>Surprise!</b></h2>
<p>One of the best ways to stream top PC games on the go — even the stunning neon lights of <i>Cyberpunk 2077 — </i>is with a Chromebook Plus. NVIDIA invited <i>Cyberpunk 2077 </i>fans well-versed on the graphics-intensive game to try it out on an unknown, hidden system.</p>
<p><iframe loading="lazy" title="GeForce NOW: Power The Cloud With Chromebook Plus" width="500" height="281" src="https://www.youtube.com/embed/Yf-zZWkyfLM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>They were shocked to realize they were playing on a Chromebook Plus with GeForce NOW’s Ultimate tier.</p>
<p>NVIDIA brought the same activation to attendees of The Game Awards, one of the industry’s most-watched award shows.</p>
<p>With the ability to stream from powerful GeForce RTX 4080 GPU-powered servers in the cloud with the Ultimate tier — paired with the cloud gaming <a href="https://www.chromebook.com/gaming">Chromebook Plus’</a> high refresh rates, high-resolution displays, gaming keyboards, fast WiFi 6 connectivity and immersive audio — it’s no surprise participants gave the same surprised and delighted response.</p>
<p>To experience the power of gaming on a Chromebook with GeForce NOW, Google and NVIDIA are offering Chromebook owners three free months of a premium GeForce NOW membership. Find more details on how to redeem the offer on the <a href="https://www.google.com/intl/en_us/chromebook/perks/">Chromebook Perks page</a>.</p>
<h2><b>Festival of Games</b></h2>
<figure id="attachment_68895" aria-describedby="caption-attachment-68895" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-68895" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Genshin_Impact_4.3-672x336.jpg" alt="Genshin Impact 4.3 update on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Genshin_Impact_4.3-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Genshin_Impact_4.3-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Genshin_Impact_4.3-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Genshin_Impact_4.3-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Genshin_Impact_4.3-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Genshin_Impact_4.3-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Genshin_Impact_4.3-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Genshin_Impact_4.3-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Genshin_Impact_4.3.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68895" class="wp-caption-text"><em>Lights, camera, action!</em></figcaption></figure>
<p>The latest update from opular open-world action RPG <i>Genshin Impact</i> from miHoYo is now available for members to stream. It brings two new characters, new events and a whole host of new features. Get to know the Geo Claymore character Navia, as well as Chevreuse, a new Pyro Polearm user, and more during the Fontinalia Festival event.</p>
<p>Don’t miss the 11 newly supported games joining the GeForce NOW library this week:</p>
<ul>
<li><i>Blasphemous 2 </i>(<a href="https://www.epicgames.com/store/p/blasphemous-2?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Bloons TD Battles</i> (<a href="https://store.steampowered.com/app/444640?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Dark Envoy </i>(<a href="https://store.steampowered.com/app/945770?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Figment 2: Creed Valley</i> (<a href="https://www.epicgames.com/store/p/figment2-creed-valley?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Ikonei Island: An Earthlock Adventure </i>(<a href="https://store.steampowered.com/app/1550730?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Loddlenaut </i>(<a href="https://store.steampowered.com/app/1644940?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Monster Hunter: World </i>(<a href="https://store.steampowered.com/app/582010?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Nova-Life: Amboise </i>(<a href="https://store.steampowered.com/app/885570?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>RIDE 5 </i>(<a href="https://www.epicgames.com/store/p/ride-5?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>The Smurfs 2 &#8211; The Prisoner of the Green Stone </i>(<a href="https://store.steampowered.com/app/2397500?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Tintin Reporter &#8211; Cigars of the Pharaoh </i>(<a href="https://store.steampowered.com/app/2125090?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<p>And there’s still time to give the gift of cloud gaming with the latest membership bundle, which includes a free, three-month PC Game Pass subscription with the purchase of a six-month GeForce NOW <a href="https://www.nvidia.com/en-us/geforce-now/memberships/">Ultimate membership</a>.</p>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">Twitter</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="qme" dir="ltr"><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f440.png" alt="👀" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="https://t.co/BJvPPrW3VW">pic.twitter.com/BJvPPrW3VW</a></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1737518250374611246?ref_src=twsrc%5Etfw">December 20, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/gfn-thursday-12-21-nv-blog-1280x680-no-cta.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/gfn-thursday-12-21-nv-blog-1280x680-no-cta-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Explore a Whole New ‘Monster Hunter: World’ on GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Cool Robots of 2023: Meet the Autonomous Movers and Shakers</title>
		<link>https://blogs.nvidia.com/blog/robot-roundup-jetson/</link>
		
		<dc:creator><![CDATA[Rick Merritt]]></dc:creator>
		<pubDate>Wed, 20 Dec 2023 16:00:34 +0000</pubDate>
				<category><![CDATA[Autonomous Machines]]></category>
		<category><![CDATA[Agriculture and Food]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[CES 2023]]></category>
		<category><![CDATA[Customer Stories]]></category>
		<category><![CDATA[Data Science]]></category>
		<category><![CDATA[Digital Twin]]></category>
		<category><![CDATA[Embedded Computing]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[Industrial and Manufacturing]]></category>
		<category><![CDATA[Isaac]]></category>
		<category><![CDATA[Jetson]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Metropolis]]></category>
		<category><![CDATA[New GPU Uses]]></category>
		<category><![CDATA[NVIDIA Isaac Sim]]></category>
		<category><![CDATA[NVIDIA Jetson]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68836</guid>

					<description><![CDATA[Outside the glare of the klieg lights that ChatGPT commanded this year, a troupe of autonomous machines nudged the frontiers of robotics forward. Here are six that showed special prowess — swimming, diving, gripping, seeing, strolling and flying through 2023. A Media Darling at CES Ella — a smart stroller from startup Glüxkind Technologies, of <a class="read-more" href="https://blogs.nvidia.com/blog/robot-roundup-jetson/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Outside the glare of the klieg lights that ChatGPT commanded this year, a troupe of autonomous machines nudged the frontiers of robotics forward.</p>
<p>Here are six that showed special prowess — swimming, diving, gripping, seeing, strolling and flying through 2023.</p>
<h2><b>A Media Darling at CES</b></h2>
<p>Ella — a <a href="https://blogs.nvidia.com/blog/ella-stroller-jetson/">smart stroller</a> from startup <a href="https://gluxkind.com/">Glüxkind Technologies</a>, of Vancouver, Canada — kicked off the year when it was named an honoree in the <a href="https://www.ces.tech/innovation-awards/honorees.aspx">CES 2023 Innovation Awards</a>.</p>
<p>The canny carriage uses computer vision running on the <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/">NVIDIA Jetson edge AI platform</a> to follow parents. Its AI-powered abilities, like smart braking and a rock-my-baby mode, captured the attention of media outlets like <i>Good Morning America</i> and <i>The Times of London</i> as well as an <a href="https://soundcloud.com/theaipodcast/ai-stroller">NVIDIA AI Podcast interview</a> with its husband-and-wife cofounders.</p>
<p>A member of <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a>, a free program for cutting-edge startups, Gl<a href="https://gluxkind.com/">ü</a>xkind was one of <a href="https://blogs.nvidia.com/blog/jetson-innovation-awards-ces/">seven companies</a> with NVIDIA-powered products recognized at the Las Vegas event in January. They included:</p>
<ul>
<li>John Deere for its fully autonomous tractor,</li>
<li>AGRIST for its robot that automatically harvests bell peppers,</li>
<li>Inception member Skydio for its drone that can fly at a set distance and height without manual intervention,</li>
<li>Neubility, another Inception member, for its self-driving delivery robot,</li>
<li>Seoul Robotics, a partner in the <a href="https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/">NVIDIA Metropolis</a> vision AI software, for its <a href="https://blogs.nvidia.com/blog/seoul-robotics-autonomy-through-infrastructure/">Level 5 Control Tower</a> that can turn standard vehicles into self-driving cars, and</li>
<li>WHILL for its one-person vehicle that automatically guides a user inside places like airports or hospitals.</li>
</ul>
<h2><b>Dexterous Food Packer</b></h2>
<p>Inception startup Soft Robotics, of Bedford, Mass., introduced its mGripAI system to an $8 trillion food industry hungry for automation. It combines 3D vision and AI to grasp delicate items such as chicken wings, attracting investors that include Tyson Foods and Johnsonville.</p>
<p>Soft Robotics uses the <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> platform and <a href="https://developer.nvidia.com/isaac-sim">NVIDIA Isaac Sim</a> robotics simulator to create 3D renderings of chicken parts on conveyor belts or in bins. With help from AI and the ray-tracing capabilities of <a href="https://www.nvidia.com/en-us/design-visualization/ampere-architecture/">NVIDIA RTX</a> technology, they help the robot gripper handle as many as 100 picks per minute, even under glare or changing light conditions.</p>
<p>“We’re all in on Omniverse and Isaac Sim, and that’s been working great for us,” David Weatherwax, senior director of software engineering at Soft Robotics, said in a <a href="https://blogs.nvidia.com/blog/isaac-soft-robotics-simulation/">January interview</a>.</p>
<p><iframe loading="lazy" title="mGripAI Poultry Automation" width="500" height="281" src="https://www.youtube.com/embed/YhfdyOa-XPQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>A Keen Eye in the Factory</b></h2>
<p>In a very different example of industrial digitalization, leading electronics manufacturer Quanta is inspecting the quality of its products using<a href="https://blogs.nvidia.com/blog/techman-robot-isaac-sim/"> the TM25S</a>, an AI-enabled robot from its subsidiary, Techman Robot.</p>
<p>Using Omniverse, Techman built a<a href="https://www.nvidia.com/en-us/omniverse/solutions/digital-twins/"> digital twin</a> of the inspection robot — as well as the product to be inspected — in Isaac Sim. Programming the robot in simulation reduced time spent on the task by over 70%, compared to programming manually on the real robot.</p>
<p>Then, with powerful optimization tools in Isaac Sim, Techman explored a massive number of program options in parallel on NVIDIA GPUs. The end result, shown in the video below, was an efficient solution that reduced the cycle time of each inspection by 20%.</p>
<p><iframe loading="lazy" title="Techman AI Robot for Quality Inspection | Developed in Isaac Sim and powered by Omniverse" width="500" height="281" src="https://www.youtube.com/embed/b2yjubjQ5Xs?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Sailing the Seas for Data Science</b></h2>
<p>For its part, <a href="https://blogs.nvidia.com/blog/saildrone-autonomous-oceanic-monitoring-jetson-deepstream/">Saildrone</a>, an Inception startup in Alameda, Calif., created uncrewed watercraft that can cost-effectively gather data for science, fisheries, weather forecasting and more. NVIDIA Jetson modules process data streams from their sensors, some with help from NVIDIA Metropolis vision AI software such as <a href="https://developer.nvidia.com/deepstream-sdk">NVIDIA DeepStream</a>, a development kit for intelligent video analytics.</p>
<p>The video below shows how three of its smart sailboats are helping evaluate ocean health around the Hawaiian Islands.</p>
<p><iframe loading="lazy" title="2023 UH Mānoa Ocean Chemistry Mission" width="500" height="281" src="https://www.youtube.com/embed/Ev2mLKXkfwY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Destination: Mars</b></h2>
<p>The next stop for one autonomous vehicle may be the red planet.</p>
<p>Caltech’s Multi-Modal Mobility Morphobot, or <a href="https://blogs.nvidia.com/blog/caltech-nasa-mars-rover-robot-jetson/">M4</a>, can configure itself to walk, fly or drive at speeds up to 40 mph (video below). An M42 version is now under development at NASA as a Mars rover candidate and has attracted interest for other uses like reconnaissance in fire zones.</p>
<p>Since <a href="https://www.nature.com/articles/s41467-023-39018-y">releasing a paper</a> on it in <i>Nature Communications</i>, the team has been inundated with proposals for the shape-shifting drone built on the NVIDIA Jetson platform.</p>
<p><iframe loading="lazy" title="M4 Drives and Flies Around Caltech&#039;s Campus" width="500" height="281" src="https://www.youtube.com/embed/J91jTI2-k_U?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Delivery Drone Flies High</b></h2>
<p>The year ended on a high note with San Francisco-based <a href="https://blogs.nvidia.com/blog/zipline-drone-jetson-inception/">Zipline announcing</a> its delivery drones flew more than 65 million miles and made more than 850,000 deliveries since the company’s start in 2011. Zipline now completes one delivery every 70 seconds, globally.</p>
<p>That’s a major milestone for the Inception startup, the field it’s helping pioneer and the customers who can receive everything from pizza to vitamins 7x faster than by truck.</p>
<p>Zipline’s latest drone uses two Jetson Orin NX modules. It can carry eight pounds of cargo for 10 miles at up to 70 mph to deliver packages in single-digit minutes while reducing carbon emissions 97% compared to gasoline-based delivery vehicles.</p>
<h2><b>Machines That Inspire, Amuse</b></h2>
<p>Individual makers designed two autonomous vehicles this year worth special mentions.</p>
<figure id="attachment_68885" aria-describedby="caption-attachment-68885" style="width: 283px" class="wp-caption alignright"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/pit-droid-first-look.jpg"><img loading="lazy" decoding="async" class="size-medium wp-image-68885" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/pit-droid-first-look-283x400.jpg" alt="Cool Jetson-based robot of 2023" width="283" height="400" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/pit-droid-first-look-283x400.jpg 283w, https://blogs.nvidia.com/wp-content/uploads/2023/12/pit-droid-first-look-354x500.jpg 354w, https://blogs.nvidia.com/wp-content/uploads/2023/12/pit-droid-first-look-319x450.jpg 319w, https://blogs.nvidia.com/wp-content/uploads/2023/12/pit-droid-first-look-152x215.jpg 152w, https://blogs.nvidia.com/wp-content/uploads/2023/12/pit-droid-first-look-71x100.jpg 71w, https://blogs.nvidia.com/wp-content/uploads/2023/12/pit-droid-first-look.jpg 578w" sizes="(max-width: 283px) 100vw, 283px" /></a><figcaption id="caption-attachment-68885" class="wp-caption-text">Goran Vuksic with his AI-powered droid</figcaption></figure>
<p>Kabilan KB, a robotics developer and student in Coimbatore, India, built an <a href="https://blogs.nvidia.com/blog/kabilan-kb-autonomous-wheelchair/">autonomous wheelchair</a> using Jetson to run computer vision models that find and navigate a path to a user’s desired destination. The undergrad at the Karunya Institute of Technology and Sciences aspires to one day launch a robotics startup.</p>
<p>Finally, an engineering manager in Copenhagen who’s a self-described <i>Star Wars</i> fanatic designed <a href="https://blogs.nvidia.com/blog/goran-vuksic-pit-droid/">an AI-powered droid</a> based on an <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">NVIDIA Jetson Orin Nano Developer Kit</a>. Goran Vuksic shared his step-by-step <a href="https://www.hackster.io/gvuksic/nvidia-jetson-orin-nano-powered-pit-droid-7da0e8">technical guide</a>, so others can build their own sci-fi companions.</p>
<p>More than 6,500 companies and 1.2 million developers — as well as a <a href="https://developer.nvidia.com/embedded/community/jetson-projects">community</a> of makers and enthusiasts — use the NVIDIA Jetson and Isaac platforms for edge AI and robotics.</p>
<p>To get a look at where autonomous machines will go next, see what’s coming at <a href="https://blogs.nvidia.com/blog/ai-innovations-ces-2024/">CES in 2024</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/Robot_Roundup-crop.jpg"
			type="image/jpeg"
			width="1280"
			height="681"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/Robot_Roundup-crop-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Cool Robots of 2023: Meet the Autonomous Movers and Shakers]]></media:title>
			<media:description type="html">Cool Jetson-based robots of 2023</media:description>
			</media:content>
			</item>
		<item>
		<title>Thomson Reuters Taps Generative AI to Power Legal Offerings</title>
		<link>https://blogs.nvidia.com/blog/thomson-reuters/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Wed, 20 Dec 2023 14:00:26 +0000</pubDate>
				<category><![CDATA[The AI Podcast]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68881</guid>

					<description><![CDATA[Thomson Reuters, the global content and technology company, is transforming the legal industry with generative AI. In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Thomson Reuters Chief Product Officer David Wong about its potential — and implications. Many of Thomson Reuters offerings for the legal industry either address an information <a class="read-more" href="https://blogs.nvidia.com/blog/thomson-reuters/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Thomson Reuters, the global content and technology company, is transforming the legal industry with <a href="https://urldefense.com/v3/__https:/www.nvidia.com/en-us/glossary/data-science/generative-ai/__;!!GFN0sa3rsbfR8OLyAw!eiPNsa31SMQnW-_BuvF_hdx903fjMClGjwTUCUagcdiP8HYXBX9OWWyo4pDmh69GwOf2q9ILffhqxiN-ue1JpPAuDC_xHoo$">generative AI</a>.</p>
<p>In the latest episode of <a href="https://urldefense.com/v3/__https:/blogs.nvidia.com/ai-podcast/__;!!GFN0sa3rsbfR8OLyAw!eiPNsa31SMQnW-_BuvF_hdx903fjMClGjwTUCUagcdiP8HYXBX9OWWyo4pDmh69GwOf2q9ILffhqxiN-ue1JpPAuDE0S89c$">NVIDIA’s AI Podcast</a>, host Noah Kravitz spoke with Thomson Reuters Chief Product Officer David Wong about its potential — and implications.</p>
<p>Many of Thomson Reuters offerings for the legal industry either address an information retrieval problem or help generate written content.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1694640141%3Fsecret_token%3Ds-BkQid7Ap5Ul&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="The Case for Generative AI in the Legal Field - Ep. 210" href="https://soundcloud.com/theaipodcast/legal/s-BkQid7Ap5Ul" target="_blank" rel="noopener">The Case for Generative AI in the Legal Field &#8211; Ep. 210</a></div>
<p>It has aN AI-driven digital solution that enables law practitioners to search laws and cases intelligently within different jurisdictions. It also provides AI-powered tools that are set to be integrated with commonly used products like Microsoft 365 to automate the time-consuming processes of drafting and analyzing legal documents.</p>
<p>These technologies increase the productivity of legal professionals, enabling them to focus their time on higher-value work. According to Wong, ultimately these tools also have the potential to help deliver better access to justice.</p>
<p>To address ethical concerns, the company has created publicly available AI development guidelines, as well as privacy and data protection policies. And it’s participating in the drafting of ethical guidelines for the industries it serves.</p>
<p>There’s still a wide range of reactions surrounding AI use in the legal field, from optimism about its potential to fears of job replacement. But Wong underscored that no matter what the outlook, “it is very likely that professionals that use AI are going to replace professionals that don’t use AI.”</p>
<p>Looking ahead, Thomson Reuters aims to further integrate generative AI, as well as <a href="https://urldefense.com/v3/__https:/blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/__;!!GFN0sa3rsbfR8OLyAw!eiPNsa31SMQnW-_BuvF_hdx903fjMClGjwTUCUagcdiP8HYXBX9OWWyo4pDmh69GwOf2q9ILffhqxiN-ue1JpPAuGs6aImQ$">retrieval-augmented generation</a> techniques into its flagship research products to help lawyers synthesize, read and respond to complicated technical and legal questions. Recently, Thomson Reuters acquired Casetext, which developed the first AI legal assistant, CoCounsel.</p>
<p>In 2024 Thomson Reuters is building on this with the launch of an AI assistant that will be the interface across Thomson Reuters products with GenAI capabilities, including those in other fields such as tax and accounting.</p>
<h2><strong>You Might Also Like</strong></h2>
<p><a href="https://blogs.nvidia.com/blog/waabi-ai-simulation/"><b>Driver’s Ed: How Waabi Uses AI Simulation to Teach Autonomous Vehicles to Drive</b></a></p>
<p>Teaching the AI brains of autonomous vehicles to understand the world as humans do requires billions of miles of driving experience—the road to achieving this astronomical level of driving leads to the virtual world. Learn how Waabi uses powerful high-fidelity simulations to train and develop production-level autonomous vehicles.</p>
<p><a href="https://blogs.nvidia.com/blog/polestar/"><b>Polestar’s Dennis Nobelius on the Sustainable Performance Brand’s Plans</b></a></p>
<p>Driving enjoyment and autonomous driving capabilities can complement one another in intelligent, sustainable vehicles. Learn about the automaker’s plans to unveil its third vehicle, the Polestar 3, the tech inside it, and what the company’s racing heritage brings to the intersection of smarts and sustainability.</p>
<p><a href="https://soundcloud.com/theaipodcast/gantheftauto-harrison-kinsley-on-ai-generated-gaming-environments"><b>GANTheftAuto: Harrison Kinsley on AI-Generated Gaming Environments</b></a></p>
<p>Humans playing games against machines is nothing new, but now computers can develop games for people to play. Programming enthusiast and social media influencer Harrison Kinsley created GANTheftAuto, an AI-based neural network that generates a playable chunk of the classic video game <i>Grand Theft Auto V</i>.</p>
<h2>Subscribe to the AI Podcast, Now Available on Amazon Music</h2>
<p><a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">The AI Podcast is now available through Amazon Music</a>.</p>
<p>In addition, get the<a href="https://blogs.nvidia.com/ai-podcast/"> AI Podcast</a> through<a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439"> iTunes</a>,<a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjI2NDAzNDEzMy9zb3VuZHMucnNz"> Google Podcasts</a>,<a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm"> Google Play</a>,<a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us"> Castbox</a>, DoggCatcher,<a href="https://overcast.fm/itunes1186480811/the-ai-podcast"> Overcast</a>,<a href="https://player.fm/series/the-ai-podcast"> PlayerFM</a>, Pocket Casts,<a href="http://www.podbay.fm/show/1186480811"> Podbay</a>,<a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast"> PodBean</a>, PodCruncher, PodKicker,<a href="https://soundcloud.com/theaipodcast"> Soundcloud</a>,<a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L"> Spotify</a>,<a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr"> Stitcher</a> and<a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/"> TuneIn</a>.</p>
<p>Make the AI Podcast better: Have a few minutes to spare? Fill out<a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short"> this listener survey</a>.</p>
<p>&nbsp;</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast.jpg"
			type="image/jpeg"
			width="1400"
			height="931"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Thomson Reuters Taps Generative AI to Power Legal Offerings]]></media:title>
			<media:description type="html">NVIDIA AI Podcast</media:description>
			</media:content>
			</item>
		<item>
		<title>Into the Omniverse: Foundry Nuke’s OpenUSD Enhancements Ring in a 3D Renaissance</title>
		<link>https://blogs.nvidia.com/blog/nuke-openusd-enhancements-3d-renaissance/</link>
		
		<dc:creator><![CDATA[Rick Champagne]]></dc:creator>
		<pubDate>Wed, 20 Dec 2023 14:00:10 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[Into the Omniverse]]></category>
		<category><![CDATA[Metaverse]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Universal Scene Description]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68726</guid>

					<description><![CDATA[The latest OpenUSD updates enable users to tackle larger, more complex scenes with enhanced geometry control and streamlined asset management.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of </i><a href="https://www.nvidia.com/en-us/omniverse/news/"><i>Into the Omniverse</i></a><i>, a series focused on how artists, developers and enterprises can transform their workflows using the latest advances in </i><a href="https://www.nvidia.com/en-us/omniverse/usd/"><i>OpenUSD</i></a><i> and </i><a href="https://www.nvidia.com/en-us/omniverse/usd/"><i>NVIDIA Omniverse</i></a><i>.</i></p>
<p>3D designers and creators are embracing <a href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description</a>, aka OpenUSD, to transform their workflows.</p>
<p>Creative software company Foundry’s latest release of <a href="https://www.foundry.com/products/nuke-family/nuke" target="_blank" rel="noopener">Nuke</a>, a powerful compositing tool for visual effects (VFX), is bringing increased support for OpenUSD, a framework that provides a unified and extensible ecosystem for describing, composing, simulating and collaborating within 3D worlds.</p>
<p>With advanced compositing and improved interoperability capabilities, artists are showcasing the immense potential of Nuke and OpenUSD for visual storytelling.</p>
<h2><b>Bringing 3D Visions to Life With Nuke and OpenUSD</b></h2>
<p>YouTuber <a href="https://www.youtube.com/channel/UCWB2cxFgUbCg79XiGKr41GA">Jacob Zirkle</a> is one such 3D artist.</p>
<p>Inspired by his 10th watch through the <i>Star Wars</i> films, Zirkle wanted to create a sci-fi ship of his own. He first combined computer graphics elements in Blender and Unreal Engine before using USD to bring the scene into Nuke for compositing.</p>
<p style="text-align: center"><img loading="lazy" decoding="async" class=" wp-image-68786 aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/Screenshot-2023-12-11-125415.png" alt="" width="597" height="323" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/Screenshot-2023-12-11-125415.png 1645w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Screenshot-2023-12-11-125415-400x216.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Screenshot-2023-12-11-125415-672x363.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Screenshot-2023-12-11-125415-768x415.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Screenshot-2023-12-11-125415-1536x830.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Screenshot-2023-12-11-125415-833x450.png 833w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Screenshot-2023-12-11-125415-398x215.png 398w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Screenshot-2023-12-11-125415-185x100.png 185w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Screenshot-2023-12-11-125415-1280x692.png 1280w" sizes="(max-width: 597px) 100vw, 597px" /><i>Zirkle’s ship, built using Blender, Nuke, Unreal Engine and USD Composer.</i></p>
<p>OpenUSD was the glue that held his workflow together.</p>
<p>“Usually, I have to deal with multiple, varying file types in my VFX pipeline, and as soon as something gets updated, it can be a real pain to apply the change across the board,” Zirkle said. “But because I was using the same OpenUSD file for all of my programs, I could save the file once, and changes get automatically propagated through the pipeline — saving me a ton of time.”</p>
<p style="text-align: center"><img loading="lazy" decoding="async" class="size-full wp-image-68789 aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/ezgif.com-video-to-gif-41.gif" alt="" width="600" height="338" /></p>
<p><a href="https://blogs.nvidia.com/blog/edward-mcevenue-omniverse-creator/">Edward McEvenue</a>, an associate creative director at NVIDIA, is using OpenUSD and Nuke to create his short film with the working title: “Dare to Dream.”</p>
<p>Through the project, McEvenue hopes to visualize aspects of automated manufacturing. He uses Autodesk 3ds Max and SideFX Houdini for 3D scene creation, Chaos V-Ray for rendering arbitrary output variables and extended dynamic range sequences, and Nuke for compositing elements for final renders.</p>
<p style="text-align: center"><img loading="lazy" decoding="async" class="size-full wp-image-68792 aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/ezgif.com-video-to-gif-40.gif" alt="" width="600" height="253" /></p>
<p>OpenUSD helps streamline data transfer between applications, speeding the iteration process. “Nuke’s USD capabilities allow me to seamlessly transition 3D assets between digital content-creation apps, providing a powerful tool for achieving advanced compositing techniques,” he said.</p>
<p>Other NVIDIA creatives have integrated OpenUSD and Nuke into their 3D workflows. A team of 10 artists developed a <a href="https://www.nvidia.com/en-in/on-demand/session/siggraph2023-sigg23-16/#:~:text=Harnessing%20OpenUSD%3A%20Iteratively%20Building%20a%20Pipeline%20in%20Production,-Will%20Cavanaugh%20%2C%20Sr&amp;text=NVIDIA%27s%20creative%20group%20shows%20how,for%20our%20own%20future%20development.">fully OpenUSD-based pipeline</a> and custom tooling on <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> — a development platform for building OpenUSD-based tools and applications — to bring to life the “<a href="https://docs.omniverse.nvidia.com/usd/latest/usd_content_samples/davinci_workshop.html">Da Vinci Workshop</a>,” a project to inspire greater OpenUSD use among pipeline developers.</p>
<p>The artists also used Adobe Substance Painter, Autodesk 3ds Max, Autodesk Maya, DaVinci Resolve, SideFX Houdini, Pixelogic Zbrush and Omniverse USD Composer. OpenUSD served as the backbone of the team’s internal pipeline, offering the flexibility needed to collaborate across applications with ease.</p>
<p><iframe loading="lazy" title="The “Da Vinci Workshop”: An OpenUSD Masterpiece" width="500" height="281" src="https://www.youtube.com/embed/1PkLdVwOQ1M?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>The “Da Vinci Workshop” OpenUSD dataset is now available on the <a href="https://www.nvidia.com/en-us/omniverse/download/">Omniverse launcher</a> — free for developers and artists.</p>
<p>Foundry Nuke representatives, Omniverse community members and the NVIDIA creative team recently joined a livestream to discuss their 3D workflows and the impact of OpenUSD. Learn more by watching the replay:</p>
<p><iframe loading="lazy" title="Visual Storytelling with OpenUSD, Nuke, and Omniverse" width="500" height="281" src="https://www.youtube.com/embed/KmADv9m9EMI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Powering Digital Workflows With OpenUSD</b></h2>
<p>The <a href="https://campaigns.foundry.com/products/nuke-family/whats-new" target="_blank" rel="noopener">15.0 and 14.1</a> updates to Nuke bring significant workflow enhancements to those working with OpenUSD.</p>
<p>The updated GeoMerge node now offers four new modes: Merge Layers, Duplicate Prims, Flatten Layers and Flatten to Single Layer. These give users greater control over geometry and OpenUSD layers, allowing for quick merging of complex structures, the duplication of workflows and more effective layer management.</p>
<p>The OpenUSD-based 3D system introduced in Nuke 14.0 enables users to handle large, intricate scenes with greater ease. And the new Scene Graph Popup feature in Nuke 15.0 allows users to easily filter through 3D scene data, reducing time and energy needed to spend searching for specific assets.</p>
<p>In addition, the main 3D scene graph now includes a search and filter feature, simplifying workspace navigation.</p>
<p><iframe loading="lazy" title="Nuke 15.0 | Overview" width="500" height="281" src="https://www.youtube.com/embed/rQVZbxh_L1M?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Foundry is also embracing OpenUSD across its other products, including the latest updates to <a href="https://campaigns.foundry.com/products/katana/whats-new" target="_blank" rel="noopener">Katana 7.0</a>, which boost pipeline efficiency by integrating USD-native workflows already aligned with Nuke’s 3D system architecture.</p>
<h2><b>Get Plugged In to the World of OpenUSD </b></h2>
<p>NVIDIA and Foundry are both members of the <a href="https://aousd.org/" target="_blank" rel="noopener">Alliance for OpenUSD (AOUSD)</a>, an organization dedicated to an open-source future using the powerful framework. To learn more, explore the <a href="https://forum.aousd.org/" target="_blank" rel="noopener">AOUSD forum</a> and check out these <a href="https://developer.nvidia.com/usd" target="_blank" rel="noopener">resources on OpenUSD</a>.</p>
<p>Share your Nuke and Omniverse work as part of the latest community <a href="https://forums.developer.nvidia.com/t/get-creative-and-sleigh-the-2nd-annual-winterartchallenge/274994">#WinterArtChallenge</a>. Use the hashtag for a chance to be featured on the @NVIDIAStudio and @NVIDIAOmniverse social channels.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Winter has returned and so has our <a href="https://twitter.com/hashtag/WinterArtChallenge?src=hash&amp;ref_src=twsrc%5Etfw">#WinterArtChallenge</a>! <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/2744.png" alt="❄" class="wp-smiley" style="height: 1em; max-height: 1em;" /><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f3bf.png" alt="🎿" class="wp-smiley" style="height: 1em; max-height: 1em;" /><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/26c4.png" alt="⛄" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>Share your winter-themed art (like this incredible one created on an RTX GPU by <a href="https://twitter.com/rafianimates?ref_src=twsrc%5Etfw">@rafianimates</a>) using the hashtag for a chance to be featured on our social channels! <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f64c.png" alt="🙌" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>We can&#39;t wait to see what you create! <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/26f7.png" alt="⛷" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="https://t.co/Ml4cUAUgW3">pic.twitter.com/Ml4cUAUgW3</a></p>
<p>&mdash; NVIDIA Studio (@NVIDIAStudio) <a href="https://twitter.com/NVIDIAStudio/status/1731738137502556553?ref_src=twsrc%5Etfw">December 4, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p><i>Get started with NVIDIA Omniverse by downloading the standard license </i><a href="https://www.nvidia.com/en-us/omniverse/download/"><i>free</i></a><i>, access </i><a href="https://developer.nvidia.com/usd"><i>OpenUSD</i></a><i> resources, and learn how </i><a href="https://www.nvidia.com/en-us/omniverse/enterprise/"><i>Omniverse Enterprise</i><i> can connect your team</i></a><i>. Stay up to date on </i><a href="https://www.instagram.com/nvidiaomniverse/"><i>Instagram</i></a><i>, </i><a href="https://medium.com/@nvidiaomniverse"><i>Medium</i></a><i> and </i><a href="https://twitter.com/nvidiaomniverse"><i>Twitter</i></a><i>. For more, join the </i><a href="https://www.nvidia.com/en-us/omniverse/community/"><i>Omniverse community</i></a><i> on the  </i><a href="https://forums.developer.nvidia.com/c/omniverse/300"><i>forums</i></a><i>, </i><a href="https://discord.com/invite/XWQNJDNuaC"><i>Discord server</i></a><i>, </i><a href="https://www.twitch.tv/nvidiaomniverse"><i>Twitch</i></a><i> and </i><a href="https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA"><i>YouTube</i></a><i> channels. </i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/nv-ov-ito-1280x680_dec.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/nv-ov-ito-1280x680_dec-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Into the Omniverse: Foundry Nuke’s OpenUSD Enhancements Ring in a 3D Renaissance]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA to Reveal New AI Innovations at CES 2024</title>
		<link>https://blogs.nvidia.com/blog/ai-innovations-ces-2024/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Tue, 19 Dec 2023 17:00:03 +0000</pubDate>
				<category><![CDATA[Autonomous Machines]]></category>
		<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Driving]]></category>
		<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[CES 2024]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[Robotics]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68869</guid>

					<description><![CDATA[In the lead-up to next month’s CES trade show in Las Vegas, NVIDIA will unveil its latest advancements in artificial intelligence — including generative AI — and a spectrum of other cutting-edge technologies. Scheduled for Monday, Jan. 8, at 8 a.m. PT, the company’s special address will be publicly streamed. Save the date and plan <a class="read-more" href="https://blogs.nvidia.com/blog/ai-innovations-ces-2024/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>In the lead-up to next month’s CES trade show in Las Vegas, NVIDIA will unveil its latest advancements in artificial intelligence — including generative AI — and a spectrum of other cutting-edge technologies.</p>
<p>Scheduled for Monday, Jan. 8, at 8 a.m. PT, the company’s special address will be publicly streamed. <a href="https://www.nvidia.com/en-us/events/ces/">Save the date</a> and plan to tune in to the virtual address, which will focus on consumer technologies and robotics, on <a href="https://www.nvidia.com/en-us/events/ces/">NVIDIA’s website</a>, YouTube or Twitch.</p>
<p>AI and NVIDIA technologies will be the focus of 14 conference sessions, including four at <a href="https://www.digitalhollywood.com/one---dh-ces-2024">CES Digital Hollywood</a>, “<a href="https://www.ces.tech/sessions-events/retail/retail02.aspx">Reshaping Retail &#8211; AI Creating Opportunity</a>,” “<a href="https://www.ces.tech/sessions-events/rd/rd03.aspx">Robots at Work</a>” and “<a href="https://www.ces.tech/sessions-events/rss/rss06.aspx">Cracking the Smart Car</a>.”</p>
<p>And throughout CES, NVIDIA’s story will be enriched by the presence of over 85 NVIDIA customers and partners.</p>
<ul>
<li>Consumer: AI, gaming and NVIDIA Studio announcements and demos with partners including Acer, ASUS, Dell, GIGABYTE, HP, Lenovo, MSI, Razer, Samsung, Zotac and more.</li>
<li>Auto: Showcasing partnerships with leaders including Mercedes-Benz, Hyundai, Kia, Polestar, Luminar and Zoox.</li>
<li>Robotics: Working alongside Dreame Innovation Technology, DriveU, Ecotron Corp., e-con Systems, Enchanted Tools, GluxKind, Hesai Technology, Leopard Imaging, Ninebot (Willand (Beijing) Technology Co., Ltd.), Orbbec, QT Company, Unitree Robotics and Voyant Photonics.</li>
<li>Enterprise: Collaborations with Accenture, Adobe, Altair, Ansys, AWS, Capgemini, Dassault Systems, Deloitte, Google, Meta, Microsoft, Siemens, Wipro and others.</li>
</ul>
<p>For the investment community, NVIDIA will participate in a CES Virtual Fireside Chat hosted by J.P. Morgan on Tuesday, Jan. 9, at 8 a.m. PT. Listen to the live audio webcast at <a href="https://investor.nvidia.com/events-and-presentations/events-and-presentations/default.aspx">investor.nvidia.com</a>.</p>
<p>Visit NVIDIA’s <a href="https://www.nvidia.com/en-us/events/ces/">event web page</a> for a complete list of sessions and a view of our extensive partner ecosystem at the show.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/las-vegas-sign.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/las-vegas-sign-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA to Reveal New AI Innovations at CES 2024]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>DLSS 3.5 Integration in D5 Render Marks New Era of Real-Time Rendering</title>
		<link>https://blogs.nvidia.com/blog/studio-dlss-gilmour-blender-davinci-resolve-unreal-engine/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 19 Dec 2023 14:00:38 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68838</guid>

					<description><![CDATA[NVIDIA DLSS 3.5 for realistic ray-traced visuals is now available on D5 Render, a real-time 3D creation software.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows.</i></p>
<p><a href="https://www.nvidia.com/en-us/geforce/news/nvidia-dlss-3-5-ray-reconstruction/">NVIDIA DLSS 3.5</a> for realistic ray-traced visuals is now available on D5 Render, a real-time 3D creation software. The integration features <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">DLSS</a> Super Resolution, Frame Generation and Ray Reconstruction powered by an AI neural network.</p>
<p>And this week’s <i>In the NVIDIA Studio</i> 3D artist Michael Gilmour shares his wondrous, intricate winter worlds in long-form videos.</p>
<p>His winter-themed creations join Arkadly Demchenko, Austin Smith and Maggie Shelton’s works in the latest Studio Standouts video, available on the <a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw">NVIDIA Studio YouTube channel</a>.</p>
<p><iframe loading="lazy" title="Winter Escapes - Community Art Showcase | NVIDIA Studio Standouts" width="500" height="281" src="https://www.youtube.com/embed/AH-VsddNEL0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Also, tune in to the <a href="https://www.nvidia.com/en-us/events/ces/">NVIDIA special address</a> at CES on Jan. 8 at 8 a.m. PT for the latest and greatest on content creation, AI-related news and more.</p>
<h2><b>DLSS 3.5 Accelerates Real-Time Rendering</b></h2>
<p>D5 Render is a software designed for 3D designers and professionals working on large-scale architectural or landscaping projects.</p>
<figure id="attachment_68845" aria-describedby="caption-attachment-68845" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image2-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68845" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image2-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image2-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image2-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image2-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image2-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image2-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image2-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image2-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68845" class="wp-caption-text">Use D5 Render and NVIDIA GeForce RTX GPUs to model and render massive scenes.</figcaption></figure>
<p>Support for NVIDIA DLSS Frame Generation in D5 Render enhances ray-tracing performance and boosts real-time viewport frame rates for a smoother editing experience, enabling intuitive, interactive 3D creation.</p>
<figure id="attachment_68848" aria-describedby="caption-attachment-68848" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image3-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68848" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image3-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image3-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image3-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image3-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image3-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image3-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image3-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image3-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68848" class="wp-caption-text">Smoother movement in the viewport with DLSS 3.5.</figcaption></figure>
<p>Ray Reconstruction, a new neural rendering AI model, further enhances ray-traced visual quality by providing intelligent denoising solutions for an extensive variety of content at quick speeds.</p>
<figure id="attachment_68851" aria-describedby="caption-attachment-68851" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image5-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68851" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image5-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image5-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image5-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image5-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image5-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image5-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image5-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image5-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68851" class="wp-caption-text">Enhanced visual quality with DLSS 3.5 and Ray Reconstruction.</figcaption></figure>
<p>With both DLSS Frame Generation and Ray Reconstruction enabled, FPS in the viewport increases by a staggering 2.5x, enabling incredible resolution and visual quality in massive scenes.</p>
<p>Autodesk VRED, a professional digital prototyping software, also adds DLSS 3.5 support, bringing smoother viewport movement and higher graphical fidelity.</p>
<h2><b>Winter Tinker</b></h2>
<p>Gilmour, this week’s featured NVIDIA Studio artist, grew up in the beautiful winters of Appleton, Wisconsin. It’s no surprise he conjured up chillingly beautiful winter worlds to share with his friends, family and the creative community — fueled by his passion for 3D art.</p>
<p>Shared as long-form videos, these winter wonderlands showcase breathtakingly photorealistic details.</p>
<p>His winter video compilation — featuring “Campfire on a Winter Cliff,” “Dickensian Christmas Reading Nook” and “Northern Lights” — is designed to offer viewers a sense of peace and relaxation while encouraging self-reflection.</p>
<p><iframe loading="lazy" title="Cozy Bed in A-Frame Cabin | Rain Ambience ASMR" width="500" height="281" src="https://www.youtube.com/embed/Zr77eGeSZac?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Gilmour began his creative workflows in Unreal Engine, building out the environments. He used the Ultra Dynamic Sky system plug-in by game developer Everett Gunther, which offered greater flexibility and more customization options to achieve the effects in this northern lights scene.</p>
<p><iframe loading="lazy" title="Wolves and The Northern Lights | Winter Campfire Ambience" width="500" height="281" src="https://www.youtube.com/embed/jRImnRwDbj8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Fully built models are available in Unreal Engine, but to achieve further customization, Gilmour created custom 3D meshes in Blender. He used Blender Cycles’ <a href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA RTX</a>-accelerated OptiX ray tracing in the viewport for interactive, photorealistic rendering — all powered by his <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3060-3060ti/">GeForce RTX 3060 graphics card</a>.</p>
<p>“Originally, I chose an NVIDIA RTX GPU because of its CUDA core integration in Blender’s Cycles rendering engine,” said Gilmour. “Now with ray-tracing capabilities in Unreal Engine 5, it’s a no-brainer.”</p>
<figure id="attachment_68854" aria-describedby="caption-attachment-68854" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image4-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68854" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image4-1280w-672x362.png" alt="" width="672" height="362" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image4-1280w-672x362.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image4-1280w-400x216.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image4-1280w-768x414.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image4-1280w-835x450.png 835w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image4-1280w-399x215.png 399w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image4-1280w-186x100.png 186w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image4-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68854" class="wp-caption-text">Organizing assets in Unreal Engine.</figcaption></figure>
<p>He then acquired models in Quixel Megascans to block out the scene in Unreal Engine, creating a rough draft using simple, unpolished 3D shapes. This helped to keep base meshes clean, eliminating the need to create new ones in the next iteration.</p>
<figure id="attachment_68857" aria-describedby="caption-attachment-68857" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image14-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68857" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image14-1280w-672x364.png" alt="" width="672" height="364" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image14-1280w-672x364.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image14-1280w-400x217.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image14-1280w-768x416.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image14-1280w-830x450.png 830w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image14-1280w-397x215.png 397w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image14-1280w-184x100.png 184w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image14-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68857" class="wp-caption-text">Moving models in Unreal Engine.</figcaption></figure>
<p>To build the fire and glowing firewood in his “Campfire on a Winter Cliff” scene, Gilmour used the M5 VFX Vol 2 and Twinmotion Backyard Pack 2 packs from Unreal Engine. The <a href="https://developer.nvidia.com/physx-sdk">NVIDIA PhysX </a>SDK, advanced shader support and real-time ray tracing enabled high-fidelity, interactive visualization for swift viewport movement.</p>
<p><iframe loading="lazy" title="Campfire on a Winter Cliff | Crackling Fire ASMR" width="500" height="281" src="https://www.youtube.com/embed/gX4RaW7zSqY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>By upgrading to a GeForce RTX 40 Series GPU, Gilmour could use NVIDIA DLSS Frame Generation to further improve viewport interactivity by tapping AI to generate additional, high-quality frames, ensuring increased FPS rendered at lower resolution while retaining high-fidelity detail.</p>
<p><iframe loading="lazy" title="Dickensian Reading Nook | Ambient Christmas Reading" width="500" height="281" src="https://www.youtube.com/embed/W70IiFUgM34?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>When finished building his scenes, Gilmour moved to Blackmagic Design’s DaVinci Resolve to color correct and add subtle film grains, lens distortion, lens reflection and glow effects. It was all GPU-accelerated, including the process of exporting final videos with the eighth-generation <a href="https://www.nvidia.com/en-us/geforce/guides/broadcasting-guide/">NVENC encoder</a>.</p>
<figure id="attachment_68860" aria-describedby="caption-attachment-68860" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image12-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68860" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image12-1280w-672x365.png" alt="" width="672" height="365" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image12-1280w-672x365.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image12-1280w-400x218.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image12-1280w-768x418.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image12-1280w-828x450.png 828w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image12-1280w-395x215.png 395w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image12-1280w-184x100.png 184w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-michael-gilmour-wk88-image12-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68860" class="wp-caption-text">Color correction in DaVinci Resolve.</figcaption></figure>
<p>The final touch to Gilmour’s wintry scenes were peaceful tunes, sampled from royalty-free music database Splice.</p>
<p>All that’s left to do is kick back, relax and soak in the scenery.</p>
<figure id="attachment_68863" aria-describedby="caption-attachment-68863" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-michael-gilmour-wk88-artist-feature-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68863" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-michael-gilmour-wk88-artist-feature-1280w-672x263.png" alt="" width="672" height="263" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-michael-gilmour-wk88-artist-feature-1280w-672x263.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-michael-gilmour-wk88-artist-feature-1280w-400x156.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-michael-gilmour-wk88-artist-feature-1280w-768x300.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-michael-gilmour-wk88-artist-feature-1280w-842x329.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-michael-gilmour-wk88-artist-feature-1280w-406x159.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-michael-gilmour-wk88-artist-feature-1280w-188x73.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-michael-gilmour-wk88-artist-feature-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68863" class="wp-caption-text">Digital 3D artist Michael Gilmour.</figcaption></figure>
<p>Check out Gilmour’s portfolio on <a href="https://www.artstation.com/michaelgilmour">ArtStation</a>.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>Twitter</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/nv-blog-header-preview-1280x680-3.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/nv-blog-header-preview-1280x680-3-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[DLSS 3.5 Integration in D5 Render Marks New Era of Real-Time Rendering]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>‘Forza Horizon’ Races Over to GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-forza-horizon/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 14 Dec 2023 14:00:54 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68797</guid>

					<description><![CDATA[This GFN Thursday is burning rubber with the latest Forza Horizon games from Microsoft Studios. Check them out on PC Game Pass. Plus, give the gift of cloud gaming with the latest membership bundle, which includes a free, three-month PC Game Pass subscription with the purchase of a six-month GeForce NOW Ultimate membership. It’s all <a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-forza-horizon/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>This GFN Thursday is burning rubber with the latest <i>Forza Horizon</i> games from Microsoft Studios. Check them out on PC Game Pass.</p>
<p>Plus, give the gift of cloud gaming with the latest membership bundle, which includes a free, three-month PC Game Pass subscription with the purchase of a six-month GeForce NOW <a href="https://www.nvidia.com/en-us/geforce-now/memberships/">Ultimate membership</a>.</p>
<p>It’s all part of an exciting week, with 13 new games joining the <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> library.</p>
<h2><b>Zoom, Zoom</b></h2>
<p>Jump into the driver’s seat in <i>Forza Horizon 4 </i>and <i>Forza Horizon 5 </i>from Playground Games and Microsoft Studios. Explore the critically acclaimed open-world racing games, featuring dynamic weather and seasons that can make or break even the most seasoned drivers.</p>
<figure id="attachment_68811" aria-describedby="caption-attachment-68811" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-68811" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_4-672x336.jpg" alt="Forza Horizon 4 on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_4-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_4-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_4-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_4-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_4-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_4-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_4-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_4-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_4.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68811" class="wp-caption-text"><em>For-za cloud.</em></figcaption></figure>
<p>Race across beautiful, historical Great Britain in <i>Forza Horizon 4</i>. Ride solo or team up online with players from around the globe in a shared, open world. Collect, modify and drive over 450 cars from the <i>Horizon</i> car roster — plus, race, stunt, create and explore to become a Horizon Superstar.</p>
<figure id="attachment_68808" aria-describedby="caption-attachment-68808" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-68808" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_5-672x336.jpg" alt="Forza Horizon 5 on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_5-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_5-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_5-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_5-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_5-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_5-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_5-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_5-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Forza_Horizon_5.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68808" class="wp-caption-text"><em>The ultimate “Horizon” adventure plays best on the ultimate cloud gaming service.</em></figcaption></figure>
<p>Clutch in, shift gears and head over to the vibrant open world of Mexico in <i>Forza Horizon 5</i>. Jump-start the week with limitless driving action in hundreds of the world’s greatest cars. Join a campaign with hundreds of challenges across varied terrains and climates, or head online for multiplayer action. Members can enjoy both titles in Steam and <i>Forza Horizon 5</i> in PC Game Pass. Visit this <a href="https://nvidia.custhelp.com/app/answers/detail/a_id/5462">Knowledgebase article</a> for further details.</p>
<p>Stream every turn at GeForce quality on nearly any device and max out image resolution thanks to the cloud. Ultimate members can get in gear at up to 4K resolution and 120 frames per second for the most realistic driving experience.</p>
<h2><b>The Ultimate Adventure</b></h2>
<figure id="attachment_68805" aria-describedby="caption-attachment-68805" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-68805" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Minecraft_Dungeon-672x336.jpg" alt="Minecraft Dungeons on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Minecraft_Dungeon-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Minecraft_Dungeon-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Minecraft_Dungeon-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Minecraft_Dungeon-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Minecraft_Dungeon-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Minecraft_Dungeon-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Minecraft_Dungeon-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Minecraft_Dungeon-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Minecraft_Dungeon.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68805" class="wp-caption-text"><em>What a blockhead.</em></figcaption></figure>
<p><i>Minecraft Dungeons</i> from Mojang Studios and Xbox Game Studios is an immensely popular title that’s amassed over 25 million players and brings the thrill of classic dungeon crawlers to a whole new level.</p>
<p>Brave the dungeons alone or team up with a squad. Up to four players can battle together online or in couch co-op, making it a great game for group gatherings. Fight through action-packed, treasure-stuffed, wildly varied levels — all part of an epic quest to save the villagers and take down the evil Arch-Illager, preventing his army from controlling the Overworld.</p>
<p>Stream it on an Ultimate and Priority account for longer gaming sessions and faster access to <a href="https://www.nvidia.com/en-us/geforce/rtx/">GeForce RTX</a>-powered servers. Venture forth across devices and play it on the big screen with <a href="https://www.nvidia.com/en-us/shield/shield-tv/">NVIDIA SHIELD TV</a> or on Samsung and LG smart TVs for the ultimate couch co-op experience.</p>
<h2><b>Games, Games, Games</b></h2>
<figure id="attachment_68802" aria-describedby="caption-attachment-68802" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-68802" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Pioneers_of_Pagonia-672x336.jpg" alt="Pioneers of Pagonia on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Pioneers_of_Pagonia-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Pioneers_of_Pagonia-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Pioneers_of_Pagonia-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Pioneers_of_Pagonia-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Pioneers_of_Pagonia-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Pioneers_of_Pagonia-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Pioneers_of_Pagonia-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Pioneers_of_Pagonia-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/12/GFN_Thursday-Pioneers_of_Pagonia.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68802" class="wp-caption-text"><em>Be a pioneer of the cloud.</em></figcaption></figure>
<p>Time for some new games. Explore, discover and reunite the fantastical islands of Pagonia in <i>Pioneers of Pagonia</i> from Envision Entertainment. Build over 40 types of buildings, use more than 70 types of goods, manage widely branched production chains and get creative to establish a thriving economy.</p>
<p>Don’t miss the 13 newly supported games joining the GeForce NOW library this week:<i></i></p>
<ul>
<li><i>Stellaris Nexus </i>(New release on <a href="https://store.steampowered.com/app/1983990?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Dec. 12)</li>
<li><i>Tin Hearts </i>(New release on <a href="https://www.xbox.com/games/store/tn-hearts/9MZSWZD5TDZP?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available PC Game Pass, Dec. 12)</li>
<li><i>Pioneers of Pagonia </i>(New release on <a href="https://store.steampowered.com/app/2155180?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Dec. 13)</li>
<li><i>House Flipper 2 </i>(New release on <a href="https://store.steampowered.com/app/1190970?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Dec. 14)</li>
<li><i>Soulslinger: Envoy of Death </i>(New release on <a href="https://store.steampowered.com/app/2429240?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Dec. 14)</li>
<li><i>Escape the Backrooms </i>(<a href="https://store.steampowered.com/app/1943950?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Flashback 2</i> (<a href="https://store.steampowered.com/app/2008420?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Forza Horizon 4 </i>(<a href="https://store.steampowered.com/app/1293830?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Forza Horizon 5</i> (<a href="https://store.steampowered.com/app/1551360?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.xbox.com/games/store/forza-horizon-5-standard-edition/9nkx70bbcdrn?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, and available on PC Game Pass)</li>
<li><i>The Front </i>(<a href="https://store.steampowered.com/app/2285150?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Minecraft Dungeons</i> (<a href="https://store.steampowered.com/app/1672970?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.xbox.com/games/store/minecraft-dungeons-ultimate-edition-for-windows/9NZ12RV7B7R3/0010/B4K4SFFCW5VS?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox </a>and available on PC Game Pass)</li>
<li><i>Primal Carnage: Extinction </i>(<a href="https://store.steampowered.com/app/321360?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Universe Sandbox </i>(<a href="https://store.steampowered.com/app/230290?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">Twitter</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Dungeons &amp; Drag&#8211; Racing <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f440.png" alt="👀" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1734981506643182018?ref_src=twsrc%5Etfw">December 13, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/gfn-thursday-12-14-nv-blog-1280x680-no-cta.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/gfn-thursday-12-14-nv-blog-1280x680-no-cta-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[‘Forza Horizon’ Races Over to GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>How Is AI Used in Fraud Detection?</title>
		<link>https://blogs.nvidia.com/blog/ai-fraud-detection-rapids-triton-tensorrt-nemo/</link>
		
		<dc:creator><![CDATA[Kevin Levitt]]></dc:creator>
		<pubDate>Wed, 13 Dec 2023 17:00:43 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Explainer]]></category>
		<category><![CDATA[NVIDIA Triton]]></category>
		<category><![CDATA[RAPIDS]]></category>
		<category><![CDATA[Synthetic Data Generation]]></category>
		<category><![CDATA[TensorRT]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68770</guid>

					<description><![CDATA[The Wild West had gunslingers, bank robberies and bounties — today’s digital frontier has identity theft, credit card fraud and chargebacks. Cashing in on financial fraud has become a multibillion-dollar criminal enterprise. And generative AI in the hands of fraudsters only promises to make this more profitable. Credit card losses worldwide are expected to reach <a class="read-more" href="https://blogs.nvidia.com/blog/ai-fraud-detection-rapids-triton-tensorrt-nemo/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The Wild West had gunslingers, bank robberies and bounties — today’s digital frontier has identity theft, credit card fraud and chargebacks.</p>
<p>Cashing in on financial fraud has become a multibillion-dollar criminal enterprise. And <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/">generative AI</a> in the hands of fraudsters only promises to make this more profitable.</p>
<p>Credit card losses worldwide are expected to reach $43 billion by 2026, according to the <a href="https://nilsonreport.com/articles/card-fraud-losses-worldwide/"><i>Nilson Report</i></a>.</p>
<p>Financial fraud is perpetrated in a growing number of ways, like harvesting hacked data from the dark web for credit card theft, using generative AI for phishing personal information, and laundering money between cryptocurrency, digital wallets and fiat currencies. Many other financial schemes are lurking in the digital underworld.</p>
<p>To keep up, financial services firms are wielding AI for fraud detection. That’s because many of these digital crimes need to be halted in their tracks in real time so that consumers and financial firms can stop losses right away.</p>
<p>So how is AI used for fraud detection?</p>
<p>AI for fraud detection uses multiple machine learning models to detect anomalies in customer behaviors and connections as well as patterns of accounts and behaviors that fit fraudulent characteristics.</p>
<h2><b>Generative AI Can Be Tapped as Fraud Copilot</b></h2>
<p>Much of financial services involves text and numbers. Generative AI and <a href="https://blogs.nvidia.com/blog/what-are-large-language-models-used-for/?ncid=em-even-877400-vt46">large language models</a> (LLMs), capable of learning meaning and context, promise disruptive capabilities across industries with new levels of output and productivity. Financial services firms can harness generative AI to develop more intelligent and capable chatbots and improve fraud detection.</p>
<p>On the opposite side, bad actors can circumvent AI guardrails with crafty generative AI prompts to use it for fraud. And LLMs are delivering human-like writing, enabling fraudsters to draft more contextually relevant emails without typos and grammar mistakes. Many different tailored versions of phishing emails can be quickly created, making generative AI an excellent copilot for perpetrating scams. There are also a number of dark web tools like FraudGPT, which can exploit generative AI for cybercrimes.</p>
<p>Generative AI can be exploited for financial harm in voice authentication security measures as well. Some banks are using voice authentication to help authorize users. A banking customer’s voice can be cloned using deep fake technology if an attacker can obtain voice samples in an effort to breach such systems. The voice data can be gathered with spam phone calls that attempt to lure the call recipient into responding by voice.</p>
<p>Chatbot scams are such a problem that the U.S. Federal Trade Commission <a href="https://www.ftc.gov/business-guidance/blog/2023/03/chatbots-deepfakes-voice-clones-ai-deception-sale">called out concerns</a> for the use of LLMs and other technology to simulate human behavior for deep fake videos and voice clones applied in imposter scams and financial fraud.</p>
<h2><b>How Is Generative AI Tackling Misuse and Fraud Detection? </b></h2>
<p>Fraud review has a powerful new tool. Workers handling manual fraud reviews can now be assisted with LLM-based assistants running RAG on the backend to tap into information from policy documents that can help expedite decision-making on whether cases are fraudulent, vastly accelerating the process.</p>
<p>LLMs are being adopted to predict the next transaction of a customer, which can help payments firms preemptively assess risks and block fraudulent transactions.</p>
<p>Generative AI also helps combat transaction fraud by improving accuracy, generating reports, reducing investigations and mitigating compliance risk.</p>
<p>Generating <a href="https://blogs.nvidia.com/blog/what-is-synthetic-data/">synthetic data</a> is another important application of generative AI for fraud prevention. Synthetic data can improve the number of data records used to train fraud detection models and increase the variety and sophistication of examples to teach the AI to recognize the latest techniques employed by fraudsters.</p>
<p>NVIDIA offers tools to help enterprises embrace generative AI to build chatbots and virtual agents with a workflow that uses <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">retrieval-augmented generation</a>. RAG enables companies to use natural language prompts to access vast datasets for information retrieval.</p>
<p>Harnessing <a href="https://www.nvidia.com/en-us/ai-data-science/ai-workflows/">NVIDIA AI workflows</a> can help accelerate building and deploying enterprise-grade capabilities to accurately produce responses for various use cases, using <a href="https://blogs.nvidia.com/blog/what-are-foundation-models/">foundation models</a>, the <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/">NVIDIA NeMo</a> framework, <a href="https://www.nvidia.com/en-us/ai-data-science/products/triton-inference-server/">NVIDIA Triton Inference Server</a> and GPU-accelerated vector database to deploy RAG-powered chatbots.</p>
<p>There’s an industry focus on safety to ensure generative AI isn’t easily exploited for harm. NVIDIA <a href="https://blogs.nvidia.com/blog/ai-chatbot-guardrails-nemo/">released NeMo Guardrails</a> to help ensure that intelligent applications powered by LLMs, such as OpenAI’s ChatGPT, are accurate, appropriate, on topic and secure.</p>
<p>The open-source software is designed to help keep AI-powered applications from being exploited for fraud and other misuses.</p>
<h2><b>What Are the Benefits of AI for Fraud Detection?</b></h2>
<p>Fraud detection has been a challenge across banking, finance, retail and e-commerce.  Fraud doesn’t only hurt organizations financially, it can also do reputational harm.</p>
<p>It’s a headache for consumers, as well, when fraud models from financial services firms overreact and register false positives that shut down legitimate transactions.</p>
<p>So financial services sectors are developing more advanced models using more data to fortify themselves against losses financially and reputationally. They’re also aiming to reduce false positives in fraud detection for transactions to improve customer satisfaction and win greater share among merchants.</p>
<h2><b>Financial Services Firms Embrace AI for Identity Verification</b></h2>
<p>The financial services industry is developing AI for identity verification. AI-driven applications using deep learning with graph neural networks (GNNs), natural language processing (NLP) and computer vision can improve identity verification for know-your customer (KYC) and anti-money laundering (AML) requirements, leading to improved regulatory compliance and reduced costs.</p>
<p>Computer vision analyzes photo documentation such as drivers licenses and passports to identify fakes. At the same time, NLP reads the documents to measure the veracity of the data on the documents as the AI analyzes them to look for fraudulent records.</p>
<p>Gains in KYC and AML requirements have massive regulatory and economic implications. Financial institutions, including banks, were fined nearly $5 billion for AML, breaching sanctions as well as failures in KYC systems in 2022, <a href="https://www.ft.com/content/7a4821e6-96f1-475c-ae55-6401e402061f">according to the <i>Financial Times</i></a>.</p>
<h2><b>Harnessing Graph Neural Networks and NVIDIA GPUs </b></h2>
<p>GNNs have been embraced for their ability to reveal suspicious activity. They’re capable of looking at billions of records and identifying previously unknown patterns of activity to make correlations about whether an account has in the past sent a transaction to a suspicious account.</p>
<p>NVIDIA has an alliance with the Deep Graph Library team, as well as the PyTorch Geometric team, which provides a GNN framework containerized offering that includes the latest updates, <a href="https://developer.nvidia.com/rapids">NVIDIA RAPIDS</a> libraries and more to help users stay up to date on cutting-edge techniques.</p>
<p>These GNN framework containers are NVIDIA-optimized and performance-tuned and tested to get the most out of NVIDIA GPUs.</p>
<p>With access to the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> software platform, developers can tap into NVIDIA RAPIDS, <a href="https://www.nvidia.com/en-us/ai-data-science/products/triton-inference-server/">NVIDIA Triton Inference Server</a> and the <a href="https://developer.nvidia.com/tensorrt">NVIDIA TensorRT</a> software development kit to support enterprise deployments at scale.</p>
<h2><b>Improving Anomaly Detection With GNNs</b></h2>
<p>Fraudsters have sophisticated techniques and can learn ways to outmaneuver fraud detection systems. One way is by unleashing complex chains of transactions to avoid notice. This is where traditional rules-based systems can miss patterns and fail.</p>
<p>GNNs build on a concept of representation within the model of local structure and feature context. The information from the edge and node features is propagated with aggregation and message passing among neighboring nodes.</p>
<p>When GNNs run multiple layers of graph convolution, the final node states contain information from nodes multiple hops away. The larger receptive field of GNNs can track the more complex and longer transaction chains used by financial fraud perpetrators in attempts to obscure their tracks.</p>
<h2><b>GNNs Enable Training Unsupervised or Self-Supervised </b></h2>
<p>Detecting financial fraud patterns at massive scale is challenged by the tens of terabytes of transaction data that needs to be analyzed in the blink of an eye and a relative lack of labeled data for real fraud activity needed to train models.</p>
<p>While GNNs can cast a wider detection net on fraud patterns, they can also train on an <a href="https://blogs.nvidia.com/blog/supervised-unsupervised-learning/">unsupervised or self-supervised</a> task.</p>
<p>By using techniques such as <a href="https://arxiv.org/abs/2102.06514">Bootstrapped Graph Latents</a> — a graph representation learning method — or <a href="https://graph-neural-networks.github.io/static/file/chapter10.pdf">link prediction with negative sampling</a>, GNN developers can pretrain models without labels and fine-tune models with far fewer labels, producing strong graph representations. The output of this can be used for models like XGBoost, GNNs or techniques for clustering, offering better results when deployed for inference.</p>
<h2><b>Tackling Model Explainability and Bias</b></h2>
<p>GNNs also enable model explainability with a suite of tools. <a href="https://blogs.nvidia.com/blog/what-is-explainable-ai/">Explainable AI</a> is an industry practice that enables organizations to use such tools and techniques to explain how AI models make decisions, allowing them to safeguard against bias.</p>
<p>Heterogeneous graph transformer and graph attention network, which are GNN models, enable attention mechanisms across each layer of the GNN, allowing developers to identify message paths that GNNs use to reach a final output.</p>
<p>Even without an attention mechanism, techniques such as <a href="https://cs.stanford.edu/people/jure/pubs/gnnexplainer-neurips19.pdf">GNNExplainer</a>, <a href="https://github.com/flyingdoog/PGExplainer">PGExplainer</a> and <a href="https://openreview.net/pdf?id=WznmQa42ZAx">GraphMask</a> have been suggested to explain GNN outputs.</p>
<h2><b>Leading Financial Services Firms Embrace AI for Gains</b><b></b></h2>
<ul>
<li aria-level="1"><a href="https://www.nvidia.com/en-us/case-studies/american-express-prevents-fraud-and-foils-cybercrime-with-nvidia-ai-solutions/"><b>American Express</b></a><b>:</b> Improved fraud detection accuracy by 6% with deep learning models and used <a href="https://developer.nvidia.com/tensorrt#tensorrt">NVIDIA TensorRT</a> on <a href="https://www.nvidia.com/en-us/ai-data-science/products/triton-inference-server/">NVIDIA Triton Inference Server</a>.</li>
</ul>
<ul>
<li aria-level="1"><b>BNY Mellon: </b>Bank of New York Mellon improved fraud detection accuracy by 20% with <a href="https://blogs.nvidia.com/blog/what-is-federated-learning/">federated learning</a>. BNY built a collaborative fraud detection framework that runs Inpher’s secure multi-party computation, which safeguards third-party data on <a href="https://www.nvidia.com/en-us/data-center/dgx-platform/">NVIDIA DGX</a> systems.​</li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://developer.nvidia.com/blog/gpu-inference-momentum-continues-to-build/"><b>PayPal</b></a><b>:</b> PayPal sought a new fraud detection system that could operate worldwide continuously to protect customer transactions from potential fraud​ in real time.​ The company delivered a new level of service, using NVIDIA GPU-powered inference to improve real-time fraud detection by 10% while lowering server capacity nearly 8x.</li>
<li style="font-weight: 400;" aria-level="1"><a href="https://developer.nvidia.com/blog/detecting-financial-fraud-using-gans-at-swedbank-with-hopsworks-and-gpus/"><b>Swedbank</b></a><b>: </b>Among Sweden’s largest banks, Swedbank trained NVIDIA GPU-driven generative adversarial networks to detect suspicious activities in efforts to stop fraud and money laundering, saving $150 million in a single year.</li>
</ul>
<p><i>Learn how NVIDIA AI Enterprise addresses fraud detection at </i><a href="https://info.nvidia.com/inference-financial-services-webinar"><i>this webinar</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/finance-corp-blog-what-is-fraud-detection-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/finance-corp-blog-what-is-fraud-detection-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[How Is AI Used in Fraud Detection?]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Pie From the Sky: Drone Startup Delivers Pizza, Meds and Side of Excitement</title>
		<link>https://blogs.nvidia.com/blog/zipline-drone-jetson-inception/</link>
		
		<dc:creator><![CDATA[Scott Martin]]></dc:creator>
		<pubDate>Wed, 13 Dec 2023 16:00:11 +0000</pubDate>
				<category><![CDATA[Autonomous Machines]]></category>
		<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[NVIDIA Jetson]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68713</guid>

					<description><![CDATA[Zipline isn’t just some pie-in-the-sky drone startup. The San Francisco-based company has completed more than 850,000 deliveries in seven countries since its start in 2011. It recently added services for Seattle’s Pagliacci Pizza, vitamin and supplement giant GNC, and large health systems like Intermountain Health, OhioHealth and Michigan Medicine. Zipline developed its drones — which <a class="read-more" href="https://blogs.nvidia.com/blog/zipline-drone-jetson-inception/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Zipline isn’t just some pie-in-the-sky drone startup.</p>
<p>The San Francisco-based company has completed more than 850,000 deliveries in seven countries since its start in 2011. It recently added services for Seattle’s Pagliacci Pizza, vitamin and supplement giant GNC, and large health systems like Intermountain Health, OhioHealth and Michigan Medicine.</p>
<p>Zipline developed its drones — which have now flown more than 65 million miles — for autonomous navigation and precision landings using the <a href="https://www.nvidia.com/en-us/ai-data-science/?ncid=pa-srch-goog-680280">NVIDIA Jetson</a> edge AI and robotics platform.</p>
<p>The fast-growing company recently landed $330 million in funding at a more than $4 billion valuation.</p>
<p>Zipline is a member of <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a>, a program that provides startups with technological support and AI platform guidance.</p>
<h2><b>Delivering With Jetson-Powered Fleets</b></h2>
<p>The company’s P1 drone, or platform one, has been deployed in production for seven years and currently uses the <a href="https://www.nvidia.com/en-sg/autonomous-machines/embedded-systems/jetson-xavier-nx/">Jetson Xavier NX</a> system-on-module to process its sensor inputs. It’s guided by GPS, air traffic control communications, inertial measurement unit sensors and its onboard detection and avoidance system, with redundancy of guidance for safety.</p>
<p>“The NVIDIA Jetson module in the wing is part of what delivers our acoustic detection and avoidance system, so it allows us to listen for other aircraft in the airspace around us and plot trajectories that avoid any conflict,” said A.J. Frantz, navigation lead at Zipline.</p>
<p>The company’s fixed-wing drones can fly out more than 55 miles, at 70 miles per hour, for deliveries from one of several Zipline distribution centers and then return. Capable of hauling up to four pounds of cargo, they autonomously fly over delivery locations and release packages that float down to their destination by parachute.</p>
<p>The company’s P2, or platform two, is a hybrid drone that can fly fast on fixed-wing flights — but also hover. It can carry eight pounds of cargo for 10 miles and packs a droid that can be lowered on a tether to complete deliveries with precision placement. It’s intended for use in dense, urban environments.</p>
<p>The P2 uses two <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">Jetson Orin NX</a> modules. One is for the drone’s sensor fusion system to understand environments. The other is in the droid that descends by tether — for redundancy to provide added safety.</p>
<p>“The P2 droid is about bringing the smallest, quickest, safest, quietest drone in for delivery, coming down precisely and leaving the package — and then going back up,” said Joseph Mardall, head of engineering at Zipline. “We want to integrate into people’s lives in a way that they love and that feels magical.”</p>
<p>Zipline completes one delivery every 70 seconds globally.</p>
<p><iframe loading="lazy" title="Zipline releases new drone designed for rapid home deliveries" width="500" height="281" src="https://www.youtube.com/embed/BtKdLrJLZ5I?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Flying Away With a Roster of Customers</b></h2>
<p>Zipline’s service offers advantages that are attracting customers. Its drones, fondly nicknamed ‘Zips,’ are capable of 7x faster delivery times compared with vehicle deliveries, according to the company.</p>
<p>“Our aircraft fly at 70 miles per hour, as the crow flies, so no traffic, no waiting at lights — we’re talking minutes here in terms of delivery times,” said Mardall. “Single-digit minutes are common for deliveries, so it’s faster than any alternative, for sure.”</p>
<p>In addition to services for pizza, vitamins and courier meds, Zipline works with Walmart, restaurant chain Sweetgreen, Michigan Medicine, MultiCare Health Systems, Intermountain Health and the government of Rwanda, among others. It also delivers to more than 4,000 hospitals and health centers, according to the company.</p>
<p>Zipline started its service delivering blood in Rwanda seven years ago and later expanded into food and convenience.</p>
<h2><b>Riding Jetson Orin for Energy Efficiency, Environmental Benefits </b></h2>
<p>Delivering energy-efficient computing is mission-critical for the run-time of autonomous machines, used in everything from delivery services and agriculture to mining and undersea exploration. NVIDIA Jetson Orin modules offer up to 275 trillion operations per second while providing market-leading energy efficiency.</p>
<p>“You can pick the right place for your algorithms to run to make sure you’re getting the most out of the hardware and the power that you are putting into the system,” said Frantz.</p>
<p>Startups using Jetson-driven applications are also leading the way in sustainability, as more next-generation electric-driven autonomous machines replace those contributing to pollution.</p>
<p>Deliveries by Zipline offer a 97% reduction in carbon emissions compared with gasoline-driven vehicles, according to the company.</p>
<p>“We are super excited to significantly reduce carbon emissions,” said Mardall. “And when building an electric aircraft, efficiency is totally key — every watt, every fraction of a watt, every joule that we can claw back can be turned into payload and range.”</p>
<p><i>Learn more about </i><a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/"><i>NVIDIA Jetson Orin</i></a><i>.</i></p>
<p>&nbsp;</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/Zip-package-drop_no_cross_red_wing-copy-1-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1367"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/Zip-package-drop_no_cross_red_wing-copy-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Pie From the Sky: Drone Startup Delivers Pizza, Meds and Side of Excitement]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Meet NANA, Moonshine Studio’s AI-Powered Receptionist Avatar</title>
		<link>https://blogs.nvidia.com/blog/studio-moonshine-blender-marvelous-designer-adobe-unreal-engine/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 12 Dec 2023 14:00:49 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio Driver]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68732</guid>

					<description><![CDATA[The creative team at Moonshine Studio — an artist-focused visual effects (VFX) studio specializing in animation and motion design — was tasked to solve a problem.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. We’re also deep diving on new </i><a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/"><i>GeForce RTX 40 Series GPU</i></a><i> features, technologies and resources, and how they dramatically accelerate content creation.</i></p>
<p>The creative team at <a href="https://moonshine.tw/">Moonshine Studio</a> — an artist-focused visual effects (VFX) studio specializing in animation and motion design — was tasked to solve a problem.</p>
<p>At their Taiwan office, receptionists were constantly engaged in meeting and greeting guests, preventing them from completing other important administrative work. To make matters worse, the automated kiosk greeting system wasn’t working as expected.</p>
<p>Senior Moonshine Studio 3D artist and this week’s <i>In the NVIDIA Studio </i>creator Eric Chiang stepped up to the challenge. He created a realistic, interactive 3D model that would serve as the foundation of a new AI-powered virtual assistant — NANA. The avatar can welcome guests and provide basic company info, easing the strain on the receptionist team.</p>
<p>Chiang built NANA using GPU-accelerated features in his favorite creative apps — powered by his <a href="https://www.nvidia.com/en-us/studio/laptops-desktops/">NVIDIA Studio</a>-badged <a href="https://www.msi.com/Desktop/MEG-Trident-X2-13th">MSI MEG Trident X2 PC</a>, which is equipped with a <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4090/">GeForce RTX 4090 graphics card</a>.</p>
<p>His creative workflow was enhanced by the Tensor Cores in his GPU, which supercharged AI-specific tasks — saving him time and elevating the quality of his work. <a href="https://www.nvidia.com/en-us/ai-on-rtx/">RTX and AI</a> also improve performance in gaming, boost productivity and more.</p>
<p><iframe loading="lazy" title="Take Your Creativity Further with AI &amp; Faster with #AIonRTX" width="500" height="281" src="https://www.youtube.com/embed/ZmbKY44onpg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>These advanced features are supported by <a href="https://www.nvidia.com/en-us/studio/">NVIDIA Studio Drivers</a>, — free for RTX GPU owners — which add performance and reliability. The December Studio Driver provides support for the Reallusion iClone AccuFACE plugin, GPU audio enhancements, AV1 in HandBrake and more — and is now ready for download.</p>
<p><iframe loading="lazy" title="AccuFACE - Video-based AI Facial Mocap | Live from Webcam or Recorded Video | iClone 8" width="500" height="281" src="https://www.youtube.com/embed/WCzHLSss_xU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p><b>Contests and Challenges Calling All Creators</b></p>
<p>Creative community The Rookies is hosting Meet Mat 3 — the 3D digital painting contest. Open to students and professionals with no more than a year of industry experience, it challenges contestants to use Adobe Substance 3D Painter to texture a blank character, MAT, in their own unique style. Prizes include <a href="https://www.nvidia.com/en-us/geforce/rtx/">GeForce RTX</a> GPUs, Wacom Cintiq displays and more. Register <a href="https://www.therookies.co/contests/groups/meet-mat-3">today</a> — entries close Jan. 5, 2024.</p>
<figure id="attachment_68742" aria-describedby="caption-attachment-68742" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-meet-mat-all-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68742" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-meet-mat-all-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-meet-mat-all-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-meet-mat-all-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-meet-mat-all-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-meet-mat-all-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-meet-mat-all-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-meet-mat-all-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-meet-mat-all-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68742" class="wp-caption-text">MAT, textured by artist Cino Lai in Adobe Substance 3D Painter.</figcaption></figure>
<p>And though temperatures continue to drop, the #WinterArtChallenge is heating up with un-brrrrrr-lievable entries like this extraordinary #InstantNeRF by @RadianceFields.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Let&#39;s see your creativity shine! <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/26f7.png" alt="⛷" class="wp-smiley" style="height: 1em; max-height: 1em;" /><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f3a8.png" alt="🎨" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>Winter is here, and we&#39;re excited to join the <a href="https://twitter.com/hashtag/WinterArtChallenge?src=hash&amp;ref_src=twsrc%5Etfw">#WinterArtChallenge</a> <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/2744.png" alt="❄" class="wp-smiley" style="height: 1em; max-height: 1em;" /><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f3bf.png" alt="🎿" class="wp-smiley" style="height: 1em; max-height: 1em;" /><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/26c4.png" alt="⛄" class="wp-smiley" style="height: 1em; max-height: 1em;" /> </p>
<p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f31f.png" alt="🌟" class="wp-smiley" style="height: 1em; max-height: 1em;" />Share your winter-themed art using the hashtag for a chance to be featured on our social channels.</p>
<p>Get inspired by this incredible <a href="https://twitter.com/hashtag/InstantNeRF?src=hash&amp;ref_src=twsrc%5Etfw">#InstantNeRF</a> by <a href="https://twitter.com/RadianceFields?ref_src=twsrc%5Etfw">@RadianceFields</a>. <a href="https://t.co/IwUgXqXx6o">pic.twitter.com/IwUgXqXx6o</a></p>
<p>&mdash; NVIDIA AI Developer (@NVIDIAAIDev) <a href="https://twitter.com/NVIDIAAIDev/status/1731750910345306211?ref_src=twsrc%5Etfw">December 4, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p>Be sure to include the #WinterArtChallenge hashtag for a chance to be featured on the @NVIDIAStudio, @NVIDIAOmniverse or @NVIDIAAIDev social channels.</p>
<h2><b>An AI on the Future</b></h2>
<p>Chiang began in Blender, sculpting intricate 3D models that served as the building blocks for NANA. Blender Cycles’ RTX-accelerated OptiX ray tracing in the viewport unlocked interactive, photorealistic modeling.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-68732-5" width="1280" height="674" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-Blender-頭部雕刻-1280w.mp4?_=5" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-Blender-頭部雕刻-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-Blender-頭部雕刻-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>He then used the Marvelous Designer software for making, editing and reusing 3D clothes to create realistic clothing for NANA. This streamlined the design and simulation process, ensuring that the avatar is not only structurally sound but impeccably dressed.</p>
<figure id="attachment_68748" aria-describedby="caption-attachment-68748" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-image1-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68748" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-image1-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-image1-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-image1-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-image1-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-image1-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-image1-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-image1-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-image1-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68748" class="wp-caption-text">NANA’s casual day outfit.</figcaption></figure>
<p>Chiang deployed Quixel Mixer and Adobe Substance 3D Painter for shading, adding depth, texture and realism to the 3D models.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-68732-6" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-SP_衣服材質-1280w.mp4?_=6" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-SP_衣服材質-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-SP_衣服材質-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>He then used the Blender plug-in AccuRIG to efficiently create precise, adaptable character rigs.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-68732-7" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-SP_褲子-1280w.mp4?_=7" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-SP_褲子-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-SP_褲子-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>Chiang put everything together in Unreal Engine, where he seamlessly integrated 3D objects into the scene, leveraging real-time rendering to create visually stunning results.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-68732-8" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-SSS-1280w.mp4?_=8" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-SSS-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-SSS-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>NVIDIA DLSS further increased viewport interactivity by using AI to upscale frames rendered at lower resolution while still retaining high-fidelity detail. All of this was powered by his GeForce RTX 4090 GPU.</p>
<figure id="attachment_68754" aria-describedby="caption-attachment-68754" style="width: 582px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-msi-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68754" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-msi-1280w-582x500.png" alt="" width="582" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-msi-1280w-582x500.png 582w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-msi-1280w-400x344.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-msi-1280w-768x660.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-msi-1280w-524x450.png 524w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-msi-1280w-250x215.png 250w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-msi-1280w-406x350.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-msi-1280w-116x100.png 116w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-msi-1280w.png 1280w" sizes="(max-width: 582px) 100vw, 582px" /></a><figcaption id="caption-attachment-68754" class="wp-caption-text">The NVIDIA Studio-badged MSI MEG Trident X2 PC, equipped with a GeForce RTX 4090 graphics card.</figcaption></figure>
<p>Chiang is excited about what AI can do for creators and society at large.</p>
<p>“What was once science fiction is now becoming reality, opening the door to a whole new stage of scientific and technological development,” he said. “We are fortunate to participate in and witness this new stage.”</p>
<figure id="attachment_68757" aria-describedby="caption-attachment-68757" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-eric-chiang-wk87-artist-feature-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68757" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-eric-chiang-wk87-artist-feature-1280w-672x263.png" alt="" width="672" height="263" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-eric-chiang-wk87-artist-feature-1280w-672x263.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-eric-chiang-wk87-artist-feature-1280w-400x156.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-eric-chiang-wk87-artist-feature-1280w-768x300.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-eric-chiang-wk87-artist-feature-1280w-842x329.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-eric-chiang-wk87-artist-feature-1280w-406x159.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-eric-chiang-wk87-artist-feature-1280w-188x73.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-eric-chiang-wk87-artist-feature-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68757" class="wp-caption-text">Moonshine Studio digital 3D artist Eric Chiang.</figcaption></figure>
<p>Visit <a href="https://moonshine.tw/">Moonshine Studio</a> and say hello to NANA.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>Twitter</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-Blender-頭部雕刻-1280w.mp4" length="1514259" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-SP_衣服材質-1280w.mp4" length="1885913" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-SP_褲子-1280w.mp4" length="1980545" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-eric-chiang-wk87-SSS-1280w.mp4" length="1603022" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/nv-blog-header-preview-1280x680-2.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/nv-blog-header-preview-1280x680-2-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Meet NANA, Moonshine Studio’s AI-Powered Receptionist Avatar]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>How NVIDIA Fuels the AI Revolution With Investments in Game Changers and Market Makers</title>
		<link>https://blogs.nvidia.com/blog/nvidia-investments/</link>
		
		<dc:creator><![CDATA[Liz Archibald]]></dc:creator>
		<pubDate>Mon, 11 Dec 2023 16:00:01 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Explainer]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68714</guid>

					<description><![CDATA[Great companies thrive on stories. Sid Siddeek, who runs NVIDIA’s venture capital arm, knows this well. Siddeek still remembers one of his first jobs, schlepping presentation materials from one investor meeting to another, helping the startup’s CEO and management team get the story out while working from a trailer that “shook when the door opened,” <a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-investments/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Great companies thrive on stories. Sid Siddeek, who runs NVIDIA’s venture capital arm, knows this well.</p>
<p>Siddeek still remembers one of his first jobs, schlepping presentation materials from one investor meeting to another, helping the startup’s CEO and management team get the story out while working from a trailer that “shook when the door opened,” he said.</p>
<p>That CEO was Jensen Huang. The startup was NVIDIA.</p>
<p>Siddeek, who has worked as an investor and an entrepreneur, knows how important it is to find the right people to share your company’s story with early on, whether they’re customers or partners, employees or investors.</p>
<p>It’s this very principle that underpins NVIDIA’s multifaceted approach to investing in the next wave of innovation, a strategy also championed by Vishal Bhagwati, who leads NVIDIA’s corporate development efforts.</p>
<p>It’s an effort that’s resulted in more than two dozen investments so far this year, accelerating as the pace of innovation in AI and accelerated computing quickens.</p>
<h2>NVIDIA’s Three-Pronged Strategy to Support the AI Ecosystem</h2>
<p>There are three ways that NVIDIA invests in the ecosystem, driving the transformation unleashed by accelerated computing. First, through NVIDIA’s corporate investments, overseen by Bhagwati. Second, through <a href="https://www.nventures.ai/">NVentures</a>, our venture capital arm, led by Siddeek. And finally, through <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a>, our vehicle for supporting startups and connecting them to venture capital.</p>
<p>There couldn’t be a better time to support companies harnessing NVIDIA technologies. AI alone could contribute more than $15 trillion to the global economy by 2030, according to PwC.</p>
<p>And if you’re working in AI and accelerated computing right now, NVIDIA stands ready to help. Developers across every industry in every country are building accelerated computing applications. And they’re just getting going.</p>
<p>The result is a collection of companies that are advancing the story of AI every day. They include Cohere, CoreWeave, Hugging Face, Inflection, Inceptive and many more. And we’re right alongside them.</p>
<p>“Partnering with NVIDIA is a game-changer,” said Ed Mehr, CEO of Machina Labs. “Their unmatched expertise will supercharge our AI and simulation capabilities.”</p>
<h2>Corporate Investments: Growing Our Ecosystem</h2>
<p>NVIDIA’s corporate investments arm focuses on strategic collaborations. These partnerships stimulate joint innovation, enhance the NVIDIA platform and expand the ecosystem. Since the beginning of 2023, announcements have been made about 14 investments.</p>
<p>These target companies include Ayar Labs, specializing in chip-to-chip optical connectivity, and Hugging Face, a hub for advanced AI models.</p>
<p>The portfolio also includes next-generation enterprise solutions. Databricks offers an industry-leading data platform for machine learning, while Cohere provides enterprise automation through AI. Other notable companies are Recursion, Kore.ai and Utilidata, each contributing unique solutions in drug discovery, conversational AI and smart electricity grids, respectively.</p>
<p>Consumer services are another investment focus. Inflection is crafting a personal AI for creative expression, while Runway serves as a platform for art and creativity through generative AI.</p>
<p>The investment strategy extends to autonomous machines. Ready Robotics is developing an operating system for industrial robotics, and Skydio builds autonomous drones.</p>
<p>NVIDIA’s most recent investments are in cloud service providers like CoreWeave. These platforms cater to a diverse clientele, from startups to Fortune 500 companies seeking to build next-generation AI services.</p>
<h2>NVentures: Investing Alongside Entrepreneurs</h2>
<p>Through NVentures, we support innovators who are deeply relevant to NVIDIA. We aim to generate strong financial returns and expand the ecosystem by funding companies that use our platforms across a wide range of industries.</p>
<p>To date, NVentures has made 19 investments in companies in healthcare, manufacturing and other key verticals. Some examples of our portfolio companies include:</p>
<ul>
<li style="font-weight: 400;" aria-level="1">Genesis Therapeutics, Inceptive, Terray, Charm, Evozyne, Generate, Superluminal: revolutionizing drug discovery</li>
<li style="font-weight: 400;" aria-level="1">Machina Labs, Seurat Technologies: disrupting industrial processes to improve manufacturing</li>
<li style="font-weight: 400;" aria-level="1">PassiveLogic: automating building systems with AI</li>
<li style="font-weight: 400;" aria-level="1">MindsDB: for developers that need to connect enterprise data to AI</li>
<li style="font-weight: 400;" aria-level="1">Moon Surgical: improving laparoscopic surgery with AI</li>
<li style="font-weight: 400;" aria-level="1">Twelve Labs: developing multimodal foundation models for video understanding</li>
<li style="font-weight: 400;" aria-level="1">Flywheel: accelerating medical imaging data development</li>
<li style="font-weight: 400;" aria-level="1">Luma AI: developers of visual and multimodal models</li>
<li style="font-weight: 400;" aria-level="1">Outrider: automating logistics hub operation</li>
<li style="font-weight: 400;" aria-level="1">Synthesia: AI Video for the enterprise</li>
<li style="font-weight: 400;" aria-level="1">Replicate: developer platform for open-source and custom models</li>
</ul>
<p>All these companies are building on work being done inside and outside NVIDIA.</p>
<p>“NVentures has a network, not just within NVIDIA, but throughout the industry, to make sure we have access to the best technology and the best people to build all the different modules that have to come together to define the distribution and supply chain of the future,” said Andrew Smith, CEO of Outrider.</p>
<h2>NVIDIA Inception: Supporting Startups and Connecting Them to Investors</h2>
<p>In addition, we’re continuing to support startups with NVIDIA Inception. Launched in 2016, this free global program offers technology and marketing support to over 17,000 startups across multiple industries and over 125 countries.</p>
<p>And, as part of Inception, we’re partnering with venture capitalists through our VC Alliance, a program that offers benefits to our valued network of venture capital firms, including connecting startups with potential investors.</p>
<h2>Partnering With Innovators in Every Industry</h2>
<p>Whatever our relationship, whether as a partner or investor, we can offer companies unique forms of support.</p>
<p>NVIDIA has the technology. NVIDIA has the richest set of libraries and the deepest understanding of the frameworks needed to optimize training and inference pipelines.</p>
<p>We have the go-to-market skills. NVIDIA has tremendous field sales, solution architect and developer relations organizations with a long track record of working with the most innovative startups and the largest companies in the world.</p>
<p>We know how to grow. We have people throughout our organization who are recognized leaders in their respective fields and can offer expert advice to companies of all sizes and industries.</p>
<p>“Partnering with NVIDIA was an easy choice,” said Victor Riparbelli, cofounder and CEO of Synthesia. “We use their hardware, benefit from their AI expertise and get valuable insights, allowing us to build better products faster.”</p>
<h2>Accelerating the Greatest Breakthroughs of Our Time</h2>
<p>In turn, these investments augment our R&amp;D in the software, systems and semiconductors undergirding this ecosystem.</p>
<p>With NVIDIA’s technologies poised to accelerate the work of researchers and scientists, entrepreneurs, startups and Fortune 500 companies, finding ways to support companies that rely on our technologies— with engineering resources, marketing support and capital — is more vital than ever.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/NVIDIA-logo-exterior-park.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/NVIDIA-logo-exterior-park-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[How NVIDIA Fuels the AI Revolution With Investments in Game Changers and Market Makers]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>500 Games and Apps Now Powered by RTX: A DLSS and Ray-Tracing Milestone</title>
		<link>https://blogs.nvidia.com/blog/500-geforce-rtx/</link>
		
		<dc:creator><![CDATA[Keoki Young]]></dc:creator>
		<pubDate>Thu, 07 Dec 2023 19:23:30 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Gaming]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68694</guid>

					<description><![CDATA[We’re celebrating a milestone this week with 500 RTX games and applications utilizing NVIDIA DLSS, ray tracing or AI technologies. It’s an achievement anchored by NVIDIA’s revolutionary RTX technology, which has transformed gaming graphics and performance. The journey began in 2018 at an electrifying event in Cologne. In a steel and concrete music venue amidst <a class="read-more" href="https://blogs.nvidia.com/blog/500-geforce-rtx/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>We’re celebrating a milestone this week with <a href="https://www.nvidia.com/en-us/geforce/news/rtx500-celebration-dlss-ray-tracing-new-games-win-prizes/">500 RTX games and applications utilizing NVIDIA DLSS, ray tracing or AI technologies</a>. It’s an achievement anchored by NVIDIA’s revolutionary RTX technology, which has transformed gaming graphics and performance.</p>
<p><iframe loading="lazy" title="YouTube video player" src="https://www.youtube.com/embed/YS8-smNHOhs?si=n3dpFyb7k7l-vngh" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>The journey began in 2018 at an electrifying event in Cologne. In a steel and concrete music venue amidst the city’s gritty industrial north side, over 1,200 gamers, breathless and giddy, erupted as NVIDIA founder and CEO Jensen Huang introduced NVIDIA RTX and declared, “This is a historic moment &#8230; Computer graphics has been reinvented.”</p>
<p>This groundbreaking launch, set against the backdrop of the world’s largest gaming expo, Gamescom, marked the introduction of the GeForce RTX 2080 Ti, 2080 and 2070 GPUs.</p>
<figure id="attachment_68695" aria-describedby="caption-attachment-68695" style="width: 1272px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-68695 size-full" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-launch.png" alt="Launched in 2018, NVIDIA RTX has redefined visual fidelity and performance in modern gaming and creative applications." width="1272" height="676" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-launch.png 1272w, https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-launch-400x213.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-launch-672x357.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-launch-768x408.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-launch-842x447.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-launch-406x215.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-launch-188x100.png 188w" sizes="(max-width: 1272px) 100vw, 1272px" /><figcaption id="caption-attachment-68695" class="wp-caption-text">Launched in 2018, NVIDIA RTX has redefined visual fidelity and performance in modern gaming and creative applications.</figcaption></figure>
<p>The most technically advanced games now rely on the <a href="https://www.nvidia.com/en-us/geforce/rtx/">techniques that RTX technologies</a> have unlocked.</p>
<p>Ray tracing, enabled by dedicated RT Cores, delivers immersive, realistic lighting and reflections in games.</p>
<p>The technique has evolved from games with only a single graphics element executed in ray tracing to games such as A<i>lan Wake 2, Cyberpunk 2077, Minecraft RTX </i>and <i>Portal RTX </i>that use ray tracing for all the light in the game.</p>
<p>And <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">NVIDIA DLSS</a>, powered by <a href="https://www.nvidia.com/en-us/data-center/tensor-cores/">Tensor Cores</a>, accelerates AI graphics, now boosting performance with DLSS Frame Generation and improving RT effects with DLSS Ray Reconstruction in titles like <i>Cyberpunk 2077: Phantom Liberty</i>.</p>
<p>Beyond gaming, these technologies revolutionize creative workflows, enabling real-time, ray-traced previews in applications that once required extensive processing time.</p>
<p>Ray tracing, <a href="https://dl.acm.org/doi/10.1145/1468075.1468082">a technique first described in 1969 by Arthur Appel</a>, mirrors how light interacts with objects to create lifelike images.</p>
<p>Ray tracing was once limited to high-end movie production. NVIDIA’s RTX graphics cards have made this cinematic quality accessible in real-time gaming, enhancing experiences with dynamic lighting, reflections and shadows.</p>
<p>High engagement rates in titles like <i>Cyberpunk 2077</i>, <i>NARAKA: BLADEPOINT</i>, <i>Minecraft with RTX</i>, <i>Alan Wake 2</i> and <i>Diablo IV</i>, where 96% or higher of RTX 40 Series t gamers use RTX ON, underscore this success.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-68706" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-500-celebration-infographic.png" alt="" width="1290" height="3062" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-500-celebration-infographic.png 1290w, https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-500-celebration-infographic-169x400.png 169w, https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-500-celebration-infographic-211x500.png 211w, https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-500-celebration-infographic-768x1823.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-500-celebration-infographic-647x1536.png 647w, https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-500-celebration-infographic-863x2048.png 863w, https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-500-celebration-infographic-190x450.png 190w, https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-500-celebration-infographic-91x215.png 91w, https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-500-celebration-infographic-42x100.png 42w, https://blogs.nvidia.com/wp-content/uploads/2023/12/rtx-500-celebration-infographic-1280x3038.png 1280w" sizes="(max-width: 1290px) 100vw, 1290px" /></p>
<p>To commemorate this milestone, 20 $500 Green Man Gaming gift cards and exclusive #RTXON keyboard keycaps are up for grabs. Participants must follow GeForce’s social channels and comply with the sweepstakes rules.</p>
<p>Stay tuned for <a href="https://www.nvidia.com/en-us/geforce/news/">more RTX 500 giveaways</a>.</p>
<p>NVIDIA’s advancement from the first RTX graphics card to powering 500 RTX games and applications with advanced technologies heralds a new gaming and creative tech era. And NVIDIA continues to lead, offering unparalleled experiences in gaming and creativity.</p>
<p><i>Stay tuned to </i><a href="https://www.nvidia.com/en-us/geforce/news/"><i>GeForce News</i></a><i> for more updates on RTX games and enhancements.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/gf-article-thumb-1200x630@2x-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1075"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/gf-article-thumb-1200x630@2x-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[500 Games and Apps Now Powered by RTX: A DLSS and Ray-Tracing Milestone]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Meet the Omnivore: SiBORG Lab Elevates Approach to Accessibility Using OpenUSD and NVIDIA Omniverse</title>
		<link>https://blogs.nvidia.com/blog/mathew-schwartz-openusd-omniverse/</link>
		
		<dc:creator><![CDATA[Nicole Castro]]></dc:creator>
		<pubDate>Thu, 07 Dec 2023 16:00:02 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Meet the Omnivore]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Rendering]]></category>
		<category><![CDATA[Universal Scene Description]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68528</guid>

					<description><![CDATA[Accessibility is a key element that all designers must consider before constructing a space or product — but the evaluation process has traditionally been tedious and time-consuming. Mathew Schwartz, an assistant professor in architecture and design at the New Jersey Institute of Technology, is using the NVIDIA Omniverse platform and the Universal Scene Description framework, <a class="read-more" href="https://blogs.nvidia.com/blog/mathew-schwartz-openusd-omniverse/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Accessibility is a key element that all designers must consider before constructing a space or product — but the evaluation process has traditionally been tedious and time-consuming.</p>
<p>Mathew Schwartz, an assistant professor in architecture and design at the New Jersey Institute of Technology, is using the <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> platform and the <a href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description</a> framework, aka OpenUSD, to help architects, interior designers and industrial designers address this challenge.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/mschwartz.png"><img loading="lazy" decoding="async" class="alignright wp-image-68681 size-thumbnail" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/mschwartz-150x150.png" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/mschwartz-150x150.png 150w, https://blogs.nvidia.com/wp-content/uploads/2023/12/mschwartz-400x400.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/mschwartz-500x500.png 500w, https://blogs.nvidia.com/wp-content/uploads/2023/12/mschwartz-450x450.png 450w, https://blogs.nvidia.com/wp-content/uploads/2023/12/mschwartz-215x215.png 215w, https://blogs.nvidia.com/wp-content/uploads/2023/12/mschwartz-100x100.png 100w, https://blogs.nvidia.com/wp-content/uploads/2023/12/mschwartz.png 512w" sizes="(max-width: 150px) 100vw, 150px" /></a>Schwartz’s research and design lab <a href="https://www.siborglab.com/">SiBORG</a> — which stands for simulation, biomechanics, robotics and graphics — focuses on understanding and improving design workflows, especially in relation to accessibility, human factors and automation. Schwartz and his team develop algorithms for research projects and turn them into usable products.</p>
<p>Using Omniverse  — a development platform that enables multi-app workflows and real-time collaboration — the team developed <a href="https://github.com/cadop/dhart">open-source, OpenUSD-based code</a> that automatically generates a complex accessibility graph for building design. This code is based on Schwartz’s <a href="https://www.sciencedirect.com/science/article/abs/pii/S092658052100008X?via%3Dihub">research paper</a>, “Human centric accessibility graph for environment analysis.”</p>
<p>The graph provides feedback related to human movement, such as the estimated energy expenditure required for taking a certain path, the number of steps it takes to complete the path, or the angles of any inclines along it.</p>
<p>With Omniverse, teams can use Schwartz’s code to visualize the graph and the paths that it creates. This can help designers better evaluate building code and safety for occupants while providing important accessibility insights.</p>
<p><iframe loading="lazy" title="Human Accessibility Simulation by Mathew Schwartz" width="500" height="281" src="https://www.youtube.com/embed/BGl80SucaiI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>The Power of OpenUSD</b></h2>
<p>Traditionally, feedback on accessibility and environmental conditions during the building design process has been limited to building code analysis. Schwartz’s work enables designers to overcome this obstacle by seamlessly integrating Omniverse and OpenUSD.</p>
<p>Previously, he had to switch between multiple applications to achieve different aspects of his simulation and modeling projects. His workflows were often split between tools such as Unity, which supports simulations with people, and McNeel Rhino3D, which offers 3D modeling features.</p>
<p>With OpenUSD, he can now combine his research, Python code, 3D environments and renders, and favorite tools into Omniverse.</p>
<p>“What got me hooked on Omniverse was how it allows me to combine the Python application programming interface with powerful physics, rendering and animation software,” he said. “My team took full advantage of the flexible Python APIs in Omniverse to develop almost the entire user interface.”</p>
<p>Schwartz’s team uses Omniverse to visualize and interact with existing open-source Python code in ways that don’t require external work, like seamlessly linking to a third-party app. The lab’s versatile data analysis tool can interact with any program that’s compatible with OpenUSD.</p>
<p>“With OpenUSD and Omniverse, we’ve been able to expand the scope of our research, as we can easily combine data analysis and visualization with the design process,” said Schwartz.</p>
<h2><b>Running Realistic Renderings and Simulations</b><b><br />
</b></h2>
<p>Schwartz also uses Omniverse to <a href="https://github.com/cadop/crowds">simulate crowd movement</a> and interactions.</p>
<p>He accelerates large crowd simulations and animations using two <a href="https://www.nvidia.com/en-us/design-visualization/rtx-a4500/">NVIDIA RTX A4500 GPUs</a>, which enable real-time visualization. These accelerated simulations can help designers gain valuable insights into how people with reduced mobility can navigate and interact in spaces.</p>
<p>“We can also show what locations will offer the best areas to place signage so that it’s most visible,” said Schwartz. “Our simulation work can be used to visualize paths taken in an early-stage design — this provides feedback on accessibility to prevent problems with building code, while allowing users to create designs that go beyond the minimum requirements.”</p>
<p><iframe loading="lazy" title="GPU Accelerated Crowds by Mathew Schwartz" width="500" height="281" src="https://www.youtube.com/embed/3krdUZLHo7I?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Schwartz also taps the feedback and assistance of many developers and researchers who actively engage on the Omniverse Discord channel. This collaborative environment has been instrumental in Schwartz’s journey, he said, as well as to the platform’s continuous improvement.</p>
<p>Schwartz’s <a href="https://github.com/cadop/dhart">open-source code</a> is available for designers to use and enhance their design workflows. Learn more about <a href="https://siborg.design">his work</a> and how <a href="https://developer.nvidia.com/omniverse">NVIDIA Omniverse can revolutionize building design</a>.</p>
<h2><b>Join In on the Creation</b></h2>
<p>Anyone can build their own <a href="https://developer.nvidia.com/omniverse">Omniverse extension or Connector</a> to enhance 3D workflows and tools.</p>
<p>Check out artwork from other “Omnivores” and submit projects in the <a href="https://www.nvidia.com/en-us/omniverse/gallery-submissions/">Omniverse gallery</a>. See how creators are using OpenUSD to accelerate a variety of 3D workflows in the latest <a href="https://resources.nvidia.com/en-us-omniverse-usd/ov-openusd-allstars">OpenUSD All Stars</a>.</p>
<p><i>Get started with NVIDIA Omniverse by downloading the standard license </i><a href="https://www.nvidia.com/en-us/omniverse/download/"><i>free</i></a><i>, access </i><a href="https://developer.nvidia.com/usd"><i>OpenUSD</i></a><i> resources, and learn how </i><a href="https://www.nvidia.com/en-us/omniverse/enterprise/"><i>Omniverse Enterprise</i><i> can connect your team</i></a><i>. Stay up to date on </i><a href="https://www.instagram.com/nvidiaomniverse/"><i>Instagram</i></a><i>, </i><a href="https://medium.com/@nvidiaomniverse"><i>Medium</i></a><i> and </i><a href="https://twitter.com/nvidiaomniverse"><i>Twitter</i></a><i>. For more, join the </i><a href="https://www.nvidia.com/en-us/omniverse/community/"><i>Omniverse community</i></a><i> on the  </i><a href="https://forums.developer.nvidia.com/c/omniverse/300"><i>forums</i></a><i>, </i><a href="https://discord.com/invite/XWQNJDNuaC"><i>Discord server</i></a><i>, </i><a href="https://www.twitch.tv/nvidiaomniverse"><i>Twitch</i></a><i> and </i><a href="https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA"><i>YouTube</i></a><i> channels. </i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/crop-siborg-lab-still.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/crop-siborg-lab-still-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Meet the Omnivore: SiBORG Lab Elevates Approach to Accessibility Using OpenUSD and NVIDIA Omniverse]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
	</channel>
</rss>
