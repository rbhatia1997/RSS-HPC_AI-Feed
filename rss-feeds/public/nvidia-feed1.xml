<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Tue, 14 May 2024 16:09:25 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.5.2</generator>
	<item>
		<title>CaLLM, Cool and Connected: Cerence Uses Generative AI to Transform the In-Car Experience</title>
		<link>https://blogs.nvidia.com/blog/cerence-generative-ai-in-car-experience/</link>
		
		<dc:creator><![CDATA[Norm Marks]]></dc:creator>
		<pubDate>Tue, 14 May 2024 16:30:03 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71593</guid>

					<description><![CDATA[The integration of AI has become pivotal in shaping the future of driving experiences. As vehicles transition into smart, connected entities, the demand for intuitive human-machine interfaces and advanced driver assistance systems has surged In this journey toward automotive intelligence, Cerence, a global leader in AI-powered mobility solutions, is tapping NVIDIA’s core expertise in automotive		<a class="read-more" href="https://blogs.nvidia.com/blog/cerence-generative-ai-in-car-experience/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>The integration of AI has become pivotal in shaping the future of driving experiences. As vehicles transition into smart, connected entities, the demand for intuitive human-machine interfaces and advanced driver assistance systems has surged</p>
<p>In this journey toward automotive intelligence, Cerence, a global leader in AI-powered mobility solutions, is tapping NVIDIA’s core expertise in automotive cloud and edge technologies to redefine the in-car user experience.</p>
<p>In a recent video, Iqbal Arshad, chief technology officer of Cerence, emphasized the point, stating: “Generative AI is the single biggest change that’s happening in the tech industry overall.”</p>
<p><iframe title="Cerence and NVIDIA: Generative AI for Next-Generation In-Vehicle Experiences" width="500" height="281" src="https://www.youtube.com/embed/XTknC-3PV00?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>The cornerstone of Cerence’s vision lies in the development of its automotive-specific Cerence Automotive Large Language Model, or <a href="https://www.cerence.com/news-releases/news-release-details/cerence-pioneers-automotive-specific-llm-collaboration-nvidia" target="_blank" rel="noopener">CaLLM</a>. It serves as the foundation for the company’s next-gen in-car computing platform, running on <a href="https://developer.nvidia.com/drive" target="_blank" rel="noopener">NVIDIA DRIVE</a>.</p>
<p>The platform, unveiled in December, showcases the future of in-car interaction, with an automotive- and mobility-specific assistant that provides an integrated in-cabin experience.</p>
<p>“We have datasets from the last 20 years of experience working in the automotive space,” Iqbal said. “And we’re able to take that data and make that an automotive-ready LLM.”</p>
<h2><strong>Generative AI a Game-Changer for the Automotive Industry</strong></h2>
<p><a href="https://www.nvidia.com/en-us/glossary/generative-ai/" target="_blank" rel="noopener">Generative AI</a> enables vehicles to comprehend and respond to human language with remarkable accuracy, revolutionizing the way drivers interact with their cars.</p>
<p>Whether it’s initiating voice commands for navigation, controlling infotainment systems or even engaging in natural language conversations, generative AI opens a realm of possibilities for creating more convenient and enjoyable driving experiences.</p>
<p>Cerence is striving to empower vehicles with the cognitive capabilities necessary to seamlessly assist drivers in navigating their daily routines.</p>
<p>The company leverages <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/" target="_blank" rel="noopener">NVIDIA DGX Cloud</a> on Microsoft Azure, providing dedicated, scalable access to the latest NVIDIA architecture, co-engineered at every layer with Microsoft Azure, optimized for peak performance in AI workload training. NVIDIA’s inferencing technology helps Cerence deliver real-time performance, facilitating seamless user experiences.</p>
<p>As Cerence sees it, the future is one of intelligent driving, where vehicles aren’t just modes of transportation, but trusted companions on the road ahead.</p>
<p>“Generative computing is going to change your in-car experience,” said Iqbal.</p>
<p>With generative AI at its core, driving will evolve into a personalized, connected and, ultimately, safer experience for all.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/cerencegenai-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/cerencegenai-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[CaLLM, Cool and Connected: Cerence Uses Generative AI to Transform the In-Car Experience]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA to Help Elevate Japan’s Sovereign AI Efforts Through Generative AI Infrastructure Build-Out</title>
		<link>https://blogs.nvidia.com/blog/japan-sovereign-ai/</link>
		
		<dc:creator><![CDATA[Masataka Osaki]]></dc:creator>
		<pubDate>Tue, 14 May 2024 13:00:42 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71602</guid>

					<description><![CDATA[Following an announcement by Japan’s Ministry of Economy, Trade and Industry, NVIDIA will play a central role in developing the nation’s generative AI infrastructure as Japan seeks to capitalize on the technology’s economic potential and further develop its workforce. NVIDIA is collaborating with key digital infrastructure providers, including GMO Internet Group, Highreso, KDDI Corporation, RUTILEA,		<a class="read-more" href="https://blogs.nvidia.com/blog/japan-sovereign-ai/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Following an announcement by Japan’s Ministry of Economy, Trade and Industry, NVIDIA will play a central role in developing the nation’s generative AI infrastructure as Japan seeks to capitalize on the technology’s economic potential and further develop its workforce.</p>
<p>NVIDIA is collaborating with key digital infrastructure providers, including GMO Internet Group, Highreso, KDDI Corporation, RUTILEA, SAKURA internet Inc. and SoftBank Corp., which the ministry has certified to spearhead the development of cloud infrastructure crucial for AI applications.</p>
<p>Over the last two months, the ministry announced plans to allocate $740 million, approximately ¥114.6 billion, to assist six local firms in this initiative. Following on from last year, this is a significant effort by the Japanese government to subsidize AI computing resources, by expanding the number of companies involved.</p>
<p>With this move, Japan becomes the latest nation to embrace the concept of <a href="https://blogs.nvidia.com/blog/what-is-sovereign-ai/">sovereign AI</a>, aiming to fortify its local startups, enterprises and research efforts with advanced AI technologies.</p>
<p>Across the globe, nations are building up domestic computing capacity through various models. Some procure and operate sovereign AI clouds with state-owned <a href="https://www.nvidia.com/en-us/industries/telecommunications/ai-factories/">telecommunications providers</a> or utilities. Others are sponsoring local cloud partners to provide a shared AI computing platform for public and private sector use.</p>
<p>Japan’s initiative follows NVIDIA founder and CEO Jensen Huang&#8217;s visit last year, where he met with political and business leaders — including Japanese Prime Minister Fumio Kishida — to discuss the future of AI.</p>
<p>During his trip, Huang emphasized that “AI factories” — next-generation data centers designed to handle the most computationally intensive AI tasks — are crucial for turning vast amounts of data into intelligence. “The AI factory will become the bedrock of modern economies across the world,” Huang said during a meeting with the Japanese press in December.</p>
<p>The Japanese government plans to subsidize a significant portion of the costs for building AI supercomputers, which will facilitate AI adoption, enhance workforce skills, support Japanese language model development and bolster resilience against natural disasters and climate change.</p>
<p>Under the country’s Economic Security Promotion Act, the ministry aims to secure a stable supply of local cloud services, reducing the time and cost of developing next-generation AI technologies.</p>
<p>Japan’s technology powerhouses are already moving fast to embrace AI. Last week, SoftBank Corp. announced that it will invest ¥150 billion, approximately $960 million, for its plan to expand the infrastructure needed to develop Japan’s top-class AI, including purchases of NVIDIA accelerated computing.</p>
<p>The news follows Huang’s meetings with leaders in Canada, France, India, Japan, Malaysia, Singapore and Vietnam over the past year, as countries seek to supercharge their regional economies and embrace challenges such as climate change with AI.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/tokyo-crop2-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1454"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/tokyo-crop2-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA to Help Elevate Japan’s Sovereign AI Efforts Through Generative AI Infrastructure Build-Out]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Drug Discovery, STAT! NVIDIA, Recursion Speed Pharma R&#038;D With AI Supercomputer</title>
		<link>https://blogs.nvidia.com/blog/drug-discovery-recursion-supercomputer/</link>
		
		<dc:creator><![CDATA[Rory Kelleher]]></dc:creator>
		<pubDate>Mon, 13 May 2024 09:00:20 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artficial Intelligence]]></category>
		<category><![CDATA[Customer Stories]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[New GPU Uses]]></category>
		<category><![CDATA[NVIDIA Hopper Architecture]]></category>
		<category><![CDATA[NVIDIA Quantum-2]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Supercomputing]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71542</guid>

					<description><![CDATA[Described as the largest system in the pharmaceutical industry, BioHive-2 at the Salt Lake City headquarters of Recursion debuts today at No. 35, up more than 100 spots from its predecessor on the latest TOP500 list of the world’s fastest supercomputers. The advance represents the company’s most recent effort to accelerate drug discovery with NVIDIA		<a class="read-more" href="https://blogs.nvidia.com/blog/drug-discovery-recursion-supercomputer/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Described as the largest system in the pharmaceutical industry, BioHive-2 at the Salt Lake City headquarters of Recursion debuts today at No. 35, up more than 100 spots from its predecessor on the latest TOP500 list of the world’s fastest supercomputers.</p>
<p>The advance represents the company’s most recent effort to accelerate drug discovery with NVIDIA technologies.</p>
<p>“Just as with large language models, we see AI models in the biology domain improve performance substantially as we scale our training with more data and compute horsepower, which ultimately leads to greater impacts on patients’ lives,” said Recursion’s CTO, Ben Mabey, who’s been applying machine learning to healthcare for more than a decade.</p>
<p>BioHive-2 packs 504 <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100 Tensor Core GPUs</a> linked on an <a href="https://www.nvidia.com/en-us/networking/quantum2/">NVIDIA Quantum-2</a> InfiniBand network to deliver 2 exaflops of AI performance. The resulting <a href="https://www.nvidia.com/en-us/data-center/dgx-superpod/">NVIDIA DGX SuperPOD</a> is nearly 5x faster than Recursion’s first-generation system, BioHive-1.</p>
<h2><b>Performance Powers Through Complexity</b></h2>
<p>That performance is key to rapid progress because “biology is insanely complex,” Mabey said.</p>
<p>Finding a new drug candidate can take scientists years performing millions of wet-lab experiments.</p>
<p>That work is vital; Recursion’s scientists run more than 2 million such experiments a week. But going forward, they’ll use AI models on BioHive-2 to direct their platform to the most promising biology areas to run their experiments.</p>
<p>“With AI in the loop today, we can get 80% of the value with 40% of the wet lab work, and that ratio will improve going forward,” he said.</p>
<h2><b>Biological Data Propels Healthcare AI</b></h2>
<p>Recursion is collaborating with biopharma companies such as Bayer AG, Roche and Genentech. Over time, it also amassed a more than 50-petabyte database of biological, chemical and patient data, helping it build powerful AI models that are accelerating drug discovery.</p>
<p>“We believe it’s one of the largest biological datasets on Earth — it was built with AI training in mind, intentionally spanning biology and chemistry,” said Mabey, who joined the company more than seven years ago in part due to its commitment to building such a dataset.</p>
<h2><b>Creating an AI Phenomenon</b></h2>
<p>Processing that data on BioHive-1, Recursion developed a family of <a href="https://blogs.nvidia.com/blog/what-are-foundation-models/">foundation models</a> called Phenom. They turn a series of microscopic cellular images into meaningful representations for understanding the underlying biology.</p>
<p>A member of that family, <a href="https://www.recursion.com/news/nothing-short-of-phenomenal-new-deep-learning-model-available-on-nvidias-bionemo-platform">Phenom-Beta</a>, is now available as a cloud API and the first third-party model on <a href="https://www.nvidia.com/en-us/clara/bionemo/">NVIDIA BioNeMo</a>, a <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> platform for drug discovery.</p>
<p>Over several months of research and iteration, BioHive-1 trained <a href="http://arxiv.org/abs/2404.10242">Phenom-1</a> using more than 3.5 billion cellular images. Recursion’s expanded system enables training even more powerful models with larger datasets in less time.</p>
<p>The company also used <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a>, hosted by Oracle Cloud Infrastructure, to provide additional supercomputing resources to power their work.</p>
<figure id="attachment_71588" aria-describedby="caption-attachment-71588" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/Recursion-Phenom-AI-model-animation.gif"><img fetchpriority="high" decoding="async" class="size-large wp-image-71588" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Recursion-Phenom-AI-model-animation-672x338.gif" alt="Animation of how Recursion trains AI models for drug discovery on NVIDIA GPUs" width="672" height="338" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/Recursion-Phenom-AI-model-animation-672x338.gif 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Recursion-Phenom-AI-model-animation-400x201.gif 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Recursion-Phenom-AI-model-animation-768x386.gif 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Recursion-Phenom-AI-model-animation-842x423.gif 842w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Recursion-Phenom-AI-model-animation-406x204.gif 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Recursion-Phenom-AI-model-animation-188x94.gif 188w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71588" class="wp-caption-text">Much like how LLMs are trained to generate missing words in a sentence, Phenom models are trained by asking them to generate the masked out pixels in images of cells.</figcaption></figure>
<p>The Phenom-1 model serves Recursion and its partners in several ways, including finding and optimizing molecules to treat a variety of diseases and cancers. Earlier models helped Recursion predict drug candidates for COVID-19 nine out of 10 times.</p>
<p>The company announced its <a href="https://ir.recursion.com/news-releases/news-release-details/recursion-announces-collaboration-and-50-million-investment">collaboration with NVIDIA</a> in July. Less than 30 days later, the combination of BioHive-1 and DGX Cloud <a href="https://ir.recursion.com/news-releases/news-release-details/recursion-bridges-protein-and-chemical-space-massive-protein">screened and analyzed</a> a massive chemical library to predict protein targets for approximately 36 billion chemical compounds.</p>
<p>In January, the company <a href="https://ir.recursion.com/news-releases/news-release-details/recursion-unveils-lowe-drug-discovery-software-jp-morgan">demonstrated</a> LOWE, an AI workflow engine with a natural-language interface to help make its tools more accessible to scientists. And in April it <a href="https://portal.valencelabs.com/blogs/post/introducing-molgps---a-foundational-gnn-for-molecular-property-prediction-Ti4InC3788me9f5">described</a> a billion-parameter AI model it built to provide a new way to predict the properties of key molecules of interest in healthcare.</p>
<p>Recursion uses NVIDIA software to optimize its systems.</p>
<p>“We love CUDA and <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a>, and we’re looking to see if <a href="https://www.nvidia.com/en-us/ai/">NVIDIA NIM</a> can help us distribute our models more easily, both internally and to partners,” he said.</p>
<h2><b>A Shared Vision for Healthcare</b></h2>
<p>The efforts are part of a broad vision that Jensen Huang, NVIDIA founder and CEO, described in a <a href="https://blogs.nvidia.com/blog/nvidia-ceo-ai-drug-discovery-jp-morgan-healthcare-2024/">fireside chat</a> with Recursion’s chairman as moving toward simulating biology.</p>
<p>“You can now recognize and learn the language of almost anything with structure, and you can translate it to anything with structure … This is the generative AI revolution,” Huang said.</p>
<p>“We share a similar view,” said Mabey.</p>
<p>“We are in the early stages of a very interesting time where just as computers accelerated chip design, AI can speed up drug design. Biology is much more complex, so it will take years to play out, but looking back, people will see this was a real turning point in healthcare,” he added.</p>
<p><i>Learn about </i><a href="https://www.nvidia.com/en-us/clara/"><i>NVIDIA’s AI platform for healthcare and life sciences</i></a><i> and subscribe to </i><a href="https://www.nvidia.com/en-us/industries/healthcare-life-sciences/healthcare-news-sign-up/"><i>NVIDIA healthcare news</i></a><i>.</i></p>
<p><i>Pictured at top: BioHive-2 with a few members of the Recursion team (from left) Paige Despain, John Durkin, Joshua Fryer, Jesse Dean, Ganesh Jagannathan, Chris Gibson, Lindsay Ellinger, Michael Secora, Alex Timofeyev, and Ben Mabey. </i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/BioHive2-with-Recursion-crop-team-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1085"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/BioHive2-with-Recursion-crop-team-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Drug Discovery, STAT! NVIDIA, Recursion Speed Pharma R&D With AI Supercomputer]]></media:title>
			<media:description type="html">Picture of Recursion team with BioHive-2 AI supercomputer for drug discovery</media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Blackwell Platform Pushes the Boundaries of Scientific Computing</title>
		<link>https://blogs.nvidia.com/blog/blackwell-scientific-computing/</link>
		
		<dc:creator><![CDATA[Dion Harris]]></dc:creator>
		<pubDate>Mon, 13 May 2024 06:00:30 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[CUDA]]></category>
		<category><![CDATA[HPC Stories]]></category>
		<category><![CDATA[RAPIDS]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71547</guid>

					<description><![CDATA[Quantum computing. Drug discovery. Fusion energy. Scientific computing and physics-based simulations are poised to make giant steps across domains that benefit humanity as advances in accelerated computing and AI drive the world’s next big breakthroughs. NVIDIA unveiled at GTC in March the NVIDIA Blackwell platform, which promises generative AI on trillion-parameter large language models (LLMs)		<a class="read-more" href="https://blogs.nvidia.com/blog/blackwell-scientific-computing/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Quantum computing. Drug discovery. Fusion energy. Scientific computing and physics-based simulations are poised to make giant steps across domains that benefit humanity as advances in accelerated computing and AI drive the world’s next big breakthroughs.</p>
<p>NVIDIA unveiled at GTC in March <a href="https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing">the NVIDIA Blackwell platform</a>, which promises generative AI on trillion-parameter large language models (LLMs) at up to 25x less cost and energy consumption than the NVIDIA Hopper architecture.</p>
<p>Blackwell has powerful implications for AI workloads, and its technology capabilities can also help to deliver discoveries across all types of scientific computing applications, including traditional numerical simulation.</p>
<p>By reducing energy costs, accelerated computing and AI drive <a href="https://www.nvidia.com/en-us/data-center/sustainable-computing/">sustainable computing</a>. Many scientific computing applications already benefit. Weather can be simulated at 200x lower cost and with 300x less energy, while digital twin simulations have 65x lower cost and 58x less energy consumption versus traditional CPU-based systems and others.</p>
<h2><b>Multiplying Scientific Computing Simulations With Blackwell</b></h2>
<p>Scientific computing and physics-based simulation often rely on what’s known as double-precision formats, or <a href="https://blogs.nvidia.com/blog/double-precision-tensor-cores/">FP64 (floating point</a>), to solve problems. <a href="https://resources.nvidia.com/en-us-blackwell-architecture">Blackwell GPUs</a> deliver 30% more FP64 and FP32 FMA (fused multiply-add) performance  than Hopper.</p>
<p>Physics-based simulations are critical to product design and development. From planes and trains to bridges, silicon chips and pharmaceuticals — testing and improving products in simulation saves researchers and developers billions of dollars.</p>
<p>Today application-specific integrated circuits (ASICs) are designed almost exclusively on CPUs in a long and complex workflow, including analog analysis to identify voltages and currents.</p>
<p>But that’s changing. The <a href="https://www.nvidia.com/en-us/industries/industrial-sector/cadence/">Cadence</a> SpectreX simulator is one example of an analog circuit design solver. SpectreX circuit simulations are projected to run 13x quicker on a GB200 Grace Blackwell Superchip — which connects Blackwell GPUs and Grace CPUs — than on a traditional CPU.</p>
<p>Also, GPU-accelerated computational fluid dynamics, or CFD, has become a key tool. Engineers and equipment designers use it to predict the behavior of designs. Cadence Fidelity runs CFD simulations that are projected to run as much as 22x faster on GB200 systems than on traditional CPU-powered systems. With parallel scalability and 30TB of memory per GB200 NVL72 rack, it’s possible to capture flow details like never before.</p>
<p>In another application, Cadence Reality’s digital twin software can be used to create a virtual replica of a physical data center, including all its components — servers, cooling systems and power supplies. Such a virtual model allows engineers to test different configurations and scenarios before implementing them in the real world, saving time and costs.</p>
<p>Cadence Reality’s magic happens from physics-based algorithms that can simulate how heat, airflow and power usage affect data centers. This helps engineers and data center operators to more effectively manage capacity, predict potential operational problems and make informed decisions to optimize the layout and operation of the data center for improved efficiency and capacity utilization. With Blackwell GPUs, these simulations are projected to run up to 30x faster than with CPUs, offering accelerated timelines and higher energy efficiency.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/Cadence-Chart.jpg"><img decoding="async" class="aligncenter wp-image-71581 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Cadence-Chart-672x379.jpg" alt="" width="672" height="379" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/Cadence-Chart-672x379.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Cadence-Chart-400x226.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Cadence-Chart-381x215.jpg 381w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Cadence-Chart-177x100.jpg 177w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Cadence-Chart.jpg 752w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<h2><b>AI for Scientific Computing</b></h2>
<p>New Blackwell accelerators and networking will deliver leaps in performance for advanced simulation.</p>
<p>The NVIDIA GB200 kicks off a new era for high-performance computing (HPC). Its architecture sports a second-generation transformer engine optimized to accelerate inference workloads for LLMs.</p>
<p>This delivers a 30x speedup on resource-intensive applications like the 1.8-trillion-parameter GPT-MoE (generative pretrained transformer-mixture of experts) model compared to the H100 generation, unlocking new possibilities for HPC. By enabling LLMs to process and decipher vast amounts of scientific data, HPC applications can sooner reach valuable insights that can accelerate scientific discovery.</p>
<p>Sandia National Laboratories <a href="https://blogs.nvidia.com/blog/generative-ai-science-isc/">is building</a> an LLM copilot for parallel programming. Traditional AI can generate basic serial computing code efficiently, but when it comes to parallel computing code for HPC applications, LLMs can falter. Sandia researchers are tackling this issue head-on with an ambitious project — automatically generating parallel code in Kokkos, a specialized programming language designed by multiple national labs for running tasks across tens of thousands of processors in the world’s most powerful supercomputers.</p>
<p>Sandia is using an AI technique known as <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">retrieval-augmented generation</a>, or RAG, which combines information-retrieval capabilities with language generation models. The team is creating a Kokkos database and integrating it with AI models using RAG.</p>
<p>Initial results are promising. Different RAG approaches from Sandia have demonstrated autonomously generated Kokkos code for parallel computing applications. By overcoming hurdles in AI-based parallel code generation, Sandia aims to unlock new possibilities in HPC across leading supercomputing facilities worldwide. Other examples <a href="https://developer.nvidia.com/blog/ai-for-a-scientific-computing-revolution/">include</a> renewables research, climate science and drug discovery.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-scaled.jpg"><img loading="lazy" decoding="async" class="aligncenter wp-image-71567 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-672x378.jpg" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<h2><b>Driving Quantum Computing Advances</b></h2>
<p>Quantum computing unlocks a time machine trip for fusion energy, climate research, drug discovery and many more areas. So researchers are hard at work simulating future quantum computers on NVIDIA GPU-based systems and software to develop and test quantum algorithms faster than ever.</p>
<p>The <a href="https://developer.nvidia.com/blog/introducing-cuda-quantum-the-platform-for-hybrid-quantum-classical-computing/">NVIDIA CUDA-Q platform</a> enables both simulation of quantum computers and hybrid application development with a unified programming model for CPUs, GPUs and <a href="https://blogs.nvidia.com/blog/what-is-a-qpu/">QPUs</a> (quantum processing units) working together.</p>
<p>CUDA-Q is speeding simulations in chemistry workflows for BASF, high-energy and nuclear physics for Stony Brook and quantum chemistry for NERSC.</p>
<p>NVIDIA Blackwell architecture will help drive quantum simulations to new heights. Utilizing the latest NVIDIA NVLink multi-node interconnect technology helps shuttle data faster for speedup benefits to quantum simulations.</p>
<h2><b>Accelerating Data Analytics for Scientific Breakthroughs </b></h2>
<p>Data processing with RAPIDS is popular for scientific computing. Blackwell introduces a hardware decompression engine to decompress compressed data and speed up analytics in RAPIDS.</p>
<p>The decompression engine provides performance improvements up to 800GB/s and enables Grace Blackwell to perform 18x faster than CPUs — on Sapphire Rapids — and 6x faster than NVIDIA H100 Tensor Core GPUs for query benchmarks.</p>
<p>Rocketing data transfers with 8TB/s of high-memory bandwidth and the Grace CPU high-speed NVLink Chip-to-Chip (C2C) interconnect, the engine speeds up the entire process of database queries. Yielding top-notch performance across data analytics and data science use cases, Blackwell speeds data insights and reduces costs.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333.jpg"><img loading="lazy" decoding="async" class="aligncenter wp-image-71578 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-580x500.jpg" alt="" width="580" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-580x500.jpg 580w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-400x345.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-768x662.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-1536x1325.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-522x450.jpg 522w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-249x215.jpg 249w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-406x350.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-116x100.jpg 116w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-1280x1104.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333.jpg 2048w" sizes="(max-width: 580px) 100vw, 580px" /></a></p>
<h2><b>Driving Extreme Performance for Scientific Computing with NVIDIA Networking</b></h2>
<p>The NVIDIA Quantum-X800 InfiniBand networking platform offers the highest throughput for scientific computing infrastructure.</p>
<p>It includes NVIDIA Quantum Q3400 and Q3200 switches and the NVIDIA ConnectX-8 SuperNIC, together hitting twice the bandwidth of the prior generation. The Q3400 platform offers 5x higher bandwidth capacity and 14.4Tflops of in-network computing with NVIDIA’s scalable hierarchical aggregation and reduction protocol (SHARPv4), providing a 9x increase compared with the prior generation.</p>
<p>The performance leap and power efficiency translates to significant reductions in workload completion time and energy consumption for scientific computing.</p>
<p><i>Learn more about </i><a href="https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/"><i>NVIDIA Blackwell</i></a><i>. </i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gb200-nvl-rack-gtc24-press-1920x1080-1.jpg"
			type="image/jpeg"
			width="1920"
			height="1080"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gb200-nvl-rack-gtc24-press-1920x1080-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Blackwell Platform Pushes the Boundaries of Scientific Computing]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Generating Science: NVIDIA AI Accelerates HPC Research</title>
		<link>https://blogs.nvidia.com/blog/generative-ai-science-isc/</link>
		
		<dc:creator><![CDATA[Geetika Gupta]]></dc:creator>
		<pubDate>Mon, 13 May 2024 06:00:06 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artficial Intelligence]]></category>
		<category><![CDATA[Customer Stories]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[New GPU Uses]]></category>
		<category><![CDATA[NVIDIA Hopper Architecture]]></category>
		<category><![CDATA[NVIDIA Modulus]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Supercomputing]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71538</guid>

					<description><![CDATA[Generative AI is taking root at national and corporate labs, accelerating high-performance computing for business and science. Researchers at Sandia National Laboratories aim to automatically generate code in Kokkos, a parallel programming language designed for use across many of the world’s largest supercomputers. It’s an ambitious effort. The specialized language, developed by researchers from several		<a class="read-more" href="https://blogs.nvidia.com/blog/generative-ai-science-isc/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Generative AI is taking root at national and corporate labs, accelerating high-performance computing for business and science.</p>
<p>Researchers at Sandia National Laboratories aim to automatically <a href="https://developer.nvidia.com/blog/advanced-ai-and-retrieval-augmented-generation-for-code-development-in-high-performance-computing/">generate code in Kokkos</a>, a parallel programming language designed for use across many of the world’s largest supercomputers.</p>
<p>It’s an ambitious effort. The specialized language, developed by researchers from several national labs, handles the nuances of running tasks across tens of thousands of processors.</p>
<p>Sandia is employing retrieval-augmented generation (<a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">RAG</a>) to create and link a Kokkos database with AI models. As researchers experiment with different RAG approaches, initial tests show promising results.</p>
<p>Cloud-based services like <a href="https://developer.nvidia.com/blog/translate-your-enterprise-data-into-actionable-insights-with-nvidia-nemo-retriever/">NeMo Retriever</a> are among the RAG options the scientists will evaluate.</p>
<p>“NVIDIA provides a rich set of tools to help us significantly accelerate the work of our HPC software developers,” said Robert Hoekstra, a senior manager of extreme scale computing at Sandia.</p>
<p>Building copilots via model tuning and RAG is just a start. Researchers eventually aim to employ foundation models trained with scientific data from fields such as climate, biology and material science.</p>
<h2><b>Getting Ahead of the Storm</b></h2>
<p>Researchers and companies in weather forecasting are embracing <a href="https://arxiv.org/abs/2309.15214">CorrDiff</a>, a generative AI model that’s part of <a href="https://www.nvidia.com/en-us/high-performance-computing/earth-2/">NVIDIA Earth-2</a>, a set of services and software for weather and climate research.</p>
<p>CorrDiff can scale the 25km resolution of traditional atmosphere models down to 2 kilometers and expand by more than 100x the number of forecasts that can be combined to improve confidence in predictions.</p>
<p>“It’s a promising innovation … We plan to leverage such models in our global and regional AI forecasts for richer insights,” said Tom Gowan, machine learning and modeling lead for Spire, a company in Vienna, Va., that collects data from its own network of tiny satellites.</p>
<p>Generative AI enables faster, more accurate forecasts, he said in a recent <a href="https://spire.com/blog/weather-climate/ai-weather-modeling-spire-and-nvidia-partnership/">interview</a>.</p>
<p>“It really feels like a big jump in meteorology,” he added. “And by partnering with NVIDIA, we have access to the world’s best GPUs that are the most reliable, fastest and most efficient ones for both training and inference.”</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/Spire-weather-forecast.jpg"><img loading="lazy" decoding="async" class="aligncenter size-large wp-image-71561" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Spire-weather-forecast-672x410.jpg" alt="Graphic showing Spire weather forecast" width="672" height="410" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/Spire-weather-forecast-672x410.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Spire-weather-forecast-400x244.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Spire-weather-forecast-768x469.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Spire-weather-forecast-737x450.jpg 737w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Spire-weather-forecast-352x215.jpg 352w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Spire-weather-forecast-164x100.jpg 164w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Spire-weather-forecast.jpg 1200w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<p>Switzerland-based Meteomatics recently <a href="https://www.meteomatics.com/en/news/meteomatics-nvidia-ai-based-weather-forecasts/">announced</a> it also plans to use NVIDIA’s generative AI platform for its weather forecasting business.</p>
<p>“Our work with NVIDIA will help energy companies maximize their renewable energy operations and increase their profitability with quick and accurate insight into weather fluctuations,” said Martin Fengler, founder and CEO of Meteomatics.</p>
<h2><b>Generating Genes to Improve Healthcare</b></h2>
<p>At Argonne National Laboratory, scientists are using the technology to generate gene sequences that help them better understand the virus behind COVID-19. Their award-winning models, called GenSLMs, spawned simulations that closely resemble real-world variants of SARS-CoV-2.</p>
<p>“Understanding how different parts of the genome are co-evolving gives us clues about how the virus may develop new vulnerabilities or new forms of resistance,” Arvind Ramanathan, a lead researcher, said in <a href="https://blogs.nvidia.com/blog/generative-ai-covid-genome-sequences/">a blog</a>.</p>
<p>GenSLMs were trained on more than 110 million genome sequences with <a href="https://www.nvidia.com/en-us/data-center/tensor-cores/">NVIDIA A100 Tensor Core GPU</a>-powered supercomputers, including Argonne’s <a href="https://nvidianews.nvidia.com/news/nvidia-turbocharges-extreme-scale-ai-for-argonne-national-laboratorys-polaris-supercomputer">Polaris</a> system, the U.S. Department of Energy’s <a href="https://blogs.nvidia.com/blog/nersc-perlmutter-ai-supercomputer/">Perlmutter</a> and NVIDIA’s <a href="https://blogs.nvidia.com/blog/making-selene-pandemic-ai/">Selene</a>.</p>
<h2><b>Microsoft Proposes Novel Materials</b></h2>
<p>Microsoft Research showed how generative AI can accelerate work in materials science.</p>
<p>Their <a href="https://www.microsoft.com/en-us/research/blog/mattergen-property-guided-materials-design/">MatterGen</a> model generates novel, stable materials that exhibit desired properties. The approach enables specifying chemical, magnetic, electronic, mechanical and other desired properties.</p>
<p>“We believe MatterGen is an important step forward in AI for materials design,” the Microsoft Research team wrote of the model they trained on Azure AI infrastructure with NVIDIA A100 GPUs.</p>
<p>Companies such as <a href="https://developer.nvidia.com/blog/using-graph-neural-networks-for-additive-manufacturing/">Carbon3D</a> are already finding opportunities, applying generative AI to materials science in commercial 3D printing operations.</p>
<p>It’s just the beginning of what researchers will be able to do for HPC and science with generative AI. The <a href="https://www.nvidia.com/en-us/data-center/h200/">NVIDIA H200 Tensor Core GPUs</a> available now and the upcoming <a href="https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/">NVIDIA Blackwell Architecture GPUs</a> will take their work to new levels.</p>
<p>Learn more about tools like <a href="https://developer.nvidia.com/modulus">NVIDIA Modulus</a>, a key component in the Earth-2 platform for building AI models that obey the laws of physics, and <a href="https://docs.nvidia.com/megatron-core/index.html">NVIDIA Megatron-Core</a>, a NeMo library to tune and train large language models.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/Weather-ensembles-SuperPOD-x1280.jpg"
			type="image/jpeg"
			width="1920"
			height="1021"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/Weather-ensembles-SuperPOD-x1280-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Generating Science: NVIDIA AI Accelerates HPC Research]]></media:title>
			<media:description type="html">Image of generative AI in science</media:description>
			</media:content>
			</item>
		<item>
		<title>Dial It In: Data Centers Need New Metric for Energy Efficiency</title>
		<link>https://blogs.nvidia.com/blog/datacenter-efficiency-metrics-isc/</link>
		
		<dc:creator><![CDATA[Jeremy Rodriguez]]></dc:creator>
		<pubDate>Mon, 13 May 2024 06:00:04 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artficial Intelligence]]></category>
		<category><![CDATA[Cloud Services]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[GPU Computing]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Parallel Computing]]></category>
		<category><![CDATA[Supercomputing]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71524</guid>

					<description><![CDATA[Data centers need an upgraded dashboard to guide their journey to greater energy efficiency, one that shows progress running real-world applications. The formula for energy efficiency is simple: work done divided by energy used. Applying it to data centers calls for unpacking some details. Today’s most widely used gauge — power usage effectiveness (PUE)  —		<a class="read-more" href="https://blogs.nvidia.com/blog/datacenter-efficiency-metrics-isc/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Data centers need an upgraded dashboard to guide their journey to greater <a href="https://www.nvidia.com/en-us/glossary/energy-efficiency/">energy efficiency</a>, one that shows progress running real-world applications.</p>
<p>The formula for energy efficiency is simple: work done divided by energy used. Applying it to data centers calls for unpacking some details.</p>
<p>Today’s most widely used gauge — power usage effectiveness (<a href="https://leonardo-energy.pl/wp-content/uploads/2018/03/Green_Grid_Metrics.pdf">PUE</a>)  — compares the total energy a facility consumes to the amount its computing infrastructure uses. Over the last 17 years, PUE has driven the most efficient operators closer to an ideal where almost no energy is wasted on processes like power conversion and cooling.</p>
<h2><b>Finding the Next Metrics</b></h2>
<p>PUE served data centers well during the rise of cloud computing, and it will continue to be useful. But it’s insufficient in today’s <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> era, when workloads and the systems running them have changed dramatically.</p>
<p>That’s because PUE doesn’t measure the useful output of a data center, only the energy that it consumes. That’d be like measuring the amount of gas an engine uses without noticing how far the car has gone.</p>
<p>Many standards exist for data center efficiency. A<a href="https://ieeexplore.ieee.org/document/7921551"> 2017 paper</a> lists nearly three dozen of them, several focused on specific targets such as cooling, water use, security and cost.</p>
<h2><b>Understanding What’s Watts</b></h2>
<p>When it comes to energy efficiency, the computer industry has a long and somewhat unfortunate history of describing systems and the processors they use in terms of power, typically in watts. It’s a worthwhile metric, but many fail to realize that watts only measure input power at a point in time, not the actual energy computers use or how efficiently they use it.</p>
<p>So, when modern systems and processors report rising input power levels in watts, that doesn’t mean they’re less energy efficient. In fact, they’re often much more efficient in the amount of work they do with the amount of energy they use.</p>
<p>Modern data center metrics should focus on energy, what the engineering community knows as kilowatt-hours or joules. The key is how much useful work they do with this energy.</p>
<h2><b>Reworking What We Call Work</b></h2>
<p>Here again, the industry has a practice of measuring in abstract terms, like processor instructions or math calculations. So, MIPS (millions of instructions per second) and FLOPS (floating point operations per second) are widely quoted.</p>
<p>Only computer scientists care how many of these low-level jobs their system can handle. Users would prefer to know how much real work their systems put out, but defining useful work is somewhat subjective.</p>
<p>Data centers focused on AI may rely on the <a href="https://www.nvidia.com/en-us/data-center/resources/mlperf-benchmarks/">MLPerf benchmarks</a>. Supercomputing centers tackling scientific research typically use <a href="https://developer.nvidia.com/hpc-application-performance">additional measures</a> of work. Commercial data centers focused on streaming media may want others.</p>
<p>The resulting suite of applications must be allowed to evolve over time to reflect the state of the art and the most relevant use cases. For example, the <a href="https://blogs.nvidia.com/blog/tensorrt-llm-inference-mlperf/">last MLPerf round</a> added tests using two generative AI models that didn’t even exist five years ago.</p>
<h2><b>A Gauge for Accelerated Computing</b></h2>
<p>Ideally, any new benchmarks should measure advances in<a href="https://blogs.nvidia.com/blog/what-is-accelerated-computing/"> accelerated computing</a>. This combination of parallel processing hardware, software and methods is running applications dramatically faster and more efficiently than CPUs across many modern workloads.</p>
<p>For example, on scientific applications, the Perlmutter supercomputer at the National Energy Research Scientific Computing Center <a href="https://blogs.nvidia.com/blog/gpu-energy-efficiency-nersc/">demonstrated</a> an average of 5x gains in energy efficiency using accelerated computing. That’s why it’s among the 39 of the top 50 supercomputers — including the No. 1 system — on<a href="https://www.top500.org/lists/green500/2023/11/"> the Green500 list</a> that use NVIDIA GPUs.</p>
<figure id="attachment_71555" aria-describedby="caption-attachment-71555" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/Power-over-time.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-71555" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Power-over-time-672x297.jpg" alt="Chart of GPU vs CPU energy efficiency" width="672" height="297" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/Power-over-time-672x297.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Power-over-time-400x177.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Power-over-time-768x340.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Power-over-time-842x373.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Power-over-time-406x180.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Power-over-time-188x83.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Power-over-time.jpg 1146w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71555" class="wp-caption-text">Because they execute lots of tasks in parallel, GPUs execute more work in less time than CPUs, saving energy.</figcaption></figure>
<p>Companies across many industries share similar results. For example, PayPal improved real-time fraud detection by 10% and <a href="https://developer.nvidia.com/blog/gpu-inference-momentum-continues-to-build/">lowered server energy consumption</a> nearly 8x with accelerated computing.</p>
<p>The gains are growing with each new generation of GPU hardware and software.</p>
<p>In a <a href="https://aiindex.stanford.edu/wp-content/uploads/2023/04/HAI_AI-Index-Report_2023.pdf">recent report</a>, Stanford University’s Human-Centered AI group estimated GPU performance “has increased roughly 7,000 times” since 2003, and price per performance is “5,600 times greater.”</p>
<figure id="attachment_71558" aria-describedby="caption-attachment-71558" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/Graph-of-data-center-benchmarks-scaled.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-71558" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Graph-of-data-center-benchmarks-672x377.jpg" alt="Chart depicts relationships among various data center energy efficiency graphics" width="672" height="377" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/Graph-of-data-center-benchmarks-672x377.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Graph-of-data-center-benchmarks-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Graph-of-data-center-benchmarks-768x431.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Graph-of-data-center-benchmarks-1536x863.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Graph-of-data-center-benchmarks-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Graph-of-data-center-benchmarks-801x450.jpg 801w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Graph-of-data-center-benchmarks-383x215.jpg 383w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Graph-of-data-center-benchmarks-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Graph-of-data-center-benchmarks-1280x719.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71558" class="wp-caption-text">Data centers need a suite of benchmarks to track energy efficiency across their major workloads.</figcaption></figure>
<h2><b>Two Experts Weigh In</b></h2>
<p>Experts see the need for a new energy-efficiency metric, too.</p>
<p>With today’s data centers achieving scores around 1.2 PUE, the metric “has run its course,” said Christian Belady, a data center engineer who had the original idea for PUE. “It improved data center efficiency when things were bad, but two decades later, they’re better, and we need to focus on other metrics more relevant to today’s problems.”</p>
<p>Looking forward, “the holy grail is a performance metric. You can’t compare different workloads directly, but if you segment by workloads, I think there is a better likelihood for success,” said Belady, who continues to work on initiatives driving data center sustainability.</p>
<p>Jonathan Koomey, a researcher and author on computer efficiency and sustainability, agreed.</p>
<p>“To make good decisions about efficiency, data center operators need a suite of benchmarks that measure the energy implications of today’s most widely used AI workloads,” said Koomey.</p>
<p>“Tokens per joule is a great example of what one element of such a suite might be,” Koomey added. “Companies will need to engage in open discussions, share information on the nuances of their own workloads and experiments, and agree to realistic test procedures to ensure these metrics accurately characterize energy use for hardware running real-world applications.”</p>
<p>“Finally, we need an open public forum to conduct this important work,” he said.</p>
<h2><b>It Takes a Village</b></h2>
<p>Thanks to metrics like PUE and rankings like the Green500, data centers and supercomputing centers have made enormous progress in energy efficiency.</p>
<p>More can and must be done to extend efficiency advances in the age of generative AI. Metrics of energy consumed doing useful work on today’s top applications can take supercomputing and data centers to a new level of energy efficiency.</p>
<p><i>To learn more about available energy-efficiency solutions, explore</i><a href="https://www.nvidia.com/en-us/data-center/sustainable-computing/"> <i>NVIDIA sustainable computing</i></a><i>.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/Concepts-for-a-data-cetner-energy-efficieicny-metric-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1091"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/Concepts-for-a-data-cetner-energy-efficieicny-metric-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Dial It In: Data Centers Need New Metric for Energy Efficiency]]></media:title>
			<media:description type="html">Concept image of data center energy efficiency metrics</media:description>
			</media:content>
			</item>
		<item>
		<title>Through the Wormhole: Media.Monks’ Vision for Enhancing Media and Marketing With AI</title>
		<link>https://blogs.nvidia.com/blog/media-monks-ai-podcast/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Thu, 09 May 2024 21:56:53 +0000</pubDate>
				<category><![CDATA[The AI Podcast]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71546</guid>

					<description><![CDATA[Meet Media.Monks’ Wormhole, an alien-like, conversational robot with a quirky personality and the ability to offer keen marketing expertise. Lewis Smithingham, senior vice president of innovation and special ops at Media.Monks, a global marketing and advertising company, discusses the creation of Wormhole and AI’s potential to enhance media and entertainment with host Noah Kravitz in		<a class="read-more" href="https://blogs.nvidia.com/blog/media-monks-ai-podcast/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Meet Media.Monks’ Wormhole, an alien-like, conversational robot with a quirky personality and the ability to offer keen marketing expertise. Lewis Smithingham, senior vice president of innovation and special ops at Media.Monks, a global marketing and advertising company, discusses the creation of Wormhole and AI’s potential to enhance media and entertainment with host Noah Kravitz in this <a href="https://soundcloud.com/theaipodcast">AI Podcast</a> episode recorded live at the <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a> global AI conference. Wormhole was designed to showcase Monks.Flow, an AI-powered platform that streamlines marketing and content creation workflows. Smithingham delves into Media.Monks’ platforms for media, entertainment and advertising and speaks to its vision for a future where AI enhances creativity and allows for more personalized, scalable content creation.</p>
<p>Stay tuned for more episodes recorded live from GTC, and hear more from Smithingham in this <a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-ep64041/">GTC interview</a>.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1816942410&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="Media.Monks’ Lewis Smithingham on Enhancing Media and Marketing With AI - Ep. 222" href="https://soundcloud.com/theaipodcast/mediamonks-lewis-smithingham" target="_blank" rel="noopener">Media.Monks’ Lewis Smithingham on Enhancing Media and Marketing With AI &#8211; Ep. 222</a></div>
<h2>Time Stamps</h2>
<p>1:45: What is Media.Monks?<br />
6:23: Description of Wormhole<br />
8:49: Possible use cases for Wormhole<br />
10:21: Takeaways from developing Wormhole<br />
12:02: What is Monks.Flow?<br />
16:54: Response from creatives on using AI in their work<br />
21:23: Smithingham’s outlook on hyperpersonalized content<br />
34:24: What’s next for the future of AI-powered media?</p>
<h2>You Might Also Like…</h2>
<p><a href="https://soundcloud.com/theaipodcast/pinar-demirdag-cuebric">Exploring Filmmaking With Cuebric’s AI: Insights From Pinar Seyhan Demirdag &#8211; Ep. 214</a></p>
<p>In today’s episode of NVIDIA’s AI Podcast, host Noah Kravitz talks with Pinar Seyhan Demirdag, co-founder and CEO of Cuebric. Cuebric is on a mission to offer new solutions in filmmaking and content creation through immersive, two-and-a-half-dimensional cinematic environments.</p>
<p><a href="https://soundcloud.com/theaipodcast/ai-deepdub">Deepdub’s Ofir Krakowski on Redefining Dubbing From Hollywood to Bollywood &#8211; Ep. 202</a></p>
<p>On the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Deepdub’s cofounder and CEO, Ofir Krakowski. Deepdub uses AI-driven dubbing to help entertainment companies boost efficiency and cut costs while increasing accessibility.</p>
<p><a href="https://soundcloud.com/theaipodcast/wsc-sports">WSC Sports’ Amos Bercovich on How AI Keeps the Sports Highlights Coming &#8211; Ep. 183</a></p>
<p>On this episode of the AI Podcast, host Noah Kravitz spoke with Amos Bercovich, algorithm group leader at WSC Sports, makers of an AI cloud platform that enables over 200 sports organizations worldwide to generate personalized and customized sports videos automatically and in real time.</p>
<p><a href="https://soundcloud.com/theaipodcast/maya-ackerman">Maya Ackerman on LyricStudio, an AI-Based Writing Songwriting Assistant &#8211; Ep. 153</a></p>
<p>Lennon and McCartney. Ashford and Simpson. Many of our all-time favorite tunes have come from songwriting duos. Now, anyone can find a snazzy compositional partner in AI. In this episode of the AI Podcast, Maya Ackerman, CEO of WaveAI, spoke with host Noah Kravtiz about WaveAI’s LyricStudio software, an AI-based lyric and poetry writing assistant.</p>
<h2>Subscribe to the AI Podcast</h2>
<p>Get the<a href="https://blogs.nvidia.com/ai-podcast/"> AI Podcast</a> through<a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439"> iTunes</a>,<a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjI2NDAzNDEzMy9zb3VuZHMucnNz"> Google Podcasts</a>,<a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm"> Google Play</a>, <a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">Amazon Music, </a><a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us">Castbox</a>, DoggCatcher,<a href="https://overcast.fm/itunes1186480811/the-ai-podcast"> Overcast</a>,<a href="https://player.fm/series/the-ai-podcast"> PlayerFM</a>, Pocket Casts,<a href="http://www.podbay.fm/show/1186480811"> Podbay</a>,<a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast"> PodBean</a>, PodCruncher, PodKicker,<a href="https://soundcloud.com/theaipodcast"> Soundcloud</a>,<a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L"> Spotify</a>,<a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr"> Stitcher</a> and<a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/"> TuneIn</a>.</p>
<p>Make the AI Podcast better: Have a few minutes to spare? Fill out<a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short"> this listener survey</a>.</p>
<p>&nbsp;</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2021/08/ai-podcast-2600x1472_-1-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1159"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2021/08/ai-podcast-2600x1472_-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Through the Wormhole: Media.Monks’ Vision for Enhancing Media and Marketing With AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>‘Honkai: Star Rail’ Blasts Off on GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-honkai-star-rail/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 09 May 2024 13:00:06 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71529</guid>

					<description><![CDATA[Gear up, Trailblazers — Honkai: Star Rail lands on GeForce NOW this week, along with an in-game reward for members to celebrate the title’s launch in the cloud. Stream it today, along with five new games joining the GeForce NOW library of more than 1,900 titles this week. Five Stars Take a galactic journey in		<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-honkai-star-rail/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Gear up, Trailblazers — <i>Honkai: Star Rail </i>lands on <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> this week, along with an in-game reward for members to celebrate the title’s launch in the cloud.</p>
<p>Stream it today, along with five new games joining the <a href="http://play.geforcenow.com">GeForce NOW library</a> of more than 1,900 titles this week.</p>
<h2><b>Five Stars</b></h2>
<p>Take a galactic journey in the cloud with <i>Honkai: Star Rail</i>, a new Cosmic Adventure Strategy role-playing game from HoYoverse, the company behind <i>Genshin Impact.</i> The title seamlessly blends intricate storytelling with immersive gameplay mechanics for an epic journey through the cosmos.</p>
<p>Meet a cast of unique characters and explore diverse planets, each with its own mysteries to uncover. Assemble formidable teams, strategically deploying skills and resources to overcome mighty adversaries and unravel the mysteries of the Honkai phenomenon. Encounter new civilizations and face off against threats that endanger the Astral Express, overcome the struggles caused by Stellaron together, powerful artifacts that hold the keys to the universe’s fate.</p>
<p>Begin the trailblazing journey without needing to wait for downloads or game updates with GeForce NOW. Members who’ve opted into <a href="https://www.nvidia.com/en-us/geforce-now/rewards/">GeForce NOW’s Rewards program</a> will receive an email with a code for a <i>Honkai: Star Rail</i> starter kit, containing 30,000 credits, three Refined Aethers and three Traveler’s Guides. All aboard the Astral Express for adventures and thrills!</p>
<h2><b>A Big Cloud for New Games </b></h2>
<figure id="attachment_71533" aria-describedby="caption-attachment-71533" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71533" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-little-kitty-big-city-tw-li-2048x1024-1-672x336.jpg" alt="Little Kitty Big City on GeForce MEOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-little-kitty-big-city-tw-li-2048x1024-1-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-little-kitty-big-city-tw-li-2048x1024-1-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-little-kitty-big-city-tw-li-2048x1024-1-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-little-kitty-big-city-tw-li-2048x1024-1-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-little-kitty-big-city-tw-li-2048x1024-1-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-little-kitty-big-city-tw-li-2048x1024-1-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-little-kitty-big-city-tw-li-2048x1024-1-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-little-kitty-big-city-tw-li-2048x1024-1-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-little-kitty-big-city-tw-li-2048x1024-1.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71533" class="wp-caption-text"><em>Stream it on GeForce MEOW.</em></figcaption></figure>
<p>Do what cats do best in <i>Little Kitty, Big City</i>, the open-world adventure game from Double Dagger Studios. Explore the city as a curious little kitty with a big personality, make new friends with stray animals, and wear delightful little hats. Create a little bit of chaos finding the way back home throughout the big city.</p>
<p>Here’s the full list of new games this week:</p>
<ul>
<li><i>Little Kitty, Big City </i>(New release on <a href="https://store.steampowered.com/app/1177980?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.xbox.com/games/store/little-kitty-big-city/9nf5s7mlm8xt?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass, May 9)</li>
<li><i>Farmer&#8217;s Life </i>(<a href="https://store.steampowered.com/app/1137750?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Honkai: Star Rail </i>(<a href="https://www.epicgames.com/store/p/honkai-star-rail?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Supermarket Simulator </i>(<a href="https://store.steampowered.com/app/2670630?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Tomb Raider: Definitive Edition</i> (<a href="https://www.xbox.com/games/store/tomb-raider-definitive-edition/bqxts0sx4w0n?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">what&#39;s the last game you 100% completed? <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f91d.png" alt="🤝" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1788237425837260837?ref_src=twsrc%5Etfw">May 8, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-thursday-5-9-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-thursday-5-9-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[‘Honkai: Star Rail’ Blasts Off on GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>&#8216;Get On the Train,&#8217; NVIDIA CEO Says at ServiceNow’s Knowledge 2024</title>
		<link>https://blogs.nvidia.com/blog/nvidia-servicenow-jensen-huang/</link>
		
		<dc:creator><![CDATA[Anne Hecht]]></dc:creator>
		<pubDate>Wed, 08 May 2024 18:28:41 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Software]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71490</guid>

					<description><![CDATA[Now’s the time to hop aboard AI, NVIDIA founder and CEO Jensen Huang declared Wednesday as ServiceNow unveiled a demo of futuristic AI avatars together with NVIDIA during a keynote at the Knowledge 24 conference in Las Vegas. &#8220;If something is moving a million times faster every 10 years, what should you do?” Huang asked,		<a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-servicenow-jensen-huang/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Now’s the time to hop aboard AI, NVIDIA founder and CEO Jensen Huang declared Wednesday as ServiceNow unveiled a demo of futuristic AI avatars together with NVIDIA during a keynote at the Knowledge 24 conference in Las Vegas.</p>
<p>&#8220;If something is moving a million times faster every 10 years, what should you do?” Huang asked, citing rapid advancements in AI capabilities. &#8220;The first thing you should do is instead of looking at the train, from the side is … get on the train, because on the train, it&#8217;s not moving that fast.”</p>
<p>The demo — built on NVIDIA NIM inference microservices and NVIDIA <a href="https://developer.nvidia.com/ace">Avatar Cloud Engine</a>, or ACE, speech and animation generative AI technologies, all available with <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> software — highlighted how AI advancements support cutting-edge digital avatar communications and have the potential to revolutionize customer service interactions.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-71521" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/servicenow3.jpg" alt="" width="1115" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/servicenow3.jpg 1115w, https://blogs.nvidia.com/wp-content/uploads/2024/05/servicenow3-400x179.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/servicenow3-672x301.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/servicenow3-768x344.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/servicenow3-842x378.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/05/servicenow3-406x182.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/servicenow3-188x84.jpg 188w" sizes="(max-width: 1115px) 100vw, 1115px" /></p>
<p>The demo showed a customer who was struggling with a slow internet connection interacting with a digital avatar. The AI customer service avatar comes to the rescue &#8211;  swiftly diagnoses the problem, offers an option for a faster internet connection, confirms the customer’s credit card number and upgrades their internet connection immediately.</p>
<p>The futuristic demonstration took place in front of thousands of conference attendees who were eager to learn about the latest enterprise generative AI technology advancements, which promise to empower workers across the globe.</p>
<p>&#8220;We&#8217;ve transitioned from instruction-driven computer coding, which very few people can do, to intention-driven computing, which is connecting with somebody through intention,&#8221; Huang said during an on-stage conversation at the conference with ServiceNow Chief Operating Officer Chirantan “CJ” Desai.</p>
<p>The moment is another compelling example of the ongoing collaboration between ServiceNow and NVIDIA to explore more engaging, personal service experiences across various functions, including IT services, human resources, customer support and more.</p>
<p>The demonstration builds upon the companies’ plan to collaborate on robust, generative AI capabilities within enterprise operations and incorporates NVIDIA <a href="https://developer.nvidia.com/ace">ACE</a> and <a href="https://www.nvidia.com/en-us/ai/">NVIDIA NIM</a> microservices.</p>
<p>These avatars are designed to add a human-like touch to digital interactions, improving customer experience by providing empathetic and efficient support.</p>
<p>These include NVIDIA Riva for automatic speech recognition and text-to-speech, NVIDIA Audio2Face for facial animation, and NVIDIA Omniverse Renderer for high-quality visual output.</p>
<p>ServiceNow and NVIDIA are further exploring the use of AI avatars to provide another communication option for users who prefer visual interactions.</p>
<p>&nbsp;</p>
<p><i>Visit </i><a href="https://knowledge.servicenow.com/flow/servicenow/k24/event/page/home"><i>this link</i></a><i> to watch a recording of Huang and Desai presenting the digital avatar demo at the Knowledge 24 keynote. </i></p>
<p>###END###</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/pano-stage-side.png"
			type="image/png"
			width="902"
			height="542"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/pano-stage-side-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[‘Get On the Train,’ NVIDIA CEO Says at ServiceNow’s Knowledge 2024]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI Decoded: New DaVinci Resolve Tools Bring RTX-Accelerated Renaissance to Editors</title>
		<link>https://blogs.nvidia.com/blog/ai-decoded-davinci-resolve/</link>
		
		<dc:creator><![CDATA[Jesse Clayton]]></dc:creator>
		<pubDate>Wed, 08 May 2024 13:00:56 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[AI Decoded]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71464</guid>

					<description><![CDATA[AI tools accelerated by NVIDIA RTX have made it easier than ever to edit and work with video. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>AI tools accelerated by <a href="https://www.nvidia.com/en-us/design-visualization/technologies/rtx/">NVIDIA RTX</a> have made it easier than ever to edit and work with video.</p>
<p>Case in point: Blackmagic Design’s <a href="https://www.blackmagicdesign.com/products/davinciresolve">DaVinci Resolve 19</a> recently added AI features that make video editing workflows more streamlined. These new features — along with all its other AI-powered effects — get a big boost from optimization for NVIDIA RTX PCs and workstations.</p>
<p>Editors use Blackmagic Design’s DaVinci Resolve — one of the leading nonlinear video editing platforms — to bring their creative vision to life, incorporating visual effects (VFX), color correction, motion graphics and more to their high-resolution footage and audio clips.</p>
<figure id="attachment_71468" aria-describedby="caption-attachment-71468" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/hollywood-md.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-71468" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/hollywood-md-672x313.jpg" alt="" width="672" height="313" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/hollywood-md-672x313.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/hollywood-md-400x186.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/hollywood-md-768x357.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/hollywood-md-842x392.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/05/hollywood-md-406x189.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/hollywood-md-188x87.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/05/hollywood-md-1280x596.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/05/hollywood-md.jpg 1440w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71468" class="wp-caption-text">DaVinci Resolve’s new AI tools accelerated by RTX unlock endless possibilities.</figcaption></figure>
<p>Resolve includes a large variety of built-in tools. Some are corrective in nature, letting editors match colors from two sets of footage, reframe footage after the fact or remove objects that weren’t meant to be in a shot. Others give editors the power to manipulate footage and audio in new ways, including smooth slow-motion effects and footage upscaling.</p>
<p>In the past, many of these tools required significant time and effort from users to implement. Resolve now uses AI acceleration to speed up many of these workflows, leaving more time for users to focus on creativity rather than batch processing.</p>
<p>Even better, the entire app is optimized for <a href="https://developer.nvidia.com/tensorrt">NVIDIA TensorRT</a> deep learning inference software to get the best performance from GPU-reliant effects and other features, boosting performance by 2x.</p>
<h2><b>New in Resolve 19</b></h2>
<p>The newest release, <a href="https://www.blackmagicdesign.com/products/davinciresolve/whatsnew">DaVinci Resolve 19</a>, adds two new AI features that make video editing more efficient: the IntelliTrack AI point tracker for object tracking, stabilization and audio panning, and UltraNR, which uses AI for spatial noise reduction.</p>
<p>IntelliTrack AI makes it easy to stabilize footage during the editing process. It can also be used in Resolve’s Fairlight tool to track on-screen subjects, and automatically generate audio panning within a scene by tracking people or objects as they move across 2D and 3D spaces. With AI audio panning to video, editors can quickly pan, or move audio across the stereo field, multiple actors in a scene, controlling their voice positions in the mix environment. All of this can be done by hand, but IntelliTrack’s AI acceleration speeds up the entire process.</p>
<p><iframe loading="lazy" title="How to use IntelliTrack Tracking in DaVinci Resolve 19" width="500" height="281" src="https://www.youtube.com/embed/rXsKkY_Mkb4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>UltraNR is an AI-accelerated denoise mode in Resolve’s spatial noise reduction palette. Editors can use it to dramatically reduce digital noise — undesired fluctuations of color or luminance that obscure detail — from a frame while maintaining image clarity. They can also combine the tool with temporal noise reduction for even more effective denoising in images with motion, where fluctuations can be more noticeable.</p>
<p><iframe loading="lazy" title="DAVINCI RESOLVE 19!! What&#039;s NEW?! You won&#039;t want to miss this!" width="500" height="281" src="https://www.youtube.com/embed/T8ENuSsScDA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Both IntelliTrack and UltraNR get a big boost when running on NVIDIA RTX PCs and workstations. TensorRT lets them run up to 3x faster on a GeForce GTX 4090 laptop vs. the Macbook Pro M3 Max.</p>
<p>In fact, all DaVinci Resolve AI effects are accelerated on RTX GPUs by NVIDIA TensorRT. The new Resolve update also includes GPU acceleration for Beauty, Edge Detect and Watercolor effects, doubling their performance on NVIDIA GPUs.</p>
<p>Find out more about DaVinci Resolve 19, and try it yourself for free, at <a href="https://www.blackmagicdesign.com/products/davinciresolve">Blackmagic Design</a>.</p>
<p>Learn how AI is supercharging creativity, and how to get the most from your own creative process, with <a href="https://www.nvidia.com/en-us/studio/">NVIDIA Studio</a>.</p>
<p><i>Generative AI is transforming gaming, videoconferencing and interactive experiences of all kinds. Make sense of what’s new and what’s next by subscribing to the </i><a href="https://www.nvidia.com/en-us/ai-on-rtx/?modal=subscribe-ai"><i>AI Decoded newsletter</i></a><i>.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/davinci-resolve-19-ai-nv-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/davinci-resolve-19-ai-nv-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI Decoded: New DaVinci Resolve Tools Bring RTX-Accelerated Renaissance to Editors]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA CEO Jensen Huang to Deliver Keynote Ahead of COMPUTEX 2024</title>
		<link>https://blogs.nvidia.com/blog/huang-computex-keynote-taipei-2024/</link>
		
		<dc:creator><![CDATA[Claudia Cook]]></dc:creator>
		<pubDate>Wed, 08 May 2024 13:00:32 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71477</guid>

					<description><![CDATA[Amid an AI revolution sweeping through trillion-dollar industries worldwide, NVIDIA founder and CEO Jensen Huang will deliver a keynote address ahead of COMPUTEX 2024, in Taipei, outlining what’s next for the AI ecosystem. Slated for June 2 at the National Taiwan University Sports Center, the address kicks off before the COMPUTEX trade show scheduled to		<a class="read-more" href="https://blogs.nvidia.com/blog/huang-computex-keynote-taipei-2024/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Amid an AI revolution sweeping through trillion-dollar industries worldwide, NVIDIA founder and CEO Jensen Huang will deliver a <a href="https://www.nvidia.com/en-us/events/computex/">keynote address</a> ahead of COMPUTEX 2024, in Taipei, outlining what’s next for the AI ecosystem.</p>
<p>Slated for June 2 at the National Taiwan University Sports Center, the address kicks off before the COMPUTEX trade show scheduled to run from June 3-6 at the Taipei Nangang Exhibition Center.</p>
<p>The keynote will be livestreamed at 7 p.m. Taiwan time (4 a.m. PT) on Sunday, June 2, with a replay available at NVIDIA.com.</p>
<p>With over 1,500 exhibitors from 26 countries and an expected crowd of 50,000 attendees, COMPUTEX is one of the world’s premier technology events.</p>
<p>It has long showcased the vibrant technology ecosystem anchored by Taiwan and has become a launching pad for the cutting-edge systems required to scale AI globally.</p>
<p>As a leader in AI, NVIDIA continues to nurture and expand the AI ecosystem. Last year, Huang’s keynote and appearances in partner press conferences exemplified NVIDIA’s role in helping advance partners across the technology industry.</p>
<p>These partners will be out in force this year.</p>
<p>NVIDIA’s partners, including Acer, ASUS, Asrock Rack, Colorful, GIGABYTE, Ingrasys, Inno3D, Inventec, MSI, Palit, Pegatron, PNY, QCT, Supermicro, Wistron, Wiwynn and Zotac will spotlight new products featuring NVIDIA technology.</p>
<p>In addition to the exhibition and demonstrations, Marc Hamilton, vice president of solutions architecture and engineering at NVIDIA, will take the stage at the TAITRA forum, a key segment of COMPUTEX dedicated to cutting-edge discussions in technology.</p>
<p>As part of the “Let’s Talk Generative AI” forum, Hamilton will present his talk, titled “Infra Build Train Go,” on June 5, from 10-10:30 a.m. at the 701 Conference Room, 7F, Taipei Nangang Exhibition Center Hall 2.</p>
<h2>NVIDIA AI Summit</h2>
<p>Following the keynote, the <a href="https://www.nvidia.com/en-us/events/ai-summit/">NVIDIA AI Summit</a> on June 5 at the Grand Hilai Taipei will delve into the practical applications of AI in manufacturing, healthcare, research and more.</p>
<p>The summit will feature over 20 sessions from industry experts and innovators as well as training sessions for developers. Kimberly Powell, vice president of healthcare and life sciences at NVIDIA, will host a special address on how generative AI is advancing the healthcare technology industry.</p>
<p>Register for the <a href="https://www.nvidia.com/en-us/events/computex/">AI Summit</a>.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/AdobeStock_15780017-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1366"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/AdobeStock_15780017-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA CEO Jensen Huang to Deliver Keynote Ahead of COMPUTEX 2024]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA DGX SuperPOD to Power US Government Generative AI</title>
		<link>https://blogs.nvidia.com/blog/dgx-superpod-us-government-generative-ai/</link>
		
		<dc:creator><![CDATA[Meg King]]></dc:creator>
		<pubDate>Tue, 07 May 2024 17:00:03 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[NVIDIA DGX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71458</guid>

					<description><![CDATA[In support of President Biden’s executive order on AI, the U.S. government will use an NVIDIA DGX SuperPOD to produce generative AI advances in climate science, healthcare and cybersecurity. The executive order, issued in October, is aimed at ensuring U.S. leadership in AI and managing its risks. MITRE, a nonprofit organization that operates federally funded		<a class="read-more" href="https://blogs.nvidia.com/blog/dgx-superpod-us-government-generative-ai/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>In support of President Biden’s executive order on AI, the U.S. government will use an NVIDIA DGX SuperPOD to produce generative AI advances in climate science, healthcare and cybersecurity.</p>
<p>The executive order, issued in October, is aimed at ensuring U.S. leadership in AI and managing its risks. MITRE, a nonprofit organization that operates federally funded research and development centers, is implementing a new <a href="https://www.nvidia.com/en-us/data-center/dgx-superpod/">NVIDIA DGX SuperPOD</a> system that will provide researchers and developers access to massive computing leaps.</p>
<p>The DGX SuperPOD will support MITRE’s Federal AI Sandbox, a platform to improve experimentation with next-generation, AI-enabled applications across federal government agencies.</p>
<p>“The recent executive order on AI encourages federal agencies to reduce barriers for AI adoptions, but agencies often lack the computing environment necessary for experimentation and prototyping,” said Charles Clancy, senior vice president and chief technology officer at MITRE. “Our new Federal AI Sandbox will help level the playing field, making the high-quality compute power needed to train and test custom AI solutions available to any agency.”</p>
<p>The Federal AI Sandbox will deliver federal agencies the computing gains needed to train large language models and other generative AI tools to develop cutting-edge applications.</p>
<p>The NVIDIA DGX SuperPOD powering the sandbox is capable of an exaFLOP of AI performance to enable researchers and developers to train and deploy custom LLMs and other AI solutions at scale.</p>
<p>“MITRE’s purchase of a DGX SuperPOD will help turbocharge the U.S. federal government’s development of its AI initiatives,” said Anthony Robbins, vice president of public sector at NVIDIA. “AI has enormous potential to improve government services for citizens and solve big challenges, like transportation and cybersecurity.”</p>
<p>The supercomputing initiative comes as the White House <a href="https://blogs.nvidia.com/blog/partnership-universities-teach-ai-skills/">recently unveiled plans</a>, which include NVIDIA, for a $110 million partnership to help universities teach AI skills.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/david-everett-strickler-igCBFrMd11I-unsplash.jpg"
			type="image/jpeg"
			width="1920"
			height="1250"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/david-everett-strickler-igCBFrMd11I-unsplash-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA DGX SuperPOD to Power US Government Generative AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>A Mighty Meeting: Generative AI, Cybersecurity Connect at RSA</title>
		<link>https://blogs.nvidia.com/blog/rsa-2024-ai-cybersecurity/</link>
		
		<dc:creator><![CDATA[Summer Liu]]></dc:creator>
		<pubDate>Mon, 06 May 2024 15:00:48 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cybersecurity]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[NVIDIA BlueField]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71415</guid>

					<description><![CDATA[Cybersecurity experts at the RSA Conference this week will be on the hunt for ways to secure their operations in the era of generative AI. They’ll find many of the latest tools use AI and accelerated computing. This intersection of security and AI is coming into focus with collaborations that companies like NVIDIA and its		<a class="read-more" href="https://blogs.nvidia.com/blog/rsa-2024-ai-cybersecurity/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Cybersecurity experts at the <a href="https://www.nvidia.com/en-us/events/rsa-conference/">RSA Conference</a> this week will be on the hunt for ways to secure their operations in the era of <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a>.</p>
<p>They’ll find many of the latest tools use AI and <a href="https://blogs.nvidia.com/blog/what-is-accelerated-computing/">accelerated computing</a>. This intersection of security and AI is coming into focus with collaborations that companies like NVIDIA and its partners will describe at the event.</p>
<h2><b>Data Science for a Data Problem</b></h2>
<p>Machine learning is a great tool for cybersecurity because data is exploding.</p>
<p>“With more devices and users expanding the landscape to defend, cybersecurity has become a data problem; and AI is a data solution,” said David Reber, NVIDIA’s chief security officer.</p>
<p>Today, security analysts can be overwhelmed by a data tsunami. Generative AI can provide security copilots that act like filters, extracting from the firehose flow of information the context and anomalies that need a human expert’s attention.</p>
<p>Generative AI also lets security managers interrogate their data directly instead of setting rules, chasing alerts and tracking dashboards. In the age of AI, security experts will move from a command line to a conversational interface.</p>
<h2><b>AI Puts Security Context on Steroids</b></h2>
<p>This shift takes context-based security to a new level, according to <a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62433/">a talk</a> Reber delivered at GTC.</p>
<p>The potential is huge, but it requires work to unearth it. At GTC, Reber encouraged cybersecurity experts to begin working with AI, starting with low-risk use cases to identify and secure gaps.</p>
<p>He also provided suggestions for how to go about securing machine learning processes, saying security experts need to:</p>
<ul>
<li>secure data supply chains,</li>
<li>develop tests for securing AI models and datasets across the development lifecycle,</li>
<li>use model cards, data cards and software bills of materials to provide AI transparency and reliability,</li>
<li>participate in community testing events such as security hackathons, and</li>
<li>update policies on how to respond to AI security events.</li>
</ul>
<h2><b>Foundations for AI Cybersecurity</b></h2>
<p>To give users a leg up, NVIDIA provides <a href="https://developer.nvidia.com/morpheus-cybersecurity">NVIDIA Morpheus</a>, a cybersecurity AI framework that filters and classifies large volumes of real-time data. Morpheus, part of the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> software suite, lets developers build applications that can detect spear phishing, insider threats and more.</p>
<p>Users can employ Morpheus with <a href="https://www.nvidia.com/en-us/ai/">NVIDIA NIM</a> and <a href="https://developer.nvidia.com/blog/translate-your-enterprise-data-into-actionable-insights-with-nvidia-nemo-retriever/">NeMo Retriever</a>, microservices from the <a href="https://build.nvidia.com/explore/discover">NVIDIA API Catalog</a> for rapidly deploying AI. The combination can unlock new use cases, such as reducing from days to seconds the time to find and resolve <a href="https://www.nvidia.com/en-us/ai-data-science/ai-workflows/security-vulnerability-analysis">common software vulnerabilities and exposures</a>, one of many <a href="https://www.nvidia.com/en-us/ai-data-science/ai-workflows/">NVIDIA AI workflows</a>.</p>
<p>A new release of <a href="https://developer.nvidia.com/networking/doca">NVIDIA DOCA</a> — the software framework for programming <a href="https://www.nvidia.com/en-us/networking/products/data-processing-unit/">NVIDIA BlueField DPUs</a> and <a href="https://www.nvidia.com/en-us/networking/ethernet-adapters/">NVIDIA ConnectX NICs</a> — provides another foundation for AI security. It now sports updated encryption features for network and storage data.</p>
<h2><b>An Expanding AI Security Ecosystem</b></h2>
<p>At RSA, many companies will show products built on NVIDIA technologies that extend security for the generative AI era, including:</p>
<ul>
<li>AIC will demonstrate Qrypt’s key generation for quantum secure encryption running on a BlueField DPU in an AIC-designed server.</li>
<li>Anjuna will discuss how the U.S. Navy is evaluating <a href="https://www.nvidia.com/en-us/data-center/solutions/confidential-computing/">confidential computing</a> on the Anjuna Seaglass platform with proprietary LLMs running on <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100 Tensor Core GPUs</a>.</li>
<li>Bloombase will show an updated version of its StoreSafe Storage Firewall powered by Morpheus and BlueField DPUs and new use cases for threat detection and fast, quantum-safe encryption of AI models and data.</li>
<li>Check Point Software will show its AI Cloud Protect security solution on BlueField DPUs, Quantum Force security gateways on ConnectX NICs, and Quantum Maestro software on <a href="https://www.nvidia.com/en-us/networking/products/ethernet/">NVIDIA Spectrum</a> switches.</li>
<li>Cisco will feature Cisco Hypershield, an AI-native security architecture, to protect against both known and unknown attacks. It will also discuss its expanding partnership with NVIDIA to help customers harness the power of AI.</li>
<li>CrowdStrike will show its CrowdStrike Falcon Foundry and CrowdStrike Falcon platform that employs NVIDIA’s GPU-optimized AI software, including NIM microservices.</li>
<li>Deloitte will showcase CyberSphere, a cyber operations platform that uses Morpheus to speed detection of cyber threats.</li>
<li>Palo Alto Networks will describe its collaboration with NVIDIA on two use cases, a next-generation reference architecture for securing generative AI deployments with NIM and its VM-Series Virtual Next-Generation Firewall, with <a href="https://developer.nvidia.com/blog/intelligent-traffic-offload-with-enhanced-ai-powered-5g-security-for-enterprises/">expanded intelligent traffic offload (ITO)</a>, supporting BlueField-3 DPUs.</li>
<li>Qrypt will demonstrate its quantum-secure key generation for securing AI workloads running on BlueField-3 DPUs using DOCA.</li>
<li>Sygnia will announce the use of BlueField DPUs and Morpheus in Velocity Edge, its new hardware-accelerated MXDR service for the energy and industrial sectors.</li>
</ul>
<p>They are part of the NVIDIA ecosystem building a new layer of security for generative AI. That community includes more than 20 companies at RSA this week from <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a>, a program for cutting-edge startups.</p>
<p>At RSA, Daniel Rohrer, vice president of software product security at NVIDIA, will be part of the keynote panel on <a href="https://www.rsaconference.com/usa/agenda/session/AI-Safety-Wheres-the-Puck-Headed">AI safety</a>.</p>
<p>In addition, Kevin Deierling, senior vice president of networking at NVIDIA, will share insights on security at the <a href="https://cloudflaresupperclubrsac.splashthat.com/">Cloudflare Executive Supper Club</a>. And NVIDIA will participate in <a href="https://thefemalequotient.equalitylounge.com/rsa-conference-2024">an event</a> about women in cybersecurity.</p>
<p>To get started with AI-powered cybersecurity, try a workflow in <a href="https://www.nvidia.com/en-us/launchpad/cybersecurity/">NVIDIA LaunchPad</a>.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/NVD4-1-cybersecurity-paid-morpheus-li-1080x1080-2525154.jpg"
			type="image/jpeg"
			width="1280"
			height="678"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/NVD4-1-cybersecurity-paid-morpheus-li-1080x1080-2525154-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[A Mighty Meeting: Generative AI, Cybersecurity Connect at RSA]]></media:title>
			<media:description type="html">Image representing AI cybersecurity with NVIDIA Morpheus</media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA and Alphabet’s Intrinsic Put Next-Gen Robotics Within Grasp</title>
		<link>https://blogs.nvidia.com/blog/alphabet-intrinsic-robotics-isaac-manipulator/</link>
		
		<dc:creator><![CDATA[Gerard Andrews]]></dc:creator>
		<pubDate>Mon, 06 May 2024 15:00:15 +0000</pubDate>
				<category><![CDATA[Robotics]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Embedded Computing]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[Isaac]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71426</guid>

					<description><![CDATA[Intrinsic, a software and AI robotics company at Alphabet, has integrated NVIDIA AI and Isaac platform technologies to advance the complex field of autonomous robotic manipulation. This week at the Automate trade show, in Chicago, Intrinsic is spotlighting leaps in robotic grasping and industrial scalability assisted by foundation models enabled by NVIDIA Isaac Manipulator, unlocking		<a class="read-more" href="https://blogs.nvidia.com/blog/alphabet-intrinsic-robotics-isaac-manipulator/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Intrinsic, a software and AI robotics company at Alphabet, has integrated NVIDIA AI and Isaac platform technologies to advance the complex field of autonomous robotic manipulation.</p>
<p>This week at the Automate trade show, in Chicago, Intrinsic is spotlighting leaps in robotic grasping and industrial scalability assisted by foundation models enabled by NVIDIA Isaac Manipulator, unlocking new value in industrial automation with AI.</p>
<p>NVIDIA <a href="https://blogs.nvidia.com/blog/isaac-generative-ai-manufacturing-logistics/">unveiled Isaac Manipulator</a> at GTC in March. <a href="https://developer.nvidia.com/isaac/manipulator">Isaac Manipulator</a> is a collection of foundation models and modular GPU-accelerated libraries that help industrial automation companies build scalable and repeatable workflows for dynamic manipulation tasks by accelerating AI model training and task reprogramming.</p>
<p><a href="https://blogs.nvidia.com/blog/what-are-foundation-models/#:~:text=Foundation%20models%20are%20AI%20neural,text%20to%20analyzing%20medical%20images.">Foundation models</a> are based on a <a href="https://blogs.nvidia.com/blog/what-is-a-transformer-model/">transformer</a> deep learning architecture that allows a neural network to learn by tracking relationships in data. They’re generally trained on huge datasets and can be used to process and understand sensor and robot information as magically as ChatGPT for text. This enables robot perception and decision-making like never before and provides zero-shot learning — the ability to perform tasks without prior examples.</p>
<p>NVIDIA’s collaboration with Intrinsic, a leading robotics software and AI company,  <a href="https://developer.nvidia.com/blog/automating-smart-pick-and-place-with-intrinsic-flowstate-and-nvidia-isaac-manipulator/">demonstrates the potential</a> for a universally applicable robotic-grasping skill to work across grippers, environments and objects.</p>
<p>“For the broader industry, our work with NVIDIA shows how foundation models can have a profound impact, including making today&#8217;s processing challenges easier to manage at scale, creating previously infeasible applications, reducing development costs, and increasing flexibility for end users,” said Wendy Tan White, CEO at Intrinsic, <a href="http://www.intrinsic.ai/blog/unlocking-new-value-in-industrial-automation-with-ai">in a blog post</a> announcing the collaboration with NVIDIA.  (White will deliver a keynote address at Automate about what the rise of AI means for innovation and growth, on Thursday, May 9, at 7 a.m. PT.)</p>
<h2><b>Developing Better Robot Grip With Isaac Manipulator</b></h2>
<p>Grasping has been a long sought after robotics skill. So far it’s been time-consuming, expensive to program and difficult to scale. As a result, many repetitive pick-and-place conditions haven’t been seamlessly handled to date by robots.</p>
<p>Simulation is changing that. Enlisting <a href="https://developer.nvidia.com/isaac/sim">NVIDIA Isaac Sim</a> on the <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> platform, Intrinsic generated <a href="https://www.nvidia.com/en-us/use-cases/synthetic-data/">synthetic data</a> for vacuum grasping using computer-aided design models of sheet metal and suction grippers. This allowed Intrinsic to create a prototype for its customer <a href="https://www.trumpf.com/en_US/products/machines-systems/">Trumpf Machine Tools</a>, a leading maker of industrial machine tools.</p>
<p><iframe loading="lazy" title="Smart Pick-and-Place in NVIDIA Isaac Sim" width="500" height="281" src="https://www.youtube.com/embed/paLR6-hjlT8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>The prototype uses Intrinsic <a href="https://intrinsic.ai/flowstate/">Flowstate</a>, a developer environment for AI-based robotics solutions, for visualizing processes, associated perception and motion planning. With a workflow that includes Isaac Manipulator, one can generate grasp poses and CUDA-accelerated robot motions, which can first be evaluated in simulation with Isaac Sim — a cost-saving step — before deployment in the real world with the Intrinsic platform.</p>
<p>Under the collaboration, NVIDIA and Intrinsic plan to bring state-of-the-art dexterity and modular AI capabilities for robotic arms, with a robust collection of foundation models and GPU-accelerated libraries to accelerate a greater number of new robotics and automation tasks.</p>
<p><iframe loading="lazy" title="Grasping skill, based on an Nvidia foundation model, used in Intrinsic Flowstate" width="500" height="281" src="https://www.youtube.com/embed/9j9G8yEXI_g?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p><i>On Tuesday, May 7, at 11 a.m. CT, NVIDIA Senior Research Scientist Adithya Murali and Intrinsic Chief Science Officer Torsten Kroeger will demonstrate the companies’ work in the session “Automating Smart Pick-and-Place With Intrinsic Flowstate and NVIDIA Isaac Manipulator ” in the Intrinsic booth 2808 at Automate. </i><i>Join  our </i><a href="https://www.nvidia.com/en-us/events/automate-conference/"><i>speaking sessions</i></a><i> at Automate. </i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/Automate-Blog-Key-Image.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/Automate-Blog-Key-Image-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA and Alphabet’s Intrinsic Put Next-Gen Robotics Within Grasp]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA AI Microservices for Drug Discovery, Digital Health Now Integrated With AWS</title>
		<link>https://blogs.nvidia.com/blog/nim-ai-microservices-for-healthcare-integrate-with-aws/</link>
		
		<dc:creator><![CDATA[Lyndi Wu]]></dc:creator>
		<pubDate>Thu, 02 May 2024 13:30:03 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Genomics]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[NVIDIA Clara]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71408</guid>

					<description><![CDATA[Harnessing optimized AI models for healthcare is easier than ever as NVIDIA NIM, a collection of cloud-native microservices, integrates with Amazon Web Services. NIM, part of the NVIDIA AI Enterprise software platform available on AWS Marketplace, enables developers to access a growing library of AI models through industry-standard application programming interfaces, or APIs. The library		<a class="read-more" href="https://blogs.nvidia.com/blog/nim-ai-microservices-for-healthcare-integrate-with-aws/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Harnessing optimized AI models for healthcare is easier than ever as <a href="https://www.nvidia.com/en-us/ai/">NVIDIA NIM</a>, a collection of cloud-native microservices, integrates with Amazon Web Services.</p>
<p><a href="http://ai.nvidia.com/">NIM</a>, part of the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> software platform available on <a href="https://aws.amazon.com/marketplace/pp/prodview-ozgjkov6vq3l6" target="_blank" rel="noopener">AWS Marketplace</a>, enables developers to access a growing library of AI models through industry-standard application programming interfaces, or APIs. The library includes <a href="https://blogs.nvidia.com/blog/what-are-foundation-models/">foundation models</a> for drug discovery, medical imaging and genomics, backed by enterprise-grade security and support.</p>
<p>NIM is now available via Amazon SageMaker — a fully managed service to prepare data and build, train and deploy machine learning models — and AWS ParallelCluster, an open-source tool to deploy and manage high performance computing clusters on AWS. NIMs can also be orchestrated using AWS HealthOmics, a purpose-built service for biological data analysis.</p>
<p>Easy access to NIM will enable the thousands of healthcare and life sciences companies already using AWS to deploy <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> more quickly, without the complexities of model development and packaging for production. It’ll also help developers build workflows that combine AI models across different modalities, such as amino acid sequences, MRI images and plain-text patient health records.</p>
<p>Presented today at the <a href="https://pages.awscloud.com/NAMER-event-T3-AWS-Life-Science-Symposium-2024-reg-event.html" target="_blank" rel="noopener">AWS Life Sciences Leader Symposium</a> in Boston, this initiative extends the availability of <a href="https://www.nvidia.com/en-us/clara/">NVIDIA Clara</a> accelerated healthcare software and services on AWS — which include fast and easy-to-deploy NIMs from <a href="https://www.nvidia.com/en-us/clara/bionemo/">NVIDIA BioNeMo</a> for drug discovery, <a href="https://www.nvidia.com/en-us/clara/monai/">NVIDIA MONAI</a> for medical imaging workflows and <a href="https://www.nvidia.com/en-us/clara/genomics/">NVIDIA Parabricks</a> for accelerated genomics.</p>
<h2><b>Pharma and Biotech Companies Adopt NVIDIA AI on AWS</b></h2>
<p><a href="https://www.nvidia.com/en-us/clara/bionemo/">BioNeMo</a> is a generative AI platform of foundation models, training frameworks, domain-specific data loaders and optimized training recipes​ that support the training and fine-tuning of biology and chemistry models on proprietary data.​ It’s used by more than 100 organizations globally.</p>
<p><a href="https://blogs.nvidia.com/blog/genomics-ai-amgen-superpod/">Amgen</a>, one of the world’s leading biotechnology companies, has used the BioNeMo framework to train generative models for protein design, and is exploring the potential use of BioNeMo with AWS.</p>
<p><i>​</i>BioNeMo models for protein structure prediction, generative chemistry and molecular docking prediction are available as NIM microservices, <a href="https://blogs.nvidia.com/blog/what-is-a-pretrained-ai-model/">pretrained</a> and optimized to run on any NVIDIA GPU or cluster of GPUs. These models can be combined to support a holistic, AI-accelerated drug discovery workflow.</p>
<p>Biotechnology company A-Alpha Bio harnesses synthetic biology and AI to measure, predict and engineer protein-to-protein interactions. When its researchers moved from a generic version of the ESM-2 protein language model to <a href="https://docs.nvidia.com/bionemo-framework/latest/models/esm2-nv.html">a version optimized by NVIDIA</a> running on <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100 Tensor Core GPUs</a> on AWS, they immediately saw a speedup of more than 10x. This lets the team sample a much more extensive field of protein candidates than they would have otherwise.</p>
<p>For organizations that want to augment these models with their own experimental data, NIM enables developers to <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">enhance a model with retrieval-augmented generation, or RAG</a> — known as a lab-in-the-loop design.</p>
<h2><b>Parabricks Enables Accelerated Genomics Pipelines</b></h2>
<p>NVIDIA NIM includes genomics models from NVIDIA Parabricks, which are also <a href="https://aws.amazon.com/blogs/industries/easily-run-nvidia-parabricks-ready2run-workflows-on-amazon-omics/" target="_blank" rel="noopener">available on AWS HealthOmics</a> as Ready2Run workflows that enable customers to deploy pre-built pipelines.</p>
<p>Life sciences company Agilent used Parabricks genomics analysis tools running on NVIDIA GPU-powered <a href="https://aws.amazon.com/ec2/pricing/" target="_blank" rel="noopener">Amazon Elastic Compute Cloud (EC2) instances</a> to significantly improve processing speeds for variant calling workflows on the company’s cloud-native <a href="https://www.agilent.com/en/product/next-generation-sequencing/clinical-informatics-platform/alissa-reporter-1947792" target="_blank" rel="noopener">Alissa Reporter</a> software. Integrating Parabricks with Alissa secondary analysis pipelines enables researchers to access rapid data analysis in a secure cloud environment.​</p>
<h2><b>Conversational AI Technology Supports Digital Health</b></h2>
<p>In addition to models that can decode proteins and genomic sequences, NIM microservices offer optimized <a href="https://www.nvidia.com/en-us/glossary/large-language-models/">large language models</a> for conversational AI and visual generative AI models for avatars and digital humans.</p>
<p>AI-powered digital assistants can enhance healthcare by answering patient questions and supporting clinicians with logistics. Trained on healthcare organization-specific data using RAG, they could connect to relevant internal data sources to synthesize research, surface insights and improve productivity.</p>
<p>Generative AI startup <a href="https://www.globenewswire.com/news-release/2024/03/18/2848236/0/en/Hippocratic-AI-Announces-Collaboration-with-NVIDIA-to-Develop-Super-Low-Latency-Empathy-Inference-for-One-of-the-World-s-First-Generative-AI-Powered-Healthcare-Agents.html" target="_blank" rel="noopener">Hippocratic AI</a> is in the final stages of testing AI-powered healthcare agents that focus on a wide range of tasks including wellness coaching, preoperative outreach and post-discharge follow-up.</p>
<p>The company, which uses NVIDIA GPUs through AWS, is adopting NVIDIA NIM and <a href="https://developer.nvidia.com/ace">NVIDIA ACE</a> microservices to power a generative AI agent for digital health.</p>
<p><iframe loading="lazy" title="Always Available, Real-Time Generative AI Healthcare Agents" width="500" height="281" src="https://www.youtube.com/embed/yg0m8eR7k24?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>The team used <a href="https://www.nvidia.com/en-us/ai-data-science/audio2face/">NVIDIA Audio2Face</a> facial animation technology, <a href="https://www.nvidia.com/en-us/ai-data-science/products/riva/">NVIDIA Riva</a> automatic speech recognition and text-to-speech capabilities, and more to power a healthcare assistant avatar’s conversation.</p>
<p>Experiment with <a href="https://build.nvidia.com/explore/healthcare">NVIDIA NIMs for healthcare</a> and get started with <a href="https://aws.amazon.com/nvidia/hcls/" target="_blank" rel="noopener">NVIDIA Clara on AWS</a>.</p>
<p><a href="https://www.nvidia.com/en-us/industries/healthcare-life-sciences/healthcare-news-sign-up/"><i>Subscribe to NVIDIA healthcare news</i></a><i>. </i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/image-17.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/image-17-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA AI Microservices for Drug Discovery, Digital Health Now Integrated With AWS]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>GeForce NOW Delivers 24 A-May-zing Games This Month</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-may-games-list/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 02 May 2024 13:00:24 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71370</guid>

					<description><![CDATA[GeForce NOW brings 24 new games for members this month. Ninja Theory’s highly anticipated Senua’s Saga: Hellblade II will be coming to the cloud soon — get ready by streaming the first in the series, Hellblade: Senua’s Sacrifice, part of the seven new games joining the GeForce NOW library this week. Plus, game across more		<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-may-games-list/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> brings 24 new games for members this month.</p>
<p>Ninja Theory’s highly anticipated <i>Senua’s Saga: Hellblade II</i> will be coming to the cloud soon — get ready by streaming the first in the series, <i>Hellblade: Senua’s Sacrifice, </i>part of the seven new games joining the <a href="http://play.geforcenow.com">GeForce NOW library</a> this week.</p>
<p>Plus, game across more devices than ever as GeForce NOW adds improved support on Steam Deck this GFN Thursday.</p>
<h2><b>Journey into Viking Hell</b></h2>
<figure id="attachment_71374" aria-describedby="caption-attachment-71374" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-71374 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-672x378.png" alt="Hellblade 1 on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-1280x720.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1.png 1920w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71374" class="wp-caption-text"><em>No sacrificing frame rates, streaming from the cloud.</em></figcaption></figure>
<p>Experience exceptional storytelling in Ninja Theory’s award-winning game <i>Hellblade: Senua’s Sacrifice</i>, available to stream from the cloud this week.</p>
<p>Set in a dark fantasy world inspired by Norse mythology and Celtic culture, the game follows the journey of Senua, a Pict warrior. Her quest is to reach Helheim, the realm of the dead,to rescue her deceased lover’s soul from the goddess Hela.</p>
<p>Solve intricate puzzles with observation, engage in melee combat and get pulled deep into Senua’s mind as she grapples with inner demons. Journey through the hauntingly beautiful landscapes of Helheim with ray tracing and high-dynamic range using an <a href="http://geforcenow.com">Ultimate or Priority membership</a> for the most immersive and stunning visual fidelity.</p>
<h2><b>Decked Out</b></h2>
<p>Thanks to GeForce NOW, nearly any device can perform like a GeForce-powered PC gaming rig. Members who want to stream their favorite PC games to Valve’s <a href="https://store.steampowered.com/steamdeck">Steam Deck</a> now have an easier way to get started.</p>
<p>Members can use a new beta <a href="https://www.nvidia.com/en-us/geforce-now/download/">installation method</a> to automatically configure GeForce NOW’s browser in Steam Deck’s Gaming Mode. The installation script automatically installs Google Chrome to the device, then adds all the settings needed to help members log into GeForce NOW and stream their favorite games.</p>
<p>The <a href="https://www.nvidia.com/en-us/geforce-now/release-highlights/">latest GeForce NOW update</a>, released last week, also allows members to navigate GeForce NOW on a browser using a gamepad, including on the Steam Deck. That means it’s even easier to find and play supported titles with <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">NVIDIA DLSS</a> technology or real-time ray tracing, regardless of the handheld’s system specs.</p>
<p>Plus, members can easily play non-Steam games on the Steam Deck thanks to the cloud. This includes games from Battle.net, Epic Games Store, Ubisoft Connect, GOG.com and Xbox, as well as supported PC Game Pass titles. No more worrying about downloads or backend configurations. And with more than 1,900 games supported, there’s always something new to stream.</p>
<p>Steam Deck is just one of many popular handheld PC devices with support for GeForce NOW. Others include <a href="https://www.asus.com/us/site/gaming/rog/gaming-handheld/rog-ally.html">ASUS ROG Ally</a>, <a href="https://www.logitechg.com/en-us/products/cloud-gaming.html">Logitech G Cloud</a>, <a href="https://www.lenovo.com/us/en/p/handheld/legion-go/len106g0001">Lenovo Legion Go</a>, <a href="https://www.msi.com/Handheld/Claw-A1MX">MSI Claw</a> and <a href="https://www.razer.com/mobile-handhelds/razer-edge">Razer Edge</a>. <a href="https://www.nvidia.com/en-us/geforce-now/download">Get started</a> now. Learn more about how to <a href="https://nvidia.custhelp.com/app/answers/detail/a_id/5337">configure GeForce NOW on Steam Deck</a>.</p>
<h2><b>May New Games Be With You</b></h2>
<figure id="attachment_71377" aria-describedby="caption-attachment-71377" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71377" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-672x336.jpg" alt="Foundry on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71377" class="wp-caption-text"><em>If you build it, they will come.</em></figcaption></figure>
<p>Get complete creative freedom in Paradox Interactive’s <i>FOUNDRY</i>, an exciting first-person factory-building sandbox game set in an infinite voxel world for expansive, ever-changing landscapes. Build a factory optimized to perfection or an artistic masterpiece, harvest resources, automate ever-growing production lines and manage complex systems to achieve mechanical mastery in <i>FOUNDRY</i>.</p>
<p>Check out the list of new games this week:</p>
<ul>
<li><i>Hellblade: Senua&#8217;s Sacrifice </i>(<a href="https://store.steampowered.com/app/414340?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.xbox.com/games/store/hellblade-senuas-sacrifice/9NCLP4LV5K7Z?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Stormgate Closed Beta </i>(New release on <a href="https://store.steampowered.com/app/2012510?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 30,<a href="https://playstormgate.com/beta"> sign up</a> for access)</li>
<li><i>Gray Zone Warfare </i>(New release on <a href="https://store.steampowered.com/app/2479810?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 30)</li>
<li><i>MotoGP24 </i>(New release on <a href="https://store.steampowered.com/app/2581700?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 2)</li>
<li><i>FOUNDRY </i>(New release on <a href="https://store.steampowered.com/app/983870?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 2)</li>
<li><i>INDIKA </i>(New release on <a href="https://store.steampowered.com/app/1373960?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 2)</li>
<li><i>Orcs Must Die! 3 </i>(New release on <a href="https://www.epicgames.com/store/p/combo-a7e03a?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, May 2)</li>
</ul>
<p>And members can look for the following throughout the rest of the month:</p>
<ul>
<li><i>Little Kitty, Big City </i>(New release on <a href="https://store.steampowered.com/app/1177980?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.xbox.com/games/store/little-kitty-big-city/9nf5s7mlm8xt?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass, May 9)</li>
<li><i>Ships at Sea </i>(New release on <a href="https://store.steampowered.com/app/1266540?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 9)</li>
<li><i>The Rogue Prince of Persia  </i>(New release on <a href="https://store.steampowered.com/app/2717880?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 14)</li>
<li><i>Men of War II </i>(New release on <a href="https://store.steampowered.com/app/1128860?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 15)</li>
<li><i>Die by the Blade </i>(New release on <a href="https://store.steampowered.com/app/1154670?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 16)</li>
<li><i>Norland </i>(New release on <a href="https://store.steampowered.com/app/1857090?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 16)</li>
<li><i>Gestalt: Steam &amp; Cinder </i>(New release on <a href="https://store.steampowered.com/app/1231990?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 21)</li>
<li><i>Synergy </i>(New release on <a href="https://store.steampowered.com/app/1989070?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 21)</li>
<li><i>SunnySide </i>(New release on <a href="https://store.steampowered.com/app/1746930?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 21)</li>
<li><i>Crown Wars: The Black Prince </i>(New release on <a href="https://store.steampowered.com/app/1658920?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 23)</li>
<li><i>Capes </i>(New release on <a href="https://store.steampowered.com/app/2081080?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 29)</li>
<li><i>Colony Survival </i>(<a href="https://store.steampowered.com/app/366090?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Exo One </i>(<a href="https://store.steampowered.com/app/773370?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Farmer’s Life </i>(<a href="https://store.steampowered.com/app/1137750?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Honkai: Star Rail </i>(<a href="https://www.epicgames.com/store/p/honkai-star-rail?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Phantom Brigade </i>(<a href="https://store.steampowered.com/app/553540?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Supermarket Simulator </i>(<a href="https://store.steampowered.com/app/2670630?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<h2><b>April Showers Brought More Titles</b></h2>
<p>In addition to the 19 games announced last month, 20 more joined the <a href="http://play.geforcenow.com">GeForce NOW library</a>:</p>
<ul>
<li><i>Gigantic: Rampage Edition </i>(New release on <a href="https://store.steampowered.com/app/1924490?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 9)</li>
<li><i>Inkbound 1.0</i> (New release, on <a href="https://store.steampowered.com/app/1062810/Inkbound/">Steam</a>, April 9)</li>
<li><i>Broken Roads </i>(New release on <a href="https://store.steampowered.com/app/1403440?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 10)</li>
<li><i>Infection Free Zone </i>(New release on <a href="https://store.steampowered.com/app/1465460?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 11)</li>
<li><i>Shadow of the Tomb Raider: Definitive Edition </i>(New release on <a href="https://www.xbox.com/games/store/shadow-of-the-tomb-raider-definitive-edition/BNQQ3WVBNZCQ?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass, April 11)</li>
<li><i>Ghostrunner </i>(<a href="https://www.epicgames.com/store/p/ghostrunner?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, free April 11-18)</li>
<li><i>Kill It With Fire 2 </i>(New release on <a href="https://store.steampowered.com/app/2357000?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 16)</li>
<li><i>The Crew Motorfest </i>(New release on <a href="https://store.steampowered.com/app/2698940?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 18)</li>
<li><i>No Rest for the Wicked </i>(New release on <a href="https://store.steampowered.com/app/1371980?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 18)</li>
<li><i>Bellwright </i>(New release on <a href="https://store.steampowered.com/app/1812450?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 23)</li>
<li><i>Age of Water </i>(New release on <a href="https://store.steampowered.com/app/2695490?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 25)</li>
<li><i>Diablo II: Resurrected </i>(<a href="https://shop.battle.net/product/diablo-ii?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
<li><i>Diablo III </i>(<a href="https://shop.battle.net/product/diablo-iii?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
<li><i>Fallout 4 </i>(<a href="https://store.steampowered.com/app/377160?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Fallout 76 </i>(<a href="https://store.steampowered.com/app/1151340?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.xbox.com/games/store/fallout-76-pc/9nkgnmnk3k3z?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>StarCraft Remastered </i>(<a href="https://shop.battle.net/product/starcraft-remastered?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
<li><i>StarCraft II </i>(<a href="https://shop.battle.net/product/starcraft-ii?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
<li><i>Stargate: Timekeepers </i>(<a href="https://store.steampowered.com/app/1523650?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Terra Invicta</i> (<a href="https://www.xbox.com/games/store/terra-invicta-game-preview/9pb0glgxqz83?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Tomb Raider I-III Remastered </i>(<a href="https://store.steampowered.com/app/2478970?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<p>Riot Games has rolled out the <i>League of Legends</i> 14.9 update globally, which adds the Vanguard security software to the game. Since Vanguard doesn’t support virtual machines like GeForce NOW, the game is under maintenance and no longer playable on the cloud gaming platform for the foreseeable future. Work is underway to find a solution for GeForce NOW members.</p>
<p><i>Lightyear Frontier </i>(Xbox) didn’t make it in April due to technical issues. Stay tuned to GFN Thursday for updates.</p>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">what are you gaming goals for next month? <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f914.png" alt="🤔" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1785700708882251889?ref_src=twsrc%5Etfw">May 1, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-thursday-5-2-nv-blog-1280x680-no-cta.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-thursday-5-2-nv-blog-1280x680-no-cta-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[GeForce NOW Delivers 24 A-May-zing Games This Month]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Explainable AI: Insights from Arthur’s Adam Wenchel</title>
		<link>https://blogs.nvidia.com/blog/arthur-podcast/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Wed, 01 May 2024 19:28:59 +0000</pubDate>
				<category><![CDATA[The AI Podcast]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71392</guid>

					<description><![CDATA[Arthur.ai enhances the performance of AI systems across various metrics like accuracy, explainability and fairness. In this episode of the NVIDIA AI Podcast, recorded live at GTC 2024, host Noah Kravitz sits down with Adam Wenchel, cofounder and CEO of Arthur, to discuss the challenges and opportunities of deploying generative AI. Their conversation spans a		<a class="read-more" href="https://blogs.nvidia.com/blog/arthur-podcast/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Arthur.ai enhances the performance of AI systems across various metrics like accuracy, explainability and fairness. In this episode of the <a href="https://blogs.nvidia.com/ai-podcast/">NVIDIA AI Podcast</a>, recorded live at GTC 2024, host Noah Kravitz sits down with Adam Wenchel, cofounder and CEO of Arthur, to discuss the challenges and opportunities of deploying generative AI. Their conversation spans a range of topics, including AI bias, the observability of AI systems and the practical implications of AI in business. For more on Arthur, visit<a href="http://arthur.ai/"> arthur.ai</a>.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1811598663%3Fsecret_token%3Ds-cC3zby3JQS4&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="Explainable AI: Insights from Arthur AI's Adam Wenchel – Ep. 221" href="https://soundcloud.com/theaipodcast/arthur-ai-adam-wenchel/s-cC3zby3JQS4" target="_blank" rel="noopener">Explainable AI: Insights from Arthur AI&#8217;s Adam Wenchel – Ep. 221</a></div>
<h2>Time Stamps:</h2>
<ul>
<li style="font-weight: 400;" aria-level="1"><strong>00:11:</strong> Introduction and background on Adam Wenchel and Arthur.ai.</li>
<li style="font-weight: 400;" aria-level="1"><strong>01:31:</strong> Discussion on the mission and services of Arthur.</li>
<li style="font-weight: 400;" aria-level="1"><strong>02:31:</strong> Real-world use cases of LLMs and generative AI in enterprises.</li>
<li style="font-weight: 400;" aria-level="1"><strong>06:22:</strong> Challenges in deploying AI systems internally within companies.</li>
<li style="font-weight: 400;" aria-level="1"><strong>08:23:</strong> The process of adapting AI models for specific business needs.</li>
<li style="font-weight: 400;" aria-level="1"><strong>09:26:</strong> Exploring AI observability and the importance of real-time monitoring.</li>
<li style="font-weight: 400;" aria-level="1"><strong>11:36:</strong> Addressing bias in AI systems and its implications.</li>
<li style="font-weight: 400;" aria-level="1"><strong>15:21:</strong> Wenchel’s journey from cybersecurity to AI and founding Arthur.</li>
<li style="font-weight: 400;" aria-level="1"><strong>20:38:</strong> Cybersecurity concerns with generative AI and large language models.</li>
<li style="font-weight: 400;" aria-level="1"><strong>21:37:</strong> Future of work and AI’s role in enhancing job performance.</li>
<li style="font-weight: 400;" aria-level="1"><strong>24:27:</strong> Future directions for Arthur and ongoing projects.</li>
</ul>
<h2>You Might Also Like…</h2>
<p><a href="https://soundcloud.com/theaipodcast/ai-daniel-castro-itif">ITIF’s Daniel Castro on Energy-Efficient AI and Climate Change – Ep. 215</a></p>
<p>AI-driven change is in the air, as are concerns about the technology’s environmental impact. In this episode of NVIDIA’s AI Podcast, Daniel Castro, vice president of the Information Technology and Innovation Foundation and director of its Center for Data Innovation, speaks with host Noah Kravitz about the motivation behind his AI energy use report, which addresses misconceptions about the technology’s energy consumption.</p>
<p><a href="https://soundcloud.com/theaipodcast/ai-wildfire">DigitalPath’s Ethan Higgins on Using AI to Fight Wildfires – Ep. 211</a></p>
<p>DigitalPath is igniting change in the golden state — using computer vision, generative adversarial networks and a network of thousands of cameras to detect signs of fire in real-time. In the latest episode of NVIDIA’s AI Podcast, host Noah Kravtiz spoke with DigitalPath system architect Ethan Higgins about the company’s role in the ALERTCalifornia initiative, a collaboration between California’s wildfire fighting agency CAL FIRE and the University of California, San Diego.</p>
<p><a href="https://soundcloud.com/theaipodcast/anima-anandkumar">Anima Anandkumar on Using Generative AI to Tackle Global Challenges – Ep. 203</a></p>
<p>Generative AI-based models can not only learn and understand natural languages — they can learn the very language of nature itself, presenting new possibilities for scientific research. On the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Anandkumar on generative AI’s potential to make splashes in the scientific community.</p>
<p><a href="https://soundcloud.com/theaipodcast/ai-alex-fielding">How Alex Fielding and Privateer Space Are Taking on Space Debris – Ep. 196</a></p>
<p>In this episode of the NVIDIA AI Podcast, host Noah Kravitz dives into an illuminating conversation with Alex Fielding, co-founder and CEO of Privateer Space. Privateer Space, Fielding’s latest venture, aims to address one of the most daunting challenges facing our world today: space debris.</p>
<h2>Subscribe to the AI Podcast</h2>
<p>Get the<a href="https://blogs.nvidia.com/ai-podcast/"> AI Podcast</a> through<a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439"> iTunes</a>,<a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjI2NDAzNDEzMy9zb3VuZHMucnNz"> Google Podcasts</a>,<a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm"> Google Play</a>, <a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">Amazon Music, </a><a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us">Castbox</a>, DoggCatcher,<a href="https://overcast.fm/itunes1186480811/the-ai-podcast"> Overcast</a>,<a href="https://player.fm/series/the-ai-podcast"> PlayerFM</a>, Pocket Casts,<a href="http://www.podbay.fm/show/1186480811"> Podbay</a>,<a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast"> PodBean</a>, PodCruncher, PodKicker,<a href="https://soundcloud.com/theaipodcast"> Soundcloud</a>,<a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L"> Spotify</a>,<a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr"> Stitcher</a> and<a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/"> TuneIn</a>.</p>
<p>Make the AI Podcast better: Have a few minutes to spare? Fill out<a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short"> this listener survey</a>.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2021/08/ai-podcast-2600x1472_-1-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1159"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2021/08/ai-podcast-2600x1472_-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Explainable AI: Insights from Arthur’s Adam Wenchel]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI Takes a Bow: Interactive GLaDOS Robot Among 9 Winners in Hackster.io Challenge</title>
		<link>https://blogs.nvidia.com/blog/glados-robot-hackster/</link>
		
		<dc:creator><![CDATA[Scott Martin]]></dc:creator>
		<pubDate>Wed, 01 May 2024 15:33:24 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Conversational AI]]></category>
		<category><![CDATA[NVIDIA Jetson]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71365</guid>

					<description><![CDATA[YouTube robotics influencer Dave Niewinski has developed robots for everything from driveable La-Z-Boy chairs to an AI-guided cornhole tosser and horse-drawn chariot racing. His recent Interactive Animatronic GLaDOS project was among nine winners in the Hackster AI Innovation Challenge. About 100 contestants vied for prizes from NVIDIA and Sparkfun by creating open-source projects to advance		<a class="read-more" href="https://blogs.nvidia.com/blog/glados-robot-hackster/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>YouTube robotics influencer Dave Niewinski has developed robots for everything from driveable La-Z-Boy chairs to an AI-guided cornhole tosser and horse-drawn chariot racing.</p>
<p>His recent <a href="https://www.hackster.io/davesarmoury/interactive-animatronic-glados-8b4238">Interactive Animatronic GLaDOS</a> project was among nine winners in the <a href="https://www.hackster.io/contests/SparkFun-NVIDIA-AI-Innovation-Challenge">Hackster AI Innovation Challenge</a>. About 100 contestants vied for prizes from NVIDIA and Sparkfun by creating open-source projects to advance the use of AI in edge computing, robotics and IoT.</p>
<p>Niewinski won first place in the generative AI applications category for his innovative robot based on the GLaDOS guide from game series <i>Portal</i>, the first-person puzzle platform from video game developer Valve.</p>
<p>Other top winners included contestants Andrei Ciobanu and Allen Tao, who took first prize in the generative AI models for the edge and AI at the edge applications categories, respectively. Ciobanu used generative AI to help virtually try on clothes, while Tao developed a ROS-based robot to map the inside of a home to help find things.</p>
<h2><b>Harnessing LLMs for Robots</b></h2>
<p>Niewinski builds custom applications for robotics at his <a href="https://www.armourylabs.com/">Armoury Labs</a> business in Waterloo, Ontario, Canada, where he uses the NVIDIA Jetson platform for edge AI and robotics, creating open-source tutorials and <a href="https://www.youtube.com/@DavesArmoury/videos">YouTube videos</a> following his experiences.</p>
<p>He built his interactive GLaDOS robot to create a personal assistant for himself in the lab. It handles queries using Transformer-based speech recognition, text-to-speech, and large language models (LLMs) running onboard an <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">NVIDIA Jetson AGX Orin</a>, which interfaces with a robot arm and camera for interactions.</p>
<p>GLaDOS can track his whereabouts in the lab, move in different directions to face him and respond quickly to queries.</p>
<p>“I like doing things with robots that people will look at and say it’s not what they had immediately expected,” he said.</p>
<p><iframe loading="lazy" title="Bringing GLaDOS to life with Robotics and AI" width="500" height="281" src="https://www.youtube.com/embed/yNcKTZsHyfA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>He wanted the assistant to sound like the original GLaDOS from <i>Portal</i> and respond quickly. Fortunately, the gaming company Valve has put all of the voice lines from <i>Portal </i>and <i>Portal 2</i> on its website, allowing Niewinski to download the audio to help train a model.</p>
<p>“Using Jetson, your average question-and-answer stuff runs pretty quick for speech,” he said.</p>
<p>Niewinski used NVIDIA’s open-source <a href="https://github.com/NVIDIA/NeMo">NeMo</a> toolkit to fine-tune a voice for GLaDOS, training a spectrogram generator network called <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/tts_en_fastpitch">FastPitch</a> and <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/tts_hifigan">HiFiGAN</a> vocoder network to refine the audio quality.</p>
<p>Both networks are deployed on Orin with <a href="https://www.nvidia.com/en-us/ai-data-science/products/riva/">NVIDIA Riva</a> to enable speech recognition and synthesis that’s been optimized to run at many times the real-time rate of speech, so that it can run alongside the LLM while maintaining a smooth, interactive delivery.</p>
<p>For generating realistic responses from GLaDOS, Niewinski uses a locally hosted LLM called OpenChat that he runs in Docker from <a href="https://github.com/dusty-nv/jetson-containers">jetson-containers</a>, saying that it was a drop-in replacement for OpenAI’s API. All of this AI is running on the <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">Jetson</a> module, using the latest open-source ML software stack built with CUDA and <a href="https://developer.nvidia.com/embedded/jetpack">JetPack</a>.</p>
<p>To enable GLaDOS to move, Niewinski developed the interactions for a Unitree Z1 robotic arm. It has a stereo camera and models for seeing and tracking a human speaking and a 3D-printed GLaDOS head and body shell around the arm.</p>
<h2><b>Trying on Generative AI for Fashion Fit</b></h2>
<p>Winner Ciobanu, based in Romania, aimed to improve the virtual clothing try-on experience with the help of generative AI, taking a top prize for his <a href="https://www.hackster.io/andrei-ciobanu2/edgestyle-fashion-preview-at-the-edge-b6d845">EdgeStyle: Fashion Preview at the Edge</a>.</p>
<p>He used AI models such as YOLOv5, SAM and OpenPose to extract and refine data from images and videos. Then he used Stable Diffusion to generate the images, which he said was key to achieving accurate virtual try-ons.</p>
<p>This system taught the model how clothes fit different poses on people, which he said enhanced the realism of the try-ons.</p>
<p>“It’s quite handy as it allows users to see how clothes would look on them without actually trying them on,” said Ciobanu.</p>
<p><iframe loading="lazy" title="EdgeStyle Demo" width="500" height="281" src="https://www.youtube.com/embed/kR_o9eEUHK4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>The NVIDIA JetPack SDK provided all the tools needed to run AI models smoothly on the Jetson Orin, he said.</p>
<p>“It’s super-helpful to have a stable set of tools, especially when you’re dealing with AI tech that keeps changing,” said Ciobanu. “It really cut down on the time and hassle for us developers, letting us focus more on the cool stuff we’re building instead of getting stuck on tech issues.”</p>
<h2> <b>Finding Lost Items With Robot Assistance</b></h2>
<p>Winner Tao, based in Ontario, Canada, created a robot to lessen the burden of searching for things lost around the house. His <a href="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.hackster.io%2Fceyeber%2Fan-eye-for-an-item-9162a7&amp;data=05%7C02%7Cscmartin%40nvidia.com%7C0e398a0434c949e581b508dc65b1f664%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638497062235862516%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=FiIs8uLHjF8szFOvOs5F1vHFD3ax0fKBEnLyL3kS9aQ%3D&amp;reserved=0">An Eye for an Item</a> project took top honors at the Hackster challenge.</p>
<p>“Finding lost objects is a chore, and recent developments in zero-shot object detection and LLMs make it feasible for a computer to detect arbitrary objects for us based on textual or pictorial descriptions, presenting an opportunity for automation,” said Tao.</p>
<p><iframe loading="lazy" title="An Eye for an Item  - Demo" width="500" height="281" src="https://www.youtube.com/embed/KAUH67vni74?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Tao said he needed robot computing capabilities to catalog objects in any unstructured environment — whether a living room or large warehouse. And he needed it to also perform real-time calculations for localization to help with navigation, as well as running inference on larger object detection models.</p>
<p>“Jetson Orin was a perfect fit, supporting all functionality from text and image queries into <a href="https://www.jetson-ai-lab.com/tutorial_nanodb.html">NanoDB</a>, to real-time odometry feedback, including leveraging <a href="https://developer.nvidia.com/isaac/ros">Isaac ROS</a>’ hardware-accelerated AprilTag detections for drift correction,” he said.</p>
<p>Other <a href="https://www.hackster.io/contests/SparkFun-NVIDIA-AI-Innovation-Challenge">winners</a> of the AI Innovation Challenge include:</p>
<ul>
<li style="font-weight: 400;" aria-level="1">George Profenza, Escalator people tracker, 2nd place, Generative AI Applications category</li>
<li style="font-weight: 400;" aria-level="1">Dimiter Kendri, Cooking meals with a local AI assistant using Jetson AGX Orin, 3rd place, Generative AI Applications category</li>
<li style="font-weight: 400;" aria-level="1">Vy Phan, ClearWaters Underwater Image Enhancement with Generative AI, 2nd place, Generative AI Models category</li>
<li style="font-weight: 400;" aria-level="1">Huy Mai, Realtime Language Segment Anything on Jetson Orin, 2nd place, Generative AI Models category</li>
<li style="font-weight: 400;" aria-level="1">Fakhrur Razi, Autonomous Intelligent Robotic Shopping Cart, 2nd place, AI at the Edge Open category</li>
<li style="font-weight: 400;" aria-level="1">Team Kinetika, Counting for Inspection and Quality Control with TensorRT, 3rd place, AI at the Edge Open category</li>
</ul>
<p><i>Learn more about </i><a href="https://developer.nvidia.com/embedded-computing"><i>NVIDIA Jetson Orin</i></a><i> for robotics and edge AI applications. Get started creating your own projects at the </i><a href="https://www.jetson-ai-lab.com/"><i>Jetson AI Lab</i></a><i>.  </i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/Hackster_Edge_AI_Challenge_Winners-Blog.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/Hackster_Edge_AI_Challenge_Winners-Blog-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI Takes a Bow: Interactive GLaDOS Robot Among 9 Winners in Hackster.io Challenge]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
	</channel>
</rss>
