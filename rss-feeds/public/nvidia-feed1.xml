<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Wed, 08 Nov 2023 04:51:54 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.3.2</generator>
	<item>
		<title>Digital Artist Steven Tung Shows Off So-fish-ticated Style This Week ‘In the NVIDIA Studio’</title>
		<link>https://blogs.nvidia.com/blog/2023/11/07/tung-msi-adobe-3d-painter-blender/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 07 Nov 2023 14:00:06 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67869</guid>

					<description><![CDATA[Taiwanese artist Steven Tung creates captivating 2D and 3D digital art that explores sci-fi, minimalism and realism and pushes artistic boundaries.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. We’re also deep-diving on new </i><a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/"><i>GeForce RTX 40 Series GPU</i></a><i> features, technologies and resources, and how they dramatically accelerate content creation.</i></p>
<p>Taiwanese artist Steven Tung creates captivating 2D and 3D digital art that explores sci-fi, minimalism and realism and pushes artistic boundaries.</p>
<p>This week <i>In the NVIDIA Studio,</i> Tung shares the inspiration and creative workflow behind his whimsical animation, <i>The Given Fish</i>.</p>
<p>Professional-grade technology, which was once available only at select special effects studios, is becoming increasingly accessible.</p>
<p>“Visual production capabilities continue to skyrocket, generating a growing demand for better computer hardware among the general public,” Tung said. “The evolving synergy between art and technology can spark endless possibilities for creators.”</p>
<p>Tung uses an <a href="https://www.msi.com/Desktop/MEG-Trident-X2-13th">MSI MEG Trident X2 desktop</a>, powered by GeForce RTX 4090 graphics, to accelerate his creative workflow.</p>
<figure id="attachment_67876" aria-describedby="caption-attachment-67876" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-kv-bg-1280w.png"><img decoding="async" fetchpriority="high" class="size-large wp-image-67876" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-kv-bg-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-kv-bg-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-kv-bg-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-kv-bg-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-kv-bg-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-kv-bg-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-kv-bg-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-kv-bg-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67876" class="wp-caption-text">The MSI MEG Trident X2 desktop, powered by GeForce RTX 4090 graphics.</figcaption></figure>
<p>“The enhanced speed and performance expedites various processes, such as updating material textures in Adobe Substance 3D Painter and rendering in Blender,” said Tung. “The necessary specifications and requirements align, enabling maximum creativity without limitations.”</p>
<h2><b>Exquisite Visuals Made E-fish-ciently</b></h2>
<p>Tung’s 3D animation, <i>The Given Fish</i>, may look simple at first glance — but it’s surprisingly complex.</p>
<div class="simplePullQuote right"><p>“GeForce RTX GPUs are indispensable hardware for 3D rendering tasks. Faster speeds bring significant benefits in production efficiency and time saved.” — Steven Tung</p>
</div>
<p>In the creative world behind the animation, the stone fish depicted can be consumed by people. The concept is that once taken out of the aquarium, the stone fish transforms into a real, living one.</p>
<p>“I have a strong desire to have an aquarium at home, but it’s not practical,” said Tung. “The next best thing is to turn that emotion into art.”</p>
<p>Tung began by creating concept sketches in Adobe Photoshop, where he had access to over 30 GPU-accelerated features that could help modify and adjust his canvas and maximize his efficiency.</p>
<figure id="attachment_67879" aria-describedby="caption-attachment-67879" style="width: 453px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-sketch-1280w.png"><img decoding="async" class="size-large wp-image-67879" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-sketch-1280w-453x500.png" alt="" width="453" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-sketch-1280w-453x500.png 453w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-sketch-1280w-363x400.png 363w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-sketch-1280w-768x847.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-sketch-1280w-408x450.png 408w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-sketch-1280w-195x215.png 195w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-sketch-1280w-91x100.png 91w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-sketch-1280w.png 1280w" sizes="(max-width: 453px) 100vw, 453px" /></a><figcaption id="caption-attachment-67879" class="wp-caption-text">Concept art for “The Given Fish.”</figcaption></figure>
<p>Next, Tung jumped from 2D to 3D with ZBrush. He first built a basic model and then refined critical details with custom brushes — adding greater depth and dimension with authentic, hand-sculpted textures.</p>
<figure id="attachment_67882" aria-describedby="caption-attachment-67882" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-wip-1280w.png"><img decoding="async" class="size-large wp-image-67882" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-wip-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-wip-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-wip-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-wip-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-wip-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-wip-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-wip-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-wip-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67882" class="wp-caption-text">Advanced sculpting in ZBrush.</figcaption></figure>
<p>He then used the UV unwrapping feature in RizomUV to ensure that his models were properly unwrapped and ready for texture application.</p>
<figure id="attachment_67885" aria-describedby="caption-attachment-67885" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-rizomuv-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67885" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-rizomuv-1280w-672x361.png" alt="" width="672" height="361" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-rizomuv-1280w-672x361.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-rizomuv-1280w-400x215.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-rizomuv-1280w-768x412.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-rizomuv-1280w-838x450.png 838w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-rizomuv-1280w-401x215.png 401w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-rizomuv-1280w-186x100.png 186w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-rizomuv-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67885" class="wp-caption-text">UV unwrapping feature in RizomUV.</figcaption></figure>
<p>Tung imported the models into Adobe 3D Substance Painter, where he meticulously painted textures, blended materials and used the built-in library to achieve lifelike stone textures. RTX-accelerated light and ambient occlusion baking optimized his assets in seconds.</p>
<figure id="attachment_67888" aria-describedby="caption-attachment-67888" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-adobe-substance-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67888" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-adobe-substance-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-adobe-substance-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-adobe-substance-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-adobe-substance-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-adobe-substance-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-adobe-substance-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-adobe-substance-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-adobe-substance-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67888" class="wp-caption-text">Applying textures in Adobe Substance 3D Painter.</figcaption></figure>
<p>To bring all the elements together, Tung imported the models and materials into Blender. He set up texture channels, assigned texture files and assembled the models so that they would be true to the compositions outlined in the initial sketch.</p>
<figure id="attachment_67891" aria-describedby="caption-attachment-67891" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-painting-fish-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67891" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-painting-fish-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-painting-fish-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-painting-fish-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-painting-fish-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-painting-fish-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-painting-fish-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-painting-fish-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-painting-fish-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67891" class="wp-caption-text">Achieving realistic stone textures in Adobe 3D Substance Painter.</figcaption></figure>
<p>Next, Tung used Blender Cycles to light and render the scene.</p>
<figure id="attachment_67894" aria-describedby="caption-attachment-67894" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/comp-studio-steven-tung-wk82-kv-bg-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67894" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/comp-studio-steven-tung-wk82-kv-bg-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/comp-studio-steven-tung-wk82-kv-bg-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/comp-studio-steven-tung-wk82-kv-bg-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/comp-studio-steven-tung-wk82-kv-bg-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/comp-studio-steven-tung-wk82-kv-bg-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/comp-studio-steven-tung-wk82-kv-bg-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/comp-studio-steven-tung-wk82-kv-bg-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/comp-studio-steven-tung-wk82-kv-bg-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67894" class="wp-caption-text">Composition edits in Blender.</figcaption></figure>
<p>Blender Cycles’ RTX-accelerated, AI-powered OptiX ray tracing enabled interactive, photorealistic movement in the viewport and sped up animation work — all powered by his GeForce RTX 4090 GPU-equipped system.</p>
<figure id="attachment_67897" aria-describedby="caption-attachment-67897" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-blender-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67897" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-blender-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-blender-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-blender-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-blender-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-blender-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-blender-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-blender-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-steven-tung-wk82-blender-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67897" class="wp-caption-text">Animation work in Blender.</figcaption></figure>
<p>RTX accelerated OptiX ray tracing in Blender Cycles enabled the fastest final frame render.</p>
<figure id="attachment_67900" aria-describedby="caption-attachment-67900" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-steven-tung-wk82-artist-feature-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67900" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-steven-tung-wk82-artist-feature-1280w-672x244.png" alt="" width="672" height="244" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-steven-tung-wk82-artist-feature-1280w-672x244.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-steven-tung-wk82-artist-feature-1280w-400x145.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-steven-tung-wk82-artist-feature-1280w-768x278.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-steven-tung-wk82-artist-feature-1280w-842x305.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-steven-tung-wk82-artist-feature-1280w-406x147.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-steven-tung-wk82-artist-feature-1280w-188x68.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-steven-tung-wk82-artist-feature-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67900" class="wp-caption-text">Digital artist Steven Tung.</figcaption></figure>
<p>Check out Tung’s portfolio on <a href="https://www.instagram.com/tung_10/">Instagram</a>.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>Twitter</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/nv-blog-header-preview-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/nv-blog-header-preview-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Digital Artist Steven Tung Shows Off So-fish-ticated Style This Week ‘In the NVIDIA Studio’]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>‘Starship for the Mind’: University of Florida Opens Malachowsky Hall, an Epicenter for AI and Data Science</title>
		<link>https://blogs.nvidia.com/blog/2023/11/03/starship-for-mind-uf-malachowsky-hall/</link>
		
		<dc:creator><![CDATA[Cheryl Martin]]></dc:creator>
		<pubDate>Fri, 03 Nov 2023 15:43:03 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Supercomputing]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Education]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67914</guid>

					<description><![CDATA[Embodying the convergence of AI and academia, the University of Florida Friday inaugurated the Malachowsky Hall for Data Science &#38; Information Technology. The sleek, seven-story building is poised to play a pivotal role in UF’s ongoing efforts to harness the transformative power of AI, reaffirming its stature as one of the nation’s leading public universities. <a class="read-more" href="https://blogs.nvidia.com/blog/2023/11/03/starship-for-mind-uf-malachowsky-hall/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Embodying the convergence of AI and academia, the University of Florida Friday inaugurated the Malachowsky Hall for Data Science &amp; Information Technology.</p>
<p>The sleek, seven-story building is poised to play a pivotal role in UF’s ongoing efforts to harness the transformative power of AI, reaffirming its stature as one of the nation’s leading public universities.</p>
<p>Evoking Apple co-founder Steve Jobs’ iconic description of a personal computer, NVIDIA’s founder and CEO Jensen Huang described Malachowsky Hall — named for NVIDIA co-founder Chris Malachowsky — and the <a href="https://blogs.nvidia.com/blog/2020/07/21/university-of-florida-nvidia-ai-supercomputer/">HiPerGator AI supercomputer</a> it hosts as a “starship for knowledge discovery.”</p>
<p>“Steve Jobs called (the PC) ‘the bicycle of the mind,’ a device that propels our thoughts further and faster,” Huang said.</p>
<p>“What Chris Malachowsky has gifted this institution is nothing short of the ‘starship of the mind’ — a vehicle that promises to take our intellect to uncharted territories,” Huang said.</p>
<p>The inauguration of the 260,000-square-foot structure marks a milestone in the partnership between UF alum Malachowsky, NVIDIA and the state of Florida — a collaboration that has propelled UF to the forefront of AI innovation.</p>
<p>Malachowsky and NVIDIA both made major contributions toward its construction, bolstered by a $110 million investment from the state of Florida.</p>
<figure id="attachment_67931" aria-describedby="caption-attachment-67931" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" loading="lazy" class="wp-image-67931 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/Ben-Sasse-and-Jensen-Huang-Malachowsky-Hall-UF-Nov-3-2023-672x448.jpg" alt="University of Florida President Ben Sasse and NVIDIA CEO Jensen Huang speak at the opening of Malachowsky Hall." width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/Ben-Sasse-and-Jensen-Huang-Malachowsky-Hall-UF-Nov-3-2023-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Ben-Sasse-and-Jensen-Huang-Malachowsky-Hall-UF-Nov-3-2023-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Ben-Sasse-and-Jensen-Huang-Malachowsky-Hall-UF-Nov-3-2023-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Ben-Sasse-and-Jensen-Huang-Malachowsky-Hall-UF-Nov-3-2023-1536x1025.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Ben-Sasse-and-Jensen-Huang-Malachowsky-Hall-UF-Nov-3-2023-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Ben-Sasse-and-Jensen-Huang-Malachowsky-Hall-UF-Nov-3-2023-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Ben-Sasse-and-Jensen-Huang-Malachowsky-Hall-UF-Nov-3-2023-322x215.jpg 322w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Ben-Sasse-and-Jensen-Huang-Malachowsky-Hall-UF-Nov-3-2023-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Ben-Sasse-and-Jensen-Huang-Malachowsky-Hall-UF-Nov-3-2023-1280x854.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-67931" class="wp-caption-text">University of Florida President Ben Sasse and NVIDIA CEO Jensen Huang speak at the opening of Malachowsky Hall.</figcaption></figure>
<p>Following the opening, Huang and UF’s new president, Ben Sasse, met to discuss the impact of AI and data science across UF and beyond for students just starting their careers.</p>
<p>Sasse underscored the importance of adaptability in a rapidly changing world, telling the audience: “work in lots and lots of different organizations … because lifelong work in any one, not just firm, but any one industry is going to end in our lives. You’re ultimately going to have to figure out how to reinvent yourselves at 30, 35, 40 and 45.”</p>
<p>Huang offered students very different advice, recalling how he met his wife, Lori, who was in the audience, as an undergraduate. “Have a good pickup line … do you want to know the pickup line?” Huang asked, pausing a beat. “You want to see my homework?”</p>
<p>The spirit of Sasse and Huang’s adaptable approach to career and personal development is embodied in Malachowsky Hall, designed to bring together people from academia and industry, research and government.</p>
<p>Packed with innovative collaboration spaces and labs, the hall features a spacious 400-seat auditorium, dedicated high-performance computing study spaces and a rooftop terrace that unveils panoramic campus vistas.</p>
<p>Sustainability is woven into its design, highlighted by energy-efficient systems and rainwater harvesting facilities.</p>
<p>Malachowsky Hall will serve as a conduit to bring the on-campus advances in AI to Florida’s thriving economy, which continues to outpace the nation in jobs and GDP growth.</p>
<figure id="attachment_67908" aria-describedby="caption-attachment-67908" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/UF-HiPerGator-AI-supercomputer-scaled.jpg"><img decoding="async" loading="lazy" class="wp-image-67908 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/UF-HiPerGator-AI-supercomputer-672x448.jpg" alt="Together, NVIDIA founder and UF alumnus Chris Malachowsky and NVIDIA donated $50 million toward the University of Florida’s HiPerGator AI supercomputer." width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/UF-HiPerGator-AI-supercomputer-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/UF-HiPerGator-AI-supercomputer-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/UF-HiPerGator-AI-supercomputer-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/UF-HiPerGator-AI-supercomputer-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/UF-HiPerGator-AI-supercomputer-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/UF-HiPerGator-AI-supercomputer-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2023/11/UF-HiPerGator-AI-supercomputer-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2023/11/UF-HiPerGator-AI-supercomputer-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/11/UF-HiPerGator-AI-supercomputer-1280x853.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67908" class="wp-caption-text">Together, NVIDIA founder and UF alumnus Chris Malachowsky and NVIDIA donated $50 million toward the University of Florida’s HiPerGator AI supercomputer.</figcaption></figure>
<p>UF’s efforts to bring AI and academia together, catalyzed by support from Malachowsky and NVIDIA, go far beyond Malachowsky Hall.</p>
<p>In 2020, UF announced that Malachowsky and NVIDIA together donated $50 million toward HiPerGator, one of the most powerful AI supercomputers in the country.</p>
<p>With additional state support, UF recently added more than 110 AI faculty members to the 300 already engaged in AI teaching and research.</p>
<p>As a result, UF extended AI-focused courses, workshops and projects across the university, enabling its 55,000 students to delve into AI and its interdisciplinary applications.</p>
<p>Friday&#8217;s ribbon-cutting will open exciting new opportunities for the university, its students and the state of Florida to realize the potential of AI innovations across sectors.</p>
<p>Huang likened pursuing knowledge through AI to embarking on a “starship.” “You’ve got to go as far as you can,” he urged students.</p>
<p>For a deeper exploration of Malachowsky Hall and UF’s groundbreaking AI initiatives, <a href="https://www.ufl.edu/">visit UF’s website</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/UF-Malachowsky-Hall-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/UF-Malachowsky-Hall-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[‘Starship for the Mind’: University of Florida Opens Malachowsky Hall, an Epicenter for AI and Data Science]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>How AI-Based Cybersecurity Strengthens Business Resilience</title>
		<link>https://blogs.nvidia.com/blog/2023/11/03/ai-cybersecurity-business-resilience/</link>
		
		<dc:creator><![CDATA[Ben Oliveri]]></dc:creator>
		<pubDate>Fri, 03 Nov 2023 15:00:54 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cybersecurity]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67865</guid>

					<description><![CDATA[The world’s 5 billion internet users and nearly 54 billion devices generate 3.4 petabytes of data per second, according to IDC. As digitalization accelerates, enterprise IT teams are under greater pressure to identify and block incoming cyber threats to ensure business operations and services are not interrupted — and AI-based cybersecurity provides a reliable way <a class="read-more" href="https://blogs.nvidia.com/blog/2023/11/03/ai-cybersecurity-business-resilience/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The world’s <a href="https://www.nvidia.com/en-us/on-demand/session/gtcspring23-S51404/">5 billion</a> internet users and nearly 54 billion devices generate <a href="https://www.idc.com/getdoc.jsp?containerId=US49346123&amp;pageType=PRINTFRIENDLY">3.4 petabytes of data per second</a>, according to IDC. As digitalization accelerates, enterprise IT teams are under greater pressure to identify and block incoming cyber threats to ensure business operations and services are not interrupted — and AI-based cybersecurity provides a reliable way to do so.</p>
<p>Few industries appear immune to cyber threats. This year alone, international hotel chains, financial institutions, Fortune 100 retailers, air traffic-control systems and the U.S. government have all reported threats and intrusions.</p>
<p>Whether from insider error, cybercriminals, hacktivists or other threats, risks in the cyber landscape can damage an enterprise’s reputation and bottom line. A breach can paralyze operations, jeopardize proprietary and customer data, result in regulatory fines and destroy customer trust.</p>
<p>Using AI and accelerated computing, businesses can reduce the time and operational expenses required to detect and block cyber threats while freeing up resources to focus on core business value operations and revenue-generating activities.</p>
<p>Here’s a look at how industries are applying AI techniques to safeguard data, enable faster threat detection and mitigate attacks to ensure the consistent delivery of service to customers and partners.</p>
<h2><strong>Public Sector: Protecting Physical Security, Energy Security and Citizen Services</strong></h2>
<p>AI-powered analytics and automation tools are helping government agencies provide citizens with instant access to information and services, make data-driven decisions, model climate change, manage natural disasters, and more. But <a href="https://www.nvidia.com/en-us/industries/public-sector/">public entities</a> managing digital tools and infrastructure face a complex cyber risk environment that includes regulatory compliance requirements, public scrutiny, large interconnected networks and the need to protect sensitive data and high-value targets.</p>
<p>Adversary nation-states may initiate cyberattacks to disrupt networks, steal intellectual property or swipe classified government documents. Internal misuse of digital tools and infrastructure combined with sophisticated external espionage places public organizations at high risk of data breach. Espionage actors have also been known to recruit inside help, with <a href="https://www.verizon.com/business/resources/reports/dbir/">16% of public administration breaches</a> showing evidence of collusion. To protect critical infrastructure, citizen data, public records and other sensitive information, federal organizations are turning to AI.</p>
<p>The U.S. Department of Energy’s (DOE) Office of Cybersecurity, Energy Security and Emergency Response (CESER) is tasked with strengthening the resilience of the country’s energy sector by addressing emerging threats and improving energy infrastructure security. The DOE-CESER has invested more than <a href="https://www.energy.gov/ceser/cybersecurity-research-development-and-demonstration-rdd-energy-delivery-systems">$240 million</a> in cybersecurity research, development and demonstration projects since 2010.</p>
<p>In one project, the department developed a tool that uses AI to <a href="https://www.energy.gov/sites/default/files/2021-08/Security%20Patch%20Automated%20Remediation%20Tool%20Analyzing%20the%20NVD%20%28SPARTAN%29%20-%20SEEDS_508.pdf">automate and optimize security vulnerability and patch management</a> in energy delivery systems. Another project for <a href="https://www.energy.gov/sites/default/files/2021-11/ADDSec%20Artificial%20Diversity%20and%20Defense%20Security%20-%20SNL.pdf">artificial diversity and defense security</a> uses software-defined networks to enhance the situational awareness of energy delivery systems, helping ensure uninterrupted flows of energy.</p>
<p>The Defense Advanced Research Projects Agency (DARPA), which is charged with researching and investing in breakthrough technologies for national security, is using machine learning and AI in several areas. The <a href="https://www.darpa.mil/program/cyber-agents-for-security-testing-and-learning-environments">DARPA CASTLE program</a> trains AI to defend against advanced, persistent cyber threats. As part of the effort, researchers intend to accelerate cybersecurity assessments with approaches that are automated, repeatable and measurable. The <a href="https://www.gardproject.org/">DARPA GARD program</a> builds platforms, libraries, datasets and training materials to help developers build AI models that are resistant to deception and adversarial attacks.</p>
<p>To keep up with an evolving threat landscape and ensure physical security, energy security and data security, public organizations must continue integrating AI to achieve a dynamic, proactive and far-reaching cyber defense posture.</p>
<h2><strong>Financial Services: Securing Digital Transactions, Payments and Portfolios </strong></h2>
<p>Banks, asset managers, insurers and other financial service organizations are using AI and machine learning to deliver superior performance in fraud detection, portfolio management, algorithmic trading and self-service banking.</p>
<p>With constant digital transactions, payments, loans and investment trades, <a href="https://www.nvidia.com/en-us/industries/finance/">financial service institutions</a> manage some of the largest, most complex and most sensitive datasets of any industry. Behind only the healthcare industry, these organizations suffer the second highest cost of a data breach, at <a href="https://www.ibm.com/downloads/cas/E3G5JMBP">nearly $6 million</a> per incident. This cost grows if regulators issue fines or if recovery includes legal fees and lawsuit settlements. Worse still, lost business may never be recovered if trust can’t be repaired.</p>
<p>Banks and financial institutions use AI to improve insider threat detection, detect phishing and ransomware, and keep sensitive information safe.</p>
<p><a href="https://www.nvidia.com/en-us/on-demand/session/gtcspring23-S51437/">FinSec Innovation Lab</a>, a joint venture by Mastercard and Enel X, is using AI to help its customers defend against ransomware. Prior to working with FinSec, one card-processing customer suffered a LockBit ransomware attack in which 200 company servers were infected in just 1.5 hours. The company was forced to shut down servers and suspend operations, resulting in an estimated $7 million in lost business.</p>
<p>FinSec replicated this attack in its lab but deployed the <a href="http://nvidia.com/morpheus">NVIDIA Morpheus</a> cybersecurity framework, <a href="https://developer.nvidia.com/networking/doca">NVIDIA DOCA</a> software framework for intrusion detection and <a href="https://www.nvidia.com/en-us/networking/products/data-processing-unit/">NVIDIA BlueField DPU</a> computing clusters. With this mix of AI and accelerated computing, FinSec was able to detect the ransomware attack in less than 12 seconds, quickly isolate virtual machines and recover 80% of the data on infected servers. This type of real-time response helps businesses avoid service downtime and lost business while maintaining customer trust.</p>
<p>With AI to help defend against cyberattacks, financial institutions can identify intrusions and anticipate future threats to keep financial records, accounts and transactions secure.</p>
<h2><strong>Retail: Keeping Sales Channels and Payment Credentials Safe</strong></h2>
<p>Retailers are using AI to power personalized product recommendations, dynamic pricing and customized marketing campaigns. Multichannel digital platforms have made in-store and online shopping more convenient: up to <a href="https://navigate.visa.com/na/spending-insights/seven-ways-to-use-card-on-file-to-reach-top-of-digital-wallet/">48% of consumers</a> save a card on file with a merchant, significantly boosting card-not-present transactions. While digitization has brought convenience, it has also made sensitive data more accessible to attackers.</p>
<p>Sitting on troves of digital payment credentials for millions of customers, retailers are a prime target for cybercriminals looking to take advantage of security gaps. According to a recent <a href="https://www.verizon.com/business/resources/reports/dbir/2023/master-guide/">Data Breach Investigations Report</a> from Verizon, 37% of confirmed data disclosures in the retail industry resulted in stolen payment card data.</p>
<p>Malware attacks, ransomware and distributed denial of service attacks are all on the rise, but phishing remains the favored vector for an initial attack. With a successful phishing intrusion, criminals can steal credentials, access systems and launch ransomware.</p>
<p>Best Buy manages a network of more than 1,000 stores across the U.S. and Canada. With multichannel digital sales across both countries, protecting consumer information and transactions is critical. To defend against phishing and other cyber threats, Best Buy began using customized machine learning and NVIDIA Morpheus to better secure their infrastructure and inform their security analysts.</p>
<p>After deploying this AI-based cyber defense, the retail giant improved the <a href="https://developer.nvidia.com/blog/nvidia-morpheus-helps-defend-against-spear-phishing-with-generative-ai/">accuracy of phishing detection to 96%</a> while reducing false-positive rates. With a proactive approach to cybersecurity, Best Buy is protecting its reputation as a tech expert focused on customer needs.</p>
<p>From complex supply chains to third-party vendors and multichannel point-of-sale networks, expect <a href="https://info.nvidia.com/retail-cybersecurity-webinar.html">retailers to continue integrating AI</a> to protect operations as well as critical proprietary and customer data.</p>
<h2><strong>Smart Cities and Spaces: Protecting Critical Infrastructure and Transit Networks</strong></h2>
<p>IoT devices and AI that analyze movement patterns, traffic and hazardous situations have great potential to improve the safety and efficiency of spaces and infrastructure. But as airports, shipping ports, transit networks and other <a href="https://www.nvidia.com/en-us/industries/smart-cities-and-spaces/">smart spaces</a> integrate IoT and use data, they also become more vulnerable to attack.</p>
<p>In the last couple of years, there have been distributed denial of service (DDoS) attacks on airports and air traffic control centers and ransomware attacks on seaports, city municipalities, police departments and more. Attacks can paralyze information systems, ground flights, disrupt the flow of cargo and traffic, and delay the delivery of goods to markets. Hostile attacks could have far more serious consequences, including physical harm or loss of life.</p>
<p>In connected spaces, AI-driven security can analyze vast amounts of data to predict threats, isolate attacks and provide rapid self-healing after an intrusion. AI algorithms trained on emails can halt threats in the inbox and block phishing attempts like those that delivered <a href="https://www.cnn.com/2023/07/06/tech/japan-port-ransomware-attack/index.html">ransomware to seaports earlier</a> this year. Machine learning can be trained to recognize DDoS attack patterns to prevent the type of incoming malicious traffic that <a href="https://apnews.com/article/technology-business-atlanta-680cf93f7eb0300127448c35299ad66e">brought down U.S. airport websites</a> last year.</p>
<p>Organizations adopting smart space technology, such as the Port of Los Angeles, are making efforts to get ahead of the threat landscape. In 2014, the Port of LA established a cybersecurity operations center and hired a dedicated cybersecurity team. In 2021, the port followed up with a cyber resilience center to enhance early-warning detection for cyberattacks that have the potential to impact the flow of cargo.</p>
<p>The U.S. Federal Aviation Administration has developed an <a href="https://www.faa.gov/sites/faa.gov/files/2022-08/PL_115-254_Sec_741_Certification_of_New_Technologies_into_the_NAS.pdf">AI certification framework</a> that assesses the trustworthiness of AI and ML applications. The FAA also implements a <a href="https://blogs.nvidia.com/blog/2022/06/07/what-is-zero-trust/">zero-trust</a> cyber approach, enforces strict access control and runs continuous verification across its digital environment.</p>
<p>By bolstering cybersecurity and integrating AI, smart space and transport infrastructure administrators can offer secure access to physical spaces and digital networks to protect the uninterrupted movement of people and goods.</p>
<h2><strong>Telecommunications: Ensure Network Resilience and Block Incoming Threats</strong></h2>
<p><a href="https://www.nvidia.com/en-us/industries/telecommunications/">Telecommunications</a> companies are leaning into AI to power predictive maintenance and maximum network uptime, network optimization, equipment troubleshooting, call-routing and self-service systems.</p>
<p>The industry is responsible for critical national infrastructure in every country, supports over <a href="https://blogs.nvidia.com/blog/2023/02/21/telco-survey-ai/">5 billion</a> customer endpoints and is expected to constantly deliver above 99% reliability. As reliance on cloud, IoT and edge computing expands and 5G becomes the norm, immense digital surface areas must be protected from misuse and malicious attack.</p>
<p>Telcos can deploy AI to ensure the security and resilience of networks. AI can monitor IoT devices and edge networks to detect anomalies and intrusions, identify fake users, mitigate attacks and quarantine infected devices. AI can continuously assess the trustworthiness of devices, users and applications, thereby shortening the time needed to identify fraudsters.</p>
<p>Pretrained AI models can be deployed to protect 5G networks from threats such as malware, data exfiltration and DOS attacks.</p>
<p>Using deep learning and NVIDIA BlueField DPUs, <a href="https://blogs.nvidia.com/blog/2021/07/12/palo-alto-networks-cyber-defenses/">Palo Alto Networks</a> has built a next-generation firewall addressing 5G needs, maximizing cybersecurity performance while maintaining a small infrastructure footprint. The DPU powers accelerated intelligent network filtering to parse, classify and steer traffic to improve performance and isolate threats. With more efficient computing that deploys fewer servers, telcos can maximize return on investment for compute investments and minimize digital attack surface areas.</p>
<p>By putting AI to work, telcos can build secure, encrypted networks to ensure network availability and data security for both individual and enterprise customers.</p>
<h2><strong>Automotive: Insulate Vehicle Software From Outside Influence and Attack </strong></h2>
<p>Modern cars <a href="https://www.nvidia.com/en-us/self-driving-cars/">rely on complex AI and ML</a> software stacks running on in-vehicle computers to process data from cameras and other sensors. These vehicles are essentially giant, moving IoT devices — they perceive the environment, make decisions, advise drivers and even control the vehicle with autonomous driving features.</p>
<p>Like other connected devices, autonomous vehicles are susceptible to various types of cyberattacks. Bad actors can infiltrate and compromise AV software both on board and from third-party providers. Denial of service attacks can disrupt over-the-air software updates that vehicles rely on to operate safely. Unauthorized access to communications systems like onboard WiFi, Bluetooth or RFID can expose vehicle systems to the risk of remote manipulation and data theft. This can jeopardize geolocation and sensor data, operational data, driver and passenger data, all of which are crucial to functional safety and the driving experience.</p>
<p>AI-based cybersecurity can help monitor in-car and network activities in real time, allowing for rapid response to threats. AI can be deployed to secure and authenticate over-the-air updates to prevent tampering and ensure the authenticity of software updates. AI-driven encryption can protect data transmitted over WiFi, Bluetooth and RFID connections. AI can also probe vehicle systems for vulnerabilities and take remedial steps.</p>
<p>Ranging from AI-powered access control to unlock and start vehicles to detecting deviations in sensor performance and patching security vulnerabilities, AI will play a crucial role in the safe development and deployment of autonomous vehicles on our roads.</p>
<h2><strong>Keeping Operations Secure and Customers Happy With AI Cybersecurity </strong></h2>
<p>By deploying AI to protect valuable data and digital operations, industries can focus their resources on innovating better products, improving customer experiences and creating new business value.</p>
<p>NVIDIA offers a number of tools and frameworks to help enterprises swiftly adjust to the evolving cyber risk environment. The NVIDIA Morpheus cybersecurity framework provides developers and software vendors with optimized, easy-to-use tools to build solutions that can proactively detect and mitigate threats while drastically reducing the cost of cyber defense operations. To help defend <a href="https://www.nvidia.com/en-us/ai-data-science/ai-workflows/spear-phishing/">against phishing attempts</a>, the NVIDIA spear phishing detection AI workflow uses NVIDIA Morpheus and synthetic training data created with the NVIDIA NeMo generative AI framework to flag and halt inbox threats.</p>
<p>The Morpheus SDK also enables <a href="https://www.nvidia.com/en-us/ai-data-science/ai-workflows/digital-fingerprinting/">digital fingerprinting</a> to collect and analyze behavior characteristics for every user, service, account and machine across a network to identify atypical behavior and alert network operators. With the <a href="https://developer.nvidia.com/networking/doca">NVIDIA DOCA</a> software framework, developers can create software-defined, DPU-accelerated services, while leveraging zero trust to build more secure applications.</p>
<p>AI-based cybersecurity empowers developers across industries to build solutions that can identify, capture and act on threats and anomalies to ensure business continuity and uninterrupted service, keeping operations safe and customers happy.</p>
<p><i>Learn how AI can help your organization </i><a href="https://developer.nvidia.com/morpheus-cybersecurity"><i>achieve a proactive cybersecurity posture</i></a><i> to protect customer and proprietary data to the highest standards.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/cybersecurity-for-industries.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/cybersecurity-for-industries-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[How AI-Based Cybersecurity Strengthens Business Resilience]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>How Are Foundation Models Used in Gaming?</title>
		<link>https://blogs.nvidia.com/blog/2023/11/02/foundation-models-gaming/</link>
		
		<dc:creator><![CDATA[Ike Nnoli]]></dc:creator>
		<pubDate>Thu, 02 Nov 2023 16:25:47 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Game Development]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67836</guid>

					<description><![CDATA[AI technologies are having a massive impact across industries, including media and entertainment, automotive, customer service and more.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>AI technologies are having a massive impact across industries, including media and entertainment, automotive, customer service and more. For game developers, these advances are paving the way for creating more realistic and immersive in-game experiences.</p>
<p>From creating lifelike characters that convey emotions to transforming simple text into captivating imagery, <a href="https://blogs.nvidia.com/blog/2023/03/13/what-are-foundation-models/" target="_blank" rel="noopener">foundation models</a> are becoming essential in accelerating developer workflows while reducing overall costs. These powerful AI models have unlocked a realm of possibilities, empowering designers and game developers to build higher-quality gaming experiences.</p>
<h2><b>What Are Foundation Models?</b></h2>
<p>A foundation model is a neural network that’s trained on massive amounts of data — and then adapted to tackle a wide variety of tasks. They’re capable of enabling a range of general tasks, such as text, image and audio generation. Over the last year, the popularity and use of foundation models has rapidly increased, with hundreds now available.</p>
<p>For example, GPT-4 is a large multimodal model developed by OpenAI that can generate human-like text based on context and past conversations. Another, DALL-E 3, can create realistic images and artwork from a description written in natural language.</p>
<p>Powerful foundation models like <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/" target="_blank" rel="noopener">NVIDIA NeMo</a> and Edify model in <a href="https://www.nvidia.com/en-us/gpu-cloud/picasso/" target="_blank" rel="noopener">NVIDIA Picasso</a> make it easy for companies and developers to inject AI into their existing workflows. For example, using the NVIDIA NeMo framework, organizations can quickly train, customize and deploy <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/" target="_blank" rel="noopener">generative AI</a> models at scale. And using NVIDIA Picasso, teams can fine-tune pretrained Edify models with their own enterprise data to build custom products and services for generative AI images, videos, 3D assets, texture materials and 360 HDRi.</p>
<p><iframe loading="lazy" title="NVIDIA NeMo Service | Boosting Enterprise Productivity with Customized Generative AI Models" width="500" height="281" src="https://www.youtube.com/embed/J86qoG6zG58?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>How Are Foundation Models Built?</b></h2>
<p>Foundation models can be used as a base for AI systems that can perform multiple tasks. Organizations can easily and quickly use a large amount of unlabeled data to create their own foundation models.</p>
<p>The dataset should be as large and diverse as possible, as too little data or poor-quality data can lead to inaccuracies — sometimes called hallucinations — or cause finer details to go missing in generated outputs.</p>
<p>Next, the dataset must be prepared. This includes cleaning the data, removing errors and formatting it in such a way that the model can understand it. Bias is a pervasive issue when preparing a dataset, so it’s important to <a href="https://dl.acm.org/doi/10.1145/3597307" target="_blank" rel="noopener">measure, reduce and tackle</a> these inconsistencies and inaccuracies.</p>
<p>Training a foundational model can be time-consuming, especially given the size of the model and the amount of data required. Hardware like NVIDIA A100 or H100 Tensor Core GPUs, along with high-performance data systems like the NVIDIA DGX SuperPOD, can accelerate training. For example, ChatGPT-3 was trained on over 1,000 NVIDIA A100 GPUs over about 34 days.</p>
<figure id="attachment_67849" aria-describedby="caption-attachment-67849" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/foundation-model-explainer-copy.jpg"><img decoding="async" loading="lazy" class="size-large wp-image-67849" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/foundation-model-explainer-copy-672x357.jpg" alt="" width="672" height="357" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/foundation-model-explainer-copy-672x357.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/foundation-model-explainer-copy-400x213.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/foundation-model-explainer-copy-768x408.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/foundation-model-explainer-copy-842x447.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/11/foundation-model-explainer-copy-406x215.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/11/foundation-model-explainer-copy-188x100.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/11/foundation-model-explainer-copy.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67849" class="wp-caption-text">The three requirements of a successful foundation model.</figcaption></figure>
<p>After ‌training, the foundation model is evaluated on quality, diversity and speed. There are <a href="https://research.aimultiple.com/large-language-model-evaluation/#5-commonly-used-performance-evaluation-methods" target="_blank" rel="noopener">several methods</a> for evaluating performance, for example:</p>
<ul>
<li>Tools and frameworks that quantify how well the model predicts a sample of text</li>
<li>Metrics that compare generated outputs with one or more references and measure the similarities between them</li>
<li>Human evaluators who assess the quality of the generated output on various criteria</li>
</ul>
<p>Once the model passes the relevant tests and evaluations, it can then be deployed for production.</p>
<h2><b>Exploring Foundation Models in Games</b></h2>
<p>Pretrained foundation models can be leveraged by middleware, tools and game developers both during production and at run-time. To train a base model, resources and time are necessary — alongside a certain level of expertise. Currently, many developers within the gaming industry are exploring off-the-shelf models, but need custom solutions that fit their specific use cases. They need models that are trained on commercially safe data and optimized for real-time performance — without exorbitant costs of deployment. The difficulty of meeting these requirements has slowed adoption of foundation models.</p>
<p>However, innovation within the generative AI space is swift, and once major hurdles are addressed, developers of all sizes — from startups to AAA studios — will use foundation models to gain new efficiencies in game development and accelerate content creation. Additionally, these models can help create completely new gameplay experiences.</p>
<p><iframe loading="lazy" title="NVIDIA ACE Enhanced with Dynamic Responses for Virtual Characters" width="500" height="281" src="https://www.youtube.com/embed/lf0z8Z3OQvM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>The top industry use cases are centered around intelligent agents and AI-powered animation and asset creation. For example, many creators today are exploring models for creating intelligent non-playable characters, or NPCs.</p>
<p>Custom LLMs fine-tuned with the lingo and lore of specific games can generate human-like text, understand context and respond to prompts in a coherent manner. They’re designed to learn patterns and language structures and understand game state changes — evolving and progressing alongside the player in the game.</p>
<p>As NPCs become increasingly dynamic,real-time animation and audio that sync with their responses will be needed. Developers are using <a href="https://www.nvidia.com/en-us/ai-data-science/products/riva/" target="_blank" rel="noopener">NVIDIA Riva</a> to create expressive character voices using speech and translation AI. And designers are tapping <a href="https://www.nvidia.com/en-us/omniverse/apps/audio2face/" target="_blank" rel="noopener">NVIDIA Audio2Face</a> for AI-powered facial animations.</p>
<p>Foundation models are also being used for asset and animation generation. Asset creation during the pre-production and production phases of game development can be time-consuming, tedious and expensive.</p>
<p>With state-of-the-art diffusion models, developers can iterate more quickly, freeing up time to spend on the most important aspects of the content pipeline, such as developing higher-quality assets and iterating. The ability to fine-tune these models from a studio’s own repository of data ensures the outputs generated are similar to the art styles and designs of their previous games.</p>
<p>Foundation models are readily available, and the gaming industry is only in the beginning phases of understanding their full capabilities. Various solutions have been built for real-time experiences, but the use cases are limited. Fortunately, developers can easily access models and microservices through cloud APIs today and explore how AI can affect their games and scale their solutions to more customers and devices than ever before.</p>
<h2><b>The Future of Foundation Models in Gaming</b><b><br />
</b></h2>
<p>Foundation models are poised to help developers realize the future of gaming. Diffusion models and <a href="https://www.nvidia.com/en-us/glossary/data-science/large-language-models/" target="_blank" rel="noopener">large language models</a> are becoming much more lightweight as developers look to run them natively on a range of hardware power profiles, including PCs, consoles and mobile devices.</p>
<p>The accuracy and quality of these models will only continue to improve as developers look to generate high-quality assets that need little to no touching up before being dropped into an AAA gaming experience.</p>
<p>Foundation models will also be used in areas that have been challenging for developers to overcome with traditional technology. For example, autonomous agents can help analyze and detect world space during game development, which will accelerate processes for quality assurance.</p>
<p>The rise of multimodal foundation models, which can ingest a mix of text, image, audio and other inputs simultaneously, will further enhance player interactions with intelligent NPCs and other game systems. Also, developers can use additional input types to improve creativity and enhance the quality of generated assets during production.</p>
<p>Multimodal models also show great promise in improving the animation of real-time characters, one of the most time-intensive and expensive processes of game development. They may be able to help make characters’ locomotion identical to real-life actors, infuse style and feel from a range of inputs, and ease the rigging process.</p>
<h2><b>Learn More About Foundation Models in Gaming</b></h2>
<p>From enhancing dialogue and generating 3D content to creating interactive gameplay, foundation models have opened up new opportunities for developers to forge the future of gaming experiences.</p>
<p>Learn more about <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/" target="_blank" rel="noopener">foundation models</a> and other technologies powering <a href="https://developer.nvidia.com/industries/game-development" target="_blank" rel="noopener">game development workflows</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/foundation-model-explainer-feature-image.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/foundation-model-explainer-feature-image-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[How Are Foundation Models Used in Gaming?]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>GeForce NOW-vember Brings Over 50 New Games to Stream In the Cloud</title>
		<link>https://blogs.nvidia.com/blog/2023/11/02/geforce-now-thursday-nov-2/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 02 Nov 2023 13:00:31 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67845</guid>

					<description><![CDATA[Gear up with gratitude for more gaming time. GeForce NOW brings members a cornucopia of 15 newly supported games to the cloud this week. That’s just the start — there are a total of 54 titles coming in the month of November. Members can also join thousands of esports fans in the cloud with the <a class="read-more" href="https://blogs.nvidia.com/blog/2023/11/02/geforce-now-thursday-nov-2/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Gear up with gratitude for more gaming time. <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> brings members a cornucopia of 15 newly supported games to the cloud this week. That’s just the start — there are a total of 54 titles coming in the month of November<i>.</i></p>
<p>Members can also join thousands of esports fans in the cloud with the addition of Virtex Stadium to the GeForce NOW library for a ‘League of Legends’ world championship viewing party.</p>
<h2><b>Esports Like Never Before</b></h2>
<figure id="attachment_67856" aria-describedby="caption-attachment-67856" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" loading="lazy" class="size-large wp-image-67856" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Virtex_Stadium-672x336.jpg" alt="Virtex Stadium on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Virtex_Stadium-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Virtex_Stadium-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Virtex_Stadium-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Virtex_Stadium-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Virtex_Stadium-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Virtex_Stadium-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Virtex_Stadium-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Virtex_Stadium-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Virtex_Stadium.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-67856" class="wp-caption-text"><em>Watch “League of Legends” esports like never before.</em></figcaption></figure>
<p>This year’s <i>League of Legends</i> world championship finals are coming to Virtex Stadium — an online virtual stadium now streaming on NVIDIA’s cloud gaming infrastructure.</p>
<p>In Virtex Stadium, esports fans can hang out with friends from across the world, create and personalize avatars, and watch live competitions together — all from the comfort of their homes.</p>
<p>Starting on Thursday, Nov. 2, watch <i>League of Legends</i> Worlds 2023 in Virtex Stadium with thousands of others. Use props and emotes to cheer players on together via chat.</p>
<p>GeForce NOW members and <i>League of Legends</i> fans can drop into Virtex Stadium without needing to create a new login. Within the Virtex Stadium app, members can choose to create a “Ready Player Me” avatar and account to save their digital characters for future visits. Members can even link their Twitch accounts to chat and emote with other viewers while in the stadium.</p>
<p>Catch all the action on the following dates:</p>
<ul>
<li>Quarterfinal 1: Nov. 2 at 9 a.m. CET</li>
<li>Quarterfinal 2: Nov. 3 at 9 a.m. CET</li>
<li>Quarterfinal 3: Nov. 4 at 9 a.m. CET</li>
<li>Quarterfinal 4: Nov. 5 at 9 a.m. CET</li>
<li>Semifinal 1: Nov. 11 at 9 a.m. CET</li>
<li>Semifinal 2: Nov. 12 at 9 a.m. CET</li>
<li>Final: Nov. 19 at 9 a.m. CET</li>
</ul>
<h2><b>Time to Shine</b></h2>
<figure id="attachment_67853" aria-describedby="caption-attachment-67853" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" loading="lazy" class="size-large wp-image-67853" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Apex_Legends_Ignite-672x336.jpg" alt="Apex Legends: Ignite on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Apex_Legends_Ignite-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Apex_Legends_Ignite-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Apex_Legends_Ignite-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Apex_Legends_Ignite-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Apex_Legends_Ignite-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Apex_Legends_Ignite-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Apex_Legends_Ignite-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Apex_Legends_Ignite-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Apex_Legends_Ignite.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-67853" class="wp-caption-text"><em>SHINY!</em></figcaption></figure>
<p>Electronic Arts’ and Respawn Entertainment’s <i>Apex Legends: Ignite</i>, the newest season for the battle royale first-person shooter, is now available to stream from the cloud. Light the way with Conduit, the new support Legend with shield-based abilities. Plus, check out a faster and deadlier Storm Point map, a new Battle Pass with rewards, and more to help ignite <i>Apex Legends</i> players’ ways to victory.</p>
<p>Members can start their adventures now, along with 15 other games newly supported in the cloud this week:</p>
<ul>
<li><i>Headbangers: Rhythm Royale</i> (New release on <a href="https://store.steampowered.com/app/1761620?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.xbox.com/games/store/headbangers-rhythm-royale/9ngrwj03gr1n?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox </a>and available on PC Game Pass, Oct. 31)</li>
<li><i>Jusant </i>(New release on <a href="https://store.steampowered.com/app/1977170?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.xbox.com/games/store/jusant/9PJB1ZRJDCBQ?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass, Oct. 31)</li>
<li><i>RoboCop: Rogue City </i>(New release on <a href="https://store.steampowered.com/app/1681430?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Nov. 2)</li>
<li><i>The Talos Principle 2 </i>(New release on <a href="https://store.steampowered.com/app/835960?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Nov. 2)</li>
<li><i>StrangerZ </i>(New release on <a href="https://store.steampowered.com/app/2293600?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Nov. 3)</li>
<li><i>Curse of the Dead Gods </i>(<a href="https://www.xbox.com/games/store/curse-of-the-dead-gods-pc/9nlw8wfh4rqt?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Daymare 1994: Sandcastle </i>(<a href="https://store.steampowered.com/app/1530470?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>ENDLESS Dungeon </i>(<a href="https://store.steampowered.com/app/1485590?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>F1 Manager 202</i>3 (<a href="https://www.xbox.com/games/store/f1-manager-2023/9P80FVDCXJKB?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Heretic’s Fork </i>(<a href="https://store.steampowered.com/app/2181610?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>HOT WHEELS UNLEASHED 2 &#8211; Turbocharged </i>(<a href="https://www.epicgames.com/store/p/hot-wheels-unleashed-2?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Kingdoms Reborn </i>(<a href="https://store.steampowered.com/app/1307890?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Q.U.B.E. 2</i> (<a href="https://www.epicgames.com/store/p/q-u-b-e-2--deluxe-edition?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Soulstice </i>(<a href="https://www.epicgames.com/store/p/soulstice?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Virtex Stadium </i>(Free)</li>
</ul>
<p>Then check out the plentiful games for the rest of November:</p>
<ul>
<li><i>The Invincible </i>(New release on <a href="https://store.steampowered.com/app/731040?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Nov 6.)</li>
<li><i>Roboquest </i>(New release on <a href="https://store.steampowered.com/app/692890?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Nov. 7)</li>
<li><i>Stronghold: Definitive Edition </i>(New release on <a href="https://store.steampowered.com/app/2140020?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Nov. 7)</li>
<li><i>Dungeons 4 </i>(New release on <a href="https://store.steampowered.com/app/1643310?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.xbox.com/games/store/dungeons-4-win/9nd9bbmdvd2c?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass, Nov. 9)</li>
<li><i>Space Trash Scavenger </i>(New release on <a href="https://store.steampowered.com/app/1759350?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Nov. 9)</li>
<li><i>Spirittea </i>(New release on <a href="https://store.steampowered.com/app/1931010?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.xbox.com/games/store/spirittea/9PPK59BXLD4N?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass, Nov 13)</li>
<li><i>Naheulbeuk&#8217;s Dungeon Master</i> (New release on <a href="https://store.steampowered.com/app/2005160?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Nov 15)</li>
<li><i>Last Train Home </i>(New release on <a href="https://store.steampowered.com/app/1469610?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Nov. 28)</li>
<li><i>Gangs of Sherwood  </i>(New release on <a href="https://store.steampowered.com/app/1351000?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Nov. 30)</li>
<li><i>Airport CEO </i>(<a href="https://store.steampowered.com/app/673610?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Arcana of Paradise —The Tower </i>(<a href="https://store.steampowered.com/app/2089500/Arcana_of_Paradise_The_Tower/">Steam</a>)</li>
<li><i>Blazing Sails: Pirate Battle Royale</i> (<a href="https://www.epicgames.com/store/p/blazing-sails?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Breathedge</i> (<a href="https://www.xbox.com/games/store/breathedge/9PHJSGJNX37S?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Bridge Constructor: The Walking Dead </i>(<a href="https://www.xbox.com/games/store/bridge-constructor-the-walking-dead/9P1LWFXNQVQ0?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Bus Simulator 21 </i>(<a href="https://www.xbox.com/games/store/bus-simulator-21-next-stop-gold-edition/9PFBJC0VVTMB?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Farming Simulator 19 </i>(<a href="https://www.xbox.com/games/store/farming-simulator-19-premium-edition-windows-10/9NJJC9Z14WT0?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>GoNNER </i>(<a href="https://www.xbox.com/games/store/gonner-win10/9PBM5VSZDW5C?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>GoNNER2 </i>(<a href="https://www.xbox.com/games/store/gonner2-win10/9P44W70MC99Z?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Hearts of Iron IV </i>(<a href="https://www.xbox.com/games/store/hearts-of-iron-iv/9NF6WPNS1S73?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Hexarchy</i> (<a href="https://store.steampowered.com/app/1356810?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>I Am Future </i>(<a href="https://www.epicgames.com/store/p/i-am-future-cozy-apocalypse-survival-6b452c?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Imagine Earth </i>(<a href="https://www.xbox.com/games/store/imagine-earth/9NPLW3TFSVH0?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Jurassic World</i> <i>Evolution 2</i> (<a href="https://www.xbox.com/games/store/jurassic-world-evolution-2/9MWHMJ0SRBXV?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Land of the Vikings </i>(<a href="https://store.steampowered.com/app/1981570?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Onimusha: Warlords </i>(<a href="https://store.steampowered.com/app/761600?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Overcooked! 2 </i>(<a href="https://www.xbox.com/en-us/games/store/Overcooked-2/BVJLKDG2TX8H">Xbox</a>, available on Microsoft Store)</li>
<li><i>Saints Row IV </i>(<a href="https://www.xbox.com/games/store/saints-row-iv-re-elected/9NFVLZQDZHKW?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Settlement Survival </i>(<a href="https://store.steampowered.com/app/1509510?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>SHENZHEN I/O </i>(<a href="https://www.xbox.com/games/store/shenzhen-io/9P1JHJ127HR4?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>SOULVARS </i>(<a href="https://store.steampowered.com/app/2087910?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>The Surge 2</i> (<a href="https://www.xbox.com/games/store/the-surge-2-premium-edition/9NK73WHQZKDS?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Thymesia </i>(<a href="https://www.xbox.com/games/store/thymesia/9N68F8TM7TKW?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Trailmakers</i> (<a href="https://www.xbox.com/games/store/trailmakers/9NSFGM8J6MBJ?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Tropico 6 </i>(<a href="https://www.xbox.com/games/store/tropico-6/9N2VDJVMFKQ9?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Wartales </i>(<a href="https://www.xbox.com/games/store/wartales/9NWQ686JB33G?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>The Wonderful One: After School Hero </i>(<a href="https://store.steampowered.com/app/2399600?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Warhammer Age of Sigmar: Realms of Ruin </i>(Steam)</li>
<li><i>West of Dead</i> (<a href="https://www.xbox.com/games/store/west-of-dead-path-of-the-crow-edition/9NSXQS17N797?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Wolfenstein: The New Order </i>(<a href="https://www.xbox.com/games/store/wolfenstein-the-new-order-pc/9p75cbj9wt9w?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Wolfenstein: The Old Blood </i>(<a href="https://store.steampowered.com/app/350080?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.epicgames.com/store/p/wolfenstein-the-old-blood?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, <a href="https://www.xbox.com/games/store/wolfenstein-the-old-blood-pc/9pbb4qhmsdkr?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox </a>and available on PC Game Pass)</li>
</ul>
<h2><b>Outstanding October</b></h2>
<p>On top of the 60 games announced in October, an additional 48 joined the cloud last month, including several from this week’s additions, <i>Curse of the Dead Gods, ENDLESS Dungeon, Farming Simulator 19, Hearts of Iron IV, Kingdoms Reborn, RoboCop: Rogue City, StrangerZ, The Talos Principle 2, Thymesia, Tropico 6 </i>and <i>Virtex Stadium</i>:<i></i></p>
<ul>
<li><i>AirportSim </i>(New release on <a href="https://store.steampowered.com/app/1715280?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Oct. 19)</li>
<li><i>Battle Chasers: Nightwar </i>(<a href="https://www.xbox.com/en-us/games/store/battle-chasers-nightwar/9nt8xr7d5l00">Xbox</a>, available on Microsoft Store)</li>
<li><i>Black Skylands </i>(<a href="https://www.xbox.com/games/store/black-skylands/9N9TTNP04TTK?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Blair Witch </i>(<a href="https://www.xbox.com/en-US/games/store/blair-witch/9ng7lg421v0q">Xbox</a>, available on Microsoft Store)</li>
<li><i>Call of the Sea </i>(<a href="https://www.xbox.com/games/store/call-of-the-sea/9NNG78K7N91K?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store</li>
<li><i>Chicory: A Colorful Tale </i>(<a href="https://www.xbox.com/games/store/chicory-a-colorful-tale/9PFGQGC0XWLV?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Cricket 22 </i>(<a href="https://www.xbox.com/games/store/cricket-22/9NWNX54ZMT1K?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Dead by Daylight</i> (<a href="https://www.xbox.com/games/store/dead-by-daylight-windows/9NMS4SFNBGBH?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Deceive Inc. </i>(<a href="https://www.epicgames.com/store/p/deceive-inc?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Dishonored </i>(<a href="https://store.steampowered.com/app/205100?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Dishonored: Death of the Outsider </i>(<a href="https://store.steampowered.com/app/614570?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.epicgames.com/store/p/dishonored-death-of-the-outsider?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, <a href="https://www.xbox.com/games/store/dishonored-death-of-the-outsider-pc/9MVF0PGV94F7?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Dishonored Definitive Edition</i> (<a href="https://www.epicgames.com/store/p/dishonored-definitive-edition?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, <a href="https://www.xbox.com/games/store/dishonored-definitive-edition-pc/9P1N07XDL1D4?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox </a>and available on PC Game Pass)</li>
<li><i>Dishonored 2 </i>(<a href="https://store.steampowered.com/app/403640?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.epicgames.com/store/p/dishonored-2?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, <a href="https://www.xbox.com/games/store/dishonored-2/9MW4RJDRSF78?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Dune: Spice Wars </i>(<a href="https://www.xbox.com/games/store/dune-spice-wars-game-preview/9N46JZZNGS3P?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Eternal Threads </i>(New release on <a href="https://www.epicgames.com/store/p/eternal-threads-197169?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, Oct. 19)</li>
<li><i>Everspace 2 </i>(<a href="https://www.xbox.com/games/store/everspace-2/9PFX7F33KVG8?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>EXAPUNKS</i> (<a href="https://www.xbox.com/games/store/exapunks/9P87731ZDLG0?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>From Space</i> (New release on <a href="https://www.xbox.com/games/store/from-space/9PLK75782446?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass, Oct. 12)</li>
<li><i>Ghostrunner 2 </i>(New release on <a href="https://store.steampowered.com/app/2144740?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Oct. 26)</li>
<li><i>Ghostwire: Tokyo </i>(<a href="https://store.steampowered.com/app/1475810?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.epicgames.com/store/p/ghostwire-tokyo?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, <a href="https://www.xbox.com/games/store/ghostwire-tokyo/9PKP39CL0C8D?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox </a>and available on PC Game Pass)</li>
<li><i>Golf With Your Friends</i> (<a href="https://www.xbox.com/games/store/golf-with-your-friends-windows-version/9MVK5W0HMRP7?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Gungrave G.O.R.E </i>(<a href="https://www.xbox.com/games/store/gungrave-gore/9P87CLMPXSN6?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>The Gunk </i>(<a href="https://www.xbox.com/games/store/the-gunk/9P008L2LS87F?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Hotel: A Resort Simulator </i>(New release on <a href="https://store.steampowered.com/app/1389840?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Oct. 12)</li>
<li><i>Kill It With Fire </i>(<a href="https://www.xbox.com/games/store/kill-it-with-fire/9MZVSHQZ666K?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Railway Empire 2 </i>(<a href="https://www.xbox.com/games/store/railway-empire-2-win/9NDXLPW4TTF2?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Rubber Bandits </i>(<a href="https://www.xbox.com/games/store//rubber-bandits/9PL36RW9ZTPW?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)<i>Saints Row IV </i>(<a href="https://www.xbox.com/games/store/saints-row-iv-re-elected/9NFVLZQDZHKW?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Saltsea Chronicles </i>(New release on <a href="https://store.steampowered.com/app/1419620?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Oct. 12)</li>
<li><i>Soulstice </i>(<a href="https://www.epicgames.com/store/p/soulstice?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>State of Decay 2: Juggernaut Edition </i>(<a href="https://store.steampowered.com/app/495420?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.epicgames.com/store/p/state-of-decay-2-juggernaut-edition?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, <a href="https://www.xbox.com/games/store/state-of-decay-2-juggernaut-edition/9nt4x7p8b9nb?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Supraland Six Inches Under </i>(<a href="https://www.epicgames.com/store/p/supraland-six-inches-under-dd0220?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Techtonica </i>(<a href="https://www.xbox.com/games/store/techtonica-game-preview/9nr1rvdk9t78?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Teenage Mutant Ninja Turtles: Shredder’s Revenge </i>(<a href="https://www.xbox.com/games/store/teenage-mutant-ninja-turtles-shredders-revenge/9NS3673HVH41?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Torchlight III </i>(<a href="https://www.xbox.com/games/store/torchlight-iii/9N944BP7SMCG?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Totally Accurate Battle Simulator </i>(<a href="https://www.xbox.com/games/store/totally-accurate-battle-simulator/9PC4RWP34M2D?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Tribe: Primitive Builder</i> (New release on <a href="https://store.steampowered.com/app/1059900?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Oct. 12)</li>
<li><i>Trine 5: A Clockwork Conspiracy </i>(<a href="https://www.epicgames.com/store/p/trine-5?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
</ul>
<p><i>War Hospital </i>didn’t make it in October due to a delay of its launch date. <i>StalCraft </i>and <i>VEILED EXPERTS </i>also didn’t make it in October due to technical issues. Stay tuned to GFN Thursday for more updates.</p>
<p>What are you looking forward to streaming this month? Let us know on <a href="https://www.twitter.com/nvidiagfn">Twitter</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Where is the most unusual place you&#39;ve played a game on GFN? <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f914.png" alt="🤔" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1719746118060216820?ref_src=twsrc%5Etfw">November 1, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/gfn-thursday-11-2-nv-blog-1280x680-no-cta.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/gfn-thursday-11-2-nv-blog-1280x680-no-cta-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[GeForce NOW-vember Brings Over 50 New Games to Stream In the Cloud]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Turing’s Mill: AI Supercomputer Revs UK’s Economic Engine</title>
		<link>https://blogs.nvidia.com/blog/2023/11/01/uk-largest-ai-supercomputer/</link>
		
		<dc:creator><![CDATA[Dion Harris]]></dc:creator>
		<pubDate>Wed, 01 Nov 2023 16:04:31 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Supercomputing]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Customer Stories]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<category><![CDATA[Industrial and Manufacturing]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[NVIDIA in Europe]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67827</guid>

					<description><![CDATA[The home of the first industrial revolution just made a massive investment in the next one. The U.K. government has announced it will spend £225 million ($273 million) to build one of the world’s fastest AI supercomputers. Called Isambard-AI, it’s the latest in a series of systems named after a legendary 19th century British engineer <a class="read-more" href="https://blogs.nvidia.com/blog/2023/11/01/uk-largest-ai-supercomputer/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The home of the first industrial revolution just made a massive investment in the next one.</p>
<p>The U.K. government has announced it will spend £225 million ($273 million) to build one of the world’s fastest AI supercomputers.</p>
<p>Called Isambard-AI, it’s the latest in a series of systems named after a legendary 19th century British engineer and hosted by the University of Bristol. When fully installed next year, it will pack 5,448 <a href="https://www.nvidia.com/en-us/data-center/grace-hopper-superchip/">NVIDIA GH200 Grace Hopper Superchips</a> to deliver a whopping 21 exaflops of AI performance for researchers across the country and beyond.</p>
<p>The announcement was made at the AI Safety Summit, a gathering of over 100 global government and technology leaders, held in Bletchley Park, the site of the world’s first digital programmable computer, which reflected the work of innovators like Alan Turing, considered the father of AI.</p>
<p>AI “will bring a transformation as far-reaching as the industrial revolution, the coming of electricity or the birth of the internet,” said British Prime Minister Rishi Sunak in a speech last week about the event, designed to catalyze international collaboration.</p>
<h2><b>Propelling the Modern Economy</b></h2>
<p>Like one of Isambard Brunel’s creations — the first propeller-driven, ocean-going iron ship — the AI technology running on his namesake is already driving countries forward.</p>
<p>AI contributes more than £3.7 billion to the U.K. economy and employs more than 50,000 people, said Michelle Donelan, the nation’s Science, Innovation and Technology Secretary, in an earlier announcement about the system.</p>
<p>The investment in the so-called AI Research Resource in Bristol “will catalyze scientific discovery and keep the U.K. at the forefront of AI development,” she said.</p>
<p>Like AI itself, the system will be used across a wide range of organizations tapping the potential of machine learning to advance robotics, data analytics, drug discovery, climate research and more.</p>
<p>“Isambard-AI represents a huge leap forward for AI computational power in the U.K.,” said Simon McIntosh-Smith, a Bristol professor and director of the Isambard National Research Facility. “Today, Isambard-AI would rank within the top 10 fastest supercomputers in the world and, when in operation later in 2024, it will be one of the most powerful AI systems for open science anywhere.”</p>
<h2><b>The Next Manufacturing Revolution</b></h2>
<p>Like the industrial revolution, AI promises advances in manufacturing. That’s one reason why Isambard-AI will be based at the National Composites Centre (NCC, pictured above) in the Bristol and Bath Science Park, one of the country’s seven manufacturing research centers.</p>
<p>The U.K.’s Frontier AI Taskforce, a research group leading a global effort on how frontier AI can be safely developed, will also be a major user of the system.</p>
<p>Hewlett Packard Enterprise, which is building Isambard-AI, is also collaborating with the University of Bristol on energy-efficiency plans that support net-zero carbon targets mandated by the British government.</p>
<h2><b>Energy-Efficient HPC</b></h2>
<p>A second system coming next year to the NCC will show Arm’s energy efficiency for non-accelerated high performance computing workloads.</p>
<p>Isambard-3 will deliver an estimated 2.7 petaflops of FP64 peak performance and consume less than 270 kilowatts of power, ranking it among the world’s three greenest non-accelerated supercomputers. That’s because the system — part of a research alliance among universities of Bath, Bristol, Cardiff and Exeter — will sport 384 Arm-based <a href="https://www.nvidia.com/en-us/data-center/grace-cpu-superchip/">NVIDIA Grace CPU Superchips</a> to power medical and scientific research.</p>
<p>“Isambard-3’s application performance efficiency of up to 6x its predecessor, which rivals many of the 50 fastest TOP500 systems, will provide scientists with a revolutionary new supercomputing platform to advance groundbreaking research,” said Bristol’s McIntosh-Smith, when the system was <a href="https://nvidianews.nvidia.com/news/nvidia-grace-drives-wave-of-new-energy-efficient-arm-supercomputers">announced</a> in March.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/NCC-UK-Isambard-AI-site.jpg"
			type="image/jpeg"
			width="1620"
			height="865"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/NCC-UK-Isambard-AI-site-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Turing’s Mill: AI Supercomputer Revs UK’s Economic Engine]]></media:title>
			<media:description type="html">Site for Isambard-AI supercomputer at the University of Bristol</media:description>
			</media:content>
			</item>
		<item>
		<title>Unlocking the Power of Language: NVIDIA’s Annamalai Chockalingam on the Rise of LLMs</title>
		<link>https://blogs.nvidia.com/blog/2023/11/01/llms-podcast/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Wed, 01 Nov 2023 13:00:00 +0000</pubDate>
				<category><![CDATA[The AI Podcast]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67783</guid>

					<description><![CDATA[Generative AI and large language models are stirring change across industries — but according to NVIDIA Senior Product Manager of Developer Marketing Annamalai Chockalingam, “we’re still in the early innings.” In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Chockalingam about LLMs: what they are, their current state and their future <a class="read-more" href="https://blogs.nvidia.com/blog/2023/11/01/llms-podcast/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/">Generative AI</a> and <a href="https://www.nvidia.com/en-us/glossary/data-science/large-language-models/">large language models</a> are stirring change across industries — but according to NVIDIA Senior Product Manager of Developer Marketing Annamalai Chockalingam, “we’re still in the early innings.”</p>
<p>In the latest episode of NVIDIA’s <a href="https://blogs.nvidia.com/ai-podcast/">AI Podcast</a>, host Noah Kravitz spoke with Chockalingam about LLMs: what they are, their current state and their future potential.</p>
<p>Describing LLMs as a “subset of the larger generative AI movement,” Chockalingam says they can do five things with language: generate, summarize, translate, instruct or chat. With a combination of “these modalities and actions, you can build applications” to solve any problem, he said.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1651053912%3Fsecret_token%3Ds-5uJAR5koNPP&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<p>Enterprises are tapping LLMs to drive innovation, develop new customer experiences and gain a competitive advantage, he said. They’re also exploring what safe deployment of those models looks like, aiming to achieve responsible development, trustworthiness and repeatability.</p>
<p>New techniques like retrieval augmented generation could boost LLM development. RAG involves feeding models with up-to-date data sources or third-party APIs to achieve “more appropriate responses,” Chockalingam said — granting them current context so that they can “generate better” answers.</p>
<p>Chockalingam encourages those interested in LLMs to “get your hands dirty and get started” — whether that means using popular applications like ChatGPT or playing with pretrained models in the <a href="https://catalog.ngc.nvidia.com/?filters=&amp;orderBy=weightPopularDESC&amp;query=">NVIDIA NGC catalog</a>.NVIDIA offers a full-stack computing platform for developers and enterprises experimenting with LLMs, with an ecosystem of over 4 million developers and 1,600 generative AI organizations. To learn more, register for <a href="https://www.nvidia.com/en-us/events/llm-developer-day/#:~:text=LLM%20Developer%20Day%20%7C%20November%2017%2C%202023%20%7C%20NVIDIA">LLM Developer Day</a> on Nov. 17 to hear from NVIDIA experts about how best to develop applications.</p>
<h2><strong>Subscribe to the AI Podcast: Now Available on Amazon Music</strong></h2>
<p><a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">The AI Podcast is now available through Amazon Music</a>.</p>
<p>In addition, get the <a href="https://blogs.nvidia.com/ai-podcast/">AI Podcast</a> through <a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439">iTunes</a>, <a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjI2NDAzNDEzMy9zb3VuZHMucnNz">Google Podcasts</a>, <a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm">Google Play</a>, <a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us">Castbox</a>, DoggCatcher, <a href="https://overcast.fm/itunes1186480811/the-ai-podcast">Overcast</a>, <a href="https://player.fm/series/the-ai-podcast">PlayerFM</a>, Pocket Casts, <a href="http://www.podbay.fm/show/1186480811">Podbay</a>, <a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast">PodBean</a>, PodCruncher, PodKicker, <a href="https://soundcloud.com/theaipodcast">Soundcloud</a>, <a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L">Spotify</a>, <a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr">Stitcher</a> and <a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/">TuneIn</a>.</p>
<p>Make the AI Podcast better. Have a few minutes to spare? Fill out <a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short">this listener survey</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast.jpg"
			type="image/jpeg"
			width="1400"
			height="931"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Unlocking the Power of Language: NVIDIA’s Annamalai Chockalingam on the Rise of LLMs]]></media:title>
			<media:description type="html">NVIDIA AI Podcast</media:description>
			</media:content>
			</item>
		<item>
		<title>Riding the Rays: Sunswift Racing Shines in World Solar Challenge Race</title>
		<link>https://blogs.nvidia.com/blog/2023/10/31/sunswift-racing-world-solar-challenge-jetson/</link>
		
		<dc:creator><![CDATA[Scott Martin]]></dc:creator>
		<pubDate>Tue, 31 Oct 2023 16:00:42 +0000</pubDate>
				<category><![CDATA[Autonomous Machines]]></category>
		<category><![CDATA[Corporate]]></category>
		<category><![CDATA[NVIDIA Jetson]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67784</guid>

					<description><![CDATA[In the world’s largest solar race car event of the year, the University of New South Wales Sunswift Racing team is having its day in the sun. The World Solar Challenge, which first began some 35 years ago, attracts academic participants from across the globe. This year’s event drew nearly 100 competitors. The race runs <a class="read-more" href="https://blogs.nvidia.com/blog/2023/10/31/sunswift-racing-world-solar-challenge-jetson/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>In the world’s largest solar race car event of the year, the University of New South Wales Sunswift Racing team is having its day in the sun.</p>
<p>The <a href="https://worldsolarchallenge.org/">World Solar Challenge</a>, which first began some 35 years ago, attracts academic participants from across the globe. This year’s event drew nearly 100 competitors.</p>
<p>The race runs nearly 1,900 miles over the course of about four days and pits challengers in a battle not for speed but for greatest energy efficiency.</p>
<p>UNSW Sydney won the energy efficiency competition and crossed the finish line first, taking the Cruiser Cup with its Sunswift 7 vehicle, which utilizes <a href="https://www.nvidia.com/en-sg/autonomous-machines/embedded-systems/jetson-xavier-nx/">NVIDIA Jetson Xavier NX</a> for energy optimization. It was also the only competitor to race with 4 people on board and a remote mission control team.</p>
<p>“It’s a completely different proposition to say we can use the least amount of energy and arrive in Adelaide before anybody else, but crossing the line first is just about bragging rights,” said Richard Hopkins, project manager at Sunswift and a UNSW professor. Hopkins previously managed Formula 1 race teams in the U.K.</p>
<p>Race organizers bill the event, which cuts across the entire Australian continent on public roads — from Darwin in the north to Adelaide in the south — as the “world’s greatest innovation and engineering challenge contributing to a more sustainable mobility future.” It’s also become a launchpad for students pursuing career paths in the electric vehicle industry.</p>
<p>Like many of the competitors, UNSW is coming back after a three-year hiatus from the race due to the COVID-19 pandemic, making this year’s competition highly anticipated.</p>
<p>“Every single team member needs to understand what they’re doing and what their role is on the team and perform at the very best during those five-and-a-half days,” said Hopkins. “It is exhausting.”</p>
<h2><b>All In on Energy Efficiency  </b></h2>
<p>The race allows participants to start with a fully charged battery and to charge when the vehicles stop for the night at two locations. The remaining energy used, some 90%, comes from the sun and the vehicles’ solar panels.</p>
<p>UNSW’s seventh-generation Sunswift 7 runs algorithms to optimize for energy efficiency, essentially shutting down all nonessential computing to maximize battery life.</p>
<p>The solar electric vehicle relies on <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/">NVIDIA Jetson</a> AI to give it an edge across its roughly 100 automotive monitoring and power management systems.</p>
<p>It can also factor in whether it should drive faster or slower based on weather forecasts. For instance, the car will urge the driver to go faster if it’s going to rain later in the day when conditions would force the car to slow down.</p>
<p>The Sunswift 7 vehicle was designed to mostly drive in a straight line from Darwin to Adelaide, and the object is to use the least amount of power outside of that mission, said Hopkins.</p>
<p>“Sunswift 7 late last year was featured in the <i>Guinness Book of World Records</i> for being the fastest electric vehicle for over 1,000 kilometers on a single charge of battery,” he said.</p>
<p><iframe loading="lazy" title="Sunswift 7 (Ep 04 - Guinness World Record attempt ) - Fastest EV over 1000k on a single charge." width="500" height="281" src="https://www.youtube.com/embed/jm1Efr8vlk4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Jetson-Based Racers for Learning</b></h2>
<p>The UNSW team created nearly 60 design iterations to improve on the aerodynamics of the vehicle. They used computational fluid dynamics modeling and ran simulations to analyze each version.</p>
<p>“We didn’t ever put the car through a physical wind tunnel,” said Hopkins.</p>
<p>The technical team has been working on a model to determine what speed the vehicle should be driven at for maximum energy conservation. “They’re working on taking in as many parameters as you can, given it’s really hard to get good driving data,” said Josh Bramley, technology manager at Sunswift Racing.</p>
<p>Sunswift 7 is running on the Robot Operating System (ROS) suite of software and relies on its NVIDIA Jetson module to process all the input from the sensors for analytics, which can be monitored by the remote pit crew back on campus at UNSW.</p>
<p>Jetson is used for all the control systems on the car, so everything from the accelerator pedal, wheel sensors, solar current sensors and more are processed on it for data to analyze for ways AI might help, said Bramley. The next version of the vehicle is expected to pack more AI, he added.</p>
<p>“A lot of the AI and computer vision will be coming for Sunswift 8 in the next solar challenge,” said Bramley.</p>
<p>More than 100 students are getting course credit for the Sunswift Racing team work, and many are interested in pursuing careers in electric vehicles, said Hopkins.</p>
<p>Past World Solar Challenge contestants have gone on to work at Tesla, SpaceX and Zipline.</p>
<p>Talk about a bright future.</p>
<p><i>Learn more about the </i><a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/"><i>NVIDIA Jetson</i></a><i> platform for edge AI and robotics.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/Sunswift7-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1366"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/Sunswift7-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Riding the Rays: Sunswift Racing Shines in World Solar Challenge Race]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>DLSS 3.5 With Ray Reconstruction Now Available in NVIDIA Omniverse</title>
		<link>https://blogs.nvidia.com/blog/2023/10/31/dlss-omniverse-cinema-4d-halloween/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 31 Oct 2023 13:00:49 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio Driver]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67789</guid>

					<description><![CDATA[The highly anticipated NVIDIA DLSS 3.5 update, including Ray Reconstruction for NVIDIA Omniverse — a platform for connecting and building custom 3D tools and apps — is now available. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The highly anticipated NVIDIA DLSS 3.5 update, including Ray Reconstruction for <a href="https://www.nvidia.com/en-us/omniverse/creators/" target="_blank" rel="noopener">NVIDIA Omniverse</a> — a platform for connecting and building custom 3D tools and apps — is now available.</p>
<p><a href="https://blogs.nvidia.com/blog/2023/10/17/rtx-video-super-resolution-ai-obs-broadcast/">RTX Video Super Resolution</a> (VSR) will be available with tomorrow’s <a href="https://www.nvidia.com/en-us/studio/">NVIDIA Studio Driver</a> release — which also supports the DLSS 3.5 update in Omniverse and is free for RTX GPU owners. The version 1.5 update delivers greater overall graphical fidelity, upscaling for native videos and support for GeForce RTX 20 Series GPUs.</p>
<p>NVIDIA Creative Director and visual effects producer Sabour Amirazodi returns <i>In the NVIDIA Studio</i> to share his Halloween-themed project: a full projection mapping show on his house, featuring haunting songs, frightful animation, spooky props and more.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Get ready for some Halloween magic! <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f383.png" alt="🎃" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>Check out this amazing artwork by <a href="https://twitter.com/itsfunkyboy?ref_src=twsrc%5Etfw">@itsfunkyboy</a> as part of our <a href="https://twitter.com/hashtag/SeasonalArtChallenge?src=hash&amp;ref_src=twsrc%5Etfw">#SeasonalArtChallenge</a>.<img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f47b.png" alt="👻" class="wp-smiley" style="height: 1em; max-height: 1em;" /> </p>
<p>Don&#39;t miss the chance to showcase your own spooky creations using <a href="https://twitter.com/hashtag/SeasonalArtChallenge?src=hash&amp;ref_src=twsrc%5Etfw">#SeasonalArtChallenge</a> for a chance to be featured. <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f64c.png" alt="🙌" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="https://t.co/uKcuFmHK4K">pic.twitter.com/uKcuFmHK4K</a></p>
<p>&mdash; NVIDIA Studio (@NVIDIAStudio) <a href="https://twitter.com/NVIDIAStudio/status/1716484714729460004?ref_src=twsrc%5Etfw">October 23, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p>Creators can join the #SeasonalArtChallenge by submitting harvest- and fall-themed pieces through November.</p>
<p><iframe loading="lazy" title="Nightmare Fuel: A Community Digital Art Showcase | NVIDIA Studio Standouts" width="500" height="281" src="https://www.youtube.com/embed/YO9l6WVTvCs?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>The latest Halloween-themed Studio Standouts video features ghouls, creepy monsters, haunted hospitals, dimly lit homes and is not for the faint-of-heart.</p>
<h2><b>Remarkable Ray Reconstruction</b></h2>
<p><a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">NVIDIA DLSS 3.5</a> — featuring Ray Reconstruction — enhances ray-traced image quality on GeForce RTX GPUs by replacing hand-tuned denoisers with an NVIDIA supercomputer-trained AI network that generates higher-quality pixels in between sampled rays.</p>
<p><iframe loading="lazy" title="NVIDIA DLSS 3.5 | New Ray Reconstruction Enhances Ray Tracing with AI" width="500" height="281" src="https://www.youtube.com/embed/sGKCrcNsVzo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Previewing content in the viewport, even with high-end hardware, can sometimes offer less than ideal image quality, as traditional denoisers require hand-tuning for every scene.</p>
<p>With DLSS 3.5, the AI neural network recognizes a wide variety of scenes, producing high-quality preview images and drastically reducing time spent rendering scenes.</p>
<p>NVIDIA Omniverse and the <a href="https://www.nvidia.com/en-us/omniverse/apps/usd-composer/" target="_blank" rel="noopener">USD Composer</a> app — featuring the Omniverse RTX Renderer — specialize in real-time preview modes, offering ray-tracing inference and higher-quality previews while building and iterating.</p>
<p>The feature can be enabled by opening “Render Settings” under “Ray Tracing,” opening the “Direct Lighting” tab and ensuring “New Denoiser (experimental)” is turned on.</p>
<h2><b>The ‘Haunted Sanctuary’</b> <b>Returns</b></h2>
<p>Sabour Amirazodi’s “home-made” installation, <i>Haunted Sanctuary</i>, has become an annual tradition, much to the delight of his neighbors.</p>
<figure id="attachment_67793" aria-describedby="caption-attachment-67793" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-crowd-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67793" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-crowd-1280w-672x341.png" alt="" width="672" height="341" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-crowd-1280w-672x341.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-crowd-1280w-400x203.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-crowd-1280w-768x390.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-crowd-1280w-842x428.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-crowd-1280w-406x206.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-crowd-1280w-188x95.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-crowd-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67793" class="wp-caption-text">Crowds form to watch the spectacular Halloween light show.</figcaption></figure>
<p>Amirazodi begins by staging props, such as pumpkins and skeletons, around his house.</p>
<figure id="attachment_67796" aria-describedby="caption-attachment-67796" style="width: 381px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-props-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67796" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-props-1280w-381x500.png" alt="" width="381" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-props-1280w-381x500.png 381w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-props-1280w-305x400.png 305w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-props-1280w-768x1008.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-props-1280w-1170x1536.png 1170w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-props-1280w-343x450.png 343w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-props-1280w-164x215.png 164w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-props-1280w-76x100.png 76w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-props-1280w.png 1280w" sizes="(max-width: 381px) 100vw, 381px" /></a><figcaption id="caption-attachment-67796" class="wp-caption-text">Physical props add to the spooky atmosphere.</figcaption></figure>
<p>Then he carefully positions his projectors — building protective casings to keep them both safe and blended into the scene.</p>
<figure id="attachment_67799" aria-describedby="caption-attachment-67799" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-building-projectors-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67799" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-building-projectors-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-building-projectors-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-building-projectors-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-building-projectors-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-building-projectors-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-building-projectors-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-building-projectors-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-building-projectors-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67799" class="wp-caption-text">Amirazodi custom builds, paints and welds his projector cases to match the Halloween-themed decor.</figcaption></figure>
<div class="simplePullQuote right"><p>“In the last few years, I’ve rendered 32,862 frames of 5K animation out of the Octane Render Engine. The loop has now become 21 minutes long, and the musical show is another 28 minutes!” — Sabour Amirazodi</p>
</div>
<p>Building a virtual scene onto a physical object requires projection mapping, so Amirazodi used NVIDIA GPU-accelerated MadMapper software and its structured light-scan feature to map custom visuals onto his house. He achieved this by connecting a DSLR camera to his mobile workstation, which was powered by an <a href="https://www.nvidia.com/en-us/design-visualization/rtx-a5000/" target="_blank" rel="noopener">NVIDIA RTX A5000 GPU</a>.</p>
<p>He used the camera to shoot a series of lines and capture photos. Then, he translated to the projector’s point of view an image on which to base a 3D model. Basic camera-matching tools found in Cinema 4D helped recreate the scene. Afterward, Amirazodi applied various mapping and perspective correction edits.</p>
<figure id="attachment_67802" aria-describedby="caption-attachment-67802" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-cinema-4d-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67802" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-cinema-4d-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-cinema-4d-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-cinema-4d-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-cinema-4d-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-cinema-4d-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-cinema-4d-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-cinema-4d-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-cinema-4d-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67802" class="wp-caption-text">Projection mapping requires matching the virtual world with real-world specifications, done in Cinema 4D.</figcaption></figure>
<p>Next, Amirazodi animated and rigged the characters. GPU acceleration in the viewport enabled smooth interactivity with complex 3D models.</p>
<p>“I like having a choice between several third-party NVIDIA GPU-accelerated 3D renderers, such as V-Ray, OctaneRender and Redshift in Cinema 4D,” noted Amirazodi.</p>
<div class="simplePullQuote right"><p>“I switched to NVIDIA graphics cards in 2017. GPUs are the only way to go for serious creators.” — Sabour Amirazodi</p>
</div>
<p>Amirazodi then spent hours on his <a href="https://www.nvidia.com/en-us/design-visualization/rtx-a6000/">RTX 6000</a> workstation creating and rendering out all the animations, assembling them in Adobe After Effects and compositing them on the scanned canvas in MadMapper. There, he crafted individual scenes to render out as chunks and assembled them in Adobe Premiere Pro. Remarkably, he repeated this workflow for every projector.</p>
<p>Once satisfied with the sequences, Amirazodi encoded everything using Adobe Media Encoder and loaded them onto BrightSign digital players — all networked to run the show synchronously.</p>
<p>Amirazodi used the advantages of GPU acceleration to streamline his workflow — saving him countless hours. “After Effects has numerous plug-ins that are GPU-accelerated — plus, Adobe Premiere Pro and Media Encoder use the new dual encoders found in the Ada generation of NVIDIA RTX 6000 GPUs, cutting my export times in half,” he said.</p>
<figure id="attachment_67805" aria-describedby="caption-attachment-67805" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-premiere-pro-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67805" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-premiere-pro-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-premiere-pro-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-premiere-pro-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-premiere-pro-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-premiere-pro-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-premiere-pro-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-premiere-pro-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-premiere-pro-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67805" class="wp-caption-text">Smooth timeline movement in Adobe Premiere Pro assisted by the NVIDIA RTX A6000 GPU.</figcaption></figure>
<p>Amirazodi’s careful efforts are all in the Halloween spirit — creating a hauntingly memorable experience for his community.</p>
<p>“The hard work and long nights all become worth it when I see the smile on my kids’ faces and all the joy it brings to the entire neighborhood,” he reflected.</p>
<figure id="attachment_67808" aria-describedby="caption-attachment-67808" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-sabour-amirazodi-wk81-artist-feature-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67808" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-sabour-amirazodi-wk81-artist-feature-1280w-672x282.png" alt="" width="672" height="282" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-sabour-amirazodi-wk81-artist-feature-1280w-672x282.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-sabour-amirazodi-wk81-artist-feature-1280w-400x168.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-sabour-amirazodi-wk81-artist-feature-1280w-768x323.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-sabour-amirazodi-wk81-artist-feature-1280w-842x354.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-sabour-amirazodi-wk81-artist-feature-1280w-406x171.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-sabour-amirazodi-wk81-artist-feature-1280w-188x79.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-sabour-amirazodi-wk81-artist-feature-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67808" class="wp-caption-text">NVIDIA Creative Director Sabour Amirazodi.</figcaption></figure>
<p>Discover more of Amirazodi’s work on <a href="https://www.imdb.com/name/nm3658528/">IMDb</a>.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>Twitter</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/nv-blog-header-preview-1280x680-2.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/nv-blog-header-preview-1280x680-2-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[DLSS 3.5 With Ray Reconstruction Now Available in NVIDIA Omniverse]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Silicon Volley: Designers Tap Generative AI for a Chip Assist</title>
		<link>https://blogs.nvidia.com/blog/2023/10/30/llm-semiconductors-chip-nemo/</link>
		
		<dc:creator><![CDATA[Rick Merritt]]></dc:creator>
		<pubDate>Mon, 30 Oct 2023 16:00:33 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[New GPU Uses]]></category>
		<category><![CDATA[NVIDIA Foundation]]></category>
		<category><![CDATA[NVIDIA Research]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67732</guid>

					<description><![CDATA[A research paper released today describes ways generative AI can assist one of the most complex engineering efforts: designing semiconductors. The work demonstrates how companies in highly specialized fields can train large language models (LLMs) on their internal data to build assistants that increase productivity. Few pursuits are as challenging as semiconductor design. Under a <a class="read-more" href="https://blogs.nvidia.com/blog/2023/10/30/llm-semiconductors-chip-nemo/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>A <a href="https://research.nvidia.com/publication/2023-10_chipnemo-domain-adapted-llms-chip-design">research paper</a> released today describes ways <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/">generative AI</a> can assist one of the most complex engineering efforts: designing semiconductors.</p>
<p>The work demonstrates how companies in highly specialized fields can train large language models (<a href="https://www.nvidia.com/en-us/glossary/data-science/large-language-models/">LLMs</a>) on their internal data to build assistants that increase productivity.</p>
<p>Few pursuits are as challenging as semiconductor design. Under a microscope, a state-of-the-art chip like an <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100 Tensor Core GPU</a> (above) looks like a well-planned metropolis, built with tens of billions of transistors, connected on streets 10,000x thinner than a human hair.</p>
<p>Multiple engineering teams coordinate for as long as two years to construct one of these digital megacities.</p>
<p>Some groups define the chip’s overall architecture, some craft and place a variety of ultra-small circuits, and others test their work. Each job requires specialized methods, software programs and computer languages.</p>
<h2><b>A Broad Vision for LLMs</b></h2>
<p>“I believe over time large language models will help all the processes, across the board,” said Mark Ren, an NVIDIA Research director and lead author on the paper.</p>
<p>Bill Dally, NVIDIA’s chief scientist, announced the paper today in a keynote at the International Conference on Computer-Aided Design, an annual gathering of hundreds of engineers working in the field called electronic design automation, or EDA.</p>
<p>“This effort marks an important first step in applying LLMs to the complex work of designing semiconductors,” said Dally at the event in San Francisco. “It shows how even highly specialized fields can use their internal data to train useful generative AI models.”</p>
<h2><b>ChipNeMo Surfaces</b></h2>
<p>The paper details how NVIDIA engineers created for their internal use a custom LLM, called ChipNeMo, trained on the company’s internal data to generate and optimize software and assist human designers.</p>
<p>Long term, engineers hope to apply generative AI to each stage of chip design, potentially reaping significant gains in overall productivity, said Ren, whose career spans more than 20 years in EDA.</p>
<p>After surveying NVIDIA engineers for possible use cases, the research team chose three to start: a chatbot, a code generator and an analysis tool.</p>
<h2><b>Initial Use Cases</b></h2>
<p>The latter — a tool that automates the time-consuming tasks of maintaining updated descriptions of known bugs — has been the most well-received so far.</p>
<p>A prototype chatbot that responds to questions about GPU architecture and design helped many engineers quickly find technical documents in early tests.</p>
<figure id="attachment_67780" aria-describedby="caption-attachment-67780" style="width: 600px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/ChipNemo.gif"><img decoding="async" loading="lazy" class="wp-image-67780 size-full" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/ChipNemo.gif" alt="Animation of a generative AI code generator using an LLM" width="600" height="338" /></a><figcaption id="caption-attachment-67780" class="wp-caption-text">A code generator will help designers write software for a chip design.</figcaption></figure>
<p>A code generator in development (demonstrated above)  already creates snippets of about 10-20 lines of software in two specialized languages chip designers use. It will be integrated with existing tools, so engineers have a handy assistant for designs in progress.</p>
<h2><b>Customizing AI Models With NVIDIA NeMo</b></h2>
<p>The paper mainly focuses on the team’s work gathering its design data and using it to create a specialized generative AI model, a process portable to any industry.</p>
<p>As its starting point, the team chose a <a href="https://blogs.nvidia.com/blog/2023/03/13/what-are-foundation-models/">foundation model</a> and customized it with <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/">NVIDIA NeMo</a>, a framework for building, customizing and deploying generative AI models that’s included in the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> software platform. The selected NeMo model sports 43 billion parameters, a measure of its capability to understand patterns. It was trained using more than a trillion tokens, the words and symbols in text and software.</p>
<figure id="attachment_67773" aria-describedby="caption-attachment-67773" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/ChipNeMo-diagram-Final.jpg"><img decoding="async" loading="lazy" class="size-large wp-image-67773" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/ChipNeMo-diagram-Final-672x338.jpg" alt="Diagram of the ChipNeMo workflow for training a custom model" width="672" height="338" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/ChipNeMo-diagram-Final-672x338.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/ChipNeMo-diagram-Final-400x201.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/ChipNeMo-diagram-Final-768x386.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/ChipNeMo-diagram-Final-842x423.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/10/ChipNeMo-diagram-Final-406x204.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/10/ChipNeMo-diagram-Final-188x95.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/10/ChipNeMo-diagram-Final.jpg 1277w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67773" class="wp-caption-text">ChipNeMo provides an example of how one deeply technical team refined a pretrained model with its own data.</figcaption></figure>
<p>The team then refined the model in two training rounds, the first using about 24 billion tokens worth of its internal design data and the second on a mix of about 130,000 conversation and design examples.</p>
<p>The work is among several examples of <a href="https://arxiv.org/pdf/2308.10204.pdf">research</a> and <a href="https://www.cadence.com/en_US/home/explore/large-language-models-llms.html">proofs of concept</a> of generative AI in the semiconductor industry, just beginning to emerge from the lab.</p>
<h2><b>Sharing Lessons Learned</b></h2>
<p>One of the most important lessons Ren’s team learned is the value of customizing an LLM.</p>
<p>On chip-design tasks, custom ChipNeMo models with as few as 13 billion parameters match or exceed performance of even much larger general-purpose LLMs like LLaMA2 with 70 billion parameters. In some use cases, ChipNeMo models were dramatically better.</p>
<p>Along the way, users need to exercise care in what data they collect and how they clean it for use in training, he added.</p>
<p>Finally, Ren advises users to stay abreast of the latest tools that can speed and simplify the work.</p>
<p>NVIDIA Research has hundreds of scientists and engineers worldwide focused on topics such as AI, computer graphics, computer vision, self-driving cars and robotics. Other recent projects in semiconductors include using AI to <a href="https://developer.nvidia.com/blog/designing-arithmetic-circuits-with-deep-reinforcement-learning/">design smaller, faster circuits</a> and to <a href="https://developer.nvidia.com/blog/autodmp-optimizes-macro-placement-for-chip-design-with-ai-and-gpus/">optimize placement of large blocks</a>.</p>
<p>Enterprises looking to build their own custom LLMs can get started today using <a href="https://www.nvidia.com/en-us/ai-data-science/products/nemo/get-started/?nvid=nv-int-unbr-268853">NeMo framework</a> available from GitHub and NVIDIA NGC catalog.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/NVIDIA-GH100-GPU-x-1280.jpg"
			type="image/jpeg"
			width="1360"
			height="724"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/NVIDIA-GH100-GPU-x-1280-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Silicon Volley: Designers Tap Generative AI for a Chip Assist]]></media:title>
			<media:description type="html">Diagram of NVIDIA Hopper GPU</media:description>
			</media:content>
			</item>
		<item>
		<title>Turning the Tide on Coral Reef Decline: CUREE Robot Dives Deep With Deep Learning</title>
		<link>https://blogs.nvidia.com/blog/2023/10/26/coral-reef-decline-curee-robot-jetson-isaac-omniverse/</link>
		
		<dc:creator><![CDATA[Scott Martin]]></dc:creator>
		<pubDate>Thu, 26 Oct 2023 16:00:57 +0000</pubDate>
				<category><![CDATA[Autonomous Machines]]></category>
		<category><![CDATA[NVIDIA Isaac Sim]]></category>
		<category><![CDATA[NVIDIA Jetson]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67573</guid>

					<description><![CDATA[Researchers are taking deep learning for a deep dive, literally. The Woods Hole Oceanographic Institution (WHOI) Autonomous Robotics and Perception Laboratory (WARPLab) and MIT are developing a robot for studying coral reefs and their ecosystems. The WARPLab autonomous underwater vehicle (AUV), enabled by an NVIDIA Jetson Orin NX module, is an effort from the world’s <a class="read-more" href="https://blogs.nvidia.com/blog/2023/10/26/coral-reef-decline-curee-robot-jetson-isaac-omniverse/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Researchers are taking deep learning for a deep dive, literally.</p>
<p>The Woods Hole Oceanographic Institution (WHOI) Autonomous Robotics and Perception Laboratory (<a href="https://warp.whoi.edu/">WARPLab</a>) and MIT are developing a robot for studying coral reefs and their ecosystems.</p>
<p>The WARPLab autonomous underwater vehicle (AUV), enabled by an <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">NVIDIA Jetson Orin NX</a> module, is an effort from the world’s largest private ocean research institution to turn the tide on reef declines.</p>
<p>Some 25% of coral reefs worldwide have vanished in the past three decades, and most of the remaining reefs are heading for extinction, according to the <a href="https://reefsolutions.whoi.edu/">WHOI Reef Solutions Initiative</a>.</p>
<p>The AUV, dubbed CUREE (Curious Underwater Robot for Ecosystem Exploration), gathers visual, audio, and other environmental data alongside divers to help understand the human impact on reefs and the sea life around them. The robot runs an expanding collection of NVIDIA Jetson-enabled edge AI to build 3D models of reefs and to track creatures and plant life. It also runs models to navigate and collect data autonomously.</p>
<p>WHOI, whose submarine first explored the Titanic in 1986, is developing its CUREE robot for data gathering to scale the effort and aid in mitigation strategies. The oceanic research organization is also exploring the use of simulation and <a href="https://blogs.nvidia.com/blog/2021/12/14/what-is-a-digital-twin/">digital twins</a> to better replicate reef conditions and investigate solutions like <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, a development platform for building and connecting 3D tools and applications.</p>
<p>Creating a digital twin of Earth in Omniverse, NVIDIA is developing the world’s most powerful AI supercomputer for predicting climate change, <a href="https://blogs.nvidia.com/blog/2021/11/12/earth-2-supercomputer/">called Earth-2</a>.</p>
<h2><b>Underwater AI: DeepSeeColor Model</b></h2>
<p>Anyone who’s gone snorkeling knows that seeing underwater isn’t as clear as seeing on land. Over distance, water attenuates the visible spectrum of light from the sun underwater, muting some colors more than others. At the same time, particles in the water create a hazy view, known as backscatter.</p>
<p>A team from WARPLab recently <a href="https://arxiv.org/pdf/2303.04025.pdf">published a research paper</a> on undersea vision correction that helps mitigate these problems and supports the work of CUREE. The paper describes a model, called DeepSeeColor, that uses a sequence of two <a href="https://blogs.nvidia.com/blog/2018/09/05/whats-the-difference-between-a-cnn-and-an-rnn/">convolutional neural networks</a> to reduce backscatter and correct colors in real time on the NVIDIA Jetson Orin NX while undersea.</p>
<p>“NVIDIA GPUs are involved in a large portion of our pipeline because, basically, when the images come in, we use DeepSeeColor to color correct them, and then we can do the fish detection and transmit that to a scientist up at the surface on a boat,” said Stewart Jamieson, a robotics Ph.D. candidate at MIT and AI developer at WARPLab.</p>
<p><iframe loading="lazy" title="DeepSeeColor: Removing backscatter and color attenuation from underwater images in realtime" width="500" height="281" src="https://www.youtube.com/embed/vpge92KRU1M?start=1&#038;feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Eyes and Ears: Fish and Reef Detection</b></h2>
<p>CUREE packs four forward-facing cameras, four hydrophones for underwater audio capture, depth sensors and inertial measurement unit sensors. GPS doesn’t work underwater, so it is only used to initialize the robot’s starting position while on the surface.</p>
<p>Using a combination of cameras and hydrophones along with AI models running on the Jetson Orin NX enables CUREE to collect data for producing 3D models of reefs and undersea terrains.</p>
<p>To use the hydrophones for audio data collection, CUREE needs to drift with its motor off so that there’s no interference with the audio.</p>
<p>“It can build a spatial soundscape map of the reef, using sounds produced by different animals,” said Yogesh Girdhar, an associate scientist at WHOI, who leads WARPLab. “We currently (in post-processing) detect where all the chatter associated with bioactivity hotspots is,” he added, referring to all the noises of sea life.</p>
<p>The team has been training detection models for both audio and video input to track creatures. But a big noise interference with detecting clear audio samples has come from one creature in particular.</p>
<p>“The problem is that, underwater, the snapping shrimps are loud,” said Girdhar. On land, this classic dilemma of how to separate sounds from background noises is known as <a href="https://blogs.nvidia.com/blog/2018/08/28/music-youtube-cocktail-party-problem-ai-artificial-intelligence-deep-learning/">the cocktail party problem</a>. “If only we could figure out an algorithm to remove the effects of sounds of snapping shrimps from audio, but at the moment we don’t have a good solution,” said Girdhar.</p>
<p>Despite few underwater datasets in existence, <a href="https://warp.whoi.edu/vmat/">pioneering fish detection and tracking</a> is going well, said Levi Cai, a Ph.D. candidate in the MIT-WHOI joint program. He said they’re taking a semi-supervised approach to the marine animal tracking problem. The tracking is initialized using targets detected by a <a href="https://github.com/warplab/megafishdetector">fish detection neural network</a> trained on open-source datasets for fish detection, which is fine-tuned with <a href="https://blogs.nvidia.com/blog/2019/02/07/what-is-transfer-learning/">transfer learning</a> from images gathered by CUREE.</p>
<p>“We manually drive the vehicle until we see an animal that we want to track, and then we click on it and have the semi-supervised tracker take over from there,” said Cai.</p>
<p><iframe loading="lazy" title="Tracking a barracuda using CUREE" width="500" height="281" src="https://www.youtube.com/embed/s_PBaYIqNKg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Jetson Orin Energy Efficiency Drives CUREE</b></h2>
<p>Energy efficiency is critical for small AUVs like CUREE. The compute requirements for data collection consume roughly 25% of the available energy resources, with driving the robots taking the remainder.</p>
<p>CUREE typically operates for as long as two hours on a charge, depending on the reef mission and the observation requirements, said Girdhar, who goes on the dive missions in St. John in the U.S. Virgin Islands.</p>
<p>To enhance energy efficiency, the team is looking into AI for managing the sensors so that computing resources automatically stay awake while making observations and sleep when not in use.</p>
<p>“Our robot is small, so the amount of energy spent on GPU computing actually matters — with Jetson Orin NX our power issues are gone, and it’s made our system much more robust,” said  Girdhar.</p>
<h2><b>Exploring Isaac Sim to Make Improvements </b></h2>
<p>The WARPLab team is experimenting with <a href="https://developer.nvidia.com/isaac-sim">NVIDIA Isaac Sim</a>, a scalable robotics simulation application and <a href="https://blogs.nvidia.com/blog/2021/06/08/what-is-synthetic-data/">synthetic data</a> generation tool powered by Omniverse, to accelerate development of autonomy and observation for CUREE.</p>
<p>The goal is to do simple simulations in Isaac Sim to get the core essence of the problem to be simulated and then finish the training in the real world undersea, said Yogesh.</p>
<p>“In a coral reef environment, we cannot depend on sonars — we need to get up really close,” he said. “Our goal is to observe different ecosystems and processes happening.”</p>
<h2><b>Understanding Ecosystems and Creating Mitigation Strategies</b></h2>
<p>The WARPLab team intends to make the CUREE platform available for others to understand the impact humans are having on undersea environments and to help create mitigation strategies.</p>
<p>The researchers plan to learn from patterns that emerge from the data. CUREE provides an almost fully autonomous data collection scientist that can communicate findings to human researchers, said Jamieson. “A scientist gets way more out of this than if the task had to be done manually, driving it around staring at a screen all day,” he said.</p>
<p>Girdhar said that ecosystems like coral reefs can be modeled with a network, with different nodes corresponding to different types of species and habitat types. Within that, he said, there are all these different interactions happening, and the researchers seek to understand this network to learn about the relationship between various animals and their habitats.</p>
<p>The hope is that there’s enough data collected using CUREE AUVs to gain a comprehensive understanding of ecosystems and how they might progress over time and be affected by harbors, pesticide runoff, carbon emissions and dive tourism, he said.</p>
<p>“We can then better design and deploy interventions and determine, for example, if we planted new corals how they would change the reef over time,” said Girdar.</p>
<p><i>Learn more about </i><a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/"><i>NVIDIA Jetson Orin NX</i></a><i>, </i><a href="https://www.nvidia.com/en-us/omniverse/"><i>Omniverse</i></a><i> and </i><a href="https://www.nvidia.com/en-us/high-performance-computing/earth-2/"><i>Earth-2</i></a><i>.</i></p>
<p><em>Image credit: Austin Greene, Woods Hole Oceanographic Institution</em></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/CUREE.jpg"
			type="image/jpeg"
			width="2048"
			height="1365"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/CUREE-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Turning the Tide on Coral Reef Decline: CUREE Robot Dives Deep With Deep Learning]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>The Sky’s the Limit: ‘Cities: Skylines II’ Streams This Week on GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/2023/10/26/geforce-now-thursday-oct-26/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 26 Oct 2023 13:00:01 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67744</guid>

					<description><![CDATA[The cloud is full of treats this GFN Thursday with Cities: Skylines II now streaming, leading 15 newly supported games this week. The game’s publisher, Paradox Interactive, is offering GeForce NOW one-month Priority memberships for those who pick up the game first, so make sure to grab one before they’re gone. Among the newly supported <a class="read-more" href="https://blogs.nvidia.com/blog/2023/10/26/geforce-now-thursday-oct-26/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The cloud is full of treats this GFN Thursday with <i>Cities: Skylines II </i>now streaming, leading 15 newly supported games this week<i>.</i> The game’s publisher, Paradox Interactive, is offering GeForce NOW one-month Priority memberships for those who pick up the game first, so make sure to grab one before they’re gone.</p>
<p>Among the newly supported additions to the <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> library are more games from the PC Game Pass catalog, including <i>Ghostwire Tokyo</i>,<i> State of Decay</i> and the <i>Dishonored</i> series. Members can also look forward to <i>Alan Wake 2</i> — streaming soon.</p>
<h2><b>Cloud City</b></h2>
<figure id="attachment_67761" aria-describedby="caption-attachment-67761" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" loading="lazy" class="size-large wp-image-67761" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Cities_Skylines_II-672x378.jpg" alt="Cities: Skylines II on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Cities_Skylines_II-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Cities_Skylines_II-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Cities_Skylines_II-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Cities_Skylines_II-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Cities_Skylines_II-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Cities_Skylines_II-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Cities_Skylines_II-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Cities_Skylines_II-1280x720.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Cities_Skylines_II.jpg 1920w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-67761" class="wp-caption-text"><em>If you build it, they will come.</em></figcaption></figure>
<p>Members can build the metropolis of their dreams this week in <i>Cities: Skylines II, </i>the sequel to Paradox Interactive’s award-winning city sim<i>.</i> Raise a city from the ground up and transform it into a thriving urban landscape. Get creative to build on an unprecedented scale while managing a deep simulation and a living economy.</p>
<p>The game’s AI and intricate economics mean every choice ripples through the fabric of a player’s city, so they’ll have to stay sharp — strategizing, solving problems and reacting to challenges. Build sky-high and sprawl across the map like never before. New dynamic map features affect how the city expands amid rising pollution, changing weather and seasonal challenges.</p>
<p>Paradox is offering one-month GeForce NOW Priority memberships to the first 100,000 people who purchase the game, so budding city planners can optimize their gameplay across nearly any device. Visit <a href="https://www.paradoxinteractive.com/games/cities-skylines-ii/geforce-now"><i>Cities Skylines II</i></a> for more info.</p>
<h2><b>Newly Risen in the Cloud</b></h2>
<p>Settle in for a spooky night with the newest PC Game Pass additions to the cloud: <i>State of Decay </i>and the <i>Dishonored</i> series.</p>
<figure id="attachment_67758" aria-describedby="caption-attachment-67758" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" loading="lazy" class="size-large wp-image-67758" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-State_of_Decay_2_Juggernaut_Edition-672x336.jpg" alt="State of Decay 2: Juggernaut Edition on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-State_of_Decay_2_Juggernaut_Edition-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-State_of_Decay_2_Juggernaut_Edition-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-State_of_Decay_2_Juggernaut_Edition-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-State_of_Decay_2_Juggernaut_Edition-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-State_of_Decay_2_Juggernaut_Edition-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-State_of_Decay_2_Juggernaut_Edition-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-State_of_Decay_2_Juggernaut_Edition-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-State_of_Decay_2_Juggernaut_Edition-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-State_of_Decay_2_Juggernaut_Edition.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-67758" class="wp-caption-text"><em>“The right choice is the one that keeps us alive.”</em></figcaption></figure>
<p>Drop into a post-apocalyptic world and fend off zombies in <i>State of Decay 2: Juggernaut Edition</i> from Undead Labs and Xbox Game Studios. Band together with a small group of survivors and rebuild a corner of civilization in this dynamic, open-world sandbox. Fortify home base, perform daring raids for food and supplies and rescue other survivors who may have unique talents to contribute. Head online with friends for an up to four-player online co-op mode and visit their communities to help defend them and bring back rewards. No two players’ experiences will be the same.</p>
<figure id="attachment_67755" aria-describedby="caption-attachment-67755" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" loading="lazy" class="size-large wp-image-67755" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Dishonored_Death_of_the_Outside-672x336.jpg" alt="" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Dishonored_Death_of_the_Outside-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Dishonored_Death_of_the_Outside-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Dishonored_Death_of_the_Outside-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Dishonored_Death_of_the_Outside-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Dishonored_Death_of_the_Outside-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Dishonored_Death_of_the_Outside-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Dishonored_Death_of_the_Outside-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Dishonored_Death_of_the_Outside-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Dishonored_Death_of_the_Outside.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-67755" class="wp-caption-text"><em>Dishonor on you, dishonor on your cow, “Dishonored” in the cloud.</em></figcaption></figure>
<p>Get supernatural with the <i>Dishonored</i> series, which comprises first-person action games set in a steampunk Lovecraftian world. In <i>Dishonored</i>, follow the story of Corvo Attano — a former bodyguard turned assassin driven by revenge after being framed for the murder of the Empress of Dunwall. Choose stealth or violence with <i>Dishonored</i>’s flexible combat system and Corvo’s supernatural abilities.</p>
<p><i>The Definitive Edition</i> includes the original <i>Dishonored</i> game with updated graphics, the “Void Walker’s Arsenal&#8221; add-on pack, plus expansion packs for more missions: “The Knife of Dunwall,” “The Brigmore Witches” and “Dunwall City Trials.”</p>
<p>Follow up with the sequel, <i>Dishonored 2</i>, set 15 years after<i> Dishonored</i>. Members can play as Corvo or his daughter, Emily, who seeks to reclaim her rightful place as the Empress of Dunwall. <i>Dishonored: Death of the Outsider</i> is the latest in the series, following the story of former assassin Billie Lurk on her mission to discover the origins of a mysterious entity called The Outsider.</p>
<h2><b>It’s Getting Dark in Here</b></h2>
<figure id="attachment_67752" aria-describedby="caption-attachment-67752" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" loading="lazy" class="size-large wp-image-67752" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/BigFish_DET_4K_054-672x378.jpg" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/BigFish_DET_4K_054-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/BigFish_DET_4K_054-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/BigFish_DET_4K_054-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/BigFish_DET_4K_054-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/10/BigFish_DET_4K_054-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/10/BigFish_DET_4K_054-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2023/10/BigFish_DET_4K_054-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2023/10/BigFish_DET_4K_054-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2023/10/BigFish_DET_4K_054-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-67752" class="wp-caption-text"><em>Maybe you should be afraid of the dark after all.</em></figcaption></figure>
<p><i>Alan Wake 2</i>, the long-awaited sequel to Remedy Entertainments’ survival-horror classic, is coming soon to the cloud.</p>
<p>What begins as a small-town murder investigation rapidly spirals into a nightmare journey. Uncover the source of a supernatural darkness in this psychological horror story filled with suspense and unexpected twists. Play as FBI agent Saga Anderson and Alan Wake, a horror writer long trapped in the Dark Place, to see events unfold from different perspectives.</p>
<p>Ultimate members will soon be able to uncover mysteries with the power of a <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4080/">GeForce RTX 4080</a> server in the cloud. Survive the surreal world of <i>Alan Wake 2</i> at up to 4K resolution and 120 frames per second, with <a href="https://blogs.nvidia.com/blog/2022/03/23/what-is-path-tracing/">path-traced</a> graphics accelerated and enhanced by <a href="https://www.nvidia.com/en-us/geforce/news/nvidia-dlss-3-5-ray-reconstruction/">NVIDIA DLSS 3.5</a> and <a href="https://www.nvidia.com/en-us/geforce/technologies/reflex/">NVIDIA Reflex</a> technology.</p>
<h2><b>Trick or Treat: Give Me All New Games to Beat</b></h2>
<figure id="attachment_67749" aria-describedby="caption-attachment-67749" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" loading="lazy" class="size-large wp-image-67749" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Ghostwire_Tokyo-672x336.jpg" alt="Ghostwire Tokyo on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Ghostwire_Tokyo-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Ghostwire_Tokyo-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Ghostwire_Tokyo-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Ghostwire_Tokyo-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Ghostwire_Tokyo-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Ghostwire_Tokyo-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Ghostwire_Tokyo-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Ghostwire_Tokyo-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/10/GFN_Thursday-Ghostwire_Tokyo.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-67749" class="wp-caption-text"><em>I ain’t afraid of no ghost.</em></figcaption></figure>
<p>It’s time for a bewitching new list of games in the cloud. <i>Ghostwire Tokyo </i>from Bethesda is an action-adventure game set in a modern-day Tokyo mysteriously depopulated by a paranormal phenomenon. Team with a spectral entity to fight the supernatural forces that have taken over the city, including ghosts, yokai and other creatures from Japanese folklore.</p>
<p>Jump into the action now with 15 new games this week:</p>
<ul>
<li><i>Cities: Skylines II </i>(New release on <a href="https://store.steampowered.com/app/949230?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.xbox.com/games/store/cities-skylines-ii/9ndntv0l9n87?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox </a>and available on PC Game Pass, Oct. 24)</li>
<li><i>RIPOUT </i>(New release on <a href="https://store.steampowered.com/app/1558830?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Oct. 24)</li>
<li><i>Ghostrunner 2 </i>(New release on <a href="https://store.steampowered.com/app/2144740?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Oct. 26)</li>
<li><i>Cricket 22 </i>(<a href="https://www.xbox.com/games/store/cricket-22/9NWNX54ZMT1K?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Deceive Inc. </i>(<a href="https://www.epicgames.com/store/p/deceive-inc?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Dishonored </i>(<a href="https://store.steampowered.com/app/205100?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Dishonored: Death of the Outsider </i>(<a href="https://store.steampowered.com/app/614570?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.epicgames.com/store/p/dishonored-death-of-the-outsider?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, <a href="https://www.xbox.com/games/store/dishonored-death-of-the-outsider-pc/9MVF0PGV94F7?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Dishonored Definitive Edition</i> (<a href="https://www.epicgames.com/store/p/dishonored-definitive-edition?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, <a href="https://www.xbox.com/games/store/dishonored-definitive-edition-pc/9P1N07XDL1D4?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox </a>and available on PC Game Pass)</li>
<li><i>Dishonored 2 </i>(<a href="https://store.steampowered.com/app/403640?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.epicgames.com/store/p/dishonored-2?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, <a href="https://www.xbox.com/games/store/dishonored-2/9MW4RJDRSF78?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Ghostwire: Tokyo </i>(<a href="https://store.steampowered.com/app/1475810?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.epicgames.com/store/p/ghostwire-tokyo?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, <a href="https://www.xbox.com/games/store/ghostwire-tokyo/9PKP39CL0C8D?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox </a>and available on PC Game Pass)</li>
<li><i>The Gunk </i>(<a href="https://www.xbox.com/games/store/the-gunk/9P008L2LS87F?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Kill It With Fire </i>(<a href="https://www.xbox.com/games/store/kill-it-with-fire/9MZVSHQZ666K?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>State of Decay 2: Juggernaut Edition </i>(<a href="https://store.steampowered.com/app/495420?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.epicgames.com/store/p/state-of-decay-2-juggernaut-edition?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, <a href="https://www.xbox.com/games/store/state-of-decay-2-juggernaut-edition/9nt4x7p8b9nb?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Totally Accurate Battle Simulator </i>(<a href="https://www.xbox.com/games/store/totally-accurate-battle-simulator/9PC4RWP34M2D?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Vampire Survivors</i> (<a href="https://store.steampowered.com/app/1794680?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<p>Make sure to check out the question of the week. Share your answer on <a href="https://www.twitter.com/nvidiagfn">Twitter</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">raise your hand if you&#39;ve felt personally victimized by the mute/unmute button <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f64b-200d-2640-fe0f.png" alt="🙋‍♀️" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1717209401298194658?ref_src=twsrc%5Etfw">October 25, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/gfn-thursday-cities-skylines-2-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/gfn-thursday-cities-skylines-2-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[The Sky’s the Limit: ‘Cities: Skylines II’ Streams This Week on GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Next-Gen Neural Networks: NVIDIA Research Announces Array of AI Advancements at NeurIPS</title>
		<link>https://blogs.nvidia.com/blog/2023/10/25/neurips-ai-research/</link>
		
		<dc:creator><![CDATA[Isha Salian]]></dc:creator>
		<pubDate>Wed, 25 Oct 2023 13:00:09 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Climate]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[NVIDIA Research]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67715</guid>

					<description><![CDATA[NVIDIA researchers are collaborating with academic centers worldwide to advance generative AI, robotics and the natural sciences — and more than a dozen of these projects will be shared at NeurIPS, one of the world’s top AI conferences. Set for Dec. 10-16 in New Orleans, NeurIPS brings together experts in generative AI, machine learning, computer <a class="read-more" href="https://blogs.nvidia.com/blog/2023/10/25/neurips-ai-research/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>NVIDIA researchers are collaborating with academic centers worldwide to advance <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/">generative AI</a>, robotics and the natural sciences — and more than a dozen of these projects will be shared at <a href="https://neurips.cc/" target="_blank" rel="noopener">NeurIPS</a>, one of the world’s top AI conferences.</p>
<p>Set for Dec. 10-16 in New Orleans, NeurIPS brings together experts in generative AI, machine learning, computer vision and more. Among the innovations <a href="https://www.nvidia.com/en-us/research/">NVIDIA Research</a> will present are new techniques for transforming text to images, photos to 3D avatars, and specialized robots into multi-talented machines.</p>
<p>“NVIDIA Research continues to drive progress across the field — including generative AI models that transform text to images or speech, autonomous AI agents that learn new tasks faster, and neural networks that calculate complex physics,” said Jan Kautz, vice president of learning and perception research at NVIDIA. “These projects, often done in collaboration with leading minds in academia, will help accelerate developers of virtual worlds, simulations and autonomous machines.”</p>
<h2><b>Picture This: Improving Text-to-Image Diffusion Models</b></h2>
<p>Diffusion models have become the most popular type of generative AI models to turn text into realistic imagery. NVIDIA researchers have collaborated with universities on multiple projects advancing diffusion models that will be presented at NeurIPS.</p>
<ul style="font-weight: 300;">
<li>A paper accepted as an oral presentation focuses on improving generative AI models’ ability to <a href="https://neurips.cc/virtual/2023/oral/73870" target="_blank" rel="noopener">understand the link between modifier words and main entities</a> in text prompts. While existing text-to-image models asked to depict a yellow tomato and a red lemon may incorrectly generate images of yellow lemons and red tomatoes, the new model analyzes the syntax of a user’s prompt, encouraging a bond between an entity and its modifiers to deliver a more faithful visual depiction of the prompt.</li>
<li>SceneScape, a new framework using <a href="https://neurips.cc/virtual/2023/poster/71859" target="_blank" rel="noopener">diffusion models to create long videos of 3D scenes from text prompts</a>, will be presented as a poster. The project combines a text-to-image model with a depth prediction model that helps the videos maintain plausible-looking scenes with consistency between the frames — generating videos of art museums, haunted houses and ice castles (pictured above).</li>
<li>Another poster describes work that improves how text-to-image models <a href="https://neurips.cc/virtual/2023/poster/70922" target="_blank" rel="noopener">generate concepts rarely seen in training data</a>. Attempts to generate such images usually result in low-quality visuals that aren’t an exact match to the user’s prompt. The new method uses a small set of example images that help the model identify good seeds — random number sequences that guide the AI to generate images from the specified rare classes.</li>
<li>A third poster shows how a text-to-image diffusion model can <a href="https://neurips.cc/virtual/2023/poster/70648" target="_blank" rel="noopener">use the text description of an incomplete point cloud</a> to generate missing parts and create a complete 3D model of the object. This could help complete point cloud data collected by lidar scanners and other depth sensors for robotics and autonomous vehicle AI applications. Collected imagery is often incomplete because objects are scanned from a specific angle — for example, a lidar sensor mounted to a vehicle would only scan one side of each building as the car drives down a street.</li>
</ul>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/Point-Cloud-Completion.jpg"><img decoding="async" loading="lazy" class="aligncenter size-large wp-image-67733" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/Point-Cloud-Completion-672x222.jpg" alt="" width="672" height="222" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/Point-Cloud-Completion-672x222.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/Point-Cloud-Completion-400x132.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/Point-Cloud-Completion-768x253.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/Point-Cloud-Completion-1536x506.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/10/Point-Cloud-Completion-842x278.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/10/Point-Cloud-Completion-406x134.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/10/Point-Cloud-Completion-188x62.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/10/Point-Cloud-Completion-1280x422.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/10/Point-Cloud-Completion.jpg 1999w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<h2><b>Character Development: Advancements in AI Avatars</b></h2>
<p>AI avatars combine multiple generative AI models to create and animate virtual characters, produce text and convert it to speech. Two NVIDIA posters at NeurIPS present new ways to make these tasks more efficient.</p>
<ul style="font-weight: 300;">
<li>A poster describes a new method to <a href="https://neurips.cc/virtual/2023/poster/72615" target="_blank" rel="noopener">turn a single portrait image into a 3D head avatar</a> while capturing details including hairstyles and accessories. Unlike current methods that require multiple images and a time-consuming optimization process, this model achieves high-fidelity 3D reconstruction without additional optimization during inference. The avatars can be animated either with blendshapes, which are 3D mesh representations used to represent different facial expressions, or with a reference video clip where a person’s facial expressions and motion are applied to the avatar.</li>
<li>Another poster by NVIDIA researchers and university collaborators advances zero-shot text-to-speech synthesis with P-Flow, a generative AI model that can <a href="https://pflow-demo.github.io/projects/pflow/" target="_blank" rel="noopener">rapidly synthesize high-quality personalized speech</a> given a three-second reference prompt. P-Flow features better pronunciation, human likeness and speaker similarity compared to recent state-of-the-art counterparts. The model can near-instantly convert text to speech on a single <a href="https://www.nvidia.com/en-us/data-center/a100/">NVIDIA A100 Tensor Core GPU</a>.</li>
</ul>
<h2><b>Research Breakthroughs in Reinforcement Learning, Robotics</b></h2>
<p>In the fields of reinforcement learning and robotics, NVIDIA researchers will present two posters highlighting innovations that improve the generalizability of AI across different tasks and environments.</p>
<ul style="font-weight: 300;">
<li>The first proposes a <a href="https://neurips.cc/virtual/2023/poster/72040" target="_blank" rel="noopener">framework for developing reinforcement learning algorithms</a> that can adapt to new tasks while avoiding the common pitfalls of gradient bias and data inefficiency. The researchers showed that their method — which features a novel meta-algorithm that can create a robust version of <i>any</i> meta-reinforcement learning model — performed well on multiple benchmark tasks.</li>
<li>Another by an NVIDIA researcher and university collaborators tackles the challenge of <a href="https://neurips.cc/virtual/2023/poster/71709" target="_blank" rel="noopener">object manipulation in robotics</a>. Prior AI models that help robotic hands pick up and interact with objects can handle specific shapes but struggle with objects unseen in the training data. The researchers introduce a new framework that estimates how objects across different categories are geometrically alike — such as drawers and pot lids that have similar handles — enabling the model to more quickly generalize to new shapes.</li>
</ul>
<h2><b>Supercharging Science: AI-Accelerated Physics, Climate, Healthcare</b></h2>
<p>NVIDIA researchers at NeurIPS will also present papers across the natural sciences — covering physics simulations, climate models and AI for healthcare.</p>
<ul style="font-weight: 300;">
<li>To accelerate <a href="https://neurips.cc/virtual/2023/poster/72670" target="_blank" rel="noopener">computational fluid dynamics for large-scale 3D simulations</a>, a team of NVIDIA researchers proposed a neural operator architecture that combines accuracy and computational efficiency to estimate the pressure field around vehicles — the first deep learning-based computational fluid dynamics method on an industry-standard, large-scale automotive benchmark. The method achieved 100,000x acceleration on a single <a href="https://www.nvidia.com/en-us/data-center/tensor-cores/">NVIDIA Tensor Core GPU</a> compared to another GPU-based solver, while reducing the error rate. Researchers can incorporate the model into their own applications using the open-source <a href="https://github.com/neuraloperator/neuraloperator" target="_blank" rel="noopener">neuraloperator library</a>.</li>
</ul>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/Computational-Fluid-Dynamics-1.jpg"><img decoding="async" loading="lazy" class="aligncenter size-large wp-image-67740" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/Computational-Fluid-Dynamics-1-672x390.jpg" alt="" width="672" height="390" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/Computational-Fluid-Dynamics-1-672x390.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/Computational-Fluid-Dynamics-1-400x232.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/Computational-Fluid-Dynamics-1-768x446.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/Computational-Fluid-Dynamics-1-775x450.jpg 775w, https://blogs.nvidia.com/wp-content/uploads/2023/10/Computational-Fluid-Dynamics-1-370x215.jpg 370w, https://blogs.nvidia.com/wp-content/uploads/2023/10/Computational-Fluid-Dynamics-1-172x100.jpg 172w, https://blogs.nvidia.com/wp-content/uploads/2023/10/Computational-Fluid-Dynamics-1.jpg 1171w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<p>&nbsp;</p>
<ul>
<li>A consortium of climate scientists and machine learning researchers from universities, national labs, research institutes, Allen AI and NVIDIA collaborated on <a href="https://neurips.cc/virtual/2023/poster/73569" target="_blank" rel="noopener">ClimSim</a>, a massive dataset for physics and machine learning-based climate research that will be shared in an oral presentation at NeurIPS. The dataset covers the globe over multiple years at high resolution — and machine learning emulators built using that data can be plugged into existing operational climate simulators to improve their fidelity, accuracy and precision. This can help scientists produce better predictions of storms and other extreme events.</li>
<li>NVIDIA Research interns are presenting a poster introducing an AI algorithm that provides personalized <a href="https://neurips.cc/virtual/2023/poster/71940" target="_blank" rel="noopener">predictions of the effects of medicine dosage</a> on patients. Using real-world data, the researchers tested the model’s predictions of blood coagulation for patients given different dosages of a treatment. They also analyzed the new algorithm’s predictions of the antibiotic vancomycin levels in patients who received the medication — and found that prediction accuracy significantly improved compared to prior methods.</li>
</ul>
<p><a href="https://www.nvidia.com/en-us/research/"><i>NVIDIA Research</i></a><i> comprises hundreds of scientists and engineers worldwide, with teams focused on topics including AI, computer graphics, computer vision, self-driving cars and robotics. </i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/Scenescape-screengrab-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/Scenescape-screengrab-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Next-Gen Neural Networks: NVIDIA Research Announces Array of AI Advancements at NeurIPS]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>On Razer’s Edge: VFX Star Surfaced Studio Creates Stunning Sci-Fi World This Week ‘In The NVIDIA Studio’</title>
		<link>https://blogs.nvidia.com/blog/2023/10/24/surfaced-studio-adobe-premiere-pro-after-effects-blender-unreal/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 24 Oct 2023 13:00:42 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67668</guid>

					<description><![CDATA[Visual effects artist Surfaced Studio returns to 'In the NVIDIA Studio' to share his real-world VFX project, created on a brand new Razer Blade 16 Mercury Edition laptop powered by GeForce RTX 4080 graphics. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Visual effects artist Surfaced Studio returns to <i>In the NVIDIA Studio</i> to share his real-world VFX project, created on a brand new <a href="https://www.razer.com/gaming-laptops/razer-blade-16/RZ09-0483TEM3-R3U1">Razer Blade 16 Mercury Edition</a> laptop powered by <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4080/">GeForce RTX 4080</a> graphics.</p>
<p><iframe loading="lazy" title="Razer Blade 16 Mercury Edition - Real World VFX Test &amp; Review" width="500" height="281" src="https://www.youtube.com/embed/d6AR3XnwtIs?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Surfaced Studio creates photorealistic, digitally generated imagery that seamlessly integrates visual effects into short films, television and console gaming.</p>
<p>He found inspiration for a recent sci-fi project by experimenting with 3D transitions: using a laptop screen as a gateway between worlds, like the portals from <i>Dr. Strange</i> or the transitions from <i>The Matrix</i>.</p>
<h2><b>Break the Rules and Become a Hero</b></h2>
<p>Surfaced Studio aimed to create an immersive experience with his latest project.</p>
<p>“I wanted to get my audience to feel surprised getting ‘sucked into’ the 3D world,” he explained.</p>
<p>Surfaced Studio began with a simple script, alongside sketches of brainstormed ideas and played out shots. “This usually helps me think through how I’d pull each effect off and whether they’re actually possible,” he said.</p>
<p>From there, he shot video and imported the footage into Adobe Premiere Pro for a rough test edit. Then, Surfaced Studio selected the most suitable clips for use.</p>
<p>He cleaned up the footage in Adobe After Effects, stabilizing shots with the Warp Stabilizer tool and removing distracting background elements with the Mocha Pro tool. Both effects were accelerated by his GeForce RTX 4080 Laptop GPU.</p>
<p>After, he created a high-contrast version of the shot for 3D motion tracking in Blender.</p>
<figure id="attachment_67675" aria-describedby="caption-attachment-67675" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-3d-motion-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67675" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-3d-motion-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-3d-motion-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-3d-motion-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-3d-motion-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-3d-motion-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-3d-motion-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-3d-motion-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-3d-motion-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67675" class="wp-caption-text">3D motion tracking in Blender.</figcaption></figure>
<p>Motion tracking is used to apply tracking data to 3D objects. “This was pretty tricky, as it’s a 16-second gimbal shot with fast moving sections and a decent camera blur,” said Surfaced Studio. “It took me a good few days to get a decent track and fix issues with manual keyframes and ‘patches’ between different sections.”</p>
<figure id="attachment_67682" aria-describedby="caption-attachment-67682" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-shooting-footage-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67682" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-shooting-footage-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-shooting-footage-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-shooting-footage-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-shooting-footage-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-shooting-footage-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-shooting-footage-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-shooting-footage-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-shooting-footage-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67682" class="wp-caption-text">A gimbal shot uses sensors and motors to stabilize and support the camera.</figcaption></figure>
<p>Surfaced Studio exported footage of the animated camera into a 3D FBX file to use in Unreal Engine and set it up in the <a href="https://www.unrealengine.com/marketplace/en-US/product/high-city-sp#">Cyberpunk High City pack</a>, which contains a modular constructor for creating highly detailed sci-fi city streets, alleys and blocks.</p>
<p><iframe loading="lazy" title="High City (Unreal 5)" width="500" height="281" src="https://www.youtube.com/embed/9ra8bt4sEcQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>“I’m not much of a 3D artist so using [the Cyberpunk High City pack] was the best option to complete the project on this side of the century,” the artist said. He then made modifications to the cityscape, reducing flickering lights and adding buildings, custom fog and Razer and NVIDIA Studio banners. He even added a billboard with an ad encouraging kindness to cats. “It’s so off to the side of most shots I doubt anyone actually noticed,” noted a satisfied Surfaced Studio.</p>
<figure id="attachment_67685" aria-describedby="caption-attachment-67685" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-razer-blade-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67685" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-razer-blade-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-razer-blade-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-razer-blade-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-razer-blade-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-razer-blade-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-razer-blade-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-razer-blade-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-razer-blade-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67685" class="wp-caption-text">A PSA from Surfaced Studio: be nice to cats.</figcaption></figure>
<p>Learning 3D effects can seem overwhelming due to the vast knowledge needed across multiple apps and district workflows. But Surfaced Studio stresses the simple importance of first understanding workflow hierarchies — and how one feeds into another — as an approachable entry point to choosing a specialty suited to a creator’s unique passion and natural talent.</p>
<p>Surfaced Studio was able to seamlessly run his scene in Unreal Engine full 4K resolution — with all textures and materials loading at maximum graphical fidelity — thanks to the GeForce RTX 4080 Laptop GPU in his Razer Blade 16. The graphics card also contains <a href="https://www.nvidia.com/en-us/geforce/news/dlss-3-5-available-september-21/#:~:text=DLSS%203.5%20is%20available%20for,NVIDIA%20DLSS%203.5%20announcement%20article.">NVIDIA DLSS</a> capabilities to increase viewport interactivity by using AI to upscale frames rendered at lower resolution while retaining high-fidelity detail.</p>
<figure id="attachment_67688" aria-describedby="caption-attachment-67688" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-unreal-engine-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67688" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-unreal-engine-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-unreal-engine-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-unreal-engine-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-unreal-engine-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-unreal-engine-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-unreal-engine-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-unreal-engine-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-unreal-engine-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67688" class="wp-caption-text">Moving virtual objects in Unreal Engine.</figcaption></figure>
<p>Surfaced Studio then took the FBX file with the exported camera tracking data into Unreal Engine, matching his ‘3D camera’ with the real-world one used to film the laptop with. “This was the crucial step in creating the ‘look-through’ effect I wanted,” he said.</p>
<p>Once satisfied with the look, Surfaced Studio exported all sequences from Unreal Engine as multilayer EXR files — including a Z-depth pass, a grayscale value range to create a depth-of-field effect — to separate visual elements from the 3D footage.</p>
<figure id="attachment_67691" aria-describedby="caption-attachment-67691" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-z-depth-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67691" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-z-depth-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-z-depth-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-z-depth-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-z-depth-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-z-depth-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-z-depth-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-z-depth-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-z-depth-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67691" class="wp-caption-text">Composite work in Adobe After Effects.</figcaption></figure>
<p>Surfaced Studio went back to After Effects for the final composites. He added distortion effects and some glow for the transition from the physical screen to the 3D world.</p>
<figure id="attachment_67694" aria-describedby="caption-attachment-67694" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-mocha-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67694" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-mocha-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-mocha-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-mocha-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-mocha-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-mocha-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-mocha-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-mocha-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-mocha-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67694" class="wp-caption-text">Cleaning up screen tracking in Adobe After Effects.</figcaption></figure>
<p>Then, Surfaced Studio again used the Z-depth pass to extract the 3D cars and overlay them onto the real footage.</p>
<figure id="attachment_67697" aria-describedby="caption-attachment-67697" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-enter-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67697" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-enter-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-enter-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-enter-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-enter-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-enter-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-enter-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-enter-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-ae-enter-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67697" class="wp-caption-text">Composite work in Adobe After Effects.</figcaption></figure>
<p>He exported the final project into Premiere Pro and added sound effects, music and a few color correction edits.</p>
<figure id="attachment_67700" aria-describedby="caption-attachment-67700" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-premiere-pro-final-edit-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67700" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-premiere-pro-final-edit-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-premiere-pro-final-edit-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-premiere-pro-final-edit-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-premiere-pro-final-edit-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-premiere-pro-final-edit-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-premiere-pro-final-edit-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-premiere-pro-final-edit-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-premiere-pro-final-edit-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67700" class="wp-caption-text">Final edits in Adobe Premiere Pro.</figcaption></figure>
<p>With GeForce RTX 4080 dual encoders, Surface Studio nearly halved Adobe Premiere Pro video decoding and encoding export times. Surfaced Studio has been using NVIDIA GPUs for over a decade, citing their widespread integration with commonly used tools.</p>
<p>“NVIDIA has simply done a better job than its competitors to reach out to and integrate with other companies that create creative apps,” said Surfaced Studio. “CUDA and RTX are widespread technologies that you find in most popular creative apps to accelerate workflows.”</p>
<p>When he’s not working on VFX projects, Surfaced Studio also uses his laptop to game. The Razer Blade 16 has the first dual-mode mini-LED display with two native resolutions: UHD+ at 120Hz — suited for VFX workflows — and FHD at 240Hz — ideal for gamers (or creators who like gaming).</p>
<figure id="attachment_67706" aria-describedby="caption-attachment-67706" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-studio-workspace-1-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67706" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-studio-workspace-1-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-studio-workspace-1-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-studio-workspace-1-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-studio-workspace-1-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-studio-workspace-1-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-studio-workspace-1-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-studio-workspace-1-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-surfaced-studio-wk80-studio-workspace-1-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67706" class="wp-caption-text">Powerful, elegant, beautiful: the Razer Blade 16 Mercury Edition.</figcaption></figure>
<p>For a limited time, gamers and creators can <a href="https://www.razer.com/campaigns/nvidia-game-bundle">get the critically acclaimed game <i>Alan Wake 2</i></a> with the purchase of the Razer Blade 16 powered by GeForce RTX 40 Series graphics cards.</p>
<p><iframe loading="lazy" title="Alan Wake 2 | 4K NVIDIA DLSS 3.5 World Premiere" width="500" height="281" src="https://www.youtube.com/embed/HwGbQwoMCxM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Surfaced Studio’s VFX tutorials are <a href="https://www.youtube.com/surfacedstudio">available on YouTube</a>, where he covers filmmaking, VFX and 3D techniques using Adobe After Effects, Blender, Photoshop, Premiere Pro and other apps.</p>
<figure id="attachment_67703" aria-describedby="caption-attachment-67703" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-surfaced-studio-wk80-artist-feature-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67703" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-surfaced-studio-wk80-artist-feature-1280w-672x282.png" alt="" width="672" height="282" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-surfaced-studio-wk80-artist-feature-1280w-672x282.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-surfaced-studio-wk80-artist-feature-1280w-400x168.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-surfaced-studio-wk80-artist-feature-1280w-768x323.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-surfaced-studio-wk80-artist-feature-1280w-842x354.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-surfaced-studio-wk80-artist-feature-1280w-406x171.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-surfaced-studio-wk80-artist-feature-1280w-188x79.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-itns-surfaced-studio-wk80-artist-feature-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67703" class="wp-caption-text">VFX artist Surfaced Studio.</figcaption></figure>
<h2><b>Join the #SeasonalArtChallenge</b></h2>
<p>Don’t forget to join the #SeasonalArtChallenge by submitting spooky Halloween-inspired art in October and harvest- and fall-themed pieces in November.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Welcome to our community <a href="https://twitter.com/hashtag/SeasonalArtChallenge?src=hash&amp;ref_src=twsrc%5Etfw">#SeasonalArtChallenge</a>! <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f383.png" alt="🎃" class="wp-smiley" style="height: 1em; max-height: 1em;" /><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f342.png" alt="🍂" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>We want to see your spooky/Halloween-themed art like this piece from <a href="https://twitter.com/michal_pruski?ref_src=twsrc%5Etfw">@michal_pruski</a> (IG), this October!</p>
<p>Share your art with <a href="https://twitter.com/hashtag/SeasonalArtChallenge?src=hash&amp;ref_src=twsrc%5Etfw">#SeasonalArtChallenge</a> for a chance to be featured on the Studio or <a href="https://twitter.com/nvidiaomniverse?ref_src=twsrc%5Etfw">@NVIDIAOmniverse</a> channels! <a href="https://t.co/J2tqIXoahP">pic.twitter.com/J2tqIXoahP</a></p>
<p>&mdash; NVIDIA Studio (@NVIDIAStudio) <a href="https://twitter.com/NVIDIAStudio/status/1708980054456144287?ref_src=twsrc%5Etfw">October 2, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>Twitter</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/surfaced-studio-nv-blog-header-preview-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/surfaced-studio-nv-blog-header-preview-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[On Razer’s Edge: VFX Star Surfaced Studio Creates Stunning Sci-Fi World This Week ‘In The NVIDIA Studio’]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Street View to the Rescue: Deep Learning Paves the Way to Safer Buildings</title>
		<link>https://blogs.nvidia.com/blog/2023/10/23/street-view-image-deep-learning-research-urban-building/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Mon, 23 Oct 2023 20:30:39 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Education]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[Public Sector]]></category>
		<category><![CDATA[Social Impact]]></category>
		<category><![CDATA[Supercomputing]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67650</guid>

					<description><![CDATA[Images such as those in Google Street View are taking on a new purpose in the hands of University of Florida Assistant Professor of Artificial Intelligence Chaofeng Wang. He’s using them, along with deep learning, in a research project to automate the evaluation of urban buildings. The project aims to help governments mitigate natural disaster <a class="read-more" href="https://blogs.nvidia.com/blog/2023/10/23/street-view-image-deep-learning-research-urban-building/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Images such as those in Google Street View are taking on a new purpose in the hands of University of Florida Assistant Professor of Artificial Intelligence Chaofeng Wang.</p>
<p>He’s using them, along with deep learning, in a research project to automate the evaluation of urban buildings. The project aims to help governments mitigate natural disaster damage by providing the information needed for decision-makers to bolster building structures or perform post-disaster recovery.</p>
<p>After a natural disaster such as an earthquake, local governments send teams to check and evaluate building conditions. Manually done, it can take up to months to go through the full stock of a city.</p>
<p>Wang’s project uses AI to accelerate the evaluation process — cutting the time needed to a few hours. The AI model is trained using images sourced from Google Street View and local governments to assign scores to buildings based on <a href="https://www.fema.gov/emergency-managers/risk-management/earthquake/training/fema-p-154" target="_blank" rel="noopener">Federal Emergency Management Agency (FEMA) P-154 standards</a>, which provide assessment guidelines based on factors like wall material, structure type, building age and more. Wang also collaborated with the <a href="https://www.worldbank.org/en/topic/disasterriskmanagement/brief/global-program-for-resilient-housing" target="_blank" rel="noopener">World Bank Global Program for Resilient Housing</a> to collect images and perform annotations, which were used to improve the model.</p>
<p>The collected images are placed in a data repository. The AI model reads the repository and performs inference on the images — a process accelerated by <a href="https://www.nvidia.com/en-us/data-center/dgx-a100/" target="_blank" rel="noopener">NVIDIA DGX A100</a> systems.</p>
<p>“Without NVIDIA GPUs, we wouldn’t have been able to do this,” Wang said. “They significantly accelerate the process, ensuring timely results.”</p>
<p>Wang used the DGX A100 nodes in the <a href="https://blogs.nvidia.com/blog/2020/07/21/university-of-florida-nvidia-ai-supercomputer/" target="_blank" rel="noopener">University of Florida’s supercomputer, HiPerGator</a>. HiPerGator is one of the world’s fastest AI supercomputers in academia, delivering 700 petaflops of AI performance, and was built with the support of NVIDIA founder and UF alumnus Chris Malachowsky and hardware, software, training and services from NVIDIA.</p>
<p>The AI model’s output is compiled into a database that feeds into a web portal, which shows information — including the safety assessment score, building type and even roof or wall material — in a map-based format.</p>
<p><img decoding="async" loading="lazy" class="alignnone size-full wp-image-67651" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/streetviewscreenshot.png" alt="" width="1757" height="787" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/streetviewscreenshot.png 1757w, https://blogs.nvidia.com/wp-content/uploads/2023/10/streetviewscreenshot-400x179.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/streetviewscreenshot-672x301.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/streetviewscreenshot-768x344.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/streetviewscreenshot-1536x688.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/10/streetviewscreenshot-842x377.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/10/streetviewscreenshot-406x182.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/10/streetviewscreenshot-188x84.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/10/streetviewscreenshot-1280x573.png 1280w" sizes="(max-width: 1757px) 100vw, 1757px" /></p>
<p>Wang’s work was funded by the <a href="https://www.nvidia.com/en-us/industries/higher-education-research/applied-research-program/" target="_blank" rel="noopener">NVIDIA Applied Research Accelerator Program</a>, which supports research projects that have the potential to make a real-world impact through the deployment of NVIDIA-accelerated applications adopted by commercial and government organizations.</p>
<h2><strong>A Helping Eye</strong></h2>
<p>Wang says that the portal can serve different needs depending on the use case. To prepare for a natural disaster, a government can use predictions solely from street view images.</p>
<p>“Those are static images — one example is Google Street View images, which get updated every several years,” he said. “But that’s good enough for collecting information and getting a general understanding about certain statistics.”</p>
<p>But for rural areas or developing regions, where such images aren’t available or not frequently updated, governments can collect the images themselves. Powered by NVIDIA GPUs, the timely delivery of building assessments can help accelerate analyses.</p>
<p>Wang also suggests that with enough refinement, his research could also create ripples for the urban planning and insurance industries.</p>
<p>The project is currently being tested by a few local governments in Mexico and is garnering interest in some African, Asian and South American countries. At its current state, it can achieve over 85% accuracy in its assessment scores, per ‌FEMA P-154 standards.</p>
<h2><b>Survey of the Land</b></h2>
<p>One challenge Wang cites is the variation in urban landscapes in different countries. Different regions have their own cultural and architectural styles. Not trained on a large or diverse enough pool of images, the AI model could be thrown off by factors like paint color when performing wall material analysis. Another challenge is urban density variation.</p>
<p>“It is a very general limitation of current AI technology,” Wang said. “In order to be useful, it requires enough training data to represent the distribution of the real world, so we’re putting efforts into the data collection process to solve the generalization issue.”</p>
<p>To overcome this challenge, Wang aims to train and test the model for more cities. So far, he’s tested about eight cities in different countries.</p>
<p>“We need to generate more detailed and high-quality annotations to train the model with,” he said. “That is the way we can improve the model in the future so that it can be used more widely.”</p>
<p>Wang’s goal is to get the project to a point where it can be deployed as a service for more general industry use.</p>
<p>“We are creating application programming interfaces that can estimate and analyze buildings and households to allow seamless integration with other products,” he said. “We are also building a user-friendly application that all government agencies and organizations can use.”</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/streetview3.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/streetview3-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Street View to the Rescue: Deep Learning Paves the Way to Safer Buildings]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>For the World to See: Nonprofit Deploys GPU-Powered Simulators to Train Providers in Sight-Saving Surgery</title>
		<link>https://blogs.nvidia.com/blog/2023/10/20/helpmesee-nonprofit-training-simulator-for-cataract-surgery/</link>
		
		<dc:creator><![CDATA[Isha Salian]]></dc:creator>
		<pubDate>Fri, 20 Oct 2023 13:00:50 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Education]]></category>
		<category><![CDATA[Embedded Computing]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[Rendering]]></category>
		<category><![CDATA[Social Impact]]></category>
		<category><![CDATA[Virtual Reality]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67485</guid>

					<description><![CDATA[GPU-powered surgical-simulation devices are helping train more than 2,000 doctors a year in lower-income countries to treat cataract blindness, the world’s leading cause of blindness, thanks to the nonprofit HelpMeSee. While cataract surgery has a success rate of around 99%, many patients in low- and middle-income countries lack access to the common procedure due to <a class="read-more" href="https://blogs.nvidia.com/blog/2023/10/20/helpmesee-nonprofit-training-simulator-for-cataract-surgery/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>GPU-powered surgical-simulation devices are helping train more than 2,000 doctors a year in lower-income countries to treat cataract blindness, the world’s <a href="https://academic.oup.com/inthealth/article/14/Supplement_1/i68/6563812" target="_blank" rel="noopener">leading cause of blindness</a>, thanks to the nonprofit HelpMeSee.</p>
<p>While cataract surgery has a success rate of <a href="https://okko.com.au/what-is-the-cataract-surgery-success-rate/#:~:text=The%20success%20rate%20for%20cataract,Sloan%2C%20F.%2C%202021." target="_blank" rel="noopener">around 99%</a>, many patients in low- and middle-income countries lack access to the common procedure due to a severe shortage of ophthalmologists. An estimated 90% of the <a href="https://academic.oup.com/inthealth/article/14/Supplement_1/i68/6563812" target="_blank" rel="noopener">100 million people</a> affected by cataract-related visual impairment or blindness are in these locations.</p>
<p>By training more healthcare providers — including those without a specialty in ophthalmology — to treat cataracts, <a href="https://helpmesee.org/" target="_blank" rel="noopener">HelpMeSee</a> improves the quality of life for patients such as a mother of two young children in Bhiwandi, near Mumbai, India, who was blinded by cataracts in both eyes.</p>
<p>“After the surgery, her vision improved dramatically and she was able to take up a job, changing the course of her entire family,” said Dr. Chetan Ahiwalay, chief instructor and subject-matter expert for HelpMeSee in India. “She and her husband are now happily raising their kids and leading a healthy life. These are the things that keep us going as doctors.”</p>
<p>HelpMeSee’s simulator devices use <a href="https://www.nvidia.com/en-us/design-visualization/rtx/">NVIDIA RTX GPUs</a> to render high-quality visuals, providing a more realistic training environment for doctors to hone their surgical skills. To further improve the trainee experience, NVIDIA experts are working with the HelpMeSee team to improve rendering performance, increase visual realism and augment the simulator with next-generation technologies such as real-time ray tracing and AI.</p>
<h2><b>Tackling Treatable Blindness With Accessible Training</b></h2>
<p>High-income countries have <a href="https://bmcpublichealth.biomedcentral.com/articles/10.1186/s12889-022-14491-0" target="_blank" rel="noopener">18x more ophthalmologists</a> per million residents than low-income countries. That coverage gap, which is far wider still in certain countries, makes it harder for those in thinly resourced areas to receive treatment for avoidable blindness.</p>
<p>HelpMeSee’s devices can train doctors on multiple eye procedures using immersive tools inspired by flight simulators used in aviation. The team trains doctors in countries including India, China, Madagascar, Mexico and the U.S., and rolls out multilingual training each year for new procedures.</p>
<p>The eye surgery simulator offers realistic 3D visuals, haptic feedback, performance scores and the opportunity to attempt a step of the procedure multiple times until the trainee achieves proficiency. Qualified instructors like Dr. Ahiwalay travel to rural and urban areas to deliver the training through structured courses — and help surgeons transition from the simulators to live surgeries.</p>
<figure id="attachment_67489" aria-describedby="caption-attachment-67489" style="width: 533px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/IMO-First-MSTC-Training_23-1-scaled.jpeg"><img decoding="async" loading="lazy" class="size-large wp-image-67489" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/IMO-First-MSTC-Training_23-1-533x500.jpeg" alt="Doctors training to perform cataract surgery" width="533" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/IMO-First-MSTC-Training_23-1-533x500.jpeg 533w, https://blogs.nvidia.com/wp-content/uploads/2023/10/IMO-First-MSTC-Training_23-1-400x375.jpeg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/IMO-First-MSTC-Training_23-1-768x720.jpeg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/IMO-First-MSTC-Training_23-1-1536x1441.jpeg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/10/IMO-First-MSTC-Training_23-1-scaled.jpeg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/10/IMO-First-MSTC-Training_23-1-480x450.jpeg 480w, https://blogs.nvidia.com/wp-content/uploads/2023/10/IMO-First-MSTC-Training_23-1-229x215.jpeg 229w, https://blogs.nvidia.com/wp-content/uploads/2023/10/IMO-First-MSTC-Training_23-1-107x100.jpeg 107w, https://blogs.nvidia.com/wp-content/uploads/2023/10/IMO-First-MSTC-Training_23-1-1280x1201.jpeg 1280w" sizes="(max-width: 533px) 100vw, 533px" /></a><figcaption id="caption-attachment-67489" class="wp-caption-text">During a training session, doctors learn to perform manual small-incision cataract surgery.</figcaption></figure>
<p>“We’re lowering the barrier for healthcare practitioners to learn these specific skills that can have a profound impact on patients,” said Dr. Bonnie An Henderson, CEO of HelpMeSee, which is based in New York. “Simulation-based training will improve surgical skills while keeping patients safe.”</p>
<h2><b>Looking Ahead to AI, Advanced Rendering </b></h2>
<p>HelpMeSee works with <a href="https://surgicalscience.com/" target="_blank" rel="noopener">Surgical Science</a>, a supplier of medical virtual-reality simulators, based in Gothenburg, Sweden, to develop the 3D models and real-time rendering for its devices. Other collaborators — Strasbourg, France-based <a href="https://www.insimo.com/" target="_blank" rel="noopener">InSimo</a> and Pune, India-based <a href="https://services.harman.com/" target="_blank" rel="noopener">Harman Connected Services</a> — develop the physics-based simulations and user interface, respectively.  <a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/delivering_the_nucleus.png"><img decoding="async" loading="lazy" class="alignright wp-image-67492" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/delivering_the_nucleus-400x400.png" alt="" width="250" height="250" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/delivering_the_nucleus-400x400.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/delivering_the_nucleus-500x500.png 500w, https://blogs.nvidia.com/wp-content/uploads/2023/10/delivering_the_nucleus-150x150.png 150w, https://blogs.nvidia.com/wp-content/uploads/2023/10/delivering_the_nucleus-768x768.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/delivering_the_nucleus-450x450.png 450w, https://blogs.nvidia.com/wp-content/uploads/2023/10/delivering_the_nucleus-215x215.png 215w, https://blogs.nvidia.com/wp-content/uploads/2023/10/delivering_the_nucleus-100x100.png 100w, https://blogs.nvidia.com/wp-content/uploads/2023/10/delivering_the_nucleus.png 1024w" sizes="(max-width: 250px) 100vw, 250px" /></a></p>
<p>“Since there are many crucial visual cues during eye surgery, the simulation requires high fidelity,” said Sebastian Ullrich, senior manager of software development at Surgical Science, who has worked with HelpMeSee for years. “To render a realistic 3D representation of the human eye, we use custom shader materials with high-resolution textures to represent various anatomical components, mimic optical properties such as refraction, use order-independent transparency sorting and employ volume rendering.”</p>
<p>NVIDIA RTX GPUs support 3D volume rendering, stereoscopic rendering and depth sorting algorithms that provide a realistic visual experience for HelpMeSee’s trainees. Working with NVIDIA, the team is investigating AI models that could provide trainees with a real-time analysis of the practice procedure and offer recommendations for improvement.</p>
<p>Watch a demo of HelpMeSee’s <a href="https://www.youtube.com/watch?v=Y2vHBo5jpD8" target="_blank" rel="noopener">cataract surgery training simulation</a>.</p>
<p><a href="https://www.nvidia.com/en-us/industries/healthcare-life-sciences/healthcare-news-sign-up/"><i>Subscribe to NVIDIA healthcare news</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/Dr.-Samuel-Kwizera.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/Dr.-Samuel-Kwizera-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[For the World to See: Nonprofit Deploys GPU-Powered Simulators to Train Providers in Sight-Saving Surgery]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Eureka! NVIDIA Research Breakthrough Puts New Spin on Robot Learning</title>
		<link>https://blogs.nvidia.com/blog/2023/10/20/eureka-robotics-research/</link>
		
		<dc:creator><![CDATA[Angie Lee]]></dc:creator>
		<pubDate>Fri, 20 Oct 2023 13:00:24 +0000</pubDate>
				<category><![CDATA[Autonomous Machines]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Isaac]]></category>
		<category><![CDATA[NVIDIA Research]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Open Source]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67624</guid>

					<description><![CDATA[A new AI agent developed by NVIDIA Research that can teach robots complex skills has trained a robotic hand to perform rapid pen-spinning tricks — for the first time as well as a human can. The stunning prestidigitation, showcased in the video above, is one of nearly 30 tasks that robots have learned to expertly <a class="read-more" href="https://blogs.nvidia.com/blog/2023/10/20/eureka-robotics-research/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>A new AI agent developed by <a href="https://www.nvidia.com/en-us/research/" target="_blank" rel="noopener">NVIDIA Research</a> that can teach robots complex skills has trained a robotic hand to perform rapid pen-spinning tricks — for the first time as well as a human can.</p>
<p>The stunning prestidigitation, showcased in the video above, is one of nearly 30 tasks that robots have learned to expertly accomplish thanks to Eureka, which autonomously writes reward algorithms to train bots.</p>
<p>Eureka has also taught robots to open drawers and cabinets, toss and catch balls, and manipulate scissors, among other tasks.</p>
<p>The Eureka research, <a href="https://eureka-research.github.io/" target="_blank" rel="noopener">published today</a>, includes a paper and the project’s AI algorithms, which developers can experiment with using <a href="https://developer.nvidia.com/isaac-gym" target="_blank" rel="noopener">NVIDIA Isaac Gym</a>, a physics simulation reference application for <a href="https://blogs.nvidia.com/blog/2018/08/02/supervised-unsupervised-learning/" target="_blank" rel="noopener">reinforcement learning</a> research. Isaac Gym is built on <a href="https://developer.nvidia.com/omniverse" target="_blank" rel="noopener">NVIDIA Omniverse</a>, a development platform for building 3D tools and applications based on the OpenUSD framework. Eureka itself is powered by the GPT-4 <a href="https://blogs.nvidia.com/blog/2023/01/26/what-are-large-language-models-used-for/" target="_blank" rel="noopener">large language model</a>.</p>
<p>“Reinforcement learning has enabled impressive wins over the last decade, yet many challenges still exist, such as reward design, which remains a trial-and-error process,” said Anima Anandkumar, senior director of AI research at NVIDIA and an author of the Eureka paper. “Eureka is a first step toward developing new algorithms that integrate generative and reinforcement learning methods to solve hard tasks.”</p>
<p><iframe loading="lazy" title="Eureka! Extreme Robot Dexterity with LLMs | NVIDIA Research Paper" width="500" height="281" src="https://www.youtube.com/embed/sDFAWnrCqKc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>AI Trains Robots</b></h2>
<p>Eureka-generated reward programs — which enable trial-and-error learning for robots — outperform expert human-written ones on more than 80% of tasks, according to the paper. This leads to an average performance improvement of more than 50% for the bots.</p>
<div style="width: 1920px;" class="wp-video"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video class="wp-video-shortcode" id="video-67624-1" width="1920" height="1080" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/franka_cabinet.mp4?_=1" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/franka_cabinet.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/10/franka_cabinet.mp4</a></video></div>
<p><i>Robot arm taught by Eureka to open a drawer.</i></p>
<p>The AI agent taps the GPT-4 LLM and <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/" target="_blank" rel="noopener">generative AI</a> to write software code that rewards robots for reinforcement learning. It doesn’t require task-specific prompting or predefined reward templates — and readily incorporates human feedback to modify its rewards for results more accurately aligned with a developer’s vision.</p>
<p>Using GPU-accelerated simulation in Isaac Gym, Eureka can quickly evaluate the quality of large batches of reward candidates for more efficient training.</p>
<p>Eureka then constructs a summary of the key stats from the training results and instructs the LLM to improve its generation of reward functions. In this way, the AI is self-improving. It’s taught all kinds of robots — quadruped, bipedal, quadrotor, dexterous hands, cobot arms and others — to accomplish all kinds of tasks.</p>
<p>The research paper provides in-depth evaluations of 20 Eureka-trained tasks, based on open-source dexterity benchmarks that require robotic hands to demonstrate a wide range of complex manipulation skills.</p>
<p>The results from nine Isaac Gym environments are showcased in visualizations generated using NVIDIA Omniverse.</p>
<div style="width: 1920px;" class="wp-video"><video class="wp-video-shortcode" id="video-67624-2" width="1920" height="1080" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/humanoid.mp4?_=2" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/humanoid.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/10/humanoid.mp4</a></video></div>
<p><i>Humanoid robot learns a running gait via Eureka.</i></p>
<p>“Eureka is a unique combination of large language models and NVIDIA GPU-accelerated simulation technologies,” said Linxi “Jim” Fan, senior research scientist at NVIDIA, who’s one of the project’s contributors. “We believe that Eureka will enable dexterous robot control and provide a new way to produce physically realistic animations for artists.”</p>
<p>It’s breakthrough work bound to get developers’ minds spinning with possibilities, adding to recent NVIDIA Research advancements like <a href="https://blogs.nvidia.com/blog/2023/10/04/ai-jim-fan/" target="_blank" rel="noopener">Voyager</a>, an AI agent built with GPT-4 that can autonomously play <i>Minecraft</i>.</p>
<p>NVIDIA Research comprises hundreds of scientists and engineers worldwide, with teams focused on topics including AI, computer graphics, computer vision, self-driving cars and robotics.</p>
<p><i>Learn more about </i><a href="https://eureka-research.github.io/" target="_blank" rel="noopener"><i>Eureka</i></a><i> and </i><a href="https://www.nvidia.com/en-us/research/" target="_blank" rel="noopener"><i>NVIDIA Research</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/10/franka_cabinet.mp4" length="275129" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/10/humanoid.mp4" length="2901442" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/eureka-featured-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/eureka-featured-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Eureka! NVIDIA Research Breakthrough Puts New Spin on Robot Learning]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Next-Level Computing: NVIDIA and AMD Deliver Powerful Workstations to Accelerate AI, Rendering and Simulation</title>
		<link>https://blogs.nvidia.com/blog/2023/10/19/ai-workstations/</link>
		
		<dc:creator><![CDATA[Stacy Ozorio]]></dc:creator>
		<pubDate>Thu, 19 Oct 2023 19:30:07 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[Rendering]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67603</guid>

					<description><![CDATA[To enable professionals worldwide to build and run AI applications right from their desktops, NVIDIA and AMD are powering a new line of workstations equipped with NVIDIA RTX Ada Generation GPUs and AMD Ryzen Threadripper PRO 7000 WX-Series CPUs. Bringing together the highest levels of AI computing, rendering and simulation capabilities, these new platforms enable <a class="read-more" href="https://blogs.nvidia.com/blog/2023/10/19/ai-workstations/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>To enable professionals worldwide to build and run AI applications right from their desktops, NVIDIA and AMD are powering a new line of <a href="https://www.nvidia.com/en-us/design-visualization/workstations/latest/">workstations</a> equipped with <a href="https://www.nvidia.com/en-us/design-visualization/technologies/rtx/" target="_blank" rel="noopener">NVIDIA RTX Ada Generation GPUs</a> and <a href="https://ir.amd.com/news-events/press-releases/detail/1162/amd-introduces-new-amd-ryzen-threadripper-7000-series" target="_blank" rel="noopener">AMD Ryzen Threadripper PRO 7000 WX-Series CPUs</a>.</p>
<p>Bringing together the highest levels of AI computing, rendering and simulation capabilities, these new platforms enable professionals to efficiently tackle the most resource-intensive, large-scale AI workflows locally.</p>
<h2><b>Bringing AI Innovation to the Desktop</b></h2>
<p>Advanced AI tasks typically require data-center-level performance. Training a <a href="https://www.nvidia.com/en-us/glossary/data-science/large-language-models/" target="_blank" rel="noopener">large language model</a> with a trillion parameters, for example, takes thousands of GPUs running for weeks, though research is underway to reduce model size and enable model training on smaller systems while still maintaining high levels of AI model accuracy.</p>
<p>The new NVIDIA RTX GPU and AMD CPU-powered AI workstations provide the power and performance required for training such smaller models, as well as local fine-tuning, and helping to offload data center and cloud resources for AI development tasks. The devices let users select single- or multi-GPU configurations as required for their workloads.</p>
<p>Smaller trained AI models also provide the opportunity to use workstations for local inferencing. RTX GPU and AMD CPU-powered workstations can be configured to run these smaller AI models for inference serving for small workgroups or departments.</p>
<p>With up to 48GB of memory in a single NVIDIA RTX GPU, these workstations offer a cost-effective way to reduce compute load on data centers. And when professionals do need to scale training and deployment from these workstations to data centers or the cloud, the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/" target="_blank" rel="noopener">NVIDIA AI Enterprise</a> software platform enables seamless portability of workflows and toolchains.</p>
<p>RTX GPU and AMD CPU-powered workstations also enable cutting-edge visual workflows. With accelerated computing power, the new workstations enable highly interactive content creation, industrial digitalization, and advanced simulation and design.</p>
<h2><b>Unmatched Power, Performance and Flexibility</b></h2>
<p>AMD Ryzen Threadripper PRO 7000 WX-Series processors provide the CPU platform for the next generation of demanding workloads. The processors deliver a significant increase in core count — up to 96 cores per CPU — and industry-leading maximum memory bandwidth in a single socket.</p>
<p>Combining them with the latest NVIDIA RTX Ada Generation GPUs brings unmatched power and performance in a workstation. The GPUs enable up to 2x the performance in ray tracing, AI processing, graphics rendering and computational tasks compared to the previous generation.</p>
<p>Ada Generation GPUs options include the RTX 4000 SFF, RTX 4000, RTX 4500, RTX 5000 and RTX 6000. They’re built on the <a href="https://www.nvidia.com/en-us/geforce/ada-lovelace-architecture/" target="_blank" rel="noopener">NVIDIA Ada Lovelace architecture</a> and feature up to 142 third-generation RT Cores, 568 fourth-generation Tensor Cores and 18,176 latest-generation CUDA cores.</p>
<p>From architecture and manufacturing to media and entertainment and healthcare, professionals across industries will be able to use the new workstations to tackle challenging AI computing workloads — along with 3D rendering, product visualization, simulation and scientific computing tasks.</p>
<h2><b>Availability</b></h2>
<p><a href="https://www.nvidia.com/en-us/design-visualization/workstations/latest/">New workstations</a> powered by NVIDIA RTX Ada Generation GPUs and the latest AMD Threadripper Pro processors will be available starting next month from BOXX and HP, with other system integrators offering them soon.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/proviz-intel-nv-workstation-kv-2972327-edit-r2.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/proviz-intel-nv-workstation-kv-2972327-edit-r2-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Next-Level Computing: NVIDIA and AMD Deliver Powerful Workstations to Accelerate AI, Rendering and Simulation]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
	</channel>
</rss>
