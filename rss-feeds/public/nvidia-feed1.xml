<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Thu, 18 Jul 2024 14:46:37 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.5.5</generator>
	<item>
		<title>Mistral AI and NVIDIA Unveil Mistral NeMo 12B, a Cutting-Edge Enterprise AI Model</title>
		<link>https://blogs.nvidia.com/blog/mistral-nvidia-ai-model/</link>
		
		<dc:creator><![CDATA[Kari Briski]]></dc:creator>
		<pubDate>Thu, 18 Jul 2024 14:00:59 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=73008</guid>

					<description><![CDATA[Mistral AI and NVIDIA today released a new state-of-the-art language model, Mistral NeMo 12B, that developers can easily customize and deploy for enterprise applications supporting chatbots, multilingual tasks, coding and summarization. By combining Mistral AI’s expertise in training data with NVIDIA’s optimized hardware and software ecosystem, the Mistral NeMo model offers high performance for diverse	<a class="read-more" href="https://blogs.nvidia.com/blog/mistral-nvidia-ai-model/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Mistral AI and NVIDIA today released a new state-of-the-art language model, <a target="_blank" href="https://mistral.ai/news/mistral-nemo">Mistral NeMo</a> 12B, that developers can easily customize and deploy for enterprise applications supporting chatbots, multilingual tasks, coding and summarization.</p>
<p>By combining Mistral AI’s expertise in training data with NVIDIA’s optimized hardware and software ecosystem, the Mistral NeMo model offers high performance for diverse applications.</p>
<p>&#8220;We are fortunate to collaborate with the NVIDIA team, leveraging their top-tier hardware and software,” said Guillaume Lample, cofounder and chief scientist of Mistral AI. “Together, we have developed a model with unprecedented accuracy, flexibility, high-efficiency and enterprise-grade support and security thanks to NVIDIA AI Enterprise deployment.”</p>
<p>Mistral NeMo was trained on the <a target="_blank" href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a> AI platform, which offers dedicated, scalable access to the latest NVIDIA architecture.</p>
<p><a target="_blank" href="https://developer.nvidia.com/tensorrt">NVIDIA TensorRT-LLM</a> for accelerated inference performance on large language models and the <a target="_blank" href="https://www.nvidia.com/en-us/ai-data-science/products/nemo/">NVIDIA NeMo</a> development platform for building custom generative AI models were also used to advance and optimize the process.</p>
<p>This collaboration underscores NVIDIA’s commitment to supporting the model-builder ecosystem.</p>
<p><b>Delivering Unprecedented Accuracy, Flexibility and Efficiency </b></p>
<p>Excelling in multi-turn conversations, math, common sense reasoning, world knowledge and coding, this enterprise-grade AI model delivers precise, reliable performance across diverse tasks.</p>
<p>With a 128K context length, Mistral NeMo processes extensive and complex information more coherently and accurately, ensuring contextually relevant outputs.</p>
<p>Released under the Apache 2.0 license, which fosters innovation and supports the broader AI community, Mistral NeMo is a 12-billion-parameter model. Additionally, the model uses the FP8 data format for model inference, which reduces memory size and speeds deployment without any degradation to accuracy.</p>
<p>That means the model learns tasks better and handles diverse scenarios more effectively, making it ideal for enterprise use cases.</p>
<p>Mistral NeMo comes packaged as an <a target="_blank" href="https://www.nvidia.com/en-us/ai/">NVIDIA NIM</a> inference microservice, offering performance-optimized inference with NVIDIA TensorRT-LLM engines.</p>
<p>This containerized format allows for easy deployment anywhere, providing enhanced flexibility for various applications.</p>
<p>As a result, models can be deployed anywhere in minutes, rather than several days.</p>
<p>NIM features enterprise-grade software that’s part of <a target="_blank" href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a>, with dedicated feature branches, rigorous validation processes, and enterprise-grade security and support.</p>
<p>It includes comprehensive support, direct access to an NVIDIA AI expert and defined service-level agreements, delivering reliable and consistent performance.</p>
<p>The open model license allows enterprises to integrate Mistral NeMo into commercial applications seamlessly.</p>
<p>Designed to fit on the memory of a single NVIDIA L40S, NVIDIA GeForce RTX 4090 or NVIDIA RTX 4500 GPU, the Mistral NeMo NIM offers high efficiency, low compute cost, and enhanced security and privacy.</p>
<p><b>Advanced Model Development and Customization </b></p>
<p>The combined expertise of Mistral AI and NVIDIA engineers has optimized training and inference for Mistral NeMo.</p>
<p>Trained with Mistral AI’s expertise, especially on multilinguality, code and multi-turn content, the model benefits from accelerated training on NVIDIA’s full stack.</p>
<p>It’s designed for optimal performance, utilizing efficient model parallelism techniques, scalability and mixed precision with Megatron-LM.</p>
<p>The model was trained using<a target="_blank" href="https://github.com/NVIDIA/Megatron-LM"> Megatron-LM</a>, part of NVIDIA <a target="_blank" href="https://www.nvidia.com/en-us/ai-data-science/products/nemo/">NeMo</a>, with 3,072 H100 80GB Tensor Core GPUs on DGX Cloud, composed of NVIDIA AI architecture, including accelerated computing, network fabric and software to increase training efficiency.</p>
<p><b>Availability and Deployment</b></p>
<p>With the flexibility to run anywhere — cloud, data center or RTX workstation — Mistral NeMo is ready to revolutionize AI applications across various platforms.</p>
<p>Experience Mistral NeMo as an NVIDIA NIM today via <a target="_blank" href="http://ai.nvidia.com">ai.nvidia.com</a>, with a downloadable NIM coming soon.</p>
<p><i>See </i><a target="_blank" href="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.nvidia.com%2Fen-us%2Fabout-nvidia%2Flegal-info%2F&amp;data=05%7C02%7Clpham%40nvidia.com%7Cd59f2f66f51e4deaac8008dc94b3ef0f%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638548747745016311%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=dm8Os%2B4LtHW2ehZrPaxn38bsutMQBDeUdQuxrIa2y1Y%3D&amp;reserved=0"><i>notice</i></a><i> regarding software product information.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/ngc-corp-blog-community-model-confidential-model-1280x680-2.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/ngc-corp-blog-community-model-confidential-model-1280x680-2-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Mistral AI and NVIDIA Unveil Mistral NeMo 12B, a Cutting-Edge Enterprise AI Model]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Hot Deal, Cool Prices: GeForce NOW Summer Sale Offers Priority and Ultimate Memberships Half Off</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-summer-sale-2024/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 18 Jul 2024 13:00:31 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=73015</guid>

					<description><![CDATA[It’s time for a sweet treat — the GeForce NOW Summer Sale offers high-performance cloud gaming at half off for a limited time. And starting today, gamers can directly access supported PC games on GeForce NOW via Xbox.com game pages, enabling them to get into their favorite Xbox PC games even faster. It all comes	<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-summer-sale-2024/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>It’s time for a sweet treat — the <a target="_blank" href="http://geforcenow.com">GeForce NOW Summer Sale</a> offers high-performance cloud gaming at half off for a limited time.</p>
<p>And starting today, gamers can directly access supported PC games on GeForce NOW via Xbox.com game pages, enabling them to get into their favorite Xbox PC games even faster.</p>
<p>It all comes with nine new games joining the cloud this week.</p>
<h2><b>We Halve a Deal</b></h2>
<figure id="attachment_73025" aria-describedby="caption-attachment-73025" style="width: 672px" class="wp-caption aligncenter"><img fetchpriority="high" decoding="async" class="size-large wp-image-73025" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Summer_Sale-672x336.jpg" alt="Summer Sale on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Summer_Sale-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Summer_Sale-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Summer_Sale-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Summer_Sale-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Summer_Sale-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Summer_Sale-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Summer_Sale-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Summer_Sale-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Summer_Sale-1280x640.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-73025" class="wp-caption-text"><em>Unlock the power of cloud gaming with GeForce NOW’s sizzling summer sale.</em></figcaption></figure>
<p>Take advantage of a special new discount — one-month and six-month GeForce NOW Priority or Ultimate memberships are now 50% off until Aug. 18. It’s perfect for members wanting to level up their gaming experience or those looking to try GeForce NOW for the first time to access and stream an ever-growing library of over 1,900 games with top-notch performance.</p>
<p>Priority members enjoy more benefits over free users, including faster access to gaming servers and gaming sessions of up to six hours. They can also stream beautifully ray-traced graphics across multiple devices with RTX ON for the most immersive experience in supported games.</p>
<p>For those looking for top-notch performance, the Ultimate tier provides members with exclusive access to servers and the ability to stream at up to 4K resolution and 120 frames per second, or up to 240 fps — even without upgraded hardware. Ultimate members get all the same benefits as <a target="_blank" href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/">GeForce RTX 40 series GPU</a> owners, including <a target="_blank" href="https://www.nvidia.com/en-us/geforce/news/dlss3-ai-powered-neural-graphics-innovations/">NVIDIA DLSS 3</a> for the smoothest frame rates and <a target="_blank" href="https://www.nvidia.com/en-us/geforce/technologies/reflex/">NVIDIA Reflex</a> for the lowest-latency streaming from the cloud.</p>
<p>Strike while it’s hot — this scorching summer sale ends soon.</p>
<h2><b>Path of the Goddess</b></h2>
<figure id="attachment_73022" aria-describedby="caption-attachment-73022" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" class="size-large wp-image-73022" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Kunitsu_Gami_Path_of_the_Goddess-672x378.jpg" alt="Kunitsu-Gami: Path of the Goddess on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Kunitsu_Gami_Path_of_the_Goddess-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Kunitsu_Gami_Path_of_the_Goddess-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Kunitsu_Gami_Path_of_the_Goddess-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Kunitsu_Gami_Path_of_the_Goddess-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Kunitsu_Gami_Path_of_the_Goddess-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Kunitsu_Gami_Path_of_the_Goddess-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Kunitsu_Gami_Path_of_the_Goddess-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Kunitsu_Gami_Path_of_the_Goddess-1280x720.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Kunitsu_Gami_Path_of_the_Goddess.jpg 1920w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-73022" class="wp-caption-text"><em>Rinse and repeat.</em></figcaption></figure>
<p>Capcom’s latest release, <i>Kunitsu-Gami: Path of the Goddess </i>is a unique Japanese-inspired, single-player Kagura Action Strategy game.</p>
<p>The game takes place on a mountain covered in defilement. During the day, purify the villages and prepare for sundown. During the night, protect the Maiden against the hordes of the Seethe. Repeat the day-and-night cycle until the mountain has been cleansed of defilement and peace has returned to the land.</p>
<p>Walk the path of the goddess in the cloud with extended gaming sessions for Ultimate and Priority members. Ultimate members can also enjoy seeing supernatural and human worlds collide in ultrawide resolutions for an even more immersive experience.</p>
<h2><b>Slay New Games</b></h2>
<figure id="attachment_73019" aria-describedby="caption-attachment-73019" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" class="size-large wp-image-73019" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Dungeons_of_Hunterberg-672x336.jpg" alt="Dungeons of Hinterberg on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Dungeons_of_Hunterberg-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Dungeons_of_Hunterberg-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Dungeons_of_Hunterberg-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Dungeons_of_Hunterberg-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Dungeons_of_Hunterberg-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Dungeons_of_Hunterberg-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Dungeons_of_Hunterberg-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Dungeons_of_Hunterberg-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Dungeons_of_Hunterberg.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-73019" class="wp-caption-text"><em>Having a holiday in Hinterberg.</em></figcaption></figure>
<p>In <i>Dungeons of Hinterberg </i>from Microbird Games, play as Luisa, a burnt-out law trainee taking a break from her fast-paced corporate life. Explore the beautiful alpine village of Hinterberg armed with just a sword and a tourist guide, and uncover the magic hidden within its dungeons. Master magic, solve puzzles and slay monsters — all from the cloud.</p>
<p>Check out the list of new games this week:</p>
<ul>
<li><i>The Crust </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1465470?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, July 15)</li>
<li><i>Gestalt: Steam &amp; Cinder </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1231990?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, July 16)</li>
<li><i>Nobody Wants to Die</i> (New release on <a target="_blank" href="https://store.steampowered.com/app/1939970?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, July 17)</li>
<li><i>Dungeons of Hinterberg </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1983260?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a target="_blank" href="https://www.xbox.com/games/store/dungeons-of-hinterberg/9pgx472j0rjp?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass, July 18)</li>
<li><i>Flintlock: The Siege of Dawn  </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1832040?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a target="_blank" href="https://www.xbox.com/games/store/flintlock-the-siege-of-dawn/9PBBQHX6V3PJ?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass, July 18)</li>
<li><i>Norland </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1857090?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, July 18)</li>
<li><i>Kunitsu-Gami: Path of the Goddess</i> (New release on <a target="_blank" href="https://store.steampowered.com/app/2510710?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, July 19)</li>
<li><i>Content Warning </i>(<a target="_blank" href="https://store.steampowered.com/app/2881650?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Crime Boss: Rockay City </i>(<a target="_blank" href="https://store.steampowered.com/app/2933080?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a target="_blank" href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Come sale away this summer<img src="https://s.w.org/images/core/emoji/15.0.3/72x72/26f5.png" alt="⛵" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a target="_blank" href="https://twitter.com/NVIDIAGFN/status/1813604574835753260?ref_src=twsrc%5Etfw">July 17, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/gfn-thursday-7-18-nv-blog-1280x680-no-cta.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/gfn-thursday-7-18-nv-blog-1280x680-no-cta-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Hot Deal, Cool Prices: GeForce NOW Summer Sale Offers Priority and Ultimate Memberships Half Off]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Decoding How AI-Powered Upscaling on NVIDIA RTX Improves Video Quality</title>
		<link>https://blogs.nvidia.com/blog/ai-decoded-upscaling/</link>
		
		<dc:creator><![CDATA[Brian Choi]]></dc:creator>
		<pubDate>Wed, 17 Jul 2024 13:00:58 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[AI Decoded]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[SHIELD]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72981</guid>

					<description><![CDATA[Video is everywhere — nearly 80% of internet bandwidth today is used to stream video from content providers and social networks.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><i>Editor’s note: This post is part of the </i><a href="https://blogs.nvidia.com/blog/tag/ai-decoded/"><i>AI Decoded series</i></a><i>, which demystifies AI by making the technology more accessible, and showcases new hardware, software, tools and accelerations for RTX PC and workstation users.</i></p>
<p>Video is everywhere — nearly 80% of internet bandwidth today is used to stream video from content providers and social networks. While screens have become bigger and support higher resolutions, nearly all video is only 1080p quality or lower.</p>
<p>Upscalers can help sharpen streamed video and, powered by AI on the NVIDIA RTX platform, significantly enhance image quality and detail.</p>
<h2><b>What Is an Upscaler?</b></h2>
<p>The larger file size of videos makes it harder to compress and transmit compared to images or text. Platforms like Netflix, Vimeo and YouTube work around this limitation by encoding video — the process of compressing the raw source of a video into a smaller container format.</p>
<p>The encoder first analyzes the video to decide what information it can remove to make it fit a target resolution and frame rate. If the target bitrate is insufficient, the video quality decreases, resulting in a loss of detail and sharpness and the presence of encoding artifacts. The smaller the file, the easier it is to share on the internet — but the worse it looks.</p>
<p>Typically, software on the viewer’s device will upscale the video file to fit the display’s native resolution. However, these upscalers are fairly simplistic, merely multiplying pixels to meet the desired resolution. They can help sharpen the outlines of objects and scenes, but the final video typically carries encoding artifacts and sometimes looks over-sharpened and unnatural.</p>
<h2><b>AI Know a Better Way</b></h2>
<p>The NVIDIA RTX platform uses AI to easily de-artifact and upscale videos.</p>
<figure id="attachment_72985" aria-describedby="caption-attachment-72985" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution-signal-flow.png"><img loading="lazy" decoding="async" class="wp-image-72985 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution-signal-flow-672x348.png" alt="" width="672" height="348" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution-signal-flow-672x348.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution-signal-flow-400x207.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution-signal-flow-768x398.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution-signal-flow-1536x797.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution-signal-flow-842x437.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution-signal-flow-406x211.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution-signal-flow-188x97.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution-signal-flow-1280x664.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution-signal-flow.png 2048w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-72985" class="wp-caption-text">Easily de-artifact and upscale videos with RTX.</figcaption></figure>
<p>The process of AI upscaling involves analyzing images and motion vectors to generate new details not present in the original video. Instead of merely multiplying pixels, it recognizes the patterns of the image and enhances them to provide greater detail and video quality.</p>
<p>Images must be first de-artifacted before any processing begins. Artifacts — or unwanted distortions and anomalies that appear in video and image files — occur due to overcompression or data loss during transmission and storage.</p>
<p>NVIDIA AI networks can de-artifact images, helping remove blocky areas sometimes seen in streamed video. Without this first step, AI upscalers might end up enhancing the artifacted image itself instead of the desired content.</p>
<h2><b>Super-Sized Video</b></h2>
<p>Just like putting on a pair of prescription glasses can instantly snap the world into focus, RTX Video Super Resolution, one of NVIDIA’s latest innovations in AI-enhanced video technology, gives users a clearer picture into the world of streamed video.</p>
<figure id="attachment_72988" aria-describedby="caption-attachment-72988" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution_full-size-scaled-1.jpg"><img loading="lazy" decoding="async" class="wp-image-72988 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution_full-size-scaled-1-672x378.jpg" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution_full-size-scaled-1-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution_full-size-scaled-1-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution_full-size-scaled-1-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution_full-size-scaled-1-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution_full-size-scaled-1-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution_full-size-scaled-1-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution_full-size-scaled-1-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution_full-size-scaled-1-1280x720.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/07/rtx-video-super-resolution_full-size-scaled-1.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-72988" class="wp-caption-text">Click the image to see the differences between bicubic upscaling (left) and RTX Video Super Resolution (right).</figcaption></figure>
<p>Available on GeForce RTX 40 and 30 Series GPUs and RTX professional GPUs, it uses AI running on dedicated Tensor Cores to remove block compression artifacts and upscale lower-resolution content up to 4K, matching the user’s native display resolution.</p>
<p>RTX Video Super Resolution can be used to enhance all video watched on browsers. By combining de-artifacting with AI upscaling techniques, it can make even low-bitrate Twitch streams look stunningly clear. RTX Video Super Resolution is also supported in popular video apps like VLC so users can apply the same upscaling process to their offline videos.</p>
<p>Creators can soon use RTX Video Super Resolution in editing apps like Black Magic’s Davinci Resolve, making it easier than ever to upscale lower-quality video files to 4K resolution, as well as convert standard-dynamic range source files into high-dynamic range (HDR).</p>
<h2><b>Say Hi to High-Dynamic Range</b></h2>
<p>RTX Video now also supports AI HDR. HDR video supports a wider range of colors, lending greater detail especially to the darker and lighter areas of images. The problem is that there isn’t that much HDR content online yet.</p>
<p><iframe loading="lazy" title="Introducing RTX Video HDR: AI-Upscale Video to HDR Quality" width="500" height="281" src="https://www.youtube.com/embed/FHAjydnpos8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Enter RTX Video HDR — by simply turning on the feature, the AI network will turn any standard or low-dynamic-range content into HDR, performing the correct tone mapping so the image still looks natural and retains its original colors.</p>
<h2><b>AI Across the Board</b></h2>
<p>RTX Video is just the latest implementation of AI upscaling powered by NVIDIA RTX.</p>
<p>Members of the GeForce NOW cloud streaming service can play their favorite PC games on nearly any device. GeForce RTX servers located all over the world first render the game video content, encode it and then stream it to the player’s local device — just like streaming video from other content providers.</p>
<p>Members on older NVIDIA GPU-powered devices can still use AI-enhanced upscaling to improve gameplay quality. This means they can enjoy the best of both worlds — gameplay rendered on servers powered by RTX 4080-class GPUs in the cloud and AI-enhanced streaming quality. Get more information on <a target="_blank" href="https://nvidia.custhelp.com/app/answers/detail/a_id/5250">enabling AI-enhanced upscaling on GeForce NOW</a>.</p>
<p>The <a target="_blank" href="https://www.nvidia.com/en-us/shield/">NVIDIA SHIELD</a> TV takes this one step further, processing AI neural networks directly on its <a target="_blank" href="https://developer.nvidia.com/embedded/buy/tegra-k1-processor">NVIDIA Tegra</a> system-on-a-chip to upscale 1080p-quality or lower content from nearly any streaming platform to a display’s native resolution. That means users can improve the video quality of content streamed from Netflix, Prime Video, Max, Disney+ and more at the push of a remote button.</p>
<p><a target="_blank" href="https://www.nvidia.com/en-us/shield/sliders/ai-upscaling/"><img loading="lazy" decoding="async" class="aligncenter wp-image-72991 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/ai-upscaling-demo-672x368.jpg" alt="" width="672" height="368" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/07/ai-upscaling-demo-672x368.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/07/ai-upscaling-demo-400x219.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/07/ai-upscaling-demo-768x421.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/07/ai-upscaling-demo-821x450.jpg 821w, https://blogs.nvidia.com/wp-content/uploads/2024/07/ai-upscaling-demo-392x215.jpg 392w, https://blogs.nvidia.com/wp-content/uploads/2024/07/ai-upscaling-demo-182x100.jpg 182w, https://blogs.nvidia.com/wp-content/uploads/2024/07/ai-upscaling-demo.jpg 1195w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<p>SHIELD TV is currently available for up to $30 off in North America and £30 or 35€ off in Europe as part of Amazon’s Prime Day event running July 16-17. For Prime members in Europe, eligible SHIELD TV purchases also include one month of the GeForce NOW Ultimate membership for free, enabling GeForce RTX 4080-class PC gameplay streamed directly to the living room.</p>
<p><iframe loading="lazy" title="Nvidia Shield TV: Why it&#039;s still the BEST Android TV box!" width="500" height="281" src="https://www.youtube.com/embed/Df4j34d54WM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>AI has enabled unprecedented improvements in video quality, helping set a new standard in streaming experiences.</p>
<p><i>Generative AI is transforming gaming, videoconferencing and interactive experiences of all kinds. Make sense of what’s new and what’s next by subscribing to the </i><a target="_blank" href="https://www.nvidia.com/en-us/ai-on-rtx/?modal=subscribe-ai"><i>AI Decoded newsletter</i></a><i>.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/ai-decoded-upscaling-nv-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/ai-decoded-upscaling-nv-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Decoding How AI-Powered Upscaling on NVIDIA RTX Improves Video Quality]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Next-Gen Video Editing: Wondershare Filmora Adds NVIDIA RTX Video HDR Support, RTX-Accelerated AI Features</title>
		<link>https://blogs.nvidia.com/blog/studio-wondershare-filmora-rtx-ai-july-driver/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 16 Jul 2024 13:00:19 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio Driver]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72952</guid>

					<description><![CDATA[Wondershare Filmora — a video editing app with AI-powered tools — now supports NVIDIA RTX Video HDR, joining editing software like Blackmagic Design’s DaVinci Resolve and Cyberlink PowerDirector.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><i>Editor’s note: This post is part of our </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a target="_blank" href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. We’re also deep diving on new </i><a target="_blank" href="https://www.nvidia.com/en-us/geforce/rtx/"><i>GeForce RTX GPU</i></a><i> features, technologies and resources, and how they dramatically accelerate content creation.</i></p>
<p>Wondershare Filmora — a video editing app with AI-powered tools — now supports NVIDIA RTX Video HDR, joining editing software like Blackmagic Design’s DaVinci Resolve and Cyberlink PowerDirector.</p>
<p>RTX Video HDR significantly enhances video quality, ensuring the final output is suitable for the best monitors available today.</p>
<p><iframe loading="lazy" title="Filmora x NVIDIA Partnership" width="500" height="281" src="https://www.youtube.com/embed/I2ZUGB8JZKc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Livestreaming software OBS Studio and XSplit Broadcaster now support Twitch Enhanced Broadcasting, giving streamers more control over video quality through client-side encoding and automatic configurations. The feature, developed in collaboration between Twitch, OBS and NVIDIA, also paves the way for more advancements, including vertical live video and advanced codecs such as HEVC and AV1.</p>
<p>A summer’s worth of creative app updates are included in the July Studio Driver, ready for <a target="_blank" href="https://www.nvidia.com/en-us/geforce/drivers/">download</a> today. Install the <a target="_blank" href="https://www.nvidia.com/en-us/software/nvidia-app/">NVIDIA app</a> beta — the essential companion for creators and gamers — to keep GeForce RTX PCs up to date with the latest NVIDIA drivers and technology.</p>
<p>Join NVIDIA at <a target="_blank" href="https://www.nvidia.com/en-us/events/siggraph/">SIGGRAPH</a> to learn about the latest breakthroughs in graphics and generative AI, and tune in to a fireside chat featuring NVIDIA founder and CEO Jensen Huang and Lauren Goode, senior writer at WIRED, on Monday, July 29 at 2:30 p.m. MT. <a target="_blank" href="https://s2024.siggraph.org/program/keynote-presentations/#speaker-huang">Register now</a>.</p>
<p>And this week’s featured<i> In the NVIDIA Studio </i>artist, Kevin Stratvert, shares all about AI-powered content creation in Wondershare Filmora.</p>
<h2><b>(Wonder)share the Beauty of RTX Video</b></h2>
<p><a href="https://blogs.nvidia.com/blog/rtx-video-hdr-remix-studio-driver/">RTX Video HDR</a> analyzes standard dynamic range video and transforms it into HDR10-quality video, expanding the color gamut to produce clearer, more vibrant frames and enhancing the sense of depth for greater immersion.</p>
<p>With RTX Video HDR, Filmora users can create high-quality content that’s ideal for gaming videos, travel vlogs or event filmmaking.</p>
<p>Combining RTX Video HDR with <a href="https://blogs.nvidia.com/blog/rtx-video-super-resolution/">RTX Video Super Resolution</a> — another AI-powered tool that uses trained models to sharpen edges, restore features and remove artifacts in video — further enhances visual quality. RTX Video HDR requires an NVIDIA RTX GPU connected to an HDR10-compatible monitor or TV. For more information, check out the <a target="_blank" href="https://nvidia.custhelp.com/app/answers/detail/a_id/5448/~/rtx-video-super-resolution-faq">RTX Video FAQ</a>.</p>
<p>Those with a RTX GPU-powered PC can send files to the Filmora desktop app and continue to edit with local RTX acceleration, doubling the speed of the export process with dual encoders on GeForce RTX 4070 Ti or above GPUs.</p>
<p>Learn more about <a target="_blank" href="https://filmora.wondershare.net/ai-features.html?gad_source=1&amp;gclid=CjwKCAjwnK60BhA9EiwAmpHZw62RpoOFbNoF1rHGVNbssHFgXqQygDzHwp_isBqCFRmYHx-0xE5gwxoCsUQQAvD_BwE">Wondershare Filmora’s AI-powered features</a>.</p>
<h2><b>Maximizing AI Features in Filmora</b></h2>
<p>Kevin Stratvert has the heart of a teacher — he’s always loved to share his technical knowledge and tips with others.</p>
<p>One day, he thought, “Why not make a YouTube video to explain stuff directly to users?” His first big hit was a tutorial on how to get Microsoft Office for free through Office.com. The video garnered millions of views and tons of engagement — and he’s continued creating content ever since.</p>
<p><iframe loading="lazy" title="&#x1f3a8; Turn Your Sketches into AI Masterpieces #AIDecoded #NVIDIAPartner @NVIDIA-Studio" width="500" height="281" src="https://www.youtube.com/embed/epPczWW0ApM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>“The more content I created, the more questions and feedback I got from viewers, sparking this cycle of creativity and connection that I just couldn’t get enough of,” said Stratvert.</p>
<p>Explaining the benefits of AI has been an area of particular interest for Stratvert, especially as it relates to AI-powered features in Wondershare Filmora. In one YouTube video, <a target="_blank" href="https://www.youtube.com/watch?v=IjLVHHmc76Q">Filmora Video Editor Tutorial for Beginners</a>, he breaks down the AI effects video editors can use to accelerate their workflows.</p>
<p><iframe loading="lazy" title="Filmora Video Editor Tutorial for Beginners" width="500" height="281" src="https://www.youtube.com/embed/IjLVHHmc76Q?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Examples include:</p>
<ul>
<li><a target="_blank" href="https://www.youtube.com/watch?v=IjLVHHmc76Q&amp;t=898s">Smart Edit</a>: Edit footage-based transcripts generated automatically, including in multiple languages.</li>
<li><a target="_blank" href="https://www.youtube.com/watch?v=IjLVHHmc76Q&amp;t=1645s">Smart Cutout</a>: Remove unwanted objects or change the background in seconds.</li>
<li><a target="_blank" href="https://www.youtube.com/watch?v=IjLVHHmc76Q&amp;t=2601s">Speech-to-Text</a>: Automatically generate compelling descriptions, titles and captions.</li>
</ul>
<p>“AI has become a crucial part of my creative toolkit, especially for refining details that really make a difference,” said Stratvert. “By handling these technical tasks, AI frees up my time to focus more on creating content, making the whole process smoother and more efficient.”</p>
<p>Stratvert has also been experimenting with <a target="_blank" href="https://www.nvidia.com/en-us/ai-on-rtx/chatrtx/">NVIDIA ChatRTX</a>, a technology that lets users interact with their local data, installing and configuring various AI models, effectively prompting AI for both text and image outputs using CLIP and more.</p>
<p><iframe loading="lazy" title="How to Use NVIDIA ChatRTX | AI Chatbot Using Your Files" width="500" height="281" src="https://www.youtube.com/embed/wZ4sPUcdlO4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p><a target="_blank" href="https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/?ncid=pa-srch-goog-47075&amp;gad_source=1&amp;gclid=CjwKCAjwnK60BhA9EiwAmpHZw-Hv4Bn8upm1h58L21KV1ziy1ThVm6BAUQepE5hwYrK6mjqA_UatjxoCmKAQAvD_BwE#cid=gf45_pa-srch-goog_en-us">NVIDIA Broadcast</a> has been instrumental in giving Stratvert a professional setup for web conferences and livestreams. The app’s features, including background noise removal and virtual background, help maintain a professional appearance on screen. It’s especially useful in home studio settings, where controlling variables in the environment can be challenging.</p>
<p><iframe loading="lazy" title="How to use NVIDIA Broadcast" width="500" height="281" src="https://www.youtube.com/embed/X0J-nO74ELA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<div class="simplePullQuote right"><p>“NVIDIA Broadcast has been instrumental in professionalizing my setup for web conferences and livestreams.” — Kevin Stratvert</p>
</div>
<p>Stratvert stresses the importance of his GeForce <a target="_blank" href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4070-family/">RTX 4070 graphics card</a> in the content creation process.</p>
<p>“With an RTX GPU, I’ve noticed a dramatic improvement in render times and the smoothness of playback, even in demanding scenarios,” he said. “Additionally, the advanced capabilities of RTX GPUs support more intensive tasks like real-time ray tracing and AI-driven editing features, which can open up new creative possibilities in my edits.”</p>
<p>Check out Stratvert’s video tutorials on his <a target="_blank" href="https://kevinstratvert.com/">website</a>.</p>
<figure id="attachment_72953" aria-describedby="caption-attachment-72953" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/07/studio-itns-kevin-stratvert-wk118-featured-setup-1280w-1.png"><img loading="lazy" decoding="async" class="size-large wp-image-72953" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/studio-itns-kevin-stratvert-wk118-featured-setup-1280w-1-672x246.png" alt="" width="672" height="246" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/07/studio-itns-kevin-stratvert-wk118-featured-setup-1280w-1-672x246.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/07/studio-itns-kevin-stratvert-wk118-featured-setup-1280w-1-400x146.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/07/studio-itns-kevin-stratvert-wk118-featured-setup-1280w-1-768x281.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/07/studio-itns-kevin-stratvert-wk118-featured-setup-1280w-1-842x308.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/07/studio-itns-kevin-stratvert-wk118-featured-setup-1280w-1-406x148.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/07/studio-itns-kevin-stratvert-wk118-featured-setup-1280w-1-188x69.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/07/studio-itns-kevin-stratvert-wk118-featured-setup-1280w-1.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-72953" class="wp-caption-text">Content creator Kevin Stratvert.</figcaption></figure>
<p><i>Follow NVIDIA Studio on </i><a target="_blank" href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a target="_blank" href="https://twitter.com/NVIDIAStudio"><i>X</i></a><i> and </i><a target="_blank" href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a target="_blank" href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a target="_blank" href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>. </i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/nv-blog-header-preview-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/nv-blog-header-preview-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Next-Gen Video Editing: Wondershare Filmora Adds NVIDIA RTX Video HDR Support, RTX-Accelerated AI Features]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Jensen Huang, Mark Zuckerberg to Discuss Future of Graphics and Virtual Worlds at SIGGRAPH 2024</title>
		<link>https://blogs.nvidia.com/blog/huang-zuckerberg-siggraph-2024/</link>
		
		<dc:creator><![CDATA[Claudia Cook]]></dc:creator>
		<pubDate>Mon, 15 Jul 2024 17:14:39 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[SIGGRAPH]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72943</guid>

					<description><![CDATA[NVIDIA founder and CEO Jensen Huang and Meta founder and CEO Mark Zuckerberg will hold a public fireside chat on Monday, July 29, at the 50th edition of the SIGGRAPH graphics conference in Denver. The two leaders will discuss the future of AI and simulation and the pivotal role of research at SIGGRAPH, which focuses	<a class="read-more" href="https://blogs.nvidia.com/blog/huang-zuckerberg-siggraph-2024/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>NVIDIA founder and CEO Jensen Huang and Meta founder and CEO Mark Zuckerberg will hold a public fireside chat on Monday, July 29, at the 50th edition of the <a target="_blank" href="https://www.nvidia.com/en-us/events/siggraph/">SIGGRAPH</a> graphics conference in Denver.</p>
<p>The two leaders will discuss the future of AI and simulation and the pivotal role of research at SIGGRAPH, which focuses on the intersection of graphics and technology.</p>
<p>Before the discussion, Huang will also appear in a fireside chat with <i>WIRED </i>senior writer Lauren Goode to discuss AI and graphics for the new computing revolution.</p>
<p>Both conversations will be available live and on replay at <a target="_blank" href="https://www.nvidia.com/en-us/">NVIDIA.com</a>.</p>
<p>The appearances at the conference, which runs July 28-Aug. 1, highlight SIGGRAPH’s continued role in technological innovation. Nearly 100 exhibitors will showcase how graphics are stepping into the future.</p>
<p>Attendees exploring the SIGGRAPH Innovation Zone will encounter startups at the forefront of computing and graphics while insights from industry leaders like Huang deliver a glimpse into the technological horizon.</p>
<p>Since the conference’s 1974 inception in Boulder, Colorado, SIGGRAPH has been at the forefront of innovation.</p>
<p>It introduced the world to demos such as the “Aspen Movie Map” — a precursor to Google Street View decades ahead of its time — and one of the first screenings of Pixar’s <i>Luxo Jr.</i>, which redefined the art of animation.</p>
<p>The conference remains the leading venue for <a href="https://blogs.nvidia.com/blog/siggraph-2024-ai-graphics-research/">groundbreaking research in computer graphics</a>.</p>
<p>Publications that redefined modern visual culture — including Ed Catmull’s 1974 paper on texture mapping, Turner Whitted’s 1980 paper on <a href="https://blogs.nvidia.com/blog/ray-tracing-global-illumination-turner-whitted/">ray-tracing techniques</a>, and James T. Kajiya’s 1986 “The Rendering Equation” — first made their debut at SIGGRAPH.</p>
<p>Innovations like these are now spilling out across the world’s industries.</p>
<p>Throughout the Innovation Zone, over a dozen startups are showcasing how they’re bringing advancements rooted in graphics into diverse fields — from robotics and manufacturing to autonomous vehicles and scientific research, including <a href="https://blogs.nvidia.com/blog/climate-startups-ai-earth-2/">climate science</a>.</p>
<p>Highlights include Tomorrow.io, which leverages <a target="_blank" href="https://www.nvidia.com/en-us/high-performance-computing/earth-2/">NVIDIA Earth-2</a> to provide precise weather insights and offers early warning systems to help organizations adapt to climate changes.</p>
<p>Looking Glass is pioneering holographic technology that enables 3D content experiences without headsets. The company is using <a target="_blank" href="https://www.nvidia.com/en-us/design-visualization/rtx-6000/">NVIDIA RTX 6000 Ada Generation GPUs</a> and <a target="_blank" href="https://developer.nvidia.com/maxine">NVIDIA Maxine</a> technology to enhance real-time audio, video and <a href="https://blogs.nvidia.com/blog/what-is-extended-reality/">augmented-reality</a> effects to make this possible.</p>
<p>Manufacturing startup nTop developed a computer-aided design tool using NVIDIA GPU-powered signed distance fields. The tool uses the <a target="_blank" href="https://developer.nvidia.com/rtx/ray-tracing/optix">NVIDIA OptiX</a> rendering engine and a two-way <a target="_blank" href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> LiveLink connector to enable real-time, high-fidelity visualization and collaboration across design and simulation platforms.</p>
<p>Conference attendees can also explore how <a target="_blank" href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> — a technology deeply rooted in visual computing — is remaking professional graphics.</p>
<p>On July 31, industry leaders and developers will gather in room 607 at the Colorado Convention Center for Generative AI Day, exploring cutting-edge solutions for visual effects, animation and game development with leaders from Bria AI, Cuebric, Getty Images, Replikant, Shutterstock and others.</p>
<p>The conference’s speaker lineup is equally compelling.</p>
<p>In addition to Huang and Zuckerberg, notable presenters include Dava Newman of MIT Media Lab and Mark Sagar from Soul Machines, who’ll delve into the intersections of bioengineering, design and digital humans.</p>
<p>Finally, as part of SIGGRAPH’s rich legacy, the inaugural Steven Parker Award will be presented to honor the memory and contributions of Steven Parker, vice president of professional graphics at NVIDIA. Renowned for his pioneering work in interactive ray tracing and computer graphics, Parker left a legacy that continues to inspire the field.</p>
<p>Join the global technology community in Denver later this month to discover why <a target="_blank" href="https://www.nvidia.com/en-us/events/siggraph/">SIGGRAPH</a> remains at the forefront of demonstrating, predicting and shaping the future of technology.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/image1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/image1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Jensen Huang, Mark Zuckerberg to Discuss Future of Graphics and Virtual Worlds at SIGGRAPH 2024]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Mile-High AI: NVIDIA Research to Present Advancements in Simulation and Gen AI at SIGGRAPH</title>
		<link>https://blogs.nvidia.com/blog/siggraph-2024-ai-graphics-research/</link>
		
		<dc:creator><![CDATA[Aaron Lefohn]]></dc:creator>
		<pubDate>Fri, 12 Jul 2024 13:00:28 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[NVIDIA Research]]></category>
		<category><![CDATA[Ray Tracing]]></category>
		<category><![CDATA[Rendering]]></category>
		<category><![CDATA[SIGGRAPH]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<category><![CDATA[Synthetic Data Generation]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72914</guid>

					<description><![CDATA[NVIDIA is taking an array of advancements in rendering, simulation and generative AI to SIGGRAPH 2024, the premier computer graphics conference, which will take place July 28 &#8211; Aug. 1 in Denver. More than 20 papers from NVIDIA Research introduce innovations advancing synthetic data generators and inverse rendering tools that can help train next-generation models.	<a class="read-more" href="https://blogs.nvidia.com/blog/siggraph-2024-ai-graphics-research/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>NVIDIA is taking an array of advancements in rendering, simulation and generative AI to <a target="_blank" href="https://s2024.siggraph.org/">SIGGRAPH 2024</a>, the premier computer graphics conference, which will take place July 28 &#8211; Aug. 1 in Denver.</p>
<p>More than 20 papers from NVIDIA Research introduce innovations advancing synthetic data generators and inverse rendering tools that can help train next-generation models. NVIDIA’s AI research is making simulation better by boosting image quality and unlocking new ways to create 3D representations of real or imagined worlds.</p>
<p>The papers focus on diffusion models for visual generative AI, physics-based simulation and increasingly realistic AI-powered rendering. They include two technical <a target="_blank" href="https://blog.siggraph.org/2024/06/siggraph-2024-technical-papers-awards-best-papers-honorable-mentions-and-test-of-time.html/">Best Paper Award winners</a> and collaborations with universities across the U.S., Canada, China, Israel and Japan as well as researchers at companies including Adobe and Roblox.</p>
<p>These initiatives will help create tools that developers and businesses can use to generate complex virtual objects, characters and environments. <a href="https://blogs.nvidia.com/blog/what-is-synthetic-data/">Synthetic data generation</a> can then be harnessed to tell powerful visual stories, aid scientists&#8217; understanding of natural phenomena or assist in simulation-based training of robots and autonomous vehicles.</p>
<p><iframe loading="lazy" title="NVIDIA Research at #SIGGRAPH2024 Preview" width="500" height="375" src="https://www.youtube.com/embed/UuFxTyg6RK4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<h2><b>Diffusion Models Improve Texture Painting, Text-to-Image Generation</b></h2>
<p>Diffusion models, a popular tool for transforming text prompts into images, can help artists, designers and other creators rapidly generate visuals for storyboards or production, reducing the time it takes to bring ideas to life.</p>
<p>Two NVIDIA-authored papers are advancing the capabilities of these generative AI models.</p>
<p><a target="_blank" href="https://research.nvidia.com/labs/par/consistory/">ConsiStory</a>, a collaboration between researchers at NVIDIA and Tel Aviv University, makes it easier to generate multiple images with a consistent main character — an essential capability for storytelling use cases such as illustrating a comic strip or developing a storyboard. The researchers’ approach introduces a technique called subject-driven shared attention, which reduces the time it takes to generate consistent imagery from 13 minutes to around 30 seconds.</p>
<figure id="attachment_72922" aria-describedby="caption-attachment-72922" style="width: 1090px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-full wp-image-72922" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/ConsiStory.jpeg" alt="Panels of multiple AI-generated images featuring the same character" width="1090" height="613" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/07/ConsiStory.jpeg 1090w, https://blogs.nvidia.com/wp-content/uploads/2024/07/ConsiStory-400x225.jpeg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/07/ConsiStory-672x378.jpeg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/07/ConsiStory-768x432.jpeg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/07/ConsiStory-800x450.jpeg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/07/ConsiStory-382x215.jpeg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/07/ConsiStory-178x100.jpeg 178w" sizes="(max-width: 1090px) 100vw, 1090px" /><figcaption id="caption-attachment-72922" class="wp-caption-text">ConsiStory is capable of generating a series of images featuring the same character.</figcaption></figure>
<p>NVIDIA researchers last year won the <a href="https://blogs.nvidia.com/blog/siggraph-research-generative-ai-materials-3d-scenes/">Best in Show award at SIGGRAPH’s Real-Time Live</a> event for AI models that turn text or image prompts into custom textured materials. This year, they’re presenting a paper that applies <a target="_blank" href="https://research.nvidia.com/labs/toronto-ai/DiffusionTexturePainting/">2D generative diffusion models to interactive texture painting</a> on 3D meshes, enabling artists to paint in real time with complex textures based on any reference image.</p>
<p><iframe loading="lazy" title="Diffusion Texture Painting | NVIDIA Research Paper" width="500" height="281" src="https://www.youtube.com/embed/lKeCta_klJ0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<h2><b>Kick-Starting Developments in Physics-Based Simulation</b></h2>
<p>Graphics researchers are narrowing the gap between physical objects and their virtual representations with physics-based simulation — a range of techniques to make digital objects and characters move the same way they would in the real world.</p>
<p>Several NVIDIA Research papers feature breakthroughs in the field, including SuperPADL, a project that tackles the challenge of<a target="_blank" href="https://research.nvidia.com/publication/2024-07_superpadl-scaling-language-directed-physics-based-control-progressive"> simulating complex human motions based on text prompts</a> (see video at top).</p>
<p>Using a combination of reinforcement learning and supervised learning, the researchers demonstrated how the SuperPADL framework can be trained to reproduce the motion of more than 5,000 skills — and can run in real time on a consumer-grade NVIDIA GPU.</p>
<p>Another NVIDIA paper features a <a target="_blank" href="https://research.nvidia.com/labs/toronto-ai/simplicits/">neural physics method</a> that applies AI to learn how objects — whether represented as a 3D mesh, a NeRF or a solid object generated by a text-to-3D model — would behave as they are moved in an environment.</p>
<div style="width: 1920px;" class="wp-video"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video class="wp-video-shortcode" id="video-72914-1" width="1920" height="1080" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/Simplicits.mp4?_=1" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/07/Simplicits.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/07/Simplicits.mp4</a></video></div>
<p>&nbsp;</p>
<p>A paper written in collaboration with Carnegie Mellon University researchers develops a new kind of renderer — one that, instead of modeling physical light, can <a target="_blank" href="https://research.nvidia.com/labs/prl/miller2024wost/WoStRobin.pdf">perform thermal analysis, electrostatics and fluid mechanics</a>. Named one of five best papers at SIGGRAPH, the method is easy to parallelize and doesn’t require cumbersome model cleanup, offering new opportunities for speeding up engineering design cycles.</p>
<p><iframe loading="lazy" title="Walkin’ Robin: Walk on Stars with Robin Boundary Conditions | NVIDIA Research Paper" width="500" height="281" src="https://www.youtube.com/embed/4v9VZqOCPsU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p style="text-align: center;"><i>In the example above, the renderer performs a thermal analysis of the Mars Curiosity rover, where keeping temperatures within a specific range is critical to mission success. </i></p>
<p>Additional simulation papers introduce a more efficient technique for <a target="_blank" href="https://research.nvidia.com/publication/2024-07_modeling-hair-strands-roving-capsules">modeling hair strands</a> and a <a target="_blank" href="https://research.nvidia.com/publication/2024-07_fluid-control-laplacian-eigenfunctions">pipeline that accelerates fluid simulation</a> by 10x.</p>
<h2><b>Raising the Bar for Rendering Realism, Diffraction Simulation</b></h2>
<p>Another set of NVIDIA-authored papers present new techniques to model visible light up to 25x faster and simulate diffraction effects — such as those used in radar simulation for training self-driving cars — up to 1,000x faster.</p>
<p>A paper by NVIDIA and University of Waterloo researchers tackles <a target="_blank" href="https://research.nvidia.com/labs/rtr/publication/steinberg2024diffraction/">free-space diffraction</a>, an optical phenomenon where light spreads out or bends around the edges of objects. The team’s method can integrate with path-tracing workflows to increase the efficiency of simulating diffraction in complex scenes, offering up to 1,000x acceleration. Beyond rendering visible light, the model could also be used to simulate the longer wavelengths of radar, sound or radio waves.</p>
<figure id="attachment_72928" aria-describedby="caption-attachment-72928" style="width: 720px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-full wp-image-72928" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/Free-Space-Diffraction.jpg" alt="Urban scene with colors showing simulation of cellular radiation propagation around buildings" width="720" height="382" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/07/Free-Space-Diffraction.jpg 720w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Free-Space-Diffraction-400x212.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Free-Space-Diffraction-672x357.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Free-Space-Diffraction-406x215.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Free-Space-Diffraction-188x100.jpg 188w" sizes="(max-width: 720px) 100vw, 720px" /><figcaption id="caption-attachment-72928" class="wp-caption-text">Simulation of cellular signal coverage in a city.</figcaption></figure>
<p><a href="https://blogs.nvidia.com/blog/what-is-path-tracing/">Path tracing</a> samples numerous paths — multi-bounce light rays traveling through a scene — to create a photorealistic picture. Two SIGGRAPH papers improve sampling quality for ReSTIR, a path-tracing algorithm first introduced by NVIDIA and Dartmouth College researchers at SIGGRAPH 2020 that has been key to bringing path tracing to games and other real-time rendering products.</p>
<p>One of these papers, a collaboration with the University of Utah, shares a new way to reuse calculated paths that <a target="_blank" href="https://research.nvidia.com/labs/rtr/publication/zhang2024area/">increases effective sample count by up to 25x</a>, significantly boosting image quality. The other <a target="_blank" href="https://research.nvidia.com/labs/rtr/publication/sawhney2022decorrelating/">improves sample quality</a> by randomly mutating a subset of the light’s path. This helps denoising algorithms perform better, producing fewer visual artifacts in the final render.</p>
<figure id="attachment_72937" aria-describedby="caption-attachment-72937" style="width: 2048px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-full wp-image-72937" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/Area-ReSTIR-sheep-scaled.jpg" alt="Model of a sheep rendering with three different path-tracing techniques" width="2048" height="826" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/07/Area-ReSTIR-sheep-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Area-ReSTIR-sheep-400x161.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Area-ReSTIR-sheep-672x271.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Area-ReSTIR-sheep-768x310.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Area-ReSTIR-sheep-1536x620.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Area-ReSTIR-sheep-842x340.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Area-ReSTIR-sheep-406x164.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Area-ReSTIR-sheep-188x76.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Area-ReSTIR-sheep-1280x517.jpg 1280w" sizes="(max-width: 2048px) 100vw, 2048px" /><figcaption id="caption-attachment-72937" class="wp-caption-text">From L to R: Compare the visual quality of previous sampling, the 25x improvement and a reference image. Model courtesy <a target="_blank" href="https://studio.blender.org/characters/5d40511bfe6b50fb62faea7d/v2/">Blender Studio</a>.</figcaption></figure>
<h2><b>Teaching AI to Think in 3D</b></h2>
<p>NVIDIA researchers are also showcasing multipurpose AI tools for 3D representations and design at SIGGRAPH.</p>
<p>One paper introduces <a target="_blank" href="https://research.nvidia.com/labs/prl/publication/williams2024fvdb/">fVDB,</a> a GPU-optimized framework for 3D deep learning that matches the scale of the real world. The fVDB framework provides AI infrastructure for the large spatial scale and high resolution of city-scale 3D models and <a href="https://blogs.nvidia.com/blog/ai-decoded-instant-nerf/">NeRFs</a>, and segmentation and reconstruction of large-scale point clouds.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-72931" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/fVDB_Cropped.gif" alt="" width="600" height="338" /></p>
<p>A Best Technical Paper award winner written in collaboration with Dartmouth College researchers introduces a theory for <a target="_blank" href="https://research.nvidia.com/publication/2024-07_microfacets-participating-media-unified-theory-light-transport-stochastic">representing how 3D objects interact with light</a>. The theory unifies a diverse spectrum of appearances into a single model.</p>
<p>And a collaboration with University of Tokyo, University of Toronto and Adobe Research introduces an algorithm that <a target="_blank" href="https://research.nvidia.com/publication/2024-07_surface-filling-curve-flows-implicit-medial-axes">generates smooth, space-filling curves on 3D meshes</a> in real time. While previous methods took hours, this framework runs in seconds and offers users a high degree of control over the output to enable interactive design.</p>
<div style="width: 1920px;" class="wp-video"><video class="wp-video-shortcode" id="video-72914-2" width="1920" height="1080" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/Space-Filling-Curves.mp4?_=2" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/07/Space-Filling-Curves.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/07/Space-Filling-Curves.mp4</a></video></div>
<h2><b>NVIDIA at SIGGRAPH </b><b><br />
</b></h2>
<p><span>Learn more about </span><a target="_blank" href="https://www.nvidia.com/en-us/events/siggraph/"><span>NVIDIA at SIGGRAPH</span></a><span>. Special events include a fireside chat between <a href="https://blogs.nvidia.com/blog/huang-zuckerberg-siggraph-2024/">NVIDIA founder and CEO Jensen Huang and Meta founder and CEO Mark Zuckerberg</a>, as well as a </span><a target="_blank" href="https://s2024.siggraph.org/program/keynote-presentations/#speaker-huang"><span>fireside chat with Huang and Lauren Goode</span></a><span>, senior writer at WIRED, on the impact of robotics and AI in industrial digitalization. </span></p>
<p>NVIDIA researchers will also present <a target="_blank" href="https://s2024.conference-program.org/presentation/?id=ind_101&amp;sess=sess421">OpenUSD Day by NVIDIA</a>, a full-day event showcasing how developers and industry leaders are adopting and evolving OpenUSD to build AI-enabled 3D pipelines.</p>
<p><a target="_blank" href="https://www.nvidia.com/en-us/research/"><i>NVIDIA Research</i></a> <i>has hundreds of scientists and engineers worldwide, with teams focused on topics including AI, computer graphics, computer vision, self-driving cars and robotics.</i> <i>See</i> <a target="_blank" href="https://research.nvidia.com/publications"><i>more of their latest work</i></a><i>.</i></p>
]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/07/Simplicits.mp4" length="8702625" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/07/Space-Filling-Curves.mp4" length="3955992" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/SuperPADL_Still.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/SuperPADL_Still-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Mile-High AI: NVIDIA Research to Present Advancements in Simulation and Gen AI at SIGGRAPH]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>‘Once Human,’ Twice the Thrills on GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-once-human/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 11 Jul 2024 13:00:33 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72884</guid>

					<description><![CDATA[Unlock new experiences every GFN Thursday. Whether post-apocalyptic survival adventures, narrative-driven games or vast, open worlds, GeForce NOW always has something fresh for members to explore. This week, GeForce NOW brings the survival game Once Human from Starry Studio to the cloud, part of three new titles. Survive the Stardust Step into a post-apocalyptic world	<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-once-human/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Unlock new experiences every GFN Thursday. Whether post-apocalyptic survival adventures, narrative-driven games or vast, open worlds, <a target="_blank" href="http://geforcenow.com">GeForce NOW</a> always has something fresh for members to explore.</p>
<p>This week, GeForce NOW brings the survival game <i>Once Human</i> from Starry Studio to the cloud<i>, </i>part of three new titles.</p>
<h2><b>Survive the Stardust</b></h2>
<figure id="attachment_72895" aria-describedby="caption-attachment-72895" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-72895" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Once_Human-672x337.jpg" alt="Once Human on GeForce NOW" width="672" height="337" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Once_Human-672x337.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Once_Human-400x201.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Once_Human-768x385.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Once_Human-1536x770.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Once_Human-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Once_Human-842x422.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Once_Human-406x204.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Once_Human-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Once_Human-1280x642.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72895" class="wp-caption-text"><em>We’re all just made of stardust.</em></figcaption></figure>
<p>Step into a post-apocalyptic world where cosmic energy has transformed humanity in <i>Once Human</i>. As a Meta-Human, survive the contamination and use the powers of Stardust to navigate a new and bizarre open-world universe.</p>
<p>Experience elements of survival, crafting and combat while challenging players to gather resources, build shelters and fend off human and monstrous threats. Uncover the rich lore through interactions with various characters and artifacts scattered throughout the world.</p>
<p>Delve into the truth of Stardust — discover where it came from and what it wants. Play alone or grab a squad to fight, build and explore together. Level up with an <a target="_blank" href="https://www.nvidia.com/en-us/geforce-now/memberships/">Ultimate or Priority membership</a> to stream across devices at higher resolutions and frame rates over free members. Gaming sessions are up to six hours for Priority members and eight hours for Ultimate members, plenty of time to unravel the cosmic mysteries of <i>Once Human.</i></p>
<h2><b>Happy New Games</b></h2>
<figure id="attachment_72892" aria-describedby="caption-attachment-72892" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-72892" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Anger_Foot-672x378.jpg" alt="Anger Foot on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Anger_Foot-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Anger_Foot-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Anger_Foot-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Anger_Foot-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Anger_Foot-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Anger_Foot-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Anger_Foot-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Anger_Foot-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-Anger_Foot-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72892" class="wp-caption-text"><em>Taking names and kicking butt.</em></figcaption></figure>
<p>Unleash the world’s deadliest feet on a colorful cast of anthropomorphic enemies in <i>Anger Foot</i> from Devolver Digital. Clear out slums, sewers and skyscrapers, grab new weapons, unlock new sneakers and upgrade powers in absurd and wonderful ways. Kick and shoot to get to the exit — and leave behind a smoldering trail of shattered doors, broken bones and crumpled energy drinks.</p>
<p>Check out the list of new games this week:<i></i></p>
<ul>
<li><i>Cricket 24 </i>(New release on <a target="_blank" href="https://www.xbox.com/games/store/cricket-24-the-official-game-of-the-ashes/9nkf2sz630zh?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass, July 9)</li>
<li><i>Once Human </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/2139460?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, July 9)</li>
<li><i>Anger Foot </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1978590?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, July 11)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a target="_blank" href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">If you could replay any game as if it were the first time, which game would it be? <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f3ae.png" alt="🎮" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a target="_blank" href="https://twitter.com/NVIDIAGFN/status/1811067859474272522?ref_src=twsrc%5Etfw">July 10, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/gfn-thursday-7-11-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/gfn-thursday-7-11-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[‘Once Human,’ Twice the Thrills on GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Japan Enhances AI Sovereignty With Advanced ABCI 3.0 Supercomputer</title>
		<link>https://blogs.nvidia.com/blog/abci-aist/</link>
		
		<dc:creator><![CDATA[Dion Harris]]></dc:creator>
		<pubDate>Thu, 11 Jul 2024 10:00:07 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Supercomputing]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72876</guid>

					<description><![CDATA[Enhancing Japan’s AI sovereignty and strengthening its research and development capabilities, Japan’s National Institute of Advanced Industrial Science and Technology (AIST) will integrate thousands of NVIDIA H200 Tensor Core GPUs into its AI Bridging Cloud Infrastructure 3.0 supercomputer (ABCI 3.0). The Hewlett Packard Enterprise Cray XD system will feature NVIDIA Quantum-2 InfiniBand networking for superior	<a class="read-more" href="https://blogs.nvidia.com/blog/abci-aist/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Enhancing Japan’s <a href="https://blogs.nvidia.com/blog/what-is-sovereign-ai/" target="_blank" rel="noopener">AI sovereignty</a> and strengthening its research and development capabilities, Japan’s National Institute of Advanced Industrial Science and Technology (AIST) will integrate thousands of <a href="https://www.nvidia.com/en-us/data-center/h200/" target="_blank" rel="noopener">NVIDIA H200</a> Tensor Core GPUs into its AI Bridging Cloud Infrastructure 3.0 supercomputer (ABCI 3.0). The Hewlett Packard Enterprise Cray XD system will feature <a href="https://www.nvidia.com/en-us/networking/quantum2/" target="_blank" rel="noopener">NVIDIA Quantum-2</a> InfiniBand networking for superior performance and scalability.</p>
<p>ABCI 3.0 is the latest iteration of Japan’s large-scale Open AI Computing Infrastructure designed to advance AI R&amp;D. This collaboration underlines Japan’s commitment to advancing its AI capabilities and fortifying its technological independence.</p>
<p>“In August 2018, we launched ABCI, the world’s first large-scale open AI computing infrastructure,” said AIST Executive Officer Yoshio Tanaka. “Building on our experience over the past several years managing ABCI, we’re now upgrading to ABCI 3.0. In collaboration with NVIDIA and HPE we aim to develop ABCI 3.0 into a computing infrastructure that will advance further research and development capabilities for <a href="https://www.nvidia.com/en-us/glossary/generative-ai/" target="_blank" rel="noopener">generative AI</a> in Japan.”</p>
<p>“As generative AI prepares to catalyze global change, it’s crucial to rapidly cultivate research and development capabilities within Japan,” said AIST Solutions Co. Producer and Head of ABCI Operations Hirotaka Ogawa. “I’m confident that this major upgrade of ABCI in our collaboration with NVIDIA and HPE will enhance ABCI’s leadership in domestic industry and academia, propelling Japan towards global competitiveness in AI development and serving as the bedrock for future innovation.”</p>
<figure id="attachment_72881" aria-describedby="caption-attachment-72881" style="width: 659px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class=" wp-image-72881" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/facility-1-400x267.png" alt="" width="659" height="440" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/07/facility-1-400x267.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/07/facility-1-322x215.png 322w, https://blogs.nvidia.com/wp-content/uploads/2024/07/facility-1-150x100.png 150w, https://blogs.nvidia.com/wp-content/uploads/2024/07/facility-1.png 624w" sizes="(max-width: 659px) 100vw, 659px" /><figcaption id="caption-attachment-72881" class="wp-caption-text">The ABCI 3.0 supercomputer will be housed in Kashiwa at a facility run by Japan&#8217;s National Institute of Advanced Industrial Science and Technology. Credit: Courtesy of National Institute of Advanced Industrial Science and Technology.</figcaption></figure>
<h2><strong>ABCI 3.0: A New Era for Japanese AI Research and Development</strong></h2>
<p>ABCI 3.0 is constructed and operated by AIST, its business subsidiary, AIST Solutions, and its system integrator, Hewlett Packard Enterprise (HPE).</p>
<p>The ABCI 3.0 project follows support from Japan’s Ministry of Economy, Trade and Industry, known as METI, for strengthening its computing resources through the Economic Security Fund and is part of a broader $1 billion initiative by METI that includes both ABCI efforts and investments in cloud AI computing.</p>
<p>NVIDIA is closely <a href="https://blogs.nvidia.com/blog/japan-sovereign-ai/" target="_blank" rel="noopener">collaborating with METI</a> on research and education following a visit last year by company founder and CEO, Jensen Huang, who met with political and business leaders, including Japanese Prime Minister Fumio Kishida, to discuss the future of AI.</p>
<h2><strong>NVIDIA’s Commitment to Japan’s Future</strong></h2>
<p>Huang pledged to collaborate on research, particularly in generative AI, robotics and <a href="https://blogs.nvidia.com/blog/what-is-quantum-computing/" target="_blank" rel="noopener">quantum computing</a>, to invest in AI startups and provide product support, training and education on AI.</p>
<p>During his visit, Huang emphasized that “AI factories” — next-generation data centers designed to handle the most computationally intensive AI tasks — are crucial for turning vast amounts of data into intelligence.</p>
<p>“The AI factory will become the bedrock of modern economies across the world,” Huang said during a meeting with the Japanese press in December.</p>
<p>With its ultra-high-density data center and energy-efficient design, ABCI provides a robust infrastructure for developing AI and big data applications.</p>
<p>The system is expected to come online by the end of this year and offer state-of-the-art AI research and development resources. It will be housed in Kashiwa, near Tokyo.</p>
<h2><strong>Unmatched Computing Performance and Efficiency</strong></h2>
<p>The facility will offer:</p>
<ul>
<li>6 AI <a href="https://blogs.nvidia.com/blog/what-is-an-exaflop/" target="_blank" rel="noopener">exaflops</a> of computing capacity, a measure of AI-specific performance without sparsity</li>
<li>410 double-precision petaflops, a measure of general computing capacity</li>
<li>Each node is connected via the Quantum-2 InfiniBand platform at 200GB/s of bisectional bandwidth.</li>
</ul>
<p>NVIDIA technology forms the backbone of this initiative, with hundreds of nodes each equipped with 8 NVLlink-connected H200 GPUs providing unprecedented computational performance and efficiency.</p>
<p>NVIDIA H200 is the first GPU to offer over 140 gigabytes (GB) of HBM3e memory at 4.8 terabytes per second (TB/s). The H200’s larger and faster memory accelerates generative AI and LLMs, while advancing scientific computing for HPC workloads with better energy efficiency and lower total cost of ownership.</p>
<p>NVIDIA H200 GPUs are 15X more energy-efficient than ABCI’s previous-generation architecture for AI workloads such as LLM token generation.</p>
<p>The integration of advanced NVIDIA Quantum-2 InfiniBand with In-Network computing — where networking devices perform computations on data, offloading the work from the CPU — ensures efficient, high-speed, low-latency communication, crucial for handling intensive AI workloads and vast datasets.</p>
<p>ABCI boasts world-class computing and data processing power, serving as a platform to accelerate joint AI R&amp;D with industries, academia and governments.</p>
<p>METI’s substantial investment is a testament to Japan’s strategic vision to enhance AI development capabilities and accelerate the use of generative AI.</p>
<p>By subsidizing AI supercomputer development, Japan aims to reduce the time and costs of developing next-generation AI technologies, positioning itself as a leader in the global AI landscape.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/Tokyo-Dynamic-Street-Scene-Via-NVDAM.webp"
			type="image/webp"
			width="2048"
			height="1367"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/Tokyo-Dynamic-Street-Scene-Via-NVDAM-842x450.webp"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Japan Enhances AI Sovereignty With Advanced ABCI 3.0 Supercomputer]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Paige Cofounder Thomas Fuchs’ Diagnosis on Improving Cancer Patient Outcomes With AI</title>
		<link>https://blogs.nvidia.com/blog/paige-thomas-fuchs/</link>
		
		<dc:creator><![CDATA[Andy Bui]]></dc:creator>
		<pubDate>Wed, 10 Jul 2024 13:00:12 +0000</pubDate>
				<category><![CDATA[The AI Podcast]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72845</guid>

					<description><![CDATA[Improved cancer diagnostics — and improved patient outcomes — could be among the changes generative AI will bring to the healthcare industry, thanks to Paige, the first company with an FDA-approved tool for cancer diagnosis. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Paige cofounder and Chief Scientific Officer Thomas Fuchs.	<a class="read-more" href="https://blogs.nvidia.com/blog/paige-thomas-fuchs/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Improved cancer diagnostics — and improved patient outcomes — could be among the changes generative AI will bring to the healthcare industry, thanks to Paige, the first company with an FDA-approved tool for cancer diagnosis. In this episode of NVIDIA’s <a href="https://blogs.nvidia.com/ai-podcast/">AI Podcast</a>, host Noah Kravitz speaks with Paige cofounder and Chief Scientific Officer Thomas Fuchs. He’s also dean of artificial intelligence and human health at the Icahn School of Medicine at Mount Sinai.</p>
<p>Tune in to hear Fuchs on machine learning and AI applications and how technology brings better precision and care to the medical industry.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1864135386%3Fsecret_token%3Ds-dz9YPLgbXUB&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="Paige Cofounder Thomas Fuchs’ Diagnosis on Improving Cancer Patient Outcomes With AI" href="https://soundcloud.com/theaipodcast/paige-thomas-fuchs/s-dz9YPLgbXUB" target="_blank" rel="noopener">Paige Cofounder Thomas Fuchs’ Diagnosis on Improving Cancer Patient Outcomes With AI</a></div>
<h2><b>Time Stamps</b></h2>
<p>1:03: Background on Paige and computational pathology<br />
7:28: How AI models use visual pattern recognition to accelerate cancer detection<br />
11:27: Paige’s results using AI in cancer imaging and pathology<br />
15:16: Challenges in cancer detection<br />
17:38: Thomas Fuchs’ background in engineering at JPL and NASA<br />
24:10: AI’s future in the medical industry</p>
<h2><b>You Might Also Like:</b></h2>
<p><a target="_blank" href="https://soundcloud.com/theaipodcast/gtc24-cornel-amariei-inception"><b>Dotlumen CEO Cornel Amariei on Assistive Technology for the Visually Impaired &#8211; Ep. 217</b></a></p>
<p>NVIDIA Inception program member Dotlumen is building AI glasses to help people with visual impairments navigate the world. CEO and founder Cornel Amariei discusses the processes of developing assistive technology and its potential for enhancing accessibility.</p>
<p><a target="_blank" href="https://soundcloud.com/theaipodcast/viome-guru-banavar"><b>Personalized Health: Viome’s Guru Banavar Discusses Startup’s AI-Driven Approach &#8211; Ep. 216</b></a></p>
<p>Viome CTO Guru Banavar discusses innovations in AI and genomics and how technology has advanced personalized health and wellness. Viome aims to tackle the root causes of chronic diseases by analyzing microbiomes and gene expression, transforming biological data into practical recommendations for a holistic approach to wellness.</p>
<p><a target="_blank" href="https://soundcloud.com/theaipodcast/cardiac-caristo-dr-keith-channon"><b>Cardiac Clarity: Dr. Keith Channon Talks Revolutionizing Heart Health With AI &#8211; Ep. 212</b></a></p>
<p>Caristo Diagnostics has developed an AI-powered solution for detecting coronary inflammation in cardiac CT scans. Dr. Keith Channon, cofounder and chief medical officer, discusses how Caristo uses AI to improve treatment plans and risk predictions by providing patient-specific readouts.</p>
<h2><b>Subscribe to the AI Podcast</b></h2>
<p>Get the<a href="https://blogs.nvidia.com/ai-podcast/"> AI Podcast</a> through<a target="_blank" href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439"> iTunes</a>, <a target="_blank" href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">Amazon Music, </a><a target="_blank" href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us">Castbox</a>, DoggCatcher,<a target="_blank" href="https://overcast.fm/itunes1186480811/the-ai-podcast"> Overcast</a>,<a target="_blank" href="https://player.fm/series/the-ai-podcast"> PlayerFM</a>, Pocket Casts,<a target="_blank" href="http://www.podbay.fm/show/1186480811"> Podbay</a>,<a target="_blank" href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast"> PodBean</a>, PodCruncher, PodKicker,<a target="_blank" href="https://soundcloud.com/theaipodcast"> Soundcloud</a>,<a target="_blank" href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L"> Spotify</a>,<a target="_blank" href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr"> Stitcher</a> and<a target="_blank" href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/"> TuneIn</a>.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2021/08/ai-podcast-2600x1472_-1-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1159"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2021/08/ai-podcast-2600x1472_-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Paige Cofounder Thomas Fuchs’ Diagnosis on Improving Cancer Patient Outcomes With AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Mission NIMpossible: Decoding the Microservices That Accelerate Generative AI</title>
		<link>https://blogs.nvidia.com/blog/ai-decoded-nim/</link>
		
		<dc:creator><![CDATA[Sama Bali]]></dc:creator>
		<pubDate>Wed, 10 Jul 2024 13:00:08 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[AI Decoded]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[NVIDIA NIM]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72866</guid>

					<description><![CDATA[In the rapidly evolving world of artificial intelligence, generative AI is captivating imaginations and transforming industries.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><i>Editor’s note: This post is part of the </i><a href="https://blogs.nvidia.com/blog/tag/ai-decoded/"><i>AI Decoded series</i></a><i>, which demystifies AI by making the technology more accessible and showcases new hardware, software, tools and accelerations for NVIDIA RTX PC and workstation users.</i></p>
<p>In the rapidly evolving world of artificial intelligence, <a target="_blank" href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> is captivating imaginations and transforming industries. Behind the scenes, an unsung hero is making it all possible: microservices architecture.</p>
<h2><b>The Building Blocks of Modern AI Applications</b></h2>
<p>Microservices have emerged as a powerful architecture, fundamentally changing how people design, build and deploy software.</p>
<p>A microservices architecture breaks down an application into a collection of loosely coupled, independently deployable services. Each service is responsible for a specific capability and communicates with other services through well-defined application programming interfaces, or APIs. This modular approach stands in stark contrast to traditional all-in-one architectures, in which all functionality is bundled into a single, tightly integrated application.</p>
<p>By decoupling services, teams can work on different components simultaneously, accelerating development processes and allowing updates to be rolled out independently without affecting the entire application. Developers can focus on building and improving specific services, leading to better code quality and faster problem resolution. Such specialization allows developers to become experts in their particular domain.</p>
<p>Services can be scaled independently based on demand, optimizing resource utilization and improving overall system performance. In addition, different services can use different technologies, allowing developers to choose the best tools for each specific task.</p>
<h2><b>A Perfect Match: Microservices and Generative AI</b></h2>
<p>The microservices architecture is particularly well-suited for developing generative AI applications due to its scalability, enhanced modularity and flexibility.</p>
<p>AI models, especially <a target="_blank" href="https://www.nvidia.com/en-us/glossary/large-language-models/">large language models</a>, require significant computational resources. Microservices allow for efficient scaling of these resource-intensive components without affecting the entire system.</p>
<p>Generative AI applications often involve multiple steps, such as data preprocessing, model inference and post-processing. Microservices enable each step to be developed, optimized and scaled independently. Plus, as AI models and techniques evolve rapidly, a microservices architecture allows for easier integration of new models as well as the replacement of existing ones without disrupting the entire application.</p>
<h2><b>NVIDIA NIM: Simplifying Generative AI Deployment</b></h2>
<p>As the demand for AI-powered applications grows, developers face challenges in efficiently deploying and managing AI models.</p>
<p><a target="_blank" href="https://www.nvidia.com/en-us/ai/">NVIDIA NIM inference microservices</a> provide models as optimized containers to deploy in the cloud, data centers, workstations, desktops and laptops. Each NIM container includes the <a href="https://blogs.nvidia.com/blog/what-is-a-pretrained-ai-model/">pretrained AI models</a> and all the necessary runtime components, making it simple to integrate AI capabilities into applications.</p>
<p>NIM offers a game-changing approach for application developers looking to incorporate AI functionality by providing simplified integration, production-readiness and flexibility. Developers can focus on building their applications without worrying about the complexities of data preparation, model training or customization, as NIM inference microservices are optimized for performance, come with runtime optimizations and support industry-standard APIs.</p>
<h2><b>AI at Your Fingertips: NVIDIA NIM on Workstations and PCs</b></h2>
<p>Building enterprise generative AI applications comes with many challenges. While cloud-hosted model APIs can help developers get started, issues related to data privacy, security, model response latency, accuracy, API costs and scaling often hinder the path to production.</p>
<p>Workstations with NIM provide developers with secure access to a broad range of models and performance-optimized inference microservices.</p>
<p>By avoiding the latency, cost and compliance concerns associated with cloud-hosted APIs as well as the complexities of model deployment, developers can focus on application development. This accelerates the delivery of production-ready generative AI applications — enabling seamless, automatic scale out with performance optimization in data centers and the cloud.</p>
<p>The recently announced general availability of the <a href="https://blogs.nvidia.com/blog/llama-3-nim-healthcare-generative-ai/">Meta Llama 3 8B model as a NIM</a>, which can run locally on RTX systems, brings state-of-the-art language model capabilities to individual developers, enabling local testing and experimentation without the need for cloud resources. With NIM running locally, developers can create sophisticated <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">retrieval-augmented generation (RAG)</a> projects right on their workstations.</p>
<p>Local RAG refers to implementing RAG systems entirely on local hardware, without relying on cloud-based services or external APIs.</p>
<p>Developers can use the Llama 3 8B NIM on workstations with one or more <a target="_blank" href="https://www.nvidia.com/en-us/design-visualization/rtx-6000/">NVIDIA RTX 6000 Ada Generation GPUs</a> or on NVIDIA RTX systems to build end-to-end RAG systems entirely on local hardware. This setup allows developers to tap the full power of Llama 3 8B, ensuring high performance and low latency.</p>
<p>By running the entire RAG pipeline locally, developers can maintain complete control over their data, ensuring privacy and security. This approach is particularly helpful for developers building applications that require real-time responses and high accuracy, such as customer-support chatbots, personalized content-generation tools and interactive virtual assistants.</p>
<p>Hybrid RAG combines local and cloud-based resources to optimize performance and flexibility in AI applications. With <a target="_blank" href="https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/workbench/">NVIDIA AI Workbench</a>, developers can get started with the hybrid-RAG Workbench Project — an example application that can be used to run vector databases and embedding models locally while performing inference using NIM in the cloud or data center, offering a flexible approach to resource allocation.</p>
<p>This hybrid setup allows developers to balance the computational load between local and cloud resources, optimizing performance and cost. For example, the vector database and embedding models can be hosted on local workstations to ensure fast data retrieval and processing, while the more computationally intensive inference tasks can be offloaded to powerful cloud-based NIM inference microservices. This flexibility enables developers to scale their applications seamlessly, accommodating varying workloads and ensuring consistent performance.</p>
<p><a target="_blank" href="https://developer.nvidia.com/ace">NVIDIA ACE</a> NIM inference microservices bring digital humans, AI non-playable characters (NPCs) and interactive avatars for customer service to life with generative AI, running on RTX PCs and workstations.</p>
<p>ACE NIM inference microservices for speech — including Riva automatic speech recognition, text-to-speech and neural machine translation — allow accurate transcription, translation and realistic voices.</p>
<p>The NVIDIA Nemotron small language model is a NIM for intelligence that includes INT4 quantization for minimal memory usage and supports roleplay and RAG use cases.</p>
<p>And ACE NIM inference microservices for appearance include Audio2Face and Omniverse RTX for lifelike animation with ultrarealistic visuals. These provide more immersive and engaging gaming characters, as well as more satisfying experiences for users interacting with virtual customer-service agents.</p>
<h2><b>Dive Into NIM</b></h2>
<p>As AI progresses, the ability to rapidly deploy and scale its capabilities will become increasingly crucial.</p>
<p>NVIDIA NIM microservices provide the foundation for this new era of AI application development, enabling breakthrough innovations. Whether building the next generation of AI-powered games, developing advanced <a target="_blank" href="https://www.nvidia.com/en-us/glossary/natural-language-processing/">natural language processing</a> applications or creating intelligent automation systems, users can access these powerful development tools at their fingertips.</p>
<p>Ways to get started:</p>
<ul>
<li>Experience and interact with NVIDIA NIM microservices on <a target="_blank" href="http://ai.nvidia.com">ai.nvidia.com</a>.</li>
<li>Join the <a target="_blank" href="https://developer.nvidia.com/developer-program">NVIDIA Developer Program</a> and get free access to NIM for testing and prototyping AI-powered applications.</li>
<li>Buy an <a target="_blank" href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> license with a free 90-day evaluation period for production deployment and use NVIDIA NIM to self-host AI models in the cloud or in data centers.</li>
</ul>
<p><i>Generative AI is transforming gaming, videoconferencing and interactive experiences of all kinds. Make sense of what’s new and what’s next by subscribing to the </i><a target="_blank" href="https://www.nvidia.com/en-us/ai-on-rtx/?modal=subscribe-ai"><i>AI Decoded newsletter</i></a><i>.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/NIMs-nv-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/NIMs-nv-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Mission NIMpossible: Decoding the Microservices That Accelerate Generative AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Widescreen Wonder: Las Vegas Sphere Delivers Dazzling Displays</title>
		<link>https://blogs.nvidia.com/blog/sphere-las-vegas/</link>
		
		<dc:creator><![CDATA[Isha Salian]]></dc:creator>
		<pubDate>Tue, 09 Jul 2024 16:00:39 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Media and Entertainment]]></category>
		<category><![CDATA[NVIDIA BlueField]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[Rendering]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72849</guid>

					<description><![CDATA[Sphere, a new kind of entertainment medium in Las Vegas, is joining the ranks of legendary circular performance spaces such as the Roman Colosseum and Shakespeare’s Globe Theater — captivating audiences with eye-popping LED displays that cover nearly 750,000 square feet inside and outside the venue. Behind the screens, around 150 NVIDIA RTX A6000 GPUs	<a class="read-more" href="https://blogs.nvidia.com/blog/sphere-las-vegas/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Sphere, a new kind of entertainment medium in Las Vegas, is joining the ranks of legendary circular performance spaces such as the Roman Colosseum and Shakespeare’s Globe Theater — captivating audiences with eye-popping LED displays that cover nearly 750,000 square feet inside and outside the venue.</p>
<p>Behind the screens, around 150 <a target="_blank" href="https://www.nvidia.com/en-us/design-visualization/rtx-a6000/">NVIDIA RTX A6000 GPUs</a> help power stunning visuals on floor-to-ceiling, 16x16K displays across the Sphere’s interior, as well as 1.2 million programmable LED pucks on the venue’s exterior — the Exosphere, which is the world’s largest LED screen.</p>
<p>Delivering robust network connectivity, <a target="_blank" href="https://www.nvidia.com/en-us/networking/products/data-processing-unit/">NVIDIA BlueField DPUs</a> and <a target="_blank" href="https://www.nvidia.com/en-us/networking/ethernet-adapters/">NVIDIA ConnectX-6 Dx NICs</a> — along with the <a target="_blank" href="https://docs.nvidia.com/doca/sdk/doca-firefly-service/index.html">NVIDIA DOCA Firefly Service</a> and <a target="_blank" href="https://developer.nvidia.com/networking/rivermax">NVIDIA Rivermax software</a> for media streaming — ensure that all the display panels act as one synchronized canvas.</p>
<p>“Sphere is captivating audiences not only in Las Vegas, but also around the world on social media, with immersive LED content delivered at a scale and clarity that has never been done before,” said Alex Luthwaite, senior vice president of show systems technology at Sphere Entertainment. “This would not be possible without the expertise and innovation of companies such as NVIDIA that are critical to helping power our vision, working closely with our team to redefine what is possible with cutting-edge display technology.”</p>
<p>Named <a href="https://time.com/collection/best-inventions-2023/6324099/sphere/" target="_blank" rel="noopener">one of TIME’s Best Inventions of 2023</a>, Sphere hosts original Sphere Experiences, concerts and residencies from the world’s biggest artists, and premier marquee and corporate events.</p>
<p>Rock band U2 opened Sphere with a 40-show run that concluded in March. Other shows include The Sphere Experience featuring Darren Aronofsky’s <i>Postcard From Earth</i>, a specially created multisensory cinematic experience that showcases all of the venue’s immersive technologies, including high-resolution visuals, advanced concert-grade sound, haptic seats and atmospheric effects such as wind and scents.</p>
<figure id="attachment_72853" aria-describedby="caption-attachment-72853" style="width: 2048px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-full wp-image-72853" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/Sphere_092823_2323-2-scaled.jpg" alt="image of the Earth from space displayed in Sphere" width="2048" height="1365" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/07/Sphere_092823_2323-2-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Sphere_092823_2323-2-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Sphere_092823_2323-2-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Sphere_092823_2323-2-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Sphere_092823_2323-2-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Sphere_092823_2323-2-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Sphere_092823_2323-2-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Sphere_092823_2323-2-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Sphere_092823_2323-2-1280x853.jpg 1280w" sizes="(max-width: 2048px) 100vw, 2048px" /><figcaption id="caption-attachment-72853" class="wp-caption-text">“Postcard From Earth” is a multisensory immersive experience. Image courtesy of Sphere Entertainment.</figcaption></figure>
<h2><b>Behind the Screens: Visual Technology Fueling the Sphere</b></h2>
<p>Sphere Studios creates video content in its Burbank, Calif., facility, then transfers it digitally to Sphere in Las Vegas. The content is then streamed in real time to rack-mounted workstations equipped with NVIDIA RTX A6000 GPUs, achieving unprecedented performance capable of delivering three layers of 16K resolution at 60 frames per second.</p>
<p>The NVIDIA Rivermax software helps provide media streaming acceleration, enabling direct data transfers to and from the GPU. Combined, the software and hardware acceleration eliminates jitter and optimizes latency.</p>
<p>NVIDIA BlueField DPUs also facilitate precision timing through the DOCA Firefly Service, which is used to synchronize clocks in a network with sub-microsecond accuracy.</p>
<p>“The integration of NVIDIA RTX GPUs, BlueField DPUs and Rivermax software creates a powerful trifecta of advantages for modern accelerated computing, supporting the unique high-resolution video streams and strict timing requirements needed at Sphere and setting a new standard for media processing capabilities,” said Nir Nitzani, senior product director for networking software at NVIDIA. “This collaboration results in remarkable performance gains, culminating in the extraordinary experiences guests have at Sphere.”<i> </i></p>
<h2><b>Well-Rounded: From Simulation to Sphere Stage</b></h2>
<p>To create new immersive content exclusively for Sphere, Sphere Entertainment launched Sphere Studios, which is dedicated to developing the next generation of original immersive entertainment. The Burbank campus consists of numerous development facilities, including a quarter-sized version of Sphere screen in Las Vegas, dubbed Big Dome, which serves as a specialized screening, production facility and lab for content.</p>
<figure id="attachment_72856" aria-describedby="caption-attachment-72856" style="width: 2048px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-full wp-image-72856" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/Big-Dome-Exterior-Credit-Sphere-Entertainment-scaled.jpeg" alt="dome-shaped building flanked by palm trees" width="2048" height="1366" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/07/Big-Dome-Exterior-Credit-Sphere-Entertainment-scaled.jpeg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Big-Dome-Exterior-Credit-Sphere-Entertainment-400x267.jpeg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Big-Dome-Exterior-Credit-Sphere-Entertainment-672x448.jpeg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Big-Dome-Exterior-Credit-Sphere-Entertainment-768x512.jpeg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Big-Dome-Exterior-Credit-Sphere-Entertainment-1536x1024.jpeg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Big-Dome-Exterior-Credit-Sphere-Entertainment-675x450.jpeg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Big-Dome-Exterior-Credit-Sphere-Entertainment-322x215.jpeg 322w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Big-Dome-Exterior-Credit-Sphere-Entertainment-150x100.jpeg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/07/Big-Dome-Exterior-Credit-Sphere-Entertainment-1280x854.jpeg 1280w" sizes="(max-width: 2048px) 100vw, 2048px" /><figcaption id="caption-attachment-72856" class="wp-caption-text">The Big Dome is 100 feet high and 28,000 square feet. Image courtesy of Sphere Entertainment.</figcaption></figure>
<p>Sphere Studios also developed the Big Sky camera system, which captures uncompressed, 18K images from a single camera, so that the studio can film content for Sphere without needing to stitch multiple camera feeds together. The studio’s custom image processing software runs on Lenovo servers powered by <a target="_blank" href="https://www.nvidia.com/en-us/data-center/a40/">NVIDIA A40 GPUs</a>.</p>
<p>The A40 GPUs also fuel creative work, including 3D video, virtualization and ray tracing. To develop visuals for different kinds of shows, the team works with apps including Unreal Engine, Unity, Touch Designer and Notch.</p>
<p><i>For more, explore upcoming sessions in </i><a target="_blank" href="https://www.nvidia.com/en-us/events/siggraph/"><i>NVIDIA’s room at SIGGRAPH</i></a><i> and watch the panel discussion “</i><a target="_blank" href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s63135/"><i>Immersion in Sphere: Redefining Live Entertainment Experiences</i></a><i>” on NVIDIA On-Demand.</i></p>
<p><i>All images courtesy of Sphere Entertainment.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/Sphere-Exosphere.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/Sphere-Exosphere-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Widescreen Wonder: Las Vegas Sphere Delivers Dazzling Displays]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>In It for the Long Haul: Waabi Pioneers Generative AI to Unleash Fully Driverless Autonomous Trucking</title>
		<link>https://blogs.nvidia.com/blog/waabi-autonomous-trucking/</link>
		
		<dc:creator><![CDATA[Norm Marks]]></dc:creator>
		<pubDate>Mon, 08 Jul 2024 15:00:00 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72803</guid>

					<description><![CDATA[Artificial intelligence is transforming the transportation industry, helping drive advances in autonomous vehicle (AV) technology. Waabi, a Toronto-based startup, is embracing generative AI to deliver self-driving vehicles at scale — starting with the long-haul trucking sector. At GTC in March, Waabi announced that it will use the NVIDIA DRIVE Thor centralized car computer to bring	<a class="read-more" href="https://blogs.nvidia.com/blog/waabi-autonomous-trucking/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Artificial intelligence is transforming the transportation industry, helping drive advances in autonomous vehicle (AV) technology.</p>
<p>Waabi, a Toronto-based startup, is embracing generative AI to deliver self-driving vehicles at scale — starting with the long-haul trucking sector.</p>
<p>At GTC in March, <a href="https://waabi.ai/nvidia-drivethor/" target="_blank" rel="noopener">Waabi announced that it will use the NVIDIA DRIVE Thor</a> centralized car computer to bring a safe, generative AI-powered autonomous trucking solution — the Waabi Driver —  to market.</p>
<p>As the company plans the launch of fully driverless operations next year, Waabi is reinvigorating the industry with a self-driving solution that’s capital-efficient, can safely handle new scenarios on the road and ultimately scales commercially.</p>
<p>Waabi is developing on <a href="https://developer.nvidia.com/drive/os" target="_blank" rel="noopener">NVIDIA DRIVE OS</a>, the company’s operating system for safe, AI-defined autonomous vehicles.</p>
<p>The innovative startup has pioneered an approach that centers on the combination of two generative AI systems: a “teacher,” called Waabi World, an advanced simulator that trains and validates a “student,” called Waabi Driver, a single, end-to-end AI system that’s capable of human-like reasoning and is fully interpretable.</p>
<p>When paired together, these systems reduce the need for extensive on-road testing and enable a safer, more efficient solution that is highly performant and scalable.</p>
<p>“We are excited to have a deep collaboration with NVIDIA to bring generative AI to the edge, on our vehicles, at scale,” said Raquel Urtasun, founder and CEO of Waabi.</p>
<p><iframe loading="lazy" title="Waabi and NVIDIA: Bringing Generative AI to the Edge" width="500" height="281" src="https://www.youtube.com/embed/iDGwP45B_GA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Generative AI accelerates the development of AVs by “providing an end-to-end system where, instead of requiring hundreds of engineers to develop a system by hand, it provides the ability to learn foundation models that can run unsupervised by observing and acting on the world,” Urtasun added.</p>
<p>Waabi’s collaboration with NVIDIA is one in a series of milestones, including the company’s <a href="https://waabi.ai/waabi-series-b-announcement/" target="_blank" rel="noopener">$200 million Series B round</a> with participation from NVIDIA, its <a href="https://waabi.ai/waabi-uber-freight/" target="_blank" rel="noopener">work with logistics company Uber Freight</a>, the launch of its first commercial autonomous trucking routes in the U.S., and the opening of a trucking terminal near Dallas to serve as the center of the company’s operations in the Lone Star state.</p>
<p>“What we’re building for autonomous vehicles — combining generative AI-powered simulation with a foundation AI model purpose-built for acting in the physical world — will enable faster, safer and more scalable deployment of this transformative technology around the world,” Urtasun noted on the company’s website.</p>
<p><i>Listen to Urtasun’s </i><a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62621/" target="_blank" rel="noopener"><i>talk at GTC</i></a><i> for more on the company’s work on using generative AI to develop autonomous vehicles.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/waabi.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/waabi-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[In It for the Long Haul: Waabi Pioneers Generative AI to Unleash Fully Driverless Autonomous Trucking]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>GeForce NOW Beats the Heat With 22 New Games in July</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-july-2024-games-list/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 04 Jul 2024 13:00:36 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72833</guid>

					<description><![CDATA[GeForce NOW is bringing 22 new games to members this month. Dive into the four titles available to stream on the cloud gaming service this week to stay cool and entertained throughout the summer — whether poolside, on a long road trip or in the air-conditioned comfort of home. Plus, get great games at great	<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-july-2024-games-list/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><a target="_blank" href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> is bringing 22 new games to members this month.</p>
<p>Dive into the four titles available to stream on the cloud gaming service this week to stay cool and entertained throughout the summer — whether poolside, on a long road trip or in the air-conditioned comfort of home.</p>
<p>Plus, get great games at great deals to stream across devices during the Steam Summer Sale. In total, more than 850 titles on GeForce NOW can be found at discounts in a dedicated Steam Summer Sale row on the GeForce NOW app, from now until July 11.</p>
<h2><b>Time to Grind</b></h2>
<figure id="attachment_72837" aria-describedby="caption-attachment-72837" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-72837" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-The_First_Descendant-672x336.jpg" alt="The First Descendant on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-The_First_Descendant-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-The_First_Descendant-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-The_First_Descendant-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-The_First_Descendant-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-The_First_Descendant-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-The_First_Descendant-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-The_First_Descendant-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-The_First_Descendant-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/07/GFN_Thursday-The_First_Descendant.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72837" class="wp-caption-text"><em>Be the first Descendant with the cloud.</em></figcaption></figure>
<p>In <i>The First Descendant</i> from NEXON, take on the role of Descendants tasked with safeguarding the powerful Iron Heart from relentless Vulgus invaders. Set in a captivating sci-fi universe, the game is a third-person co-op action role-playing shooter that seamlessly blends looting mechanics with strategic combat. Engage in intense gunplay, face off against formidable bosses and collect valuable loot while fighting to preserve humanity’s future.</p>
<p>Check out the list of new games this week:</p>
<ul>
<li><i>The Falconeer </i>(Free on <a target="_blank" href="https://www.epicgames.com/store/p/the-falconeer?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store,</a> July 4)</li>
<li><i>The First Descendant </i>(<a target="_blank" href="https://store.steampowered.com/app/2074920?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Star Traders: Frontiers </i>(<a target="_blank" href="https://store.steampowered.com/app/335620?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Wuthering Waves </i>(<a target="_blank" href="https://wutheringwaves.kurogames.com/?utm_source=nvidia&amp;utm_campaign=geforce_now">Native</a> and <a target="_blank" href="https://www.epicgames.com/store/p/wuthering-waves-76ebc5?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
</ul>
<p>And members can look for the following later this month:</p>
<ul>
<li><i>Once Human </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/2139460?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, July 9)</li>
<li><i>Anger Foot </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1978590?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, July 11)</li>
<li><i>The Crust </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1465470?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, July 15)</li>
<li><i>Gestalt: Steam &amp; Cinder </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1231990?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, July 16)</li>
<li><i>Flintlock: The Siege of Dawn  </i>(New release <a target="_blank" href="https://store.steampowered.com/app/1832040?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a target="_blank" href="https://www.xbox.com/games/store/flintlock-the-siege-of-dawn/9PBBQHX6V3PJ?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass, July 18)</li>
<li><i>Dungeons of Hinterberg </i>(New release <a target="_blank" href="https://store.steampowered.com/app/1983260?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a target="_blank" href="https://www.xbox.com/games/store/dungeons-of-hinterberg/9pgx472j0rjp?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass, July 18)</li>
<li><i>Norland </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1857090?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, July 18)</li>
<li><i>Cataclismo </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1422440?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, July 22</li>
<li><i>CONSCRIPT </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1286990?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, July 23)</li>
<li><i>F1 Manager 2024 </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/2591280?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, July 23)</li>
<li><i>EARTH DEFENSE FORCE 6 </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/2291060?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, July 25)</li>
<li><i>Stormgate Early Access </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/2012510?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, July 30)</li>
<li><i>Cyber Knights: Flashpoint </i>(<a target="_blank" href="https://store.steampowered.com/app/1021210?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Content Warning </i>(<a target="_blank" href="https://store.steampowered.com/app/2881650?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Crime Boss: Rockay City </i>(<a target="_blank" href="https://store.steampowered.com/app/2933080?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Gang Beasts </i>(<a target="_blank" href="https://store.steampowered.com/app/285900?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a target="_blank" href="https://www.xbox.com/games/store/gang-beasts/BPQZT43FWD49?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>HAWKED</i> (<a target="_blank" href="https://store.steampowered.com/app/1955960?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Kingdoms and Castles </i>(<a target="_blank" href="https://store.steampowered.com/app/569480?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<h2><b>Jam-Packed June</b></h2>
<p>In addition to the 17 games announced last month, 10 more joined the <a target="_blank" href="http://play.geforcenow.com">GeForce NOW library</a>:<i></i></p>
<ul>
<li><i>Killer Klowns from Outer Space: The Game </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1556100?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, June 4)</li>
<li><i>Sneak Out </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/2410490?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, June 6)</li>
<li><i>Beyond Good &amp; Evil &#8211; 20th Anniversary Edition </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/2556990/Beyond_Good__Evil__20th_Anniversary_Edition/">Steam</a> and <a target="_blank" href="https://www.ubisoft.com/en-us/game/beyond-good-and-evil/20th-anniversary-edition">Ubisoft</a>, June 24)</li>
<li><i>As Dusk Falls </i>(<a target="_blank" href="https://store.steampowered.com/app/1341820?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a target="_blank" href="https://www.xbox.com/games/store/as-dusk-falls/9NR7XDNVP5SW?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Bodycam </i>(<a target="_blank" href="https://store.steampowered.com/app/2406770/Bodycam/">Steam</a>)</li>
<li><i>Drug Dealer Simulator 2</i> (<a target="_blank" href="https://store.steampowered.com/app/1708850?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Sea of Thieves </i>(<a target="_blank" href="https://store.steampowered.com/app/1172620?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a target="_blank" href="https://www.xbox.com/games/store/sea-of-thieves-2023-edition/9P2N57MC619K?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Skye: The Misty Isle </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1710180?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, June 19)</li>
<li><i>XDefiant</i> (Ubisoft)</li>
<li><i>Tell Me Why </i>(<a target="_blank" href="https://store.steampowered.com/app/1180660?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a target="_blank" href="https://www.xbox.com/games/store/tell-me-why/9NBL0XKVCN5L?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
</ul>
<p><i>Torque Drift 2 </i>didn’t make it in June due to technical issues. Stay tuned to GFN Thursday for updates.</p>
<p>What are you planning to play this weekend? Let us know on <a target="_blank" href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Fill in the blank:</p>
<p><img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f4c6.png" alt="📆" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Game that you&#39;ve played for over a year: _____<br /><img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f465.png" alt="👥" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Multiplayer game you can&#39;t stop playing: _____<br /><img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f621.png" alt="😡" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Game that makes you rage: _____</p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a target="_blank" href="https://twitter.com/NVIDIAGFN/status/1808531147401359480?ref_src=twsrc%5Etfw">July 3, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/gfn-thursday-7-4-nv-blog-1280x680-no-cta.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/gfn-thursday-7-4-nv-blog-1280x680-no-cta-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[GeForce NOW Beats the Heat With 22 New Games in July]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Decoding How the Generative AI Revolution BeGAN</title>
		<link>https://blogs.nvidia.com/blog/ai-decoded-gan-canvas-app/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Wed, 03 Jul 2024 13:00:55 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[AI Decoded]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72808</guid>

					<description><![CDATA[Generative models have completely transformed the AI landscape — headlined by popular apps such as ChatGPT and Stable Diffusion. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><i>Editor’s note: This post is part of the </i><a href="https://blogs.nvidia.com/blog/tag/ai-decoded/" target="_blank" rel="noopener"><i>AI Decoded series</i></a><i>, which demystifies AI by making the technology more accessible, and showcases new hardware, software, tools and accelerations for RTX PC users.</i></p>
<p>Generative models have completely transformed the AI landscape — headlined by popular apps such as ChatGPT and Stable Diffusion.</p>
<p>Paving the way for this boom were foundational AI models and generative adversarial networks (GANs), which sparked a leap in productivity and creativity.</p>
<p>NVIDIA’s <a href="https://blogs.nvidia.com/blog/gaugan-photorealistic-landscapes-nvidia-research/" target="_blank" rel="noopener">GauGAN</a>, which powers the <a href="https://www.nvidia.com/en-us/studio/canvas/" target="_blank" rel="noopener">NVIDIA Canvas app</a>, is one such model that uses AI to transform rough sketches into photorealistic artwork.</p>
<h2><b>How It All BeGAN</b></h2>
<p>GANs are deep learning models that involve two complementary neural networks: a generator and a discriminator.</p>
<p>These neural networks compete against each other. The generator attempts to create realistic, lifelike imagery, while the discriminator tries to tell the difference between what’s real and what’s generated. As its neural networks keep challenging each other, GANs get better and better at making realistic-looking samples.</p>
<p>GANs excel at understanding complex data patterns and creating high-quality results. They&#8217;re used in applications including image synthesis, style transfer, data augmentation and image-to-image translation.</p>
<p>NVIDIA’s GauGAN, named after post-Impressionist painter Paul Gauguin, is an AI demo for photorealistic image generation. Built by NVIDIA Research, it directly led to the development of the NVIDIA Canvas app — and can be experienced for free through the <a target="_blank" href="https://www.nvidia.com/en-us/research/ai-demos/">NVIDIA AI Playground</a>.</p>
<p>GauGAN has been wildly popular since it debuted at NVIDIA GTC in 2019 — used by art teachers, creative agencies, museums and millions more online.</p>
<h2><b>Giving Sketch to Scenery a Gogh</b></h2>
<p>Powered by GauGAN and local <a href="https://www.nvidia.com/en-us/design-visualization/technologies/rtx/" target="_blank" rel="noopener">NVIDIA RTX GPUs</a>, NVIDIA Canvas uses AI to turn simple brushstrokes into realistic landscapes, displaying results in real time.</p>
<p>Users can start by sketching simple lines and shapes with a palette of real-world elements like grass or clouds —- referred to in the app as “materials.”</p>
<p><iframe loading="lazy" title="NVIDIA Canvas: New Update | 4x Higher Resolution &amp; 5 New Materials" width="500" height="281" src="https://www.youtube.com/embed/wKztRskmsig?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>The AI model then generates the enhanced image on the other half of the screen in real time. For example, a few triangular shapes sketched using the “mountain” material will appear as a stunning, photorealistic range. Or users can select the “cloud” material and with a few mouse clicks transform environments from sunny to overcast.</p>
<p>The creative possibilities are endless — sketch a pond, and other elements in the image, like trees and rocks, will reflect in the water. Change the material from snow to grass, and the scene shifts from a cozy winter setting to a tropical paradise.</p>
<figure id="attachment_72809" aria-describedby="caption-attachment-72809" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/07/beachcove.png"><img loading="lazy" decoding="async" class="size-large wp-image-72809" src="https://blogs.nvidia.com/wp-content/uploads/2024/07/beachcove-672x368.png" alt="" width="672" height="368" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/07/beachcove-672x368.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/07/beachcove-400x219.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/07/beachcove-768x420.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/07/beachcove-1536x840.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/07/beachcove.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/07/beachcove-823x450.png 823w, https://blogs.nvidia.com/wp-content/uploads/2024/07/beachcove-393x215.png 393w, https://blogs.nvidia.com/wp-content/uploads/2024/07/beachcove-183x100.png 183w, https://blogs.nvidia.com/wp-content/uploads/2024/07/beachcove-1280x700.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-72809" class="wp-caption-text">Canvas offers nine different styles, each with 10 variations and 20 materials to play with.</figcaption></figure>
<p>Canvas features a Panorama mode that enables artists to create 360-degree images for use in 3D apps. YouTuber <a href="https://www.youtube.com/watch?v=d2O-kj5KF5w" target="_blank" rel="noopener">Greenskull AI</a> demonstrated Panorama mode by painting an ocean cove, before then importing it into Unreal Engine 5.</p>
<p><iframe loading="lazy" title="NVIDIA Canvas Panorama - Painting in 360° with Ai" width="500" height="281" src="https://www.youtube.com/embed/d2O-kj5KF5w?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p><a href="https://www.nvidia.com/en-us/studio/canvas/" target="_blank" rel="noopener">Download</a> the NVIDIA Canvas app to get started.</p>
<p>Consider exploring <a href="https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/" target="_blank" rel="noopener">NVIDIA Broadcast</a>, another AI-powered content creation app that transforms any room into a home studio. Broadcast is free for RTX GPU owners.</p>
<p><i>Generative AI is transforming gaming, videoconferencing and interactive experiences of all kinds. Make sense of what’s new and what’s next by subscribing to the </i><a target="_blank" href="https://www.nvidia.com/en-us/ai-on-rtx/?modal=subscribe-ai"><i>AI Decoded newsletter</i></a><i>.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/canvas-app-nv-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/07/canvas-app-nv-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Decoding How the Generative AI Revolution BeGAN]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>How an NVIDIA Engineer Unplugs to Recharge During Free Days</title>
		<link>https://blogs.nvidia.com/blog/nvidia-life-free-days-2024/</link>
		
		<dc:creator><![CDATA[Haley Hirai]]></dc:creator>
		<pubDate>Fri, 28 Jun 2024 13:00:23 +0000</pubDate>
				<category><![CDATA[NVIDIA Life]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72785</guid>

					<description><![CDATA[On a weekday afternoon, Ashwini Ashtankar sat on the bank of the Doodhpathri River, in a valley nestled in the Himalayas. Taking a deep breath, she noticed that there was no city noise, no pollution — and no work emails. Ashtankar, a senior tools development engineer in NVIDIA’s Pune, India, office, took advantage of the	<a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-life-free-days-2024/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>On a weekday afternoon, Ashwini Ashtankar sat on the bank of the Doodhpathri River, in a valley nestled in the Himalayas. Taking a deep breath, she noticed that there was no city noise, no pollution — and no work emails.</p>
<p>Ashtankar, a senior tools development engineer in NVIDIA’s Pune, India, office, took advantage of the company’s free days — two extra days off per quarter when the whole company disconnects from work — to recharge. Free days are fully paid by NVIDIA, not counted as vacation or as personal time off, and are in addition to country-specific holidays and time-away programs.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-large wp-image-72789" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/Snow_Peak_Sonmarg-672x378.jpg" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/Snow_Peak_Sonmarg-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Snow_Peak_Sonmarg-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Snow_Peak_Sonmarg-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Snow_Peak_Sonmarg-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Snow_Peak_Sonmarg-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Snow_Peak_Sonmarg-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Snow_Peak_Sonmarg-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Snow_Peak_Sonmarg-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Snow_Peak_Sonmarg-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></p>
<p>Free days give employees time to take an adventure, a breather — or both. Ashtankar and her husband, Dipen Sisodia — also an NVIDIAN — spent it outdoors, hiking up a mountain, playing in snow and exploring forests and lush green meadows.</p>
<p>“My free days give me time to focus on myself and recharge,” said Ashtankar. “We didn’t take our laptops. We were able to completely disconnect, like all NVIDIANs were doing at the same time.”</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-large wp-image-72792" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/Mountain_top_bike-672x378.jpg" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/Mountain_top_bike-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Mountain_top_bike-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Mountain_top_bike-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Mountain_top_bike-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Mountain_top_bike-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Mountain_top_bike-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Mountain_top_bike-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Mountain_top_bike-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Mountain_top_bike-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></p>
<p>Ashtankar returned to work feeling refreshed and recharged, she said. Her team tests software features of NVIDIA products, focusing on GPU display drivers and the <a target="_blank" href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> game-streaming service, to make sure bugs are found and addressed before a product reaches customers.</p>
<p>“I take pride in tackling challenges with the highest level of quality and creativity, all in support of delivering the best products to our customers,” she said. “To do that, sometimes the most productive thing we can do is rest and let the soul catch up with the body.”</p>
<p>Ashtankar plans to build her career at NVIDIA for many years to come.</p>
<p>“I’ve never heard of another company that truly cares this much about its employees,” she said.</p>
<p><i>Learn more about </i><a target="_blank" href="https://www.nvidia.com/en-us/about-nvidia/careers/life-at-nvidia/"><i>NVIDIA life, culture and careers</i></a><i>. </i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/Ashwini-Ashtankar-Free-Days-Featured-Photo.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/Ashwini-Ashtankar-Free-Days-Featured-Photo-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[How an NVIDIA Engineer Unplugs to Recharge During Free Days]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>GeForce NOW Unleashes High-Stakes Horror With ‘Resident Evil Village’</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-resident-evil-village/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 27 Jun 2024 13:00:51 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72759</guid>

					<description><![CDATA[Get ready to feel some chills, even amid the summer heat. Capcom’s award-winning Resident Evil Village brings a touch of horror to the cloud this GFN Thursday, part of three new games joining GeForce NOW this week. And a new app update brings a visual enhancement to members, along with new ways to curate their	<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-resident-evil-village/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Get ready to feel some chills, even amid the summer heat. Capcom’s award-winning <i>Resident Evil Village</i> brings a touch of horror to the cloud this GFN Thursday, part of three new games joining <a target="_blank" href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> this week.</p>
<p>And a new app update brings a visual enhancement to members, along with new ways to curate their GeForce NOW gaming libraries.</p>
<figure id="attachment_72772" aria-describedby="caption-attachment-72772" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-72772" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Greetings_From_GFN-1-672x357.png" alt="Greetings on GFN" width="672" height="357" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Greetings_From_GFN-1-672x357.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Greetings_From_GFN-1-400x213.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Greetings_From_GFN-1-768x408.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Greetings_From_GFN-1-842x447.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Greetings_From_GFN-1-406x215.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Greetings_From_GFN-1-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Greetings_From_GFN-1.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72772" class="wp-caption-text"><em>#GreetingsFromGFN by @railbeam.</em></figcaption></figure>
<p>Members are showcasing their favorite locations to visit in the cloud. Follow along with #GreetingsFromGFN on @NVIDIAGFN social media accounts and share picturesque scenes from the cloud for a chance to be featured.</p>
<h2><b>The Bell Tolls for All</b></h2>
<figure id="attachment_72769" aria-describedby="caption-attachment-72769" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-72769" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Resident_Evil_Village-672x378.jpg" alt="Resident Evil Village on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Resident_Evil_Village-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Resident_Evil_Village-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Resident_Evil_Village-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Resident_Evil_Village-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Resident_Evil_Village-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Resident_Evil_Village-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Resident_Evil_Village-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Resident_Evil_Village-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Resident_Evil_Village-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72769" class="wp-caption-text"><em>The cloud — big enough, even, for Lady Dimitrescu and her towering castle.</em></figcaption></figure>
<p><i>Resident Evil Village</i>, the follow-up to Capcom’s critically acclaimed <i>Resident Evil 7 Biohazard</i>, delivers a gripping blend of survival-horror and action. Step into the shoes of Ethan Winters, a desperate father determined to rescue his kidnapped daughter.</p>
<p>Set against a backdrop of a chilling European village teeming with mutant creatures, the game includes a captivating cast of characters, including the enigmatic Lady Dimitrescu, who haunts the dimly lit halls of her grand castle. Fend off hordes of enemies, such as lycanthropic villagers and grotesque abominations.</p>
<p>Experience classic survival-horror tactics — such as resource management and exploration — mixed with action featuring intense combat and higher enemy counts.</p>
<p><a target="_blank" href="https://www.nvidia.com/en-us/geforce-now/memberships/">Ultimate and Priority members</a> can experience the horrors of this dark and twisted world in gruesome, mesmerizing detail with support for ray tracing and high dynamic range (HDR) for the most lifelike shadows and sharp visual fidelity when navigating every eerie hallway. Members can stream it all seamlessly from <a target="_blank" href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA GeForce RTX</a>-powered servers in the cloud and get a taste of the chills with the <i>Resident Evil Village</i> demo before taking on the towering Lady Dimitrescu in the full game.</p>
<h2><b>I Can See Clearly Now</b></h2>
<p>The latest GeForce NOW app update — version 2.0.64 — adds support for 10-bit color precision. Available for Ultimate members, this feature enhances image quality when streaming on Windows, macOS and <a target="_blank" href="https://www.nvidia.com/en-us/shield/">NVIDIA SHIELD TV</a>.</p>
<figure id="attachment_72766" aria-describedby="caption-attachment-72766" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-72766" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-10_bit_Color_Precision-672x361.png" alt="SDR10 on GeForce NOW" width="672" height="361" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-10_bit_Color_Precision-672x361.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-10_bit_Color_Precision-400x215.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-10_bit_Color_Precision-768x413.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-10_bit_Color_Precision-1536x825.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-10_bit_Color_Precision.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-10_bit_Color_Precision-838x450.png 838w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-10_bit_Color_Precision-186x100.png 186w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-10_bit_Color_Precision-1280x688.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72766" class="wp-caption-text"><em>Rolling out now.</em></figcaption></figure>
<p>10-bit color precision significantly improves the accuracy and richness of color gradients during streaming. Members will especially notice its effects in scenes with detailed color transitions, such as for vibrant skies, dimly lit interiors, and various loading screens and menus. It’s useful for non-HDR displays and non-HDR-supported games. Find the setting in the GeForce NOW app &gt; Streaming Quality &gt; Color Precision, with the recommended default value of 10-bit.</p>
<p>Try it out on the neon-lit streets of <i>Cyberpunk 2077</i> for smoother color transitions, and traverse the diverse landscapes of<i> Assassin’s Creed Valhalla</i> and other games for a more immersive streaming experience.</p>
<p>The update, rolling out now, also brings bug fixes and new ways to curate a member’s in-app game library. For more information, visit the <a target="_blank" href="https://nvidia.custhelp.com/app/answers/detail/a_id/5390">NVIDIA Knowledgebase</a>.</p>
<h2><b>Lights, Camera, Action: New Games</b></h2>
<figure id="attachment_72763" aria-describedby="caption-attachment-72763" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-72763" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Beyond_Good_And_Evil_20th_Anniversary_Edition-672x336.jpg" alt="Beyond Good and Evil 20th Anniversary Edition on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Beyond_Good_And_Evil_20th_Anniversary_Edition-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Beyond_Good_And_Evil_20th_Anniversary_Edition-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Beyond_Good_And_Evil_20th_Anniversary_Edition-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Beyond_Good_And_Evil_20th_Anniversary_Edition-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Beyond_Good_And_Evil_20th_Anniversary_Edition-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Beyond_Good_And_Evil_20th_Anniversary_Edition-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Beyond_Good_And_Evil_20th_Anniversary_Edition-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Beyond_Good_And_Evil_20th_Anniversary_Edition-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Beyond_Good_And_Evil_20th_Anniversary_Edition.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72763" class="wp-caption-text"><em>Uncover the truth.</em></figcaption></figure>
<p>Join the rebellion as action reporter Jade in <i>Beyond Good &amp; Evil &#8211; 20th Anniversary Edition </i>from Ubisoft. Embark on this epic adventure in up to 4K 60 frames per second with improved graphics and audio, a new speedrun mode, updated achievements and an exclusive anniversary gallery. Enjoy unique new rewards exploring Hillys and discover more about Jade’s past in a new treasure hunt throughout the planet.</p>
<p>Check out the list of new games this week:</p>
<ul>
<li><i>Beyond Good &amp; Evil &#8211; 20th Anniversary Edition </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/2556990/Beyond_Good__Evil__20th_Anniversary_Edition/">Steam</a> and <a target="_blank" href="https://www.ubisoft.com/en-us/game/beyond-good-and-evil/20th-anniversary-edition">Ubisoft</a>, June 24)</li>
<li><i>Drug Dealer Simulator 2</i> (<a target="_blank" href="https://store.steampowered.com/app/1708850?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Resident Evil Village </i>(<a target="_blank" href="https://store.steampowered.com/app/1196590?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Resident Evil Village Demo </i>(<a target="_blank" href="https://store.steampowered.com/app/1196590?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a target="_blank" href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Would you rather have infinite health or infinite ammo in-game? <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/2764.png" alt="❤" class="wp-smiley" style="height: 1em; max-height: 1em;" /><img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f52b.png" alt="🔫" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a target="_blank" href="https://twitter.com/NVIDIAGFN/status/1805632044195516463?ref_src=twsrc%5Etfw">June 25, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-thursday-6-27-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-thursday-6-27-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[GeForce NOW Unleashes High-Stakes Horror With ‘Resident Evil Village’]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Into the Omniverse: SyncTwin Helps Democratize Industrial Digital Twins With Generative AI, OpenUSD</title>
		<link>https://blogs.nvidia.com/blog/synctwin-digital-twins-generative-ai-openusd/</link>
		
		<dc:creator><![CDATA[James McKenna]]></dc:creator>
		<pubDate>Thu, 27 Jun 2024 13:00:19 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Digital Twin]]></category>
		<category><![CDATA[Into the Omniverse]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[SIGGRAPH]]></category>
		<category><![CDATA[Universal Scene Description]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72742</guid>

					<description><![CDATA[SyncTwin’s application enables teams to optimize industrial efficiency while enhancing sustainability across manufacturing processes.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><i>Editor’s note: This post is part of </i><a target="_blank" href="https://www.nvidia.com/en-us/omniverse/news/"><i>Into the Omniverse</i></a><i>, a series focused on how technical artists, developers and enterprises can transform their workflows using the latest advances in </i><a target="_blank" href="https://www.nvidia.com/en-us/omniverse/usd/"><i>OpenUSD</i></a><i> and </i><a target="_blank" href="https://www.nvidia.com/en-us/omniverse/usd/"><i>NVIDIA Omniverse</i></a><i>.</i></p>
<p>Efficiency and sustainability are critical for organizations looking to be at the forefront of industrial innovation.</p>
<p>To address the digitalization needs of manufacturing and other industries, <a target="_blank" href="https://www.synctwin.ai/">SyncTwin </a>GmbH — a company that builds software to optimize production, intralogistics and assembly — developed a <a target="_blank" href="https://www.nvidia.com/en-us/omniverse/solutions/digital-twins/">digital twin</a> app using <a target="_blank" href="https://www.nvidia.com/en-us/ai-data-science/products/cuopt/">NVIDIA cuOpt</a>, an accelerated optimization engine for solving complex routing problems, and <a target="_blank" href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, a platform of application programming interfaces, software development kits and services that enable developers to build <a target="_blank" href="https://www.nvidia.com/en-us/omniverse/usd/">OpenUSD</a>-based applications.</p>
<p>SyncTwin is harnessing the power of the extensible OpenUSD framework for describing, composing, simulating, and collaborating within 3D worlds to help its customers create physically accurate digital twins of their factories. The digital twins can be used to optimize production and enhance digital precision to meet industrial performance.</p>
<h2><b>OpenUSD’s Role in Modern Manufacturing</b></h2>
<p>Manufacturing workflows are incredibly complex, making effective communication and integration across various domains pivotal to ensuring operational efficiency. The SyncTwin app provides seamless collaboration capabilities for factory plant managers and their teams, enabling them to optimize processes and resources.</p>
<p>The app uses OpenUSD and Omniverse to help make factory planning and operations easier and more accessible by integrating various manufacturing aspects into a cohesive digital twin. Customers can integrate visual data, production details, product catalogs, orders, schedules, resources and production settings <a target="_blank" href="https://www.google.com/url?q=https://developer.nvidia.com/blog/transforming-microsoft-xls-and-ppt-files-into-a-factory-digital-twin-with-openusd/&amp;sa=D&amp;source=docs&amp;ust=1720024234143097&amp;usg=AOvVaw3pcW7Wfq_o95dh5vj0UF4S">from a variety of file formats all in one place with OpenUSD</a>.</p>
<p><img loading="lazy" decoding="async" class=" wp-image-72746 aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_blog_steps_app_2.png" alt="" width="816" height="440" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_blog_steps_app_2.png 1928w, https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_blog_steps_app_2-400x216.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_blog_steps_app_2-672x362.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_blog_steps_app_2-768x414.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_blog_steps_app_2-1536x829.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_blog_steps_app_2-834x450.png 834w, https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_blog_steps_app_2-399x215.png 399w, https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_blog_steps_app_2-185x100.png 185w, https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_blog_steps_app_2-1280x690.png 1280w" sizes="(max-width: 816px) 100vw, 816px" /></p>
<p>The SyncTwin app creates realistic, virtual environments that facilitate seamless interactions between different sectors of factory operations. This capability enables diverse data—including floorplans from Microsoft PowerPoint and warehouse container data from Excel spreadsheets — to be aggregated in a unified digital twin.</p>
<p>The flexibility of OpenUSD allows for non-destructive editing and composition of complex 3D assets and animations, further enhancing the digital twin.</p>
<p>“OpenUSD is the common language bringing all these different factory domains into a single digital twin,” said <a href="https://blogs.nvidia.com/blog/omniverse-developer-michael-wagner/">Michael Wagner</a>, cofounder and chief technology officer of SyncTwin. “The framework can be instrumental in dismantling data silos and enhancing collaborative efficiency across different factory domains, such as assembly, logistics and infrastructure planning.”</p>
<p>Hear Wagner discuss turning PowerPoint and Excel data into digital twin scenarios using the SyncTwin App in a <a target="_blank" href="https://www.linkedin.com/events/7209117147254374401/comments/">LinkedIn livestream</a> on July 4 at 11 a.m. CET.</p>
<p><img loading="lazy" decoding="async" class=" wp-image-72749 aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_log6.png" alt="" width="818" height="460" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_log6.png 1920w, https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_log6-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_log6-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_log6-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_log6-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_log6-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_log6-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_log6-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/06/synctwin_log6-1280x720.png 1280w" sizes="(max-width: 818px) 100vw, 818px" /></p>
<h2><b>Pioneering Generative AI in Factory Planning</b></h2>
<p>By integrating <a target="_blank" href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> into its platform, SyncTwin also provides users with data-driven insights and recommendations, enhancing decision-making processes.</p>
<p>This AI integration automates complex analyses, accelerates operations and reduces the need for manual inputs. Learn more about how SyncTwin and other startups are combining the powers of OpenUSD and generative AI to elevate their technologies in this <a target="_blank" href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62644/">NVIDIA GTC session</a>.</p>
<p>Hear SyncTwin and NVIDIA experts discuss how digital twins are unlocking new possibilities in this recent community livestream:</p>
<p><iframe loading="lazy" title="Exploring Physics-Based Digital Twins With OpenUSD" width="500" height="281" src="https://www.youtube.com/embed/4j4doXJ3uao?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>By tapping into the power of OpenUSD and NVIDIA’s AI and optimization technologies, SyncTwin is helping set new standards for factory planning and operations, improving operational efficiency and supporting the vision of sustainability and cost reduction across manufacturing.</p>
<h2><b>Get Plugged Into the World of OpenUSD</b></h2>
<p>Learn more about OpenUSD and meet with NVIDIA experts at <a target="_blank" href="https://www.nvidia.com/en-us/events/siggraph/">SIGGRAPH</a>, taking place July 28-Aug. 1 at the Colorado Convention Center and online. Attend these SIGGRAPH highlights:</p>
<ul>
<li>NVIDIA founder and CEO Jensen Huang’s <a target="_blank" href="https://s2024.siggraph.org/program/keynote-presentations/#speaker-huang">fireside chat</a> on Monday, July 29, covering the latest in generative AI and accelerated computing.</li>
<li><a target="_blank" href="https://s2024.conference-program.org/presentation/?id=ind_101&amp;sess=sess421">OpenUSD Day</a> on Tuesday, July 30, where industry luminaries and developers will showcase how to build 3D pipelines and tools using OpenUSD.</li>
<li><a target="_blank" href="https://www.nvidia.com/en-us/events/siggraph/">Hands-on OpenUSD</a> training for all skill levels.</li>
</ul>
<p>Check out this <a target="_blank" href="https://www.youtube.com/playlist?list=PL3jK4xNnlCVcUP08kj6eOzvCA82U_JKiy">video series</a> about how OpenUSD can improve 3D workflows. For more resources on OpenUSD, explore the Alliance for OpenUSD <a target="_blank" href="https://forum.aousd.org/">forum</a> and visit the <a target="_blank" href="https://aousd.org/">AOUSD website</a>.</p>
<p><i>Get started with NVIDIA Omniverse by downloading the standard license </i><a target="_blank" href="https://www.nvidia.com/en-us/omniverse/download/"><i>free</i></a><i>, access </i><a target="_blank" href="https://developer.nvidia.com/usd"><i>OpenUSD</i></a><i> resources and learn how </i><a target="_blank" href="https://www.nvidia.com/en-us/omniverse/enterprise/"><i>Omniverse Enterprise</i><i> can connect team</i></a><i>s. Follow Omniverse on </i><a target="_blank" href="https://www.instagram.com/nvidiaomniverse/"><i>Instagram</i></a><i>, </i><a target="_blank" href="https://www.linkedin.com/showcase/nvidia-omniverse/"><i>LinkedIn</i></a><i>, </i><a target="_blank" href="https://medium.com/@nvidiaomniverse"><i>Medium</i></a><i> and </i><a target="_blank" href="https://twitter.com/nvidiaomniverse"><i>X</i></a><i>. For more, join the </i><a target="_blank" href="https://www.nvidia.com/en-us/omniverse/community/"><i>Omniverse community</i></a><i> on the </i><a target="_blank" href="https://forums.developer.nvidia.com/c/omniverse/300"><i>forums</i></a><i>, </i><a target="_blank" href="https://discord.com/invite/XWQNJDNuaC"><i>Discord server</i></a><i> and </i><a target="_blank" href="https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA"><i>YouTube</i></a><i> channel. </i></p>
<p><i>Featured image courtesy of SyncTwin GmbH.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/nv-ov-ito-1280x680-synctwin-noCred.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/nv-ov-ito-1280x680-synctwin-noCred-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Into the Omniverse: SyncTwin Helps Democratize Industrial Digital Twins With Generative AI, OpenUSD]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Thinking Outside the Blox: How Roblox Is Using Generative AI to Enhance User Experiences</title>
		<link>https://blogs.nvidia.com/blog/roblox-anupam-singh/</link>
		
		<dc:creator><![CDATA[Andy Bui]]></dc:creator>
		<pubDate>Wed, 26 Jun 2024 13:00:22 +0000</pubDate>
				<category><![CDATA[The AI Podcast]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72308</guid>

					<description><![CDATA[Roblox is a colorful online platform that aims to reimagine the way that people come together — now that vision is being augmented by generative AI. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Anupam Singh, vice president of AI and growth engineering at Roblox, on how the company is using	<a class="read-more" href="https://blogs.nvidia.com/blog/roblox-anupam-singh/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Roblox is a colorful online platform that aims to reimagine the way that people come together — now that vision is being augmented by generative AI. In this episode of NVIDIA’s <a href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">AI Podcast</a>, host Noah Kravitz speaks with Anupam Singh, vice president of AI and growth engineering at Roblox, on how the company is using the technology to enhance virtual experiences with features such as automated chat filters and real-time text translation, which help build inclusivity and user safety. Singh also discusses how generative AI can be used to power coding assistants that help creators focus more on creative expression, rather than spending time manually scripting world-building features.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1851430170%3Fsecret_token%3Ds-Hqyyg8rKctd&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="How Roblox Is Using Generative AI to Enhance User Experiences - Ep. 227" href="https://soundcloud.com/theaipodcast/anumpam-singh-roblox/s-Hqyyg8rKctd" target="_blank" rel="noopener">How Roblox Is Using Generative AI to Enhance User Experiences &#8211; Ep. 227</a></div>
<h2>Time Stamps</h2>
<p>1:49: Background on Roblox and user interactions within the platform<br />
6:38: Singh’s insight on AI and machine learning’s role in Roblox’s growth<br />
15:51: Using generative AI to enhance user self-expression<br />
20:04: How generative AI simplifies content creation<br />
24:26: What’s next for Roblox</p>
<h2>You Might Also Like:</h2>
<p><a href="https://soundcloud.com/theaipodcast/mediamonks-lewis-smithingham" target="_blank" rel="noopener"><b>Media.Monks’ Lewis Smithingham on Enhancing Media and Marketing With AI &#8211; Ep. 222</b></a></p>
<p>In this episode, Lewis Smithingham, senior vice president of innovation and special operations at Media.Monks, discusses AI’s potential to enhance the media and entertainment industry. Smithingham delves into Media.Monk’s platform for entertainment and speaks to its vision where AI enhances creativity and allows for more personalized, scalable content creation.</p>
<p><a href="https://soundcloud.com/theaipodcast/legal" target="_blank" rel="noopener"><b>The Case for Generative AI in the Legal Field &#8211; Ep. 210</b></a></p>
<p>AI-driven digital solutions enable law practitioners to search laws and cases intelligently — automating the time-consuming process of drafting and analyzing legal documents. In this episode, Thomson Reuters Chief Product Officer David Wong discusses AI’s potential to help deliver better access to justice.</p>
<p><a href="https://soundcloud.com/theaipodcast/legal" target="_blank" rel="noopener"><b>Deepdub’s Ofir Krakowski on Redefining Dubbing from Hollywood to Bollywood &#8211; Ep. 202</b></a></p>
<p>Deepdub acts as a digital bridge, providing access to content by using generative AI to break down language and cultural barriers in the entertainment landscape. In this episode, Deepdub co-founder and CEO Ofir Krakowski speaks on how AI-driven dubbing helps entertainment companies boost efficiency and increase accessibility.</p>
<h2><b>Subscribe to the AI Podcast</b></h2>
<p>Get the <a href="https://blogs.nvidia.com/ai-podcast/" target="_blank" rel="noopener">AI Podcast</a> through <a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439" target="_blank" rel="noopener">iTunes</a>, <a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm" target="_blank" rel="noopener">Google Play</a>, <a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast" target="_blank" rel="noopener">Amazon Music</a>, <a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us" target="_blank" rel="noopener">Castbox</a>, DoggCatcher, <a href="https://overcast.fm/itunes1186480811/the-ai-podcast" target="_blank" rel="noopener">Overcast</a>, <a href="https://player.fm/series/the-ai-podcast" target="_blank" rel="noopener">PlayerFM</a>, Pocket Casts, <a href="http://www.podbay.fm/show/1186480811" target="_blank" rel="noopener">Podbay</a>, <a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast" target="_blank" rel="noopener">PodBean</a>, PodCruncher, PodKicker, <a href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">Soundcloud</a>, <a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L" target="_blank" rel="noopener">Spotify</a>, <a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr" target="_blank" rel="noopener">Stitcher</a> and <a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/" target="_blank" rel="noopener">TuneIn</a>.</p>
<p>Make the AI Podcast better: Have a few minutes to spare? Fill out <a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short" target="_blank" rel="noopener">this listener survey</a>.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/2023-Avatar-Lineup-Avatars-have-been-previously-only-created-by-Roblox-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1365"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/2023-Avatar-Lineup-Avatars-have-been-previously-only-created-by-Roblox-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Thinking Outside the Blox: How Roblox Is Using Generative AI to Enhance User Experiences]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
	</channel>
</rss>
