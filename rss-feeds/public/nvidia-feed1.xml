<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Tue, 28 Nov 2023 17:21:42 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.4.1</generator>
	<item>
		<title>NVIDIA BioNeMo Enables Generative AI for Drug Discovery on AWS</title>
		<link>https://blogs.nvidia.com/blog/bionemo-on-aws-generative-ai-drug-discovery/</link>
		
		<dc:creator><![CDATA[Kimberly Powell]]></dc:creator>
		<pubDate>Tue, 28 Nov 2023 17:21:33 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Genomics]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[NVIDIA Clara]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68361</guid>

					<description><![CDATA[Researchers and developers at leading pharmaceutical and techbio companies can now easily deploy NVIDIA Clara software and services for accelerated healthcare through Amazon Web Services. Announced today at AWS re:Invent, the initiative gives healthcare and life sciences developers using AWS cloud resources the flexibility to integrate NVIDIA-accelerated offerings such as NVIDIA BioNeMo — a generative <a class="read-more" href="https://blogs.nvidia.com/blog/bionemo-on-aws-generative-ai-drug-discovery/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Researchers and developers at leading pharmaceutical and techbio companies can now easily deploy <a href="https://aws.amazon.com/nvidia/hcls/" target="_blank" rel="noopener">NVIDIA Clara software and services</a> for accelerated healthcare through Amazon Web Services.</p>
<p><a href="https://nvidianews.nvidia.com/news/aws-nvidia-strategic-collaboration-for-generative-ai">Announced today at AWS re:Invent</a>, the initiative gives healthcare and life sciences developers using AWS cloud resources the flexibility to integrate NVIDIA-accelerated offerings such as <a href="https://www.nvidia.com/en-gb/clara/bionemo/">NVIDIA BioNeMo</a> — a generative AI platform for drug discovery — coming to <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a> on AWS, and currently available via the AWS ParallelCluster cluster management tool for high performance computing and the Amazon SageMaker machine learning service.</p>
<p>Thousands of healthcare and life sciences companies globally use AWS. They will now be able to access BioNeMo to build or customize digital biology foundation models with proprietary data, scaling up model training and deployment using NVIDIA GPU-accelerated cloud servers on AWS.</p>
<p>Techbio innovators including <a href="https://www.alchemab.com/" target="_blank" rel="noopener">Alchemab Therapeutics</a>, <a href="https://www.basecamp-research.com/" target="_blank" rel="noopener">Basecamp Research</a>, <a href="https://www.characterbio.com/" target="_blank" rel="noopener">Character Biosciences</a>, <a href="https://www.evozyne.com/" target="_blank" rel="noopener">Evozyne</a>, <a href="https://www.etcembly.com/" target="_blank" rel="noopener">Etcembly</a> and <a href="https://labgeni.us/" target="_blank" rel="noopener">LabGenius</a> are among the AWS users already using BioNeMo for generative AI-accelerated drug discovery and development. This collaboration gives them more ways to rapidly scale up cloud computing resources for developing generative AI models trained on biomolecular data.</p>
<p>This announcement extends NVIDIA’s existing healthcare-focused offerings available on AWS — <a href="https://www.nvidia.com/en-us/clara/monai/">NVIDIA MONAI</a> for medical imaging workflows and <a href="https://www.nvidia.com/en-us/clara/parabricks/">NVIDIA Parabricks</a> for accelerated genomics.</p>
<h2><b>New to AWS: NVIDIA BioNeMo Advances Generative AI for Drug Discovery</b></h2>
<p><a href="https://www.nvidia.com/en-gb/gpu-cloud/bionemo/">BioNeMo</a> is a domain-specific framework for digital biology generative AI, including pretrained large language models (LLMs), data loaders and optimized training recipes that can help advance computer-aided drug discovery by speeding target identification, protein structure prediction and drug candidate screening.</p>
<p>Drug discovery teams can use their proprietary data to build or optimize models with BioNeMo and run them on cloud-based high performance computing clusters.</p>
<p>One of these models, ESM-2 — a powerful LLM that supports protein structure prediction —  achieves almost linear scaling on 256 NVIDIA H100 Tensor Core GPUs. Researchers can scale to 512 H100 GPUs to complete training in a few days instead of a month, the training time published in the original paper.</p>
<p>Developers can train ESM-2 at scale using checkpoints of 650 million or 3 billion parameters. Additional AI models supported in the BioNeMo training framework include small-molecule generative model MegaMolBART and protein sequence generation model ProtT5.</p>
<p>BioNeMo’s pretrained models and optimized training recipes — which are available using self-managed services like AWS ParallelCluster and Amazon ECS as well as integrated, managed services through NVIDIA DGX Cloud and Amazon SageMaker — can help R&amp;D teams build foundation models that can explore more drug candidates, optimize wet lab experimentation and find promising clinical candidates faster.</p>
<h2><b>Also Available on AWS: NVIDIA Clara for Medical Imaging and Genomics</b></h2>
<p>Project MONAI, cofounded and <a href="https://www.nvidia.com/en-us/clara/monai/">enterprise-supported by NVIDIA</a> to support medical imaging workflows, has been downloaded more than 1.8 million times and is available for deployment on AWS. Developers can harness their proprietary healthcare datasets already stored on AWS cloud resources to rapidly annotate and build AI models for medical imaging.</p>
<p>These models, trained on NVIDIA GPU-powered <a href="https://aws.amazon.com/ec2/pricing/" target="_blank" rel="noopener">Amazon EC2 instances</a>, can be used for interactive annotation and fine-tuning for segmentation, classification, registration and detection tasks in medical imaging. Developers can also harness MRI image synthesis models available in MONAI to augment training datasets.</p>
<p>To accelerate genomics pipelines, <a href="https://aws.amazon.com/marketplace/pp/prodview-apbngojlskcyq" target="_blank" rel="noopener">Parabricks</a> enables variant calling on a whole human genome in around 15 minutes, compared to a day on a CPU-only system. <a href="https://aws.amazon.com/blogs/hpc/getting-started-with-nvidia-parabricks-on-aws-batch-using-aws-cloudformation/" target="_blank" rel="noopener">On AWS</a>, developers can quickly scale up to process large amounts of genomic data across multiple GPU nodes.</p>
<p>More than a dozen <a href="https://aws.amazon.com/blogs/industries/easily-run-nvidia-parabricks-ready2run-workflows-on-amazon-omics/" target="_blank" rel="noopener">Parabricks workflows are available on</a> AWS HealthOmics as Ready2Run workflows, which enable customers to easily run pre-built pipelines.</p>
<p>Get started with <a href="https://aws.amazon.com/nvidia/hcls/" target="_blank" rel="noopener">NVIDIA Clara on AWS</a> to accelerate AI workflows for drug discovery, genomics and medical imaging.</p>
<p><i>Subscribe to </i><a href="https://www.nvidia.com/en-us/industries/healthcare-life-sciences/healthcare-news-sign-up/"><i>NVIDIA healthcare news</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/hc-corp-blog-aws23-bionemo-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/hc-corp-blog-aws23-bionemo-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA BioNeMo Enables Generative AI for Drug Discovery on AWS]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA GPUs on AWS to Offer 2x Simulation Leap in Omniverse Isaac Sim, Accelerating Smarter Robots</title>
		<link>https://blogs.nvidia.com/blog/gpu-aws-omniverse-isaac-sim-robots/</link>
		
		<dc:creator><![CDATA[Gerard Andrews]]></dc:creator>
		<pubDate>Tue, 28 Nov 2023 17:20:12 +0000</pubDate>
				<category><![CDATA[Autonomous Machines]]></category>
		<category><![CDATA[Corporate]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[NVIDIA Isaac Sim]]></category>
		<category><![CDATA[Omniverse]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68341</guid>

					<description><![CDATA[Developing more intelligent robots in the cloud is about to get a speed multiplier. NVIDIA Isaac Sim and NVIDIA L40S GPUs are coming to Amazon Web Services, enabling developers to build and deploy accelerated robotics applications in the cloud. Isaac Sim, an extensible simulator for AI-enabled robots, is built on the NVIDIA Omniverse development platform <a class="read-more" href="https://blogs.nvidia.com/blog/gpu-aws-omniverse-isaac-sim-robots/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Developing more intelligent robots in the cloud is about to get a speed multiplier.</p>
<p><a href="https://developer.nvidia.com/isaac-sim">NVIDIA Isaac Sim</a> and <a href="https://www.nvidia.com/en-us/data-center/l40s/">NVIDIA L40S GPUs</a> are coming to Amazon Web Services, enabling developers to build and deploy accelerated robotics applications in the cloud. Isaac Sim, an extensible simulator for AI-enabled robots, is built on the <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> development platform for building and connecting <a href="https://www.nvidia.com/en-us/omniverse/usd/">OpenUSD</a> applications.</p>
<p>Combining powerful AI compute with graphics and media acceleration, the L40S GPU is built to power the next generation of data center workloads. Based on the Ada Lovelace architecture, the L40S enables ultrafast real-time rendering delivering up to a 3.8x performance leap for Omniverse compared with the previous generation, boosting engineering and robotics teams.</p>
<p>The generational leap in acceleration results in 2x faster performance than the A40 GPU across a broad set of robotic simulations tasks when using Isaac Sim.</p>
<p>L40S GPUs can also be harnessed for generative AI workloads, from fine-tuning large language models within a matter of hours, to real-time inferencing for text-to-image and chat applications.</p>
<p>New Amazon Machine Images (AMIs) on the NVIDIA L40S in AWS Marketplace will enable roboticists to easily access preconfigured virtual machines to operate Isaac Sim workloads.</p>
<p>Robotics development in simulation is speeding the process of deploying applications, turbocharging industries such as <a href="https://blogs.nvidia.com/blog/isaac-jetson-robotics/">retail</a>, <a href="https://blogs.nvidia.com/blog/isaac-soft-robotics-simulation/">food processing</a>, <a href="https://blogs.nvidia.com/blog/bmw-group-nvidia-omniverse/">manufacturing</a>, logistics and more.</p>
<p>Revenue from mobile robots in warehouses worldwide is expected to explode, more than tripling from $11.6 billion in 2023 to $42.2 billion by 2030, according to ABI Research.</p>
<p>Robotics systems have played an important role across fulfillment centers to help meet the demands of online shoppers and provide a better workplace for employees. Amazon Robotics has deployed more than 750,000 robots in its warehouses around the world to improve the experience for employees supporting package fulfillment and its customers.</p>
<p>“Simulation technology plays a critical role in how we develop, test and deploy our robots.” said Brian Basile, head of virtual systems at Amazon Robotics. “At Amazon Robotics we continue to increase the scale and complexity of our simulations. With the new AWS L40S offering we will push the boundaries of simulation, rendering and model training even further.”</p>
<h2><b>Accelerated Robotics Development With Isaac Sim</b></h2>
<p>Robotics systems can demand large datasets for precision operation in deployed applications. Gathering these datasets and testing them in the real world is time-consuming, costly and impractical.</p>
<p><a href="https://blogs.nvidia.com/blog/what-is-robotics-simulation/">Robotics simulation</a> drives the training and testing of AI-based robotic applications. With <a href="https://blogs.nvidia.com/blog/what-is-synthetic-data/">synthetic data</a>, simulations are enabling virtual advances like never before. Simulations can help verify, validate and optimize robot designs, systems and their algorithms before operation. It can also be used to optimize facility designs before construction or remodeling starts for maximum efficiencies, reducing costly manufacturing change orders.</p>
<p>Isaac Sim offers access to the latest robotics simulation tools and capabilities as well as cloud access, enabling teams to collaborate more effectively. Access to the <a href="https://developer.nvidia.com/omniverse/replicator">Omniverse Replicator</a> synthetic data generation engine in Isaac Sim allows machine learning engineers to build production-ready synthetic datasets for training robust deep learning perception models.</p>
<h2><b>Customer Adoption of Isaac Sim on AWS</b></h2>
<p>AWS early adopters tapping into the Isaac Sim platform include <a href="https://blogs.nvidia.com/blog/isaac-jetson-robotics/">Amazon Robotics</a>, <a href="https://blogs.nvidia.com/blog/isaac-soft-robotics-simulation/">Soft Robotics</a> and <a href="https://www.theorystudios.com/synthetic-data">Theory Studios</a>.</p>
<p>Amazon Robotics has begun using Omniverse to build digital twins for automating, optimizing and planning its autonomous warehouses in virtual environments before deploying them into the real world.</p>
<p>Using Isaac Sim for sensor emulation, Amazon Robotics will accelerate development of its <a href="https://www.youtube.com/watch?v=LUnZXBL_lqA">Proteus autonomous mobile robot</a>, improving it to help the online retail giant efficiently manage fulfillment.</p>
<p><i>Learn more about </i><a href="https://developer.nvidia.com/isaac-sim"><i>Isaac Sim</i></a><i>, powered by </i><a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>.</p>
<p>&nbsp;</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/AWS-reinvent-robotics-blog-key-visual.png"
			type="image/png"
			width="2048"
			height="1062"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/AWS-reinvent-robotics-blog-key-visual-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA GPUs on AWS to Offer 2x Simulation Leap in Omniverse Isaac Sim, Accelerating Smarter Robots]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Powers Training for Some of the Largest Amazon Titan Foundation Models</title>
		<link>https://blogs.nvidia.com/blog/nemo-amazon-titan/</link>
		
		<dc:creator><![CDATA[Nirmala De]]></dc:creator>
		<pubDate>Tue, 28 Nov 2023 17:19:07 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cloud Services]]></category>
		<category><![CDATA[Customer Stories]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Parallel Computing]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68363</guid>

					<description><![CDATA[Everything about large language models is big — giant models train on massive datasets across thousands of NVIDIA GPUs. That can pose a lot of big challenges for companies pursuing generative AI. NVIDIA NeMo, a framework for building, customizing and running LLMs, helps overcome these challenges. A team of experienced scientists and developers at Amazon <a class="read-more" href="https://blogs.nvidia.com/blog/nemo-amazon-titan/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Everything about large language models is big — giant models train on massive datasets across thousands of NVIDIA GPUs.</p>
<p>That can pose a lot of big challenges for companies pursuing generative AI. <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/">NVIDIA NeMo</a>, a framework for building, customizing and running <a href="https://www.nvidia.com/en-us/glossary/data-science/large-language-models/">LLMs</a>, helps overcome these challenges.</p>
<p>A team of experienced scientists and developers at Amazon Web Services creating <a href="https://aws.amazon.com/bedrock/titan/">Amazon Titan</a> <a href="https://blogs.nvidia.com/blog/what-are-foundation-models/">foundation models</a> for <a href="https://aws.amazon.com/bedrock/">Amazon Bedrock</a>, a generative AI service for foundation models, has been using NVIDIA NeMo for over the past several months.</p>
<p>“One key reason for us to work with NeMo is that it is extensible, comes with optimizations that allow us to run with high GPU utilization while also enabling us to scale to larger clusters so we can train and deliver models to our customers faster,” said Leonard Lausen, a senior applied scientist at AWS.</p>
<p style="margin: 12.0pt 0in 12.0pt 0in;"><b>Think Big, Really Big</b></p>
<p>Parallelism techniques in NeMo enable efficient LLM training at scale. When coupled with the Elastic Fabric Adapter from AWS, it allowed the team to spread its LLM across many GPUs to accelerate training.</p>
<p>EFA provides AWS customers with an UltraCluster Networking infrastructure that can directly connect more than 10,000 GPUs and bypass the operating system and CPU using <a href="https://developer.nvidia.com/gpudirect">NVIDIA GPUDirect</a>.</p>
<p>The combination allowed the AWS scientists to deliver excellent model quality — something that’s not possible at scale when relying solely on data parallelism approaches.</p>
<h2><b>Framework Fits All Sizes</b></h2>
<p>“The flexibility of NeMo,” Lausen said, “allowed AWS to tailor the training software for the specifics of the new Titan model, datasets and infrastructure.”</p>
<p>AWS’s innovations include efficient streaming from Amazon Simple Storage Service (Amazon S3) to the GPU cluster. “It was easy to incorporate these improvements because NeMo builds upon popular libraries like PyTorch Lightning that standardize LLM training pipeline components,” Lausen said.</p>
<p>AWS and NVIDIA aim to infuse products like NVIDIA NeMo and services like Amazon Titan with lessons learned from their collaboration for the benefit of customers.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/Amazon-Titan-logo-KV.jpg"
			type="image/jpeg"
			width="1280"
			height="683"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/Amazon-Titan-logo-KV-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Powers Training for Some of the Largest Amazon Titan Foundation Models]]></media:title>
			<media:description type="html">Amazon Titan logo, a foundation model trained with NVIDIA NeMo</media:description>
			</media:content>
			</item>
		<item>
		<title>3D Artist Nourhan Ismail Brings Isometric Innovation ‘In the NVIDIA Studio’ With Adobe After Effects and Blender</title>
		<link>https://blogs.nvidia.com/blog/ismail-adobe-after-effects-blender/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 28 Nov 2023 14:00:44 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68394</guid>

					<description><![CDATA[This week’s talented In the NVIDIA Studio artist, Nourhan Ismail, created a literal NVIDIA studio.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. </i></p>
<p>This week’s talented <i>In the NVIDIA Studio</i> artist, Nourhan Ismail, created a literal NVIDIA studio.</p>
<p>Her piece, called <i>Creator by Day, Gamer by Night</i>, was crafted with the isometric art style and impressive graphical fidelity Ismail’s known for, rich with vibrant colors and playful details. It also captures her “work hard, play hard” mentality as a 3D artist, interior designer and game level designer.</p>
<p>The same art style is featured in the NVIDIA Studio Sessions YouTube miniseries led by Ismail, which provides step-by-step tutorials on how to create a low-poly bedroom, from inception to final render.</p>
<p><iframe title="Creating Low Poly Bedroom in Blender w/ Nourhan Ismail" width="500" height="281" src="https://www.youtube.com/embed/videoseries?list=PL4w6jm6S2lzso-UjuP-cB0Nsv9NloOThB" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Facial Animations Made Easier</b></h2>
<p>Reallusion is the maker of <a href="https://www.reallusion.com/iclone/default.html">Reallusion iClone</a>, real-time 3D animation software built to produce professional animations for films and video games.</p>
<p>To expedite character animation workflows, the company recently launched its <a href="https://mocap.reallusion.com/iclone-motion-live-mocap/accuface.html?_gl=1*1qxpyqc*_ga*MzYwNDE5ODQ4LjE3MDA2MDg2MDk.*_ga_Q3FS71VPKC*MTcwMDYwODYwOC4xLjEuMTcwMDYxMTQzNS40Mi4wLjA.">AccuFACE plug-in</a>, which accurately captures facial expressions from webcams and conventional video files, without the need for expensive, specialized equipment.</p>
<p><iframe title="AccuFACE - Video-based AI Facial Mocap | Live from Webcam or Recorded Video | iClone 8" width="500" height="281" src="https://www.youtube.com/embed/WCzHLSss_xU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>The <a href="https://developer.nvidia.com/maxine">NVIDIA Maxine</a> software development platform, the foundational technology behind the revolutionary <a href="https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/">NVIDIA Broadcast app</a>, powers this incredible capability by weighing output and analyzing facial expressions and blendshapes to predict facial mesh animations.</p>
<p>From there, the AccuFACE plug-in converts this data into facial mesh assets for creators to apply seamlessly. It also fine-tunes lip and tongue articulation using proprietary AccuLIPS technology.</p>
<p><iframe title="Advanced Facial Animations With OpenUSD and AI" width="500" height="281" src="https://www.youtube.com/embed/XwtzEU91oAI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Download the <a href="https://mocap.reallusion.com/iclone-motion-live-mocap/accuface.html">plug-in</a> today, available to creators with <a href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA RTX</a> GPUs.</p>
<h2><b>Turning Pain Into Beauty</b></h2>
<p>Ismail’s creative journey began at age four as a form of escape from the armed conflict occurring in Syria, her homeland. During that time, Ismail’s family faced many difficulties, including the loss of their home.</p>
<p>In the aftermath, she looked to her father, an accomplished artist and fashion designer, as a source of inspiration.</p>
<p>“His encouragement propelled me to showcase the pinnacle of my abilities, reminding me that art has the power to transform pain into beauty,” she said.</p>
<p>That encouragement has guided and fueled Ismail’s creative journey, eventually giving rise to her signature, single-room isometric style, an homage to the power of resilience and finding beauty in adversity.</p>
<figure id="attachment_68401" aria-describedby="caption-attachment-68401" style="width: 500px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68401" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w-500x500.png" alt="" width="500" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w-500x500.png 500w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w-400x400.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w-150x150.png 150w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w-768x768.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w-450x450.png 450w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w-215x215.png 215w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w-100x100.png 100w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w.png 1280w" sizes="(max-width: 500px) 100vw, 500px" /></a><figcaption id="caption-attachment-68401" class="wp-caption-text">Warm and homey.</figcaption></figure>
<p>“Starting with a single room, I delve into interior design, crafting spaces that reflect the comfort and joy I yearned for during challenging times,” she said. “To me, overcoming adversity proves that even from the harshest circumstances, beauty can emerge.”</p>
<p>Ismail started as a self-taught 3D artist, driven by a passion to learn the intricacies of creating digital masterpieces.</p>
<p>“Posting my works became a personal gauge of improvement — not for validation, but as a record of my learning curve,” she said.</p>
<figure id="attachment_68404" aria-describedby="caption-attachment-68404" style="width: 500px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68404" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w-500x500.png" alt="" width="500" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w-500x500.png 500w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w-400x400.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w-150x150.png 150w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w-768x768.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w-450x450.png 450w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w-215x215.png 215w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w-100x100.png 100w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w.png 1280w" sizes="(max-width: 500px) 100vw, 500px" /></a><figcaption id="caption-attachment-68404" class="wp-caption-text">Beautifully conceived, masterfully executed.</figcaption></figure>
<p>Each of Ismail’s pieces is a testament to her evolving skills, dedication and love for sharing her craft, especially with her father.</p>
<p>In fact, she dedicated her first isometric house to her father. “That was the happiest moment, to create something inspiring and make someone happy,” she said.</p>
<h2><b>Isometric Art</b></h2>
<p>Ismail first collects reference material on Adobe Behance to gain inspiration on ways to mix different art styles.</p>
<p>She then opens Blender and starts sketching in 3D. Blender Cycles’ RTX-accelerated OptiX ray tracing, powered by her <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3080-3080ti/">GeForce RTX 3080 Ti GPU</a>, ensured smooth viewport movement.</p>
<figure id="attachment_68422" aria-describedby="caption-attachment-68422" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-scaled.jpg"><img loading="lazy" decoding="async" class="wp-image-68422 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-672x378.jpg" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68422" class="wp-caption-text">A gorgeous work in progress.</figcaption></figure>
<p>While the models are still fairly rudimentary, Ismail calculates the angles that light should be coming in from.</p>
<p>“Lighting is an emotional element,” she said. “The lighting of each piece evokes different emotions and a certain idiosyncratic introspectiveness, making the experience unique to each person.”</p>
<figure id="attachment_68407" aria-describedby="caption-attachment-68407" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68407" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68407" class="wp-caption-text">The NVIDIA Studio has NVIDIA Canvas!</figcaption></figure>
<p>Her trick is to regularly switch between rich, colorful scenes and plain color models to measure the emotional weight and visual impact. She either creates the custom textures herself or downloads premade ones online when on a time crunch.</p>
<figure id="attachment_68410" aria-describedby="caption-attachment-68410" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68410" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68410" class="wp-caption-text">Ismail’s incredible detail on full display.</figcaption></figure>
<p>Then, she plays with camera angles to analyze depth shadows and lighting, setting up animations and sequence shots in Blender. There, Blender Cycles’ RTX-accelerated OptiX ray tracing delivered seamless viewport movement.</p>
<div style="width: 1280px;" class="wp-video"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video class="wp-video-shortcode" id="video-68394-1" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-nvidia-camera-animation-1280w.mp4?_=1" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-nvidia-camera-animation-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-nvidia-camera-animation-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>Final touch-ups are done in post-production in Adobe After Effects. Over 30 GPU-accelerated effects sped the process, allowed Ismail to complete the project with time to spare.</p>
<figure id="attachment_68416" aria-describedby="caption-attachment-68416" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68416" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68416" class="wp-caption-text">“Creator by Day, Gamer by Night” in dark mode.</figcaption></figure>
<p>“There will always be hard times, so never give up and keep believing in yourself,” Ismail encourages content creators.</p>
<figure id="attachment_68419" aria-describedby="caption-attachment-68419" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68419" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w-672x252.png" alt="" width="672" height="252" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w-672x252.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w-400x150.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w-768x288.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w-842x316.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w-406x152.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w-188x71.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68419" class="wp-caption-text">Digital 3D artist Nourhan Ismail.</figcaption></figure>
<p>Check out Ismail’s <a href="https://www.instagram.com/noah.pabllooll/">Instagram</a> for more spectacular isometric art.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>Twitter</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-nvidia-camera-animation-1280w.mp4" length="1210576" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/nv-blog-header-preview-1280x680-3.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/nv-blog-header-preview-1280x680-3-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[3D Artist Nourhan Ismail Brings Isometric Innovation ‘In the NVIDIA Studio’ With Adobe After Effects and Blender]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Medical Imaging AI Made Easier: NVIDIA Offers MONAI as Hosted Cloud Service</title>
		<link>https://blogs.nvidia.com/blog/monai-cloud-apis-rsna/</link>
		
		<dc:creator><![CDATA[Prerna Dogra]]></dc:creator>
		<pubDate>Sun, 26 Nov 2023 14:00:26 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cloud Services]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68260</guid>

					<description><![CDATA[NVIDIA today launched a cloud service for medical imaging AI to further streamline and accelerate the creation of ground-truth data and training of specialized AI models through fully managed, cloud-based application programming interfaces. NVIDIA MONAI cloud APIs — announced at the annual meeting of RSNA, the Radiological Society of North America, taking place this week <a class="read-more" href="https://blogs.nvidia.com/blog/monai-cloud-apis-rsna/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>NVIDIA today launched a cloud service for medical imaging AI to further streamline and accelerate the creation of ground-truth data and training of specialized AI models through fully managed, cloud-based application programming interfaces.</p>
<p><a href="https://www.nvidia.com/en-us/clara/monai/">NVIDIA MONAI</a> cloud APIs — announced at the annual meeting of RSNA, the Radiological Society of North America, taking place this week in Chicago — provide an expedited path for developers and platform providers to integrate AI into their medical imaging offerings using pretrained foundation models and AI workflows for enterprises. The APIs are built on the open-source MONAI project founded by NVIDIA and King’s College London.</p>
<p>Medical imaging is critical across healthcare, making up approximately <a href="https://arxiv.org/pdf/2008.09104.pdf" target="_blank" rel="noopener">90% of healthcare data</a>. It’s used by radiologists and clinicians to do screening, diagnosis and intervention, by biopharma researchers to evaluate how clinical trial patients respond to new drugs and by medical device makers to provide real-time decision support.</p>
<p>The scale of work across each of these areas requires a medical imaging-specific AI factory — an enterprise-grade platform that delivers large-scale data management, creates ground-truth annotations, accelerates model development and establishes seamless AI application deployment.</p>
<p>With NVIDIA MONAI cloud APIs, solution providers can more easily integrate AI into their medical imaging platforms, enabling them to provide supercharged tools for radiologists, researchers and clinical trial teams to build domain-specialized AI factories. The APIs are <a href="https://developer.nvidia.com/nvidia-monai-cloud-api-early-access-program">available in early access</a> through the <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a> AI supercomputing service.</p>
<p>The NVIDIA MONAI cloud API is integrated into Flywheel, a leading medical imaging data and AI platform that supports end-to-end workflows for AI development. Developers at medical image annotation companies including <a href="https://redbrickai.com/" target="_blank" rel="noopener">RedBrick AI</a> and at machine learning operations (MLOps) platform providers including <a href="https://www.dataiku.com/" target="_blank" rel="noopener">Dataiku</a> are poised to integrate NVIDIA MONAI cloud APIs into their offerings.</p>
<h2><b>Easy-to-Deploy Annotation and Training for Medical Imaging</b></h2>
<p>Building efficient and cost-effective AI solutions requires a robust, domain-specialized development foundation that includes full-stack optimizations for software, scalable multi-node systems and state-of-the-art research. It also requires high-quality ground-truth data — which can be arduous and time-consuming to gather, particularly for 3D medical images that require a high level of expertise to annotate.</p>
<p>NVIDIA MONAI cloud APIs feature interactive annotation powered by the VISTA-3D (Vision Imaging Segmentation and Annotation) foundation model. It’s purpose-built for continuous learning, a capability that improves AI model performance based on user feedback and new data.</p>
<p>Trained on a dataset of annotated images from 3D CT scans from more than 4,000 patients, spanning various diseases and parts of the body, VISTA-3D accelerates the creation of 3D segmentation masks for medical image analysis. With continuous learning, the AI model’s annotation quality improves over time.</p>
<p>To further accelerate AI training, this release includes APIs that make it seamless to build custom models based on MONAI pretrained models. NVIDIA MONAI cloud APIs also include Auto3DSeg, which automates hyperparameter tuning and AI model selection for a given 3D segmentation task, simplifying the model development process.</p>
<p>NVIDIA researchers recently won four challenges at the MICCAI medical imaging conference using Auto3DSeg. These included AI models to analyze 3D CT scans of the kidneys and heart, brain MRIs and 3D ultrasounds of the heart.</p>
<h2><b>Solutions Providers, Platform Builders Embrace NVIDIA MONAI Cloud APIs</b></h2>
<p>Medical imaging solution providers and machine learning platforms are using NVIDIA MONAI cloud APIs to deliver critically valuable AI insights to accelerate their customers’ work.</p>
<p>Flywheel has integrated MONAI through <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> and is now offering NVIDIA MONAI cloud APIs to accelerate medical image curation, labeling analysis and training. The Minneapolis-based company’s centralized, cloud-based platform powers biopharma companies, life science organizations, healthcare providers and academic medical centers to identify, curate and train medical imaging data for the development of trustworthy AI.</p>
<p>“NVIDIA MONAI cloud APIs lower the cost of building high-quality AI models for radiology, disease research and the evaluation of clinical trial data,” said Dan Marcus, chief scientific officer at Flywheel. “With the addition of cloud APIs for interactive annotation and automated segmentation, customers of our medical imaging AI platform can accelerate AI model development to more quickly deliver innovative solutions.”</p>
<p>Annotation and viewer solution providers, including Redbrick AI, <a href="https://radicalimaging.com/" target="_blank" rel="noopener">Radical Imaging</a>, <a href="https://www.v7labs.com/" target="_blank" rel="noopener">V7 Labs</a> and <a href="https://centaurlabs.com/" target="_blank" rel="noopener">Centaur Labs</a>, will also use NVIDIA MONAI cloud APIs to bring AI-assisted annotation and training capabilities to market faster, without having to host and manage the AI infrastructure on their own.</p>
<p>RedBrick AI is integrating the VISTA-3D model available through NVIDIA MONAI cloud APIs to deliver interactive cloud annotation for its medical device customers that support distributed teams of clinicians.</p>
<p>“VISTA-3D allows our clients to rapidly build models across different modalities and conditions,” said Shivam Sharma, CEO of RedBrick AI. “The foundation model is generalizable, making it easy to fine-tune for various clinical applications with accurate, reliable segmentation results.”</p>
<p>To streamline enterprise AI model development, MLOps platform builders including Dataiku, ClearML and Weight &amp; Biases are also investigating the use of NVIDIA MONAI cloud APIs.</p>
<p>Dataiku plans to integrate NVIDIA MONAI cloud APIs to further simplify AI model creation for medical imaging applications.</p>
<p>“With NVIDIA MONAI cloud APIs, Dataiku users would be able to easily use Auto3DSeg, a low-code option to accelerate the development of state-of-the-art segmentation models, through Dataiku’s web interface connected to an NVIDIA-hosted, GPU-accelerated service,” said Kelci Miclaus, global head of AI health and life sciences solutions at Dataiku. “This democratizes AI in biomedical imaging by extending the power to create and apply AI-driven workflows to both data and domain experts.”</p>
<p>Join the medical imaging innovators accelerating AI development with NVIDIA MONAI cloud APIs by signing up for <a href="https://developer.nvidia.com/nvidia-monai-cloud-api-early-access-program/join">early access</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/hc-corp-blog-monai-services-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/hc-corp-blog-monai-services-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Medical Imaging AI Made Easier: NVIDIA Offers MONAI as Hosted Cloud Service]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Hungry for Gaming: 18 New Games to Join GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/hungry-for-gaming-18-new-games-to-join-geforce-now/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 23 Nov 2023 14:00:44 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68348</guid>

					<description><![CDATA[GeForce NOW is bringing 18 new games to the cloud this week, part of a gratitude-filled GFN Thursday. A collaboration between Chromebook Plus, CD PROJEKT RED and GeForce NOW brought an immersive 3D activation to Times Square over the weekend, containing a hidden Easter egg for Cyberpunk 2077 players. Plus, this holiday season, give the <a class="read-more" href="https://blogs.nvidia.com/blog/hungry-for-gaming-18-new-games-to-join-geforce-now/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> is bringing 18 new games to the cloud this week, part of a gratitude-filled GFN Thursday.</p>
<p>A collaboration between Chromebook Plus, CD PROJEKT RED and GeForce NOW brought an immersive 3D activation to Times Square over the weekend, containing a hidden Easter egg for <i>Cyberpunk 2077</i> players.</p>
<p>Plus, this holiday season, give the gift of high-performance cloud gaming with <a href="https://blogs.nvidia.com/blog/geforce-now-thursday-nov-16/">a free, three-month PC Game Pass subscription</a> included with a six-month GeForce NOW <a href="https://www.nvidia.com/en-us/geforce-now/memberships/">Ultimate membership</a>.</p>
<h2><b>Eye Spy</b></h2>
<figure id="attachment_68356" aria-describedby="caption-attachment-68356" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-68356" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-672x378.png" alt="Chromebook Plus activation with GeForce NOW and Cyberpunk, Times Square" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-1280x720.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68356" class="wp-caption-text"><em>Crack the code now with Chromebook Plus, GeForce NOW and “Cyberpunk 2077.”</em></figcaption></figure>
<p>Times Square was transformed into a futuristic dystopia last weekend by a stunning 3D <i>Cyberpunk 2077</i> activation. The immersive display showcased the power of GeForce NOW on a Chromebook Plus, enabling gamers to stream thousands of titles from popular digital gaming stores from the cloud, right out of the box.</p>
<p><iframe loading="lazy" title="Chromebook Plus presents Cyberpunk 2077 x GeForce NOW" width="500" height="281" src="https://www.youtube.com/embed/G_oqD3ytjVU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Long-time <i>Cyberpunk 2077 </i>fans were also challenged to try their hand at spotting a code hidden in the activation — the latest hint in a long line of clues needed to solve a riddle that has had players guessing for the past three years.</p>
<p>Chromebook owners with an <a href="http://geforcenow.com">Ultimate or Priority membership</a> can explore <i>Cyberpunk 2077</i>’s Night City with <a href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA RTX ON</a> for the most immersive gaming experience, including the “Phantom Liberty” expansion and 2.0 update. Google and NVIDIA are offering all Chromebook owners <a href="https://www.google.com/intl/en_us/chromebook/perks/">three free months of a GeForce NOW Priority membership</a> to get gamers started.</p>
<p>And those interested in leveling up to the highest-performing tier can get three free months of a GeForce NOW Ultimate membership with the purchase of a Cloud Gaming Chromebook. Find more details on how to redeem the offer on the <a href="https://www.google.com/intl/en_us/chromebook/perks/">Chromebook Perks page</a>.</p>
<h2><b>Grateful for Great Games</b></h2>
<figure id="attachment_68353" aria-describedby="caption-attachment-68353" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-68353" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-672x378.jpg" alt="Chivalry 2 on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68353" class="wp-caption-text"><em>That’s one way to carve a turkey.</em></figcaption></figure>
<p>Get the weekend started with the new weekly games list:<i></i></p>
<ul>
<li><i>Breathedge</i> (<a href="https://www.xbox.com/games/store/breathedge/9PHJSGJNX37S?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Bridge Constructor: The Walking Dead </i>(<a href="https://www.xbox.com/games/store/bridge-constructor-the-walking-dead/9P1LWFXNQVQ0?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Bus Simulator 21 </i>(<a href="https://www.xbox.com/games/store/bus-simulator-21-next-stop-gold-edition/9PFBJC0VVTMB?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Chivalry 2 </i>(<a href="https://www.xbox.com/games/store/chivalry-2/9N7CJX93ZGWN?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Dungeons 4</i> (<a href="https://www.epicgames.com/store/p/dungeons-4-595454?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Hexarchy</i> (<a href="https://store.steampowered.com/app/1356810?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Hearts of Iron IV</i> (<a href="https://www.xbox.com/games/store/hearts-of-iron-iv/9NF6WPNS1S73?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>I Am Future </i>(<a href="https://www.epicgames.com/store/p/i-am-future-cozy-apocalypse-survival-6b452c?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Imagine Earth </i>(<a href="https://www.xbox.com/games/store/imagine-earth/9NPLW3TFSVH0?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>The Invincible </i>(<a href="https://www.epicgames.com/store/p/the-invincible?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Land of the Vikings </i>(<a href="https://store.steampowered.com/app/1981570?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Saints Row IV: Re-Elected </i>(<a href="https://www.xbox.com/games/store/saints-row-iv-re-elected/9NFVLZQDZHKW?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>SHENZHEN I/O </i>(<a href="https://www.xbox.com/games/store/shenzhen-io/9P1JHJ127HR4?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Supraland: Six Inches Under </i>(<a href="https://www.xbox.com/games/store/supraland-six-inches-under/9P5RS5065835?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>The Surge 2</i> (<a href="https://www.xbox.com/games/store/the-surge-2-premium-edition/9NK73WHQZKDS?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Thymesia </i>(<a href="https://www.xbox.com/games/store/thymesia/9N68F8TM7TKW?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Tropico 6</i> (<a href="https://www.xbox.com/games/store/tropico-6/9N2VDJVMFKQ9?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>West of Dead</i> (<a href="https://www.xbox.com/games/store/west-of-dead-path-of-the-crow-edition/9NSXQS17N797?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
</ul>
<p>What are you looking forward to streaming? Let us know on <a href="https://www.twitter.com/nvidiagfn">Twitter</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">tell us a device you have that you&#39;re grateful for <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/2601.png" alt="☁" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>bonus points for pictures</p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1727371365789934020?ref_src=twsrc%5Etfw">November 22, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/gfn-thursday-11-23-nv-blog-1280x680-no-cta.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/gfn-thursday-11-23-nv-blog-1280x680-no-cta-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Hungry for Gaming: 18 New Games to Join GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Teenage Dream: Aspiring Computer Science Major Experiences NVIDIA Life With Make-A-Wish Visit</title>
		<link>https://blogs.nvidia.com/blog/nvidia-life-make-a-wish/</link>
		
		<dc:creator><![CDATA[Samantha Zee]]></dc:creator>
		<pubDate>Wed, 22 Nov 2023 16:00:26 +0000</pubDate>
				<category><![CDATA[NVIDIA Life]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68301</guid>

					<description><![CDATA[A calendar packed with meetings, calls and lab visits may sound like a typical workday for many — but for Luca Lofranco, whose greatest wish was to experience what it’s like to work at NVIDIA, it was a dream come true. Eighteen-year-old Lofranco recently traveled from his hometown near Toronto, Canada, to spend the day <a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-life-make-a-wish/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>A calendar packed with meetings, calls and lab visits may sound like a typical workday for many — but for Luca Lofranco, whose greatest wish was to experience what it’s like to work at NVIDIA, it was a dream come true.</p>
<p>Eighteen-year-old Lofranco recently traveled from his hometown near Toronto, Canada, to spend the day at our Santa Clara campus, supported by Make-A-Wish, a nonprofit that grants life-changing wishes for children with critical illnesses. The wish from Lofranco, who has Hodgkin’s lymphoma, was the fifth NVIDIA has been a part of in the last decade.</p>
<p>The NVIDIA team kept the day’s agenda a secret — surprising Lofranco with tours of the demo room and robotics lab, a chat with the University Recruiting team, a ride in a self-driving car and a video call with NVIDIA founder and CEO Jensen Huang. An aspiring computer science major, Lofranco was stoked for it all because, as his mom Cassandra shared, “NVIDIA is his Disneyland.”</p>
<figure id="attachment_68318" aria-describedby="caption-attachment-68318" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-68318 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-1536x1025.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-322x215.jpg 322w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-1280x854.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68318" class="wp-caption-text">NVIDIA’s auto garage</figcaption></figure>
<h2><b>A Long-Time NVIDIA Fan </b></h2>
<p>After attending his first computer science summer camp when he was eight, Lofranco learned 3D modeling in Autodesk Maya, programming in Python, as well as 3D printing. His budding interest in tech grew and, soon enough, he was building his own gaming rigs.</p>
<p>NVIDIA quickly became Lofranco’s favorite tech company, he said, so much so that he carved the company logo out of a piece of wood using a computer numerical control machine.</p>
<p>For gaming, he enjoys using NVIDIA GeForce RTX 3070 and GeForce GTX 1080 Ti GPUs. But Lofranco’s ultimate draw to NVIDIA wasn’t its products but its culture.</p>
<p>“Everyone is driven to see the same outcome and comes together to make it happen,” he said. “Everything is designed for collaboration.”</p>
<figure id="attachment_68324" aria-describedby="caption-attachment-68324" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-68324 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-672x409.jpg" alt="" width="672" height="409" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-672x409.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-400x244.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-768x468.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-1536x935.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-739x450.jpg 739w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-353x215.jpg 353w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-164x100.jpg 164w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-1280x779.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68324" class="wp-caption-text">Lofranco in NVIDIA gear</figcaption></figure>
<h2><b>A VIP Experience</b></h2>
<p>Ahead of Lofranco’s visit, the NVIDIA team sent him a box of swag — including a hoodie, a hat and a custom NVIDIA badge.</p>
<p>Once he arrived on campus, NVIDIA volunteers welcomed and whisked Lofranco off on a campus tour, followed by a meeting with the solutions architect team, which includes NVIDIANs focused on healthcare, auto, AI, cloud service providers and <a href="https://blogs.nvidia.com/blog/what-are-large-language-models-used-for/">large language models</a>.</p>
<p><img loading="lazy" decoding="async" class="aligncenter wp-image-68327 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-667x500.jpg" alt="" width="667" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-667x500.jpg 667w, https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-400x300.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-768x576.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-1536x1152.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-600x450.jpg 600w, https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-287x215.jpg 287w, https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-133x100.jpg 133w, https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-1280x960.jpg 1280w" sizes="(max-width: 667px) 100vw, 667px" /></p>
<p>Next, a visit to the robotics lab helped satisfy Lofranco’s “maker” curiosity. He saw an <a href="https://www.nvidia.com/en-sg/data-center/dgx-platform/">NVIDIA DGX Station</a> as well as test robots for developing the <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/">NVIDIA Jetson</a> edge AI platform, and was soon directing a robot arm to stack colored blocks.</p>
<p>After learning that Lofranco’s favorite foods include lobster, tiramisu and Kit Kat candy bars, the café team prepared a special menu for him and all employees in the office that day. Everyone enjoyed a lobster roll pop-up station in the campus park and tiramisu-flavored ice cream with assorted toppings, including Kit Kat pieces.</p>
<figure id="attachment_68330" aria-describedby="caption-attachment-68330" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-68330 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-1536x1025.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-322x215.jpg 322w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-1280x854.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68330" class="wp-caption-text">Lofranco checks out NVIDIA GPUs in the company’s demo room</figcaption></figure>
<h2><b>Innovators</b></h2>
<p>On a visit to the demo room at NVIDIA’s Santa Clara site, Lofranco and his father revealed that they tinker with innovations themselves. They programmed their water heater in the family hot tub to maintain a comfortable temperature and decrease the time needed to warm it — all thanks to Python code and Raspberry Pi experimentation.</p>
<p>With so much to soak in, Lofranco described his wish day at NVIDIA as “unfathomable” — and that was before his video call with Huang, which stretched from a planned quarter hour to 45 minutes.</p>
<p>After a conversation that spanned NVIDIA’s origins, many near failures and innovation, Huang gifted Lofranco a <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4090/">GeForce RTX 4090</a> Founders Edition GPU and shared some sound advice: “Keep playing video games — but make sure to prioritize your homework.”</p>
<figure id="attachment_68333" aria-describedby="caption-attachment-68333" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-68333 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-1536x1025.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-322x215.jpg 322w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-1280x854.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68333" class="wp-caption-text">Lofranco with the surprise gift from Huang following their chat</figcaption></figure>
<p>Capping a packed day of fun-filled support from nearly 50 NVIDIANs was a visit to the auto lab and a spin in one of NVIDIA’s self-driving test cars.</p>
<p>How was it all? “Breathtaking,” said Lofranco, who learned firsthand from Huang that while NVIDIA has evolved from being the underdog to a leading tech company, it still feels “like a family.”</p>
<p><i>Learn more about </i><a href="https://www.nvidia.com/en-us/about-nvidia/careers/life-at-nvidia/"><i>NVIDIA life, culture and careers</i></a><i>. </i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08087-Edit-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1366"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08087-Edit-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Teenage Dream: Aspiring Computer Science Major Experiences NVIDIA Life With Make-A-Wish Visit]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI-Powered Tech Company Helps Grocers Start Afresh in Supply Chain Management</title>
		<link>https://blogs.nvidia.com/blog/ai-afresh-grocer/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Wed, 22 Nov 2023 14:00:29 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[The AI Podcast]]></category>
		<category><![CDATA[Agriculture and Food]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Climate]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68338</guid>

					<description><![CDATA[Talk about going after low-hanging fruit. Afresh is an AI startup that helps grocery stores and retailers reduce food waste by making supply chains more efficient. In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with the company’s cofounder and president, Nathan Fenner, about its mission, offerings and the greater challenge of <a class="read-more" href="https://blogs.nvidia.com/blog/ai-afresh-grocer/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Talk about going after low-hanging fruit. Afresh is an AI startup that helps grocery stores and retailers reduce food waste by making supply chains more efficient.</p>
<p>In the latest episode of NVIDIA’s <a href="https://blogs.nvidia.com/ai-podcast/">AI Podcast</a>, host Noah Kravitz spoke with the company’s cofounder and president, Nathan Fenner, about its mission, offerings and the greater challenge of eliminating food waste.</p>
<p>Most supply chain and inventory management offerings targeting grocers and retailers are outdated. Fenner and his team noticed those solutions, built for the nonperishable side of the business, didn’t work as well on the fresh side — creating enormous amounts of food waste and causing billions in lost profits.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1671268662%3Fsecret_token%3Ds-75QpZNVnAWT&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="AI-Powered Tech Company Helps Grocers Start Afresh in Supply Chain Management" href="https://soundcloud.com/theaipodcast/nathan-fenner-afresh/s-75QpZNVnAWT" target="_blank" rel="noopener">AI-Powered Tech Company Helps Grocers Start Afresh in Supply Chain Management</a></div>
<p>The team first sought to solve the store-replenishment challenge by developing a platform to help grocers decide how much fresh produce to order to optimize costs while meeting demand.</p>
<p>They created machine learning and AI models that could effectively use the data generated by fresh produce, which is messier than data generated by nonperishable goods because of factors like time to decay, greater demand fluctuation and unreliability caused by lack of barcodes, leading to incorrect scans at self-checkout registers.</p>
<p>The result was a fully integrated, machine learning-based platform that helps grocers make informed decisions at each node of the operations process.</p>
<p>The company also recently launched inventory management software that allows grocers to save time and increase data accuracy by intelligently tracking inventory. That information can be inputted back into the platform’s ordering solution, further refining the accuracy of inventory data.</p>
<p>It’s all part of Afresh’s greater mission to tackle climate change.</p>
<p>“The most impactful thing we can do is reduce food waste to mitigate climate change,” Fenner said. “It’s really one of the key things that brought me into the business: I think I’ve always had a keen eye to work in the climate space. It’s really motivating for a lot of our team, and it’s a key part of our mission.”</p>
<h2><b>Subscribe to the AI Podcast: Now Available on Amazon Music</b></h2>
<p><a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">The AI Podcast is now available through Amazon Music</a>.</p>
<p>In addition, get the <a href="https://blogs.nvidia.com/ai-podcast/">AI Podcast</a> through <a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439">iTunes</a>, <a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjI2NDAzNDEzMy9zb3VuZHMucnNz">Google Podcasts</a>, <a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm">Google Play</a>, <a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us">Castbox</a>, DoggCatcher, <a href="https://overcast.fm/itunes1186480811/the-ai-podcast">Overcast</a>, <a href="https://player.fm/series/the-ai-podcast">PlayerFM</a>, Pocket Casts, <a href="http://www.podbay.fm/show/1186480811">Podbay</a>, <a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast">PodBean</a>, PodCruncher, PodKicker, <a href="https://soundcloud.com/theaipodcast">Soundcloud</a>, <a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L">Spotify</a>, <a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr">Stitcher</a> and <a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/">TuneIn</a>.</p>
<p>Make the AI Podcast better. Have a few minutes to spare? Fill out <a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short">this listener survey</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast.jpg"
			type="image/jpeg"
			width="1400"
			height="931"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI-Powered Tech Company Helps Grocers Start Afresh in Supply Chain Management]]></media:title>
			<media:description type="html">NVIDIA AI Podcast</media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Collaborates With Genentech to Accelerate Drug Discovery Using Generative AI</title>
		<link>https://blogs.nvidia.com/blog/genentech-drug-discovery-bionemo/</link>
		
		<dc:creator><![CDATA[Rory Kelleher]]></dc:creator>
		<pubDate>Tue, 21 Nov 2023 14:00:25 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68193</guid>

					<description><![CDATA[Genentech, a member of the Roche Group, is pioneering the use of generative AI to discover and develop new therapeutics and deliver treatments to patients more efficiently. A new collaboration between Genentech, the biotechnology pioneer, and NVIDIA aims to transform the discovery and development of new medicines by bringing together experts from each company to <a class="read-more" href="https://blogs.nvidia.com/blog/genentech-drug-discovery-bionemo/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Genentech, a member of the Roche Group, is pioneering the use of <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/">generative AI</a> to discover and develop new therapeutics and deliver treatments to patients more efficiently.</p>
<p>A new <a href="https://www.gene.com/media/press-releases/15010/2023-11-21/genentech-and-nvidia-enter-into-strategi" target="_blank" rel="noopener">collaboration between Genentech</a>, the biotechnology pioneer, and NVIDIA aims to transform the discovery and development of new medicines by bringing together experts from each company to optimize and accelerate Genentech’s proprietary algorithms.</p>
<p>NVIDIA will work with Genentech to accelerate these models on <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a>, which provides dedicated instances of AI supercomputing and software hosted by NVIDIA cloud service provider partners.</p>
<p>Genentech plans to use <a href="https://www.nvidia.com/en-us/gpu-cloud/bionemo/">NVIDIA BioNeMo</a>, which enables biotech companies to customize models at scale, and integrate BioNeMo cloud application programming interfaces directly into computational drug discovery workflows.</p>
<p>BioNeMo, now generally available as a training service, is a domain-specific platform that simplifies, accelerates and scales generative AI applications for computational drug discovery. It allows researchers to <a href="https://blogs.nvidia.com/blog/what-is-a-pretrained-ai-model/">pretrain</a> or fine-tune state-of-the-art models on DGX Cloud.</p>
<p>The collaboration will initially focus on optimizing Genentech’s drug discovery AI models in its “lab in a loop” framework. The goal: To allow its researchers to understand complex biomolecular patterns and relationships to truly disrupt drug development and improve the success rate of R&amp;D, and to empower scientists to deliver multiplicative, rather than linear or additive, benefits for patients and the broader healthcare ecosystem.</p>
<p>“Our collaboration with NVIDIA builds on our long history of successfully inventing and deploying technology in ways that were not initially apparent to others,” said Aviv Regev, executive vice president and head of Genentech Research &amp; Early Development (gRED). “We were the first biotech company to leverage molecular biology for drug discovery and development, which changed the world. We pioneered antibody therapeutics that became the paradigm of treatment. And now, we have brought AI, the lab and the clinic together to uncover otherwise inaccessible patterns in vast quantities of data, and to design experiments to test those patterns. Collaborating with NVIDIA, and introducing generative AI, has the power to turbocharge the discovery and design of therapeutics that will improve the lives of patients across the world.”</p>
<p><iframe loading="lazy" title="Genentech and NVIDIA Revolutionize Drug Discovery with Generative AI in Lab in the Loop" width="500" height="281" src="https://www.youtube.com/embed/-Ijg2g8AsjE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Streamlining Drug Discovery With Computation  </b></h2>
<p>Drug discovery and development is currently a lengthy, complicated and costly process. Drug targets for novel medicines are difficult to predict, as is successfully developing a molecule as a potential therapeutic. AI can play a transformational role because generative and other AI models can help scientists rapidly identify potential drug molecules and interactions by training on large-scale datasets.</p>
<p>For Genentech, using AI helps bridge the gap between lab experiments and computational algorithms.</p>
<p>The company’s R&amp;D group, gRED, has already done significant work using AI — across multiple modalities — to discover and develop novel therapeutics while learning more about the building blocks of biology and diseases.</p>
<p>Teams from Genentech and NVIDIA will now work together to optimize Genentech’s custom-developed models to shorten this time-consuming process of drug discovery and development and lead to greater success.</p>
<h2><b>Putting AI in a Loop</b></h2>
<p>Genentech’s “lab in a loop” is an iterative framework for generating and exploring molecular designs with predicted properties. It aims to use experimental data to inform generative computational models and better optimize future molecular designs. NVIDIA will help Genentech optimize its framework by accelerating training and inference of Genentech’s drug discovery models.</p>
<p>Through this collaboration, NVIDIA AI experts will gain insights into AI-related challenges in drug discovery and development. NVIDIA plans to use these insights to improve its BioNeMo platform and others to further accommodate the requirements of models used by the biotech industry.</p>
<p>“AI can play a transformational role in accelerating drug discovery and development — as it has across many parts of healthcare and life sciences,” said Kimberly Powell, vice president of healthcare at NVIDIA. “Together, NVIDIA and Genentech are unlocking scientific innovation by developing and implementing AI models and algorithms that enable us to rapidly iterate and unearth insights.”</p>
<p><a href="https://www.nvidia.com/en-us/industries/healthcare-life-sciences/healthcare-news-sign-up/"><i>Subscribe to NVIDIA healthcare news</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/hc-corp-blog-genentech-1280x680-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/hc-corp-blog-genentech-1280x680-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Collaborates With Genentech to Accelerate Drug Discovery Using Generative AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>3D Artist Cooks Up Stunningly Photorealistic Food Renders This Week ‘In the NVIDIA Studio’</title>
		<link>https://blogs.nvidia.com/blog/carpenen-adobe-substance-3d-painter-lightroom-blender/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 21 Nov 2023 14:00:04 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68261</guid>

					<description><![CDATA[It’s the season of gratitude: that time of year to give thanks for the people and small moments that make life so special.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. </i></p>
<p>It’s the season of gratitude: that time of year to give thanks for the people and small moments that make life so special.</p>
<p>This week’s featured <i>In the NVIDIA Studio</i> artist, Ravissen Carpenen, is serving up a feast of mouthwateringly photorealistic 3D food renders to the dinner table.</p>
<p>His delectable time-lapse videos are featured on his YouTube channel, <a href="https://www.youtube.com/channel/UC9Vs9hDHCD1pD85uCehjlAg">CG Realism</a> — presented with a side of upbeat music and a pinch of style.</p>
<p>Carpenen was one of several contributors to the food-themed Studio Standout video contest, alongside Roger Roque (<a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbFhGU0p5aEVnT2VHSU5IaHhuWDB3YURySWhtQXxBQ3Jtc0tsT196Ui14MWhNeHpTTmRzX2pNTFRWdlRld1VOVDNVaTQzbTljUV9xV1lWWXZDcW5kMVctcC1wWW9PVkloNjVpMXBLTHloUHVIa1FIZzZvNmZPbkdXWV9YVVFBUXExYXBWNU5yS0Y0aUNCeWFKREw5RQ&amp;q=https%3A%2F%2Fwww.instagram.com%2Frogerroqueid%2F&amp;v=P1BIBbjntsM">@rogerroqueid</a>), Nicole Morena (<a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbmtuWHZKam1CUHB1VUd3aHBBZzRwZnhRTHZrQXxBQ3Jtc0tuX1NHQ3ZwZGpVcVZiS1RfMjRzR3VBd3Z5OTZIWnJPOVVKcS1UWTBLUFBtcENxYmdURy1QcjUzNU92aEFlMTJlZExuNjJINzBOaDJsNXZOLVB6cWt3OGpjRlNaQUZ5eDZHSnVxQjVjbEJUeXp1N0RyWQ&amp;q=https%3A%2F%2Fwww.instagram.com%2Fnicky.blender%2F&amp;v=P1BIBbjntsM">@nicky.blender</a>), Heloise Cart (<a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqa0l4ajNyVDBqV0Fta0xOOGhmXzZyNXJaM204Z3xBQ3Jtc0tsdUl4ZW5pZEdNMTUtblhkdW5QcjZpOTZvQkszMGVDdWlGM3Jva2p1eTlERkw5V0p2VjJBREVaSkRJVS1DQ1dWZ1o5Z0JyM3NZbFotUUFnRV9iYjZqYlhXR29zX0F5b3VQUHhJdzdQM25WQ1M0S2EzSQ&amp;q=https%3A%2F%2Fwww.instagram.com%2Fisoheell%2F&amp;v=P1BIBbjntsM">@isoheell</a>) and Kris Theroin (<a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbnRlYnpmR2pIY0pXQXp4Q2hieERxZm90dldyUXxBQ3Jtc0ttODhUdFRJRkJUOUVxRzE5SHE4cGM4dTVRa1FCX1JhYktoaUp6NGxwdE55QWc0MEpyQUdzbVFIN2lMX215WEdacEZ3OUphRDVJSkdpMmNjZlNGT3JEMC12MGJwZ3lyR0ptSFFOUXVOQ016M2NCbHlBYw&amp;q=https%3A%2F%2Fwww.instagram.com%2Fkristheorin%2F&amp;v=P1BIBbjntsM">@kristheorin</a>).</p>
<p><iframe loading="lazy" title="Try Not To Get Hungry Challenge | NVIDIA Studio Standouts" width="500" height="281" src="https://www.youtube.com/embed/P1BIBbjntsM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Finally, livestreamers using OBS Studio — a free, open-source software for video recording and livestreaming — can download the latest update with HDR10 capture support, WHIP and WebRTC output and more. Learn more <a href="https://github.com/obsproject/obs-studio/releases">details</a>.</p>
<h2><b>All About That Baste</b></h2>
<p>Carpenen’s wife, a pastry chef, inspired his photorealistic, food-centered works.</p>
<p>“My aim, one day, is to be able to create ultra-realistic renders that will be used in film and movies,” he said.</p>
<p><iframe loading="lazy" title="Happy Meal - Blender Timelapse" width="500" height="281" src="https://www.youtube.com/embed/vwA5CaYVPQQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>His projects begin with online research and reference gathering, mainly on Pinterest and Behance, which he then compiles into mood boards using the stand-alone image tracking program PureRef.</p>
<p>Before any modeling takes place, Carpenen lights the scene — but without textures.</p>
<p>“This is to tell the story of the artwork, as light intends to give artwork an emotional flow, alongside as well as color and materials,” he said.</p>
<p>Carpenen initially sculpts his models in ZBrush using customizable brushes to shape, texture and paint his virtual clay in a real-time environment with instant feedback.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-68261-2" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/Turkey-Blender-Timelapse-video.mp4?_=2" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/Turkey-Blender-Timelapse-video.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/11/Turkey-Blender-Timelapse-video.mp4</a></video></div>
<p>&nbsp;</p>
<p>He then browses the Quixel Megascans library for models that can further add realism, such as garlic cloves and rosemary garnishes for his turkey project.</p>
<h2><b>Rare-in for More</b></h2>
<p>Carpenen uses Marmoset Toolbag’s ambient occlusion, curvature, normal and thickness features to bake the ZBrush meshes from high-poly to low-poly models as 32-bit textures.</p>
<p><iframe loading="lazy" title="Medium Cooked Steak - 3D Timelapse" width="500" height="281" src="https://www.youtube.com/embed/c2NOK9eDRDA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>The process saves memory space, minimizing lag time while allowing greater flexibility in the modeling stage.</p>
<figure id="attachment_68271" aria-describedby="caption-attachment-68271" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68271" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w-672x372.png" alt="" width="672" height="372" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w-672x372.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w-400x221.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w-768x425.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w-814x450.png 814w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w-389x215.png 389w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w-181x100.png 181w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68271" class="wp-caption-text">Bake ZBrush meshes from high-poly to low-poly models as 32-bit textures in Marmoset Toolbag.</figcaption></figure>
<p>Carpenen’s GeForce RTX 3070 GPU-powered system with RTX acceleration instantly optimized his meshes. RTX-accelerated ray tracing and OptiX AI-powered denoising also enabled smoother viewport movement.</p>
<h2><b>Baking a Berry Good Pie</b></h2>
<p>Once the renders are ready, Carpenen imports them into Adobe Substance 3D Painter to apply custom colors and textures.</p>
<p><iframe loading="lazy" title="Blackberry Pie - Blender Timelapse" width="500" height="281" src="https://www.youtube.com/embed/xPA6-ZW293Q?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>There, Carpenen uses RTX-accelerated light and ambient occlusion baking — though not in the oven — to optimize his assets, such as this berry pie, in mere seconds.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-68261-3" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/Blackberry-Pie-Blender-Timelapse-video.mp4?_=3" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/Blackberry-Pie-Blender-Timelapse-video.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/11/Blackberry-Pie-Blender-Timelapse-video.mp4</a></video></div>
<p>&nbsp;</p>
<p>He also had the option to set up a <a href="https://www.nvidia.com/en-us/omniverse/ecosystem/">live link</a> connection between 3D Painter and <a href="https://www.nvidia.com/en-us/omniverse/creators/">NVIDIA Omniverse</a>, a development platform for connecting and building <a href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description (OpenUSD)</a>-based tools and applications, via the <a href="https://www.nvidia.com/en-us/omniverse/apps/usd-composer/">USD Composer foundation app</a>.</p>
<p><iframe loading="lazy" title="Adobe Substance 3D Painter Connector Overview with Omniverse USD Composer" width="500" height="281" src="https://www.youtube.com/embed/_XRN2qAWJN0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>The connection would allow Carpenen’s texture work in Substance 3D Painter to directly translate to USD Composer — eliminating the need for numerous file imports, exports and reformatting.</p>
<h2><b>Donut Hole in One</b></h2>
<p>Carpenen uses Blender to bring his scenes together with advanced model sculpting, animations and further lighting refinement.</p>
<p><iframe loading="lazy" title="Donut Fever - Blender Timelapse" width="500" height="281" src="https://www.youtube.com/embed/LESrdWIZgv0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>RTX GPUs allow smoother movement in the viewport thanks to Blender Cycles’ RTX-accelerated OptiX ray tracing.</p>
<figure id="attachment_68277" aria-describedby="caption-attachment-68277" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68277" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68277" class="wp-caption-text">Beautifully rendered donuts make us go nuts.</figcaption></figure>
<p>And for exporting final files, RTX-accelerated OptiX ray tracing in Blender Cycles delivers the fastest final-frame render.</p>
<figure id="attachment_68280" aria-describedby="caption-attachment-68280" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68280" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68280" class="wp-caption-text">It doesn’t get any sweeter than this.</figcaption></figure>
<h2><b>Thanks to AI, This Work Is Toast</b></h2>
<p>Carpenen uses Adobe Photoshop Lightroom to put the finishing touches on his food scenes.</p>
<p>GPU-accelerated image processing enables dramatically more responsive adjustments on his 4K-resolution display.</p>
<p><iframe loading="lazy" title="Blender 2.92 - Toasty Morning" width="500" height="281" src="https://www.youtube.com/embed/bHmrGJhm8-4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Carpenen had even more RTX-accelerated AI tools at his disposal in Lightroom. The “Raw Details” feature refines the fine color details of high-resolution RAW images. And “Super Resolution” uses AI to upscale images with higher quality than traditional methods.</p>
<p>According to Carpenen, putting in the work is key.</p>
<p>“It’s equivalent to practicing football — if you don’t get enough time daily to practice, you can’t hone skills,” he said. “It’s important to know how to tackle obstacles — and that knowledge can only be gained by experience.”</p>
<figure id="attachment_68283" aria-describedby="caption-attachment-68283" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68283" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w-672x252.png" alt="" width="672" height="252" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w-672x252.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w-400x150.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w-768x288.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w-842x316.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w-406x152.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w-188x71.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68283" class="wp-caption-text">Digital 3D artist Ravissen Carpenen’s logo and signature work.</figcaption></figure>
<p>Check out Carpenen’s YouTube <a href="https://www.youtube.com/channel/UC9Vs9hDHCD1pD85uCehjlAg">channel</a>, CG Realism, and <a href="https://www.artstation.com/rcarts">ArtStation</a> to check out more food projects.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>Twitter</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/11/Turkey-Blender-Timelapse-video.mp4" length="1998359" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/11/Blackberry-Pie-Blender-Timelapse-video.mp4" length="1265816" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/nv-blog-header-preview-1280x680-1-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/nv-blog-header-preview-1280x680-1-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[3D Artist Cooks Up Stunningly Photorealistic Food Renders This Week ‘In the NVIDIA Studio’]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>What Is a SuperNIC?</title>
		<link>https://blogs.nvidia.com/blog/what-is-a-supernic/</link>
		
		<dc:creator><![CDATA[Itay Ozery]]></dc:creator>
		<pubDate>Mon, 20 Nov 2023 14:00:12 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Explainer]]></category>
		<category><![CDATA[Networking]]></category>
		<category><![CDATA[NVIDIA BlueField]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68257</guid>

					<description><![CDATA[Generative AI is the latest turn in the fast-changing digital landscape. One of the groundbreaking innovations making it possible is a relatively new term: SuperNIC.  What Is a SuperNIC? SuperNIC is a new class of network accelerators designed to supercharge hyperscale AI workloads in Ethernet-based clouds. It provides lightning-fast network connectivity for GPU-to-GPU communication, achieving <a class="read-more" href="https://blogs.nvidia.com/blog/what-is-a-supernic/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><span data-contrast="auto">Generative AI is the latest turn in the fast-changing digital landscape. One of the groundbreaking innovations making it possible is a relatively new term: SuperNIC.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<h2 aria-level="1"><strong>What Is a SuperNIC?</strong></h2>
<p><span data-contrast="auto">SuperNIC is a new class of network accelerators designed to supercharge hyperscale AI workloads in Ethernet-based clouds. It provides lightning-fast network connectivity for GPU-to-GPU communication, achieving speeds reaching 400Gb/s using remote direct memory access (RDMA) over converged Ethernet (RoCE) technology. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<p><span data-contrast="auto">SuperNICs combine the following unique attributes:</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<ul>
<li><span data-contrast="auto">High-speed packet reordering to ensure that data packets are received and processed in the same order they were originally transmitted. This maintains the sequential integrity of the data flow.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></li>
<li><span data-contrast="auto">Advanced congestion control using real-time telemetry data and network-aware algorithms to manage and prevent congestion in AI networks.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></li>
<li><span data-contrast="auto">Programmable compute on the input/output (I/O) path to enable customization and extensibility of network infrastructure in AI cloud data centers.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></li>
<li><span data-contrast="auto">Power-efficient, low-profile design to efficiently accommodate AI workloads within constrained power budgets.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></li>
<li><span data-contrast="auto">Full-stack AI optimization, including compute, networking, storage, system software, communication libraries and application frameworks.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></li>
</ul>
<p><span data-contrast="auto">NVIDIA recently unveiled the world’s first SuperNIC tailored for AI computing, based on the </span><a href="https://www.nvidia.com/en-us/networking/products/data-processing-unit/"><span data-contrast="none">BlueField-3 networking platform</span></a><span data-contrast="auto">. It’s a part of the NVIDIA Spectrum-X platform, where it integrates seamlessly with the Spectrum-4 Ethernet switch system. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<p><span data-contrast="auto">Together, the NVIDIA BlueField-3 SuperNIC and Spectrum-4 switch system form the foundation of an accelerated computing fabric specifically designed to optimize AI workloads. Spectrum-X consistently delivers high network efficiency levels, outperforming traditional Ethernet environments.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<p><span data-contrast="auto">“In a world where AI is driving the next wave of technological innovation, the BlueField-3 SuperNIC is a vital cog in the machinery,” said Yael Shenhav, vice president of DPU and NIC products at NVIDIA. “SuperNICs ensure that your AI workloads are executed with efficiency and speed, making them foundational components for enabling the future of AI computing.”</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<h2 aria-level="1"><strong>The Evolving Landscape of AI and Networking </strong></h2>
<p aria-level="1"><span data-contrast="auto">The AI field is undergoing a seismic shift, thanks to the advent of </span><a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/"><span data-contrast="none">generative AI</span></a><span data-contrast="auto"> and </span><a href="https://www.nvidia.com/en-us/glossary/data-science/large-language-models/"><span data-contrast="none">large language models</span></a><span data-contrast="auto">. These powerful technologies have unlocked new possibilities, enabling computers to handle new tasks. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<p><span data-contrast="auto">AI success relies heavily on GPU-accelerated computing to process mountains of data, train large AI models, and enable real-time inference. This new compute power has opened new possibilities, but it has also challenged Ethernet cloud networks.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<p><span data-contrast="auto">Traditional Ethernet, the technology that underpins internet infrastructure, was conceived to offer broad compatibility and connect loosely coupled applications. It wasn’t designed to handle the demanding computational needs of modern AI workloads, which involve tightly coupled parallel processing, rapid data transfers and unique communication patterns </span><span data-contrast="none">— all of which demand optimized </span><span data-contrast="auto">network connectivity. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<p><span data-contrast="auto">Foundational network interface cards (NICs) were designed for general-purpose computing, universal data transmission</span> <span data-contrast="auto">and interoperability. They were never designed to cope with the unique challenges posed by the computational intensity of AI workloads. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<p><span data-contrast="auto">Standard NICs lack the requisite features and capabilities for efficient data transfer, low latency and the deterministic performance crucial for AI tasks. SuperNICs, on the other hand, are purpose-built for modern AI workloads.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<h2 aria-level="1"><strong>SuperNIC Advantages in AI Computing Environments </strong></h2>
<p aria-level="1"><a href="https://blogs.nvidia.com/blog/whats-a-dpu-data-processing-unit/"><span data-contrast="none">Data processing units</span></a><span data-contrast="auto"> (DPUs) deliver a wealth of advanced features, offering high throughput, low-latency network connectivity and more. Since their introduction in 2020, DPUs have gained popularity in the realm of cloud computing, primarily due to their capacity to offload, accelerate and isolate data center infrastructure processing.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<p><span data-contrast="auto">Although DPUs and SuperNICs share a range of features and capabilities, SuperNICs are uniquely optimized for accelerating networks for AI. The chart below shows how they compare:</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<p><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> <a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/bluefield-supernic-diagram.png"><img loading="lazy" decoding="async" class="aligncenter size-large wp-image-68294" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/bluefield-supernic-diagram-672x366.png" alt="NVIDIA BlueField SuperNIC and DPU comparison chart" width="672" height="366" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/bluefield-supernic-diagram-672x366.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/bluefield-supernic-diagram-400x218.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/bluefield-supernic-diagram-768x419.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/bluefield-supernic-diagram-1536x838.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/bluefield-supernic-diagram.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/bluefield-supernic-diagram-825x450.png 825w, https://blogs.nvidia.com/wp-content/uploads/2023/11/bluefield-supernic-diagram-394x215.png 394w, https://blogs.nvidia.com/wp-content/uploads/2023/11/bluefield-supernic-diagram-183x100.png 183w, https://blogs.nvidia.com/wp-content/uploads/2023/11/bluefield-supernic-diagram-1280x698.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a></span></p>
<p><span data-contrast="auto">Distributed AI training and inference communication flows depend heavily on network bandwidth availability for success. SuperNICs, distinguished by their sleek design, scale more effectively than DPUs, delivering an impressive 400Gb/s of network bandwidth per GPU. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<p><span data-contrast="auto">The 1:1 ratio between GPUs and SuperNICs within a system can significantly enhance AI workload efficiency, leading to greater productivity and superior outcomes for enterprises. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<p><span data-contrast="auto">The sole purpose of SuperNICs is to accelerate networking for AI cloud computing. Consequently, it achieves this goal using less computing power than a DPU, which requires substantial computational resources to offload applications from a host CPU. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<p><span data-contrast="auto">The reduced computing requirements also translate to lower power consumption, which is especially crucial in systems containing up to eight SuperNICs.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<p><span data-contrast="auto">Additional distinguishing features of the SuperNIC include its dedicated AI networking capabilities. When tightly integrated with an AI-optimized NVIDIA Spectrum-4 switch, it offers adaptive routing, out-of-order packet handling and optimized congestion control. These advanced features are instrumental in accelerating Ethernet AI cloud environments.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<h2 aria-level="1"><strong>Revolutionizing AI Cloud Computing</strong></h2>
<p aria-level="1"><span data-contrast="auto">The NVIDIA BlueField-3 SuperNIC offers several benefits that make it key for AI-ready infrastructure:</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
<ul>
<li><span data-contrast="auto">Peak AI workload efficiency: The BlueField-3 SuperNIC is purpose-built for network-intensive, massively parallel computing, making it ideal for AI workloads. It ensures that AI tasks run efficiently </span><span data-contrast="none">— </span><span data-contrast="auto">without bottlenecks.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></li>
<li><span data-contrast="auto">Consistent and predictable performance: In multi-tenant data centers where numerous tasks are processed simultaneously, the BlueField-3 SuperNIC ensures that each job and tenant’s performance is isolated, predictable and unaffected by other network activities.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></li>
<li><span data-contrast="auto">Secure multi-tenant cloud infrastructure: Security is a top priority, especially in data centers handling sensitive information. The BlueField-3 SuperNIC maintains high security levels, enabling multiple tenants to coexist while keeping data and processing isolated.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></li>
<li><span data-contrast="auto">Extensible network infrastructure: The BlueField-3 SuperNIC isn’t limited in scope </span><span data-contrast="none">— </span><span data-contrast="auto">it’s highly flexible and adaptable to a myriad of other network infrastructure needs.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></li>
<li><span data-contrast="auto">Broad server manufacturer support: The BlueField-3 SuperNIC fits seamlessly into most enterprise-class servers without excessive power consumption in data centers.</span></li>
</ul>
<p><i><span data-contrast="auto">Learn more about NVIDIA BlueField-3 SuperNICs, including how they integrate across NVIDIA’s data center platforms, in the whitepaper: </span></i><a href="https://resources.nvidia.com/en-us-accelerated-networking-resource-library/next-generation-netw"><i><span data-contrast="none">Next-Generation Networking for the Next Wave of AI</span></i></a><i><span data-contrast="auto">.</span></i><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"> </span></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/bluefield-supernic.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/bluefield-supernic-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[What Is a SuperNIC?]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>From Guangzhou to Los Angeles, Automakers Dazzle With AI-Powered Vehicles</title>
		<link>https://blogs.nvidia.com/blog/guangzhou-los-angeles-auto-shows-ai-vehicles/</link>
		
		<dc:creator><![CDATA[Calisa Cole]]></dc:creator>
		<pubDate>Fri, 17 Nov 2023 18:40:08 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68246</guid>

					<description><![CDATA[Good news for car lovers: Two acclaimed auto shows, taking place now through next week, are delighting attendees with displays of next-generation automotive designs powered by AI. Hundreds of thousands of auto enthusiasts worldwide are expected to visit Guangzhou, China — known as the city of flowers — to attend its auto show, running through <a class="read-more" href="https://blogs.nvidia.com/blog/guangzhou-los-angeles-auto-shows-ai-vehicles/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Good news for car lovers: Two acclaimed auto shows, taking place now through next week, are delighting attendees with displays of next-generation automotive designs powered by AI.</p>
<p>Hundreds of thousands of auto enthusiasts worldwide are expected to visit Guangzhou, China — known as the city of flowers — to attend its auto show, running through Sunday, Nov. 26. The event will feature new developments in electric vehicles (EVs) and automated driving, with 1,100 vehicles on display.</p>
<p>And across the world, in the city of angels, the Los Angeles Auto Show is expected to reach its highest-ever attendee numbers. Also running through Nov. 26, the show will include classic and exotic cars from private collections, as well as a public test track where attendees can get behind the wheel of the latest EVs.</p>
<h2><strong>Auto Guangzhou</strong></h2>
<figure id="attachment_68247" aria-describedby="caption-attachment-68247" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/filmstriptest.jpg"><img loading="lazy" decoding="async" class="wp-image-68247 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/filmstriptest-672x133.jpg" alt="" width="672" height="133" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/filmstriptest-672x133.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/filmstriptest-400x79.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/filmstriptest-768x152.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/filmstriptest-842x166.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/11/filmstriptest-406x80.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/11/filmstriptest-188x37.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/11/filmstriptest.jpg 1277w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68247" class="wp-caption-text">Human Horizons, NIO, ZEEKR</figcaption></figure>
<p>One of the most anticipated reveals is from Lotus, which is showcasing its new fully electric Emeya Hyper-GT that launched in September. This stunning luxury vehicle with sports-car agility achieves an impressive suite of intelligent features, powered by dual NVIDIA DRIVE Orin processors. The high-performance processing power enables drivers to enjoy the car’s safe and secure driving capabilities and supports future features through over-the-air (OTA) updates.</p>
<p>With an eye on safety, Emeya carries 34 state-of-the-art surround sensors for diverse and redundant sensor data processing in real time — giving drivers added confidence when behind the wheel. With DRIVE Orin embedded in the back of the vehicle, Emeya delivers advanced driver assistance system (ADAS) capabilities and also offers the built-in headroom to support an autonomous future.</p>
<p>Emeya Hyper-GT is built on Lotus’ innovative Electric Premium Architecture, which underpins the Eletre Hyper-SUV as well, also powered by NVIDIA DRIVE Orin.</p>
<p>In addition, Lotus is showcasing its full range of Lotus electric vehicles, including the Evija hypercar, Eletre Hyper-SUV and Type 136, its recently launched electric bike. Emira, Lotus’ final internal combustion engine vehicle, is also on display.</p>
<p>Several other NVIDIA DRIVE ecosystem members are featuring their next-gen EVs at Auto Guangzhou:</p>
<ul>
<li><b>DENZA</b>, a joint venture between BYD and Mercedes-Benz, is highlighting the intelligent-driving features of its <a href="https://blogs.nvidia.com/blog/denza-smart-driving-n7-model-nvidia-drive-orin/" target="_blank" rel="noopener">N7 model lineup</a>. All N7 models can be equipped with the NVIDIA DRIVE Orin system-on-a-chip. In addition, DENZA is showcasing its next generation of car configurators built on <a href="https://blogs.nvidia.com/blog/denza-wpp-car-configurators-nvidia-omniverse-cloud/" target="_blank" rel="noopener">NVIDIA Omniverse Cloud</a>, enabling consumers to customize various aspects, such as colors, materials and more.</li>
<li style="font-weight: 400;" aria-level="1"><strong>Human</strong><b> Horizons</b> is showcasing the <a href="https://blogs.nvidia.com/blog/auto-shanghai-nvidia-drive/" target="_blank" rel="noopener">HiPhi Y SUV</a>, which includes a second-generation intelligent door system design, a range of more than 497 miles on a single charge and an autonomous-driving system powered by NVIDIA DRIVE Orin.</li>
<li><b>JI YUE</b>, a Geely Holding and Baidu joint venture, is displaying the <a href="https://zgh.com/media-center/news/2023-10-27-02/?lang=en" target="_blank" rel="noopener">ROBOCAR JiYue 01</a>, the first model to offer the premium intelligent driving feature ROBO Drive Max, powered by NVIDIA DRIVE Orin.</li>
<li><b>NIO</b> is exhibiting eight models equipped with Banyan, NIO’s Smart Digital System, and <a href="https://blogs.nvidia.com/blog/hello-world-nio-expands-global-footprint-with-intelligent-vehicle-experiences/" target="_blank" rel="noopener">Adam</a>, an NVIDIA-powered supercomputer. Adam uses NVIDIA DRIVE Orin to enable advanced automated-driving features and allow continuous OTA upgrades.</li>
<li><b>XPENG</b> is unveiling and commencing pre-sales for its next-generation, super-intelligent, seven-seater MPV, the XPENG X9. The company is also showcasing the <a href="https://blogs.nvidia.com/blog/xpeng-g6-coupe-suv-drive-orin/" target="_blank" rel="noopener">XPENG G6</a>, the XPENG P7i and the XPENG G9, all featuring NVIDIA DRIVE Orin.</li>
<li><b>ZEEKR</b> introduces the ZEEKR 007. The electric sedan is ZEEKR’s first sedan and fourth model, powered by NVIDIA DRIVE Orin. The ZEEKR 007 has a sensor suite consisting of one lidar, 12 high-definition cameras and five millimeter-wave radars for advanced smart assist driving functions with multiple redundancy.</li>
</ul>
<p>In addition, NVIDIA DRIVE ecosystem partner <b>DeepRoute.ai</b>, a smart driving solutions provider, is demonstrating its DeepRoute <a href="https://blogs.nvidia.com/blog/nvidia-drive-ecosystem-growth/" target="_blank" rel="noopener">Driver 3.0</a>, designed to offer a non-geofenced solution for automated vehicles.</p>
<h2><b>Los Angeles Auto Show</b></h2>
<p><img loading="lazy" decoding="async" class="aligncenter wp-image-68250 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/la-auto-show-614x500.png" alt="" width="614" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/la-auto-show-614x500.png 614w, https://blogs.nvidia.com/wp-content/uploads/2023/11/la-auto-show-400x326.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/la-auto-show-768x626.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/la-auto-show-1536x1252.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/la-auto-show-552x450.png 552w, https://blogs.nvidia.com/wp-content/uploads/2023/11/la-auto-show-264x215.png 264w, https://blogs.nvidia.com/wp-content/uploads/2023/11/la-auto-show-123x100.png 123w, https://blogs.nvidia.com/wp-content/uploads/2023/11/la-auto-show-1280x1043.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/11/la-auto-show.png 1999w" sizes="(max-width: 614px) 100vw, 614px" /></p>
<p>At the LA Auto Show, Lucid Motors is showcasing its highly anticipated <a href="https://lucidmotors.com/media-room/introducing-lucid-gravity" target="_blank" rel="noopener">Gravity SUV</a>, which will begin production in late 2024. Powered by NVIDIA DRIVE, the luxury SUV features supercar levels of performance and an impressive battery range to mitigate range anxiety.</p>
<p>In addition, Lucid is displaying its Lucid Air sedan, including the Air Pure and Air Touring models. All of these vehicles feature the future-ready DreamDrive Pro driver-assistance system, powered by the NVIDIA DRIVE platform.</p>
<p><img loading="lazy" decoding="async" class="alignnone wp-image-68289 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/Genesis-Interior-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/Genesis-Interior-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Genesis-Interior-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Genesis-Interior-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Genesis-Interior-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Genesis-Interior-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Genesis-Interior-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Genesis-Interior-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Genesis-Interior-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Genesis-Interior-1280x853.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></p>
<p>And Genesis is unveiling the new 2025 GV80 SUV, which features a <a href="https://blogs.nvidia.com/blog/hyundai-ai-infotainment-nvidia-drive/" target="_blank" rel="noopener">next-generation infotainment system</a> powered by NVIDIA DRIVE, including audio, video, navigation and connectivity services on an updatable platform with a 27-inch-wide OLED display.</p>
<p><a href="https://developer.nvidia.com/drive" target="_blank" rel="noopener"><i>Learn more</i></a><i> about the industry-leading designs and technologies NVIDIA is developing with its automotive partners.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/automainfeature.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/automainfeature-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[From Guangzhou to Los Angeles, Automakers Dazzle With AI-Powered Vehicles]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI to See ‘Major Second Wave,’ NVIDIA CEO Says in Fireside Chat With iliad Group Exec</title>
		<link>https://blogs.nvidia.com/blog/fireside-chat-scaleway/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Fri, 17 Nov 2023 17:41:23 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Supercomputing]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68228</guid>

					<description><![CDATA[European startups will get a massive boost from a new generation of AI infrastructure, NVIDIA founder and CEO Jensen Huang said Friday in a fireside chat with iliad Group Deputy CEO Aude Durand — and it’s coming just in time. “We’re now seeing a major second wave,” Huang said of the state of AI during <a class="read-more" href="https://blogs.nvidia.com/blog/fireside-chat-scaleway/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>European startups will get a massive boost from a new generation of AI infrastructure, NVIDIA founder and CEO Jensen Huang said Friday in a fireside chat with iliad Group Deputy CEO Aude Durand — and it’s coming just in time.</p>
<p>“We’re now seeing a major second wave,” Huang said of the state of AI during a virtual appearance at Scaleway’s ai-PULSE conference in Paris for an audience of more than 1,000 in-person attendees.</p>
<p>Two elements are propelling this force, Huang explained in a conversation livestreamed from Station F, the world’s largest startup campus, which Huang joined via video conference from NVIDIA’s headquarters in Silicon Valley.</p>
<p>First, “a recognition that every region and every country needs to build their sovereign AI,” Huang said. Second, the “adoption of AI in different industries,” as generative AI spreads throughout the world, Huang explained.</p>
<p>“So the types of breakthroughs that we’re seeing in language I fully expect to see in digital biology and manufacturing and robotics,” Huang said, noting this could create big opportunities for Europe with its rich digital biology and healthcare industries. “And of course, Europe is also home of some of the largest industrial manufacturing companies.”</p>
<h2><b>Praise for France’s AI Leadership</b></h2>
<p>Durand kicked off the conversation by asking Huang about his views on the European AI ecosystem, especially in France, where the government has invested millions of euros in AI research and development.</p>
<p>“Europe has always been rich in AI expertise,” Huang said, noting that NVIDIA works with 4,000 startups in Europe, more than 400 of them in France alone, pointing to Mistral, Qubit Pharmaceuticals and Poolside AI.</p>
<p>“At the same time, you have to really get the computing infrastructure going,” Huang said. “And this is the reason why Scaleway is so important to the advancement of AI in France” and throughout Europe, Huang said.</p>
<p>Highlighting the critical role of data in AI’s regional growth, Huang noted companies’ increasing awareness of the value of training AI with region-specific data. AI systems need to reflect the unique cultural and industrial nuances of each region, an approach gaining traction across Europe and beyond.</p>
<h2>NVIDIA and Scaleway: Powering Europe’s AI Revolution</h2>
<p>Scaleway, a subsidiary of iliad Group, a major European telecoms player, is doing its part to kick-start that second wave in Europe, offering cloud credits for access to its AI supercomputer cluster, which packs 1,016 <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100 Tensor Core GPUs</a>.</p>
<p>As a regional cloud service provider, Scaleway also provides sovereign infrastructure that ensures access and compliance with EU data protection laws, which is critical for businesses with a European footprint.</p>
<p>Regional members of the <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception program</a>, which provides development assistance to startups, will also be able to access <a href="https://blogs.nvidia.com/blog/scaleway-european-startups-inception">NVIDIA AI Enterprise software on Scaleway Marketplace</a>.</p>
<p>The software includes the <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/">NVIDIA NeMo</a> framework and pretrained models for building LLMs, <a href="https://developer.nvidia.com/rapids">NVIDIA RAPIDS</a> for accelerated data science and <a href="https://developer.nvidia.com/nvidia-triton-inference-server">NVIDIA Triton Inference Server</a> and <a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-supercharges-large-language-model-inference-on-nvidia-h100-gpus/">NVIDIA TensorRT-LLM</a> for boosting inference.</p>
<h2>Revolutionizing AI With Supercomputing Prowess</h2>
<p>Recapping a month packed with announcements, Huang explained how NVIDIA is rapidly advancing high performance computing and AI worldwide to provide the infrastructure needed to power this second wave.</p>
<p>These systems are, in effect,  “supercomputers,” Huang said, with AI systems now among the world’s most powerful.</p>
<p>They include Scaleway’s newly available <a href="https://www.scaleway.com/en/news/scaleway-releases-the-details-of-its-offering-based-on-nabuchodonosor-its-dedicated-ai-supercomputer-built-on-nvidia-dgx-h100-infrastructure/">Nabuchodonosor</a> supercomputer, or “Nabu,” an <a href="https://www.nvidia.com/en-us/data-center/dgx-superpod/">NVIDIA DGX SuperPOD</a> with 127 <a href="https://www.nvidia.com/en-us/data-center/dgx-h100/?ncid=pa-srch-goog-560181&amp;_bt=676835775117&amp;_bk=dgx%20h100&amp;_bm=p&amp;_bn=g&amp;_bg=154931763096&amp;gad_source=1&amp;gclid=EAIaIQobChMI0NPi36mVggMV80lHAR0zigLiEAAYASAAEgJCF_D_BwE">NVIDIA DGX H100</a> systems, which will help startups in France and across Europe scale up AI workloads.</p>
<p>“As you know the Scaleway system that we brought online, Nabu, is not your normal computer,” Huang said. “In every single way, it’s a supercomputer.”</p>
<p>Such systems are underpinning powerful new services.</p>
<p>Earlier this week, <a href="https://nvidianews.nvidia.com/news/nvidia-introduces-generative-ai-foundry-service-on-microsoft-azure-for-enterprises-and-startups-worldwide">NVIDIA announced an AI Foundry service</a> on Microsoft Azure, aimed at accelerating the development of customized generative AI applications.</p>
<p>Huang highlighted NVIDIA AI foundry’s appeal to a diverse user base, including established enterprises such as Amdocs, Getty Images, SAP and ServiceNow.</p>
<p><a href="https://nvidianews.nvidia.com/news/nvidia-grace-hopper-superchip-powers-jupiter-defining-a-new-class-of-supercomputers-to-propel-ai-for-scientific-discovery">Huang noted that JUPITER, to be hosted at the Jülich facility, in Germany</a>, and poised to be Europe’s premier exascale AI supercomputer, will run on 24,000 NVIDIA GH200 Grace Hopper Superchips, offering unparalleled computational capacity for diverse AI tasks and simulations.</p>
<p>Huang touched on NVIDIA’s just-announced HGX H200 AI computing platform, built on NVIDIA’s Hopper architecture and featuring the H200 Tensor Core GPU. Set for release in Q2 of 2024, it promises to redefine industry standards.</p>
<p>He also detailed NVIDIA’s strategy to develop ‘AI factories,’ advanced data centers that power diverse applications across industries, including electric vehicles, robotics, and generative AI services.</p>
<h2>Open Source</h2>
<p>Finally, Durand asked Huang about the role of open source and open science in AI.</p>
<p>Huang said he’s a “huge fan” of open source. “Let’s acknowledge that without open source, how would AI have made the tremendous progress it has over the last decade,” Huang said.</p>
<p>“And so the ability for open source to energize the vibrancy and pull in the research and pull in the engagement of every startup, every researcher, every industry is really quite vital,” Huang said. “And you’re seeing it play out just presently, now going forward.”</p>
<p><em>Friday’s fireside conversation was part of Scaleway’s ai-PULSE conference, showcasing the latest AI trends and innovations. To learn more, visit <a href="https://www.ai-pulse.eu/">https://www.ai-pulse.eu/</a>. </em></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/original-7ADF7A87-2022-455E-B43A-2120E78B0B43.jpg.jpeg"
			type="image/jpeg"
			width="1170"
			height="619"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/original-7ADF7A87-2022-455E-B43A-2120E78B0B43.jpg-842x450.jpeg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI to See ‘Major Second Wave,’ NVIDIA CEO Says in Fireside Chat With iliad Group Exec]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA and Scaleway Speed Development for European Startups and Enterprises</title>
		<link>https://blogs.nvidia.com/blog/scaleway-european-startups-inception/</link>
		
		<dc:creator><![CDATA[Serge Lemonde]]></dc:creator>
		<pubDate>Fri, 17 Nov 2023 10:00:43 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[NVIDIA DGX]]></category>
		<category><![CDATA[NVIDIA in Europe]]></category>
		<category><![CDATA[RAPIDS]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68220</guid>

					<description><![CDATA[Europe’s startup ecosystem is getting a boost of accelerated computing for generative AI. NVIDIA and cloud service provider (CSP) Scaleway are working together to deliver access to GPUs, NVIDIA AI Enterprise software, and services for turbocharging large language models (LLMs) and generative AI development for European startups. Scaleway, a subsidiary of French telecommunications provider iliad <a class="read-more" href="https://blogs.nvidia.com/blog/scaleway-european-startups-inception/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Europe’s startup ecosystem is getting a boost of accelerated computing for generative AI.</p>
<p>NVIDIA and cloud service provider (CSP) Scaleway are working together to deliver access to GPUs, NVIDIA AI Enterprise software, and services for turbocharging large language models (LLMs) and generative AI development for European startups.</p>
<p>Scaleway, a subsidiary of French telecommunications provider iliad Group, is offering cloud credits for access to its AI supercomputer cluster, which packs 1,016 <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100 Tensor Core GPUs</a>. As a regional CSP, Scaleway also provides sovereign infrastructure that ensures access and compliance with EU data protection laws — critical to businesses with a European footprint.</p>
<h2><b>Sovereign Cloud, Generative AI </b></h2>
<p>Complying with regulations governing how data and metadata can be stored in cloud computing is critical. When doing business in Europe, U.S. companies, for example, need to comply with EU regulations on sovereignty to secure data against access from foreign adversaries or entities. Noncompliance risks data vulnerabilities, financial penalties and legal consequences.</p>
<p>Regional CSPs like Scaleway provide a strategic path forward for companies to do business in Europe with a sovereign infrastructure. iliad Group’s data centers, where Scaleway operates, are fortified by compliance certifications that ensure data security, covering key aspects like healthcare, public safety, governance and public service activities.</p>
<h2><b>Delivering Sovereign Accelerated Computing </b></h2>
<p>NVIDIA is working with Scaleway to expand access to sovereign accelerated computing in the EU, enabling companies to deploy AI applications and scale up faster.  <b> </b></p>
<p>Through the <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception program</a>, startups already relying on the sovereign cloud computing capabilities of Scaleway’s NVIDIA-accelerated infrastructure include Hugging Face, with more to come. Inception is a free global program that provides technical guidance, training, discounts and networking opportunities.</p>
<p>Inception member Hugging Face, based in New York and with operations in France, creates tools and resources to help developers build, deploy and train AI models.</p>
<p>“AI is the new way of building technology, and making the fastest AI accelerators accessible within regional clouds is key to democratizing AI across the world, enabling enterprises and startups to build the experiences of tomorrow,” said Jeff Boudier, head of product at Hugging Face. “I’m really excited that selected French startups will be able to access NVIDIA H100 GPUs in Scaleway’s cluster through the new startup program Scaleway and Hugging Face just announced with Meta and Station F.”</p>
<h2><b>H100 and NVIDIA AI to Scale </b></h2>
<p>Scaleway’s newly available <a href="https://www.scaleway.com/en/news/scaleway-releases-the-details-of-its-offering-based-on-nabuchodonosor-its-dedicated-ai-supercomputer-built-on-nvidia-dgx-h100-infrastructure/">Nabuchodonosor</a> supercomputer, an <a href="https://www.nvidia.com/en-us/data-center/dgx-superpod/">NVIDIA DGX SuperPOD</a> with 127 <a href="https://www.nvidia.com/en-us/data-center/dgx-h100/?ncid=pa-srch-goog-560181&amp;_bt=676835775117&amp;_bk=dgx%20h100&amp;_bm=p&amp;_bn=g&amp;_bg=154931763096&amp;gad_source=1&amp;gclid=EAIaIQobChMI0NPi36mVggMV80lHAR0zigLiEAAYASAAEgJCF_D_BwE">NVIDIA DGX H100</a> systems, will help startups in France and across Europe scale up AI workloads.</p>
<p>Regional Inception members will also be able to access NVIDIA AI Enterprise software on Scaleway Marketplace, including the <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/">NVIDIA NeMo</a> framework and pretrained models for building LLMs, <a href="https://developer.nvidia.com/rapids">NVIDIA RAPIDS</a> for accelerated data science, and <a href="https://developer.nvidia.com/nvidia-triton-inference-server">NVIDIA Triton Inference Server</a> and <a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-supercharges-large-language-model-inference-on-nvidia-h100-gpus/">NVIDIA TensorRT-LLM</a> for boosting inference.</p>
<h2><b>NVIDIA Inception Services on Tap</b></h2>
<p><a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a> has more than 4,000 members across Europe. Member companies of Scaleway’s own startup program are eligible to join Inception for benefits and resources. Scaleway is earmarking companies to fast-track for Inception membership.</p>
<p>Inception members gain access to cloud computing credits, <a href="http://www.nvidia.com/dli">NVIDIA Deep Learning Institute</a> courses, technology experts, preferred pricing on hardware and software, guidance on the latest software development kits and AI frameworks, as well as opportunities for matchmaking with investors.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/ai-pulse-corp-blog-scaleway-2023-1260x680-1.jpg"
			type="image/jpeg"
			width="1260"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/ai-pulse-corp-blog-scaleway-2023-1260x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA and Scaleway Speed Development for European Startups and Enterprises]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI Training AI: GatorTronGPT at the Forefront of University of Florida’s Medical AI Innovations</title>
		<link>https://blogs.nvidia.com/blog/gatortrongpt/</link>
		
		<dc:creator><![CDATA[Mona Flores]]></dc:creator>
		<pubDate>Thu, 16 Nov 2023 22:31:40 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68233</guid>

					<description><![CDATA[How do you train an AI to understand clinical language with less clinical data? Train another AI to synthesize training data. Artificial intelligence is changing the way medicine is done, and is increasingly being used in all sorts of clinical tasks. This is fueled by generative AI and models like GatorTronGPT, a generative language model <a class="read-more" href="https://blogs.nvidia.com/blog/gatortrongpt/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>How do you train an AI to understand clinical language with less clinical data? Train another AI to synthesize training data.</p>
<p>Artificial intelligence is changing the way medicine is done, and is increasingly being used in all sorts of clinical tasks.</p>
<p>This is fueled by <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/">generative AI</a> and models like GatorTronGPT, a generative language model trained on the University of Florida’s HiPerGator AI supercomputer and <a href="https://www.nature.com/articles/s41746-023-00958-w">detailed in a paper published in Nature Digital Medicine Thursday</a>.</p>
<p>GatorTronGPT joins a growing number of large language models (<a href="https://blogs.nvidia.com/blog/what-are-large-language-models-used-for/">LLMs</a>) trained on clinical data. Researchers trained the model using the GPT-3 framework, also used by ChatGPT.</p>
<p>They used a massive corpus of 277 billion words for this purpose. The training corpora included 82 billion words from de-identified clinical notes and 195 billion words from various English texts.</p>
<p>But there’s a twist: The research team also used GatorTronGPT to generate a synthetic clinical text corpus with over 20 billion words of synthetic clinical text, with carefully prepared prompts. The synthetic clinical text focuses on clinical factors and reads just like real clinical notes written by doctors.</p>
<p>This <a href="https://blogs.nvidia.com/blog/what-is-synthetic-data/">synthetic data</a> was then used to train a BERT-based model called GatorTron-S.</p>
<p>In a comparative evaluation, GatorTron-S exhibited remarkable performance on clinical natural language understanding tasks like clinical concept extraction and medical relation extraction, beating the records set by the original BERT-based model, GatorTron-OG, which was trained on the 82-billion-word clinical dataset.</p>
<p>More impressively, it was able to do so using less data.</p>
<p>Both GatorTron-OG and GatorTron-S models were trained on 560 <a href="https://www.nvidia.com/en-us/data-center/a100/">NVIDIA A100 Tensor Core GPUs</a> running NVIDIA’s Megatron-LM package on the University of Florida’s <a href="https://blogs.nvidia.com/blog/university-of-florida-rankings-ai/">HiPerGator supercomputer</a>. Technology from the Megatron LM framework used in the project has since been incorporated with the <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/">NVIDIA NeMo</a> framework, which has been central to more recent work on GatorTronGPT.</p>
<p>Using synthetic data created by LLMs addresses several challenges. LLMs require vast amounts of data, and there’s a limited availability of quality medical data.</p>
<p>In addition, synthetic data allows for model training that complies with medical privacy regulations, such as HIPAA.</p>
<p>The work with GatorTronGPT is just the latest example of how LLMs — which exploded onto the scene last year with the rapid adoption of ChatGPT — can be tailored to assist in a growing number of fields.</p>
<p>It’s also an example of the advances made possible by new AI techniques powered by accelerated computing.</p>
<p>The GatorTronGPT effort is the latest result of an <a href="https://blogs.nvidia.com/blog/university-of-florida-nvidia-ai-supercomputer/">ambitious collaboration</a> announced in 2020, when the University of Florida and NVIDIA unveiled plans to erect the world’s fastest AI supercomputer in academia.</p>
<p>This initiative was driven by a $50 million gift, a fusion of contributions from NVIDIA founder Chris Malachowsky and NVIDIA itself.</p>
<p>Using AI to train more AI is just one example of HiPerGator’s impact, with the supercomputer promising to power more innovations in medical sciences and <a href="https://blogs.nvidia.com/blog/uf-health-syngatortron-ai-synthetic-clinical-data/">across disciplines</a> throughout the University of Florida system.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/UF-Malachowsky-Hall-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/UF-Malachowsky-Hall-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI Training AI: GatorTronGPT at the Forefront of University of Florida’s Medical AI Innovations]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Three Ways Generative AI Can Bolster Cybersecurity</title>
		<link>https://blogs.nvidia.com/blog/generative-ai-cybersecurity/</link>
		
		<dc:creator><![CDATA[David Reber Jr.]]></dc:creator>
		<pubDate>Thu, 16 Nov 2023 16:00:37 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cybersecurity]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[New GPU Uses]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68187</guid>

					<description><![CDATA[Human analysts can no longer effectively defend against the increasing speed and complexity of cybersecurity attacks. The amount of data is simply too large to screen manually. Generative AI, the most transformative tool of our time, enables a kind of digital jiu jitsu. It lets companies shift the force of data that threatens to overwhelm <a class="read-more" href="https://blogs.nvidia.com/blog/generative-ai-cybersecurity/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Human analysts can no longer effectively defend against the increasing speed and complexity of cybersecurity attacks. The amount of data is simply too large to screen manually.</p>
<p><a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/">Generative AI</a>, the most transformative tool of our time, enables a kind of digital jiu jitsu. It lets companies shift the force of data that threatens to overwhelm them into a force that makes their defenses stronger.</p>
<p>Business leaders seem ready for the opportunity at hand. In a <a href="https://www.ibm.com/thought-leadership/institute-business-value/en-us/c-suite-study/ceo">recent survey</a>, CEOs said cybersecurity is one of their top three concerns, and they see generative AI as a lead technology that will deliver competitive advantages.</p>
<p>Generative AI brings both risks and benefits. An earlier blog outlined <a href="https://blogs.nvidia.com/blog/ai-security-steps/">six steps to start the process of securing enterprise AI</a>.</p>
<p>Here are three ways generative AI can bolster cybersecurity.</p>
<h2><b>Begin With Developers</b></h2>
<p>First, give developers a security copilot.</p>
<p>Everyone plays a role in security, but not everyone is a security expert. So, this is one of the most strategic places to begin.</p>
<p>The best place to start bolstering security is on the front end, where developers are writing software. An AI-powered assistant, trained as a security expert, can help them ensure their code follows best practices in security.</p>
<p>The AI software assistant can get smarter every day if it’s fed previously reviewed code. It can learn from prior work to help guide developers on best practices.</p>
<p>To give users a leg up, NVIDIA is creating a <a href="https://www.nvidia.com/en-us/ai-data-science/ai-workflows/generative-ai-chatbots/">workflow for building such co-pilots or chatbots</a>. This particular workflow uses components from <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/">NVIDIA NeMo</a>, a framework for building and customizing <a href="https://www.nvidia.com/en-us/glossary/data-science/large-language-models/">large language models</a>.</p>
<p>Whether users customize their own models or use a commercial service, a security assistant is just the first step in applying generative AI to cybersecurity.</p>
<h2><b>An Agent to Analyze Vulnerabilities</b></h2>
<p>Second, let generative AI help navigate the sea of known software vulnerabilities.</p>
<p>At any moment, companies must choose among thousands of patches to mitigate known exploits. That’s because every piece of code can have roots in dozens if not thousands of different software branches and open-source projects.</p>
<p>An LLM focused on vulnerability analysis can help prioritize which patches a company should implement first. It’s a particularly powerful security assistant because it reads all the software libraries a company uses as well as its policies on the features and APIs it supports.</p>
<p>To test this concept, NVIDIA built a pipeline to analyze software containers for vulnerabilities. The agent identified areas that needed patching with high accuracy, speeding the work of human analysts up to 4x.</p>
<p>The takeaway is clear. It’s time to enlist generative AI as a first responder in vulnerability analysis.</p>
<h2><b>Fill the Data Gap</b></h2>
<p>Finally, use LLMs to help fill the growing data gap in cybersecurity.</p>
<p>Users rarely share information about data breaches because they’re so sensitive. That makes it difficult to anticipate exploits.</p>
<p>Enter LLMs. Generative AI models can create <a href="https://blogs.nvidia.com/blog/what-is-synthetic-data/">synthetic data</a> to simulate never-before-seen attack patterns. Such synthetic data can also fill gaps in training data so machine-learning systems learn how to defend against exploits before they happen.</p>
<h2><b>Staging Safe Simulations</b></h2>
<p>Don’t wait for attackers to demonstrate what’s possible. Create safe simulations to learn how they might try to penetrate corporate defenses.</p>
<p>This kind of proactive defense is the hallmark of a strong security program. Adversaries are already using generative AI in their attacks. It’s time users harness this powerful technology for cybersecurity defense.</p>
<p>To show what’s possible, another <a href="https://www.nvidia.com/en-us/ai-data-science/ai-workflows/spear-phishing/">AI workflow</a> uses generative AI to defend against spear phishing — the carefully targeted bogus emails that cost companies an estimated $2.4 billion in 2021 alone.</p>
<p>This workflow generated synthetic emails to make sure it had plenty of good examples of spear phishing messages. The AI model trained on that data learned to understand the intent of incoming emails through natural language processing capabilities in <a href="https://developer.nvidia.com/morpheus-cybersecurity">NVIDIA Morpheus</a>, a framework for AI-powered cybersecurity.</p>
<p>The resulting model caught 21% more spear phishing emails than existing tools. Check out our <a href="https://developer.nvidia.com/blog/generative-ai-and-accelerated-computing-for-spear-phishing-detection/">developer blog</a> or watch the video below to learn more.</p>
<p><iframe loading="lazy" title="Improve Spear Phishing Detection with Generative AI" width="500" height="281" src="https://www.youtube.com/embed/57dEPP67XrY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Wherever users choose to start this work, automation is crucial, given the shortage of cybersecurity experts and the thousands upon thousands of users and use cases that companies need to protect.</p>
<p>These three tools — software assistants, virtual vulnerability analysts and synthetic data simulations — are great starting points for applying generative AI to a security journey that continues every day.</p>
<p>But this is just the beginning. Companies need to integrate generative AI into all layers of their defenses.</p>
<p>Attend a <a href="https://www.nvidia.com/en-us/events/llm-developer-day/">webinar</a> for more details on how to get started.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/Security-KV-Final-AdobeStock_312879614-scaled.jpeg"
			type="image/jpeg"
			width="2048"
			height="1152"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/Security-KV-Final-AdobeStock_312879614-842x450.jpeg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Three Ways Generative AI Can Bolster Cybersecurity]]></media:title>
			<media:description type="html">Security analyst using generative AI</media:description>
			</media:content>
			</item>
		<item>
		<title>Into the Omniverse: OpenUSD Enhancements for Autodesk Maya Make 3D Workflows a Ferret-Tale</title>
		<link>https://blogs.nvidia.com/blog/openusd-enhancements-for-autodesk-maya/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Thu, 16 Nov 2023 14:00:53 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[Into the Omniverse]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Universal Scene Description]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68127</guid>

					<description><![CDATA[3D artists can improve the productivity and efficiency of their generative AI-enabled content-creation workflows thanks to the latest updates to popular OpenUSD software.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of </i><a href="https://www.nvidia.com/en-us/omniverse/news/"><i>Into the Omniverse</i></a><i>, a series focused on how artists, developers and enterprises can transform their workflows using the latest advances in </i><a href="https://www.nvidia.com/en-us/omniverse/usd/"><i>OpenUSD</i></a><i> and </i><a href="https://www.nvidia.com/en-us/omniverse/usd/"><i>NVIDIA Omniverse</i></a><i>.</i></p>
<p>In 3D art and design, efficient workflows are essential for quickly bringing creative visions to life.</p>
<p><a href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description</a>, aka OpenUSD, is a framework that enhances these workflows by providing a unified, extensible ecosystem for describing, composing, simulating and collaborating within 3D worlds. OpenUSD is a key technology in Autodesk’s suite of products and solutions, across media and entertainment; architecture, engineering and construction; and product design and manufacturing.</p>
<p>Unveiled at the <a href="https://conferences.autodesk.com/flow/autodesk/au2023/web/page/overview" target="_blank" rel="noopener">AU 2023</a> conference this week, the latest OpenUSD updates to Autodesk Maya enable artists and technical professionals to create and manipulate OpenUSD assets with greater control and efficiency, while also ensuring more efficient and accurate 3D workflows.</p>
<h2><b></b><b>Bridging the Digital and Real Worlds With Maya and OpenUSD</b></h2>
<p>Many creators are using Maya and OpenUSD to propel their 3D workflows.</p>
<p><a href="https://www.linkedin.com/in/karol-osinski-3dartist" target="_blank" rel="noopener">Karol Osinski</a> is a 3D artist at <a href="http://www.s20m.com" target="_blank" rel="noopener">S20M</a>, an architectural and design firm that specializes in tackling unique, bold and elegant projects. When it comes to creating architectural visualizations, Osinski says the biggest challenge is matching the digital world to the real one.</p>
<p>Using USD and creative tools such as Maya, SideFX Houdini and Epic Games’ Unreal Engine, Osinski creates high-quality visuals for clients while accelerating his architectural workflows.</p>
<p style="text-align: center;"><img loading="lazy" decoding="async" class=" wp-image-68143 aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/ezgif.com-video-to-gif-38.gif" alt="" width="644" height="363" /><i>Osinski’s panoramic view from the 20th floor terrace in the Upper East Side</i></p>
<p>“OpenUSD provides the possibility of bridging different tools like never before,” said Osinski. “I love how accessible USD is for first-time users and how it opens opportunities to make designs very complex.”</p>
<p><a href="https://blogs.nvidia.com/blog/sir-wade-autodesk-maya-blender-davinci-resolve" target="_blank" rel="noopener">“Sir Wade” Neistadt</a>, an animator and YouTube creator, aims to make animation and 3D education more accessible through his video tutorials and industry training. The first step of his unique animation workflow is to act out his animations on camera. He then translates them in Maya to begin his animation work before using USD to export them to other 3D software, including Blender, for finishing touches.</p>
<p style="text-align: center;"><img loading="lazy" decoding="async" class=" wp-image-68137 aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-sir-wade-neistadt-wk83-robot-bts-maya-1280w-1.png" alt="" width="722" height="435" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-sir-wade-neistadt-wk83-robot-bts-maya-1280w-1.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-sir-wade-neistadt-wk83-robot-bts-maya-1280w-1-400x241.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-sir-wade-neistadt-wk83-robot-bts-maya-1280w-1-672x405.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-sir-wade-neistadt-wk83-robot-bts-maya-1280w-1-768x463.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-sir-wade-neistadt-wk83-robot-bts-maya-1280w-1-746x450.png 746w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-sir-wade-neistadt-wk83-robot-bts-maya-1280w-1-356x215.png 356w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-sir-wade-neistadt-wk83-robot-bts-maya-1280w-1-166x100.png 166w" sizes="(max-width: 722px) 100vw, 722px" /><i>The making of Sir Wade’s VFX robot animation</i></p>
<p>3D artists at NVIDIA are also experiencing the power of Maya and OpenUSD. Technical specialist <a href="https://www.linkedin.com/in/lee-fraser/" target="_blank" rel="noopener">Lee Fraser</a> led the “Ferret-Tale Project” to showcase character creation and animation workflows enabled by OpenUSD and <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/">generative AI</a>.</p>
<p>To create the demo, Fraser and his team collaborated across 3D applications like Blender, Autodesk Maya and Reallusion Character Creator through <a href="https://www.nvidia.com/en-us/omniverse/ecosystem/">OpenUSD Connectors</a>. This allowed them to reduce the data prep and import and export time that’s usually required when working with multiple data sources.</p>
<p>“My favorite thing about using OpenUSD is not having to think about where the 3D files I use originated from,” Fraser said. “It was also easy to use USD layers to experiment with applying different animation clips with different characters.”</p>
<p><iframe loading="lazy" title="The Making of an OpenUSD and Generative AI Ferret-Tale" width="500" height="281" src="https://www.youtube.com/embed/mYcTbOV334Q?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Members of the creative community joined a recent livestream to share their workflows using Autodesk tools, OpenUSD and <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, a development platform for connecting and building OpenUSD-based tools and applications.</p>
<p>Whether adjusting lighting conditions in an environment or looking at building designs from the street view, designers in architecture, engineering, construction and operations are advancing their work with AI. Learn more by watching the replay:</p>
<p><iframe loading="lazy" title="Architecting 3D Environments With Autodesk and OpenUSD" width="500" height="281" src="https://www.youtube.com/embed/jJhwq3uO_Uk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Shaping the Future of 3D With More Efficient Workflows</b></h2>
<p>AU 2023 attendees experienced how Autodesk is <a href="https://www.autodesk.com/customer-value/me/maya">enhancing Maya</a> with its new OpenUSD plug-in to provide additional practical workflows for various production processes. The software’s latest features include:</p>
<ul>
<li><strong>Simplified asset sharing:</strong> Designers can now use relative paths when creating OpenUSD stages, allowing for easy asset sharing between different systems. This includes support for sublayers, references, payloads and textures.</li>
<li><strong>Enhanced control:</strong> Plug-in developers and technical directors can overwrite the default prim writers in Maya USD to gain complete control over their OpenUSD exports.</li>
</ul>
<p>Plus, Autodesk introduced impressive capabilities to <a href="https://help-staging.autodesk.com/view/MAYAUL/2024/ENU/?guid=GUID-3C97F007-F02A-43AD-A4A4-3590E120DA1D">LookdevX in Maya</a>, a look-development tool that lets users create OpenUSD shade graphs and custom materials in Maya. These new features include:</p>
<ul>
<li><b>Streamlined shader creation:</b> Users can employ a unified shader workflow, replacing the need for multiple shaders. They can select their desired shader type within the parameters panel, with intuitive error messages guiding them to the correct selection.</li>
<li><b>Efficient operations:</b> Creators can copy, paste and duplicate shaders and materials using the Outliner and LookdevX tool sets, with the option to include or exclude connections.</li>
<li><b>Seamless color management:</b> LookdevX in Maya integrates with color managers in other digital content creation apps to ensure accurate color representation. Color management data is precisely embedded in USD files for accurate reading.</li>
<li><b>Advanced graphing:</b> Users can explore advanced graphing options with the integrated component workflow, supporting multichannel Extended Dynamic Range (EXR) workflows within USD, MaterialX or Arnold shading graphs.</li>
<li><b>Efficient troubleshooting: </b>Solo nodes enable faster look-development workflows and efficient graph troubleshooting. Users can inspect renders of upstream nodes, supporting both Autodesk Arnold and MaterialX graphs, including materials, shaders and compounds.</li>
</ul>
<p style="text-align: center;"><img loading="lazy" decoding="async" class=" wp-image-68131 aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/Picture1.png" alt="" width="587" height="330" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/Picture1.png 480w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Picture1-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Picture1-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Picture1-178x100.png 178w" sizes="(max-width: 587px) 100vw, 587px" /><i>Access to default prim options in Maya UI</i></p>
<h2><b>Get Plugged Into the World of OpenUSD</b></h2>
<p>Anyone can build their own <a href="https://developer.nvidia.com/omniverse">Omniverse extension or Connector</a> to enhance their 3D workflows and tools. Explore the Omniverse ecosystem’s <a href="https://www.nvidia.com/en-us/omniverse/ecosystem/">growing catalog</a> of connections, extensions, foundation applications and third-party tools.</p>
<p>Autodesk and NVIDIA are founding members of the <a href="https://aousd.org/">Alliance for OpenUSD</a> (AOUSD), together strengthening an open future with USD. To learn more, explore the <a href="https://forum.aousd.org/">AOUSD forum</a> and check out <a href="https://developer.nvidia.com/usd">resources on OpenUSD</a>.</p>
<p>Share your Autodesk Maya and Omniverse work through November as part of the <a href="https://forums.developer.nvidia.com/t/the-new-community-challenge-is-here-we-are-kicking-off-the-seasonalartchallenge/268346">#SeasonalArtChallenge</a>. Use the hashtag to submit an autumn harvest-themed scene for a chance to be featured on the @NVIDIAStudio and @NVIDIAOmniverse social channels.</p>
<p><i>Get started with NVIDIA Omniverse by downloading the standard license </i><a href="https://www.nvidia.com/en-us/omniverse/download/"><i>free</i></a><i>, or learn how </i><a href="https://www.nvidia.com/en-us/omniverse/enterprise/"><i>Omniverse Enterprise</i><i> can connect your team</i></a><i>. </i></p>
<p><i>Developers can check out these </i><a href="https://docs.omniverse.nvidia.com/dev-guide/latest/index.html"><i>Omniverse resources</i></a><i> to begin building on the platform. </i></p>
<p><i>Stay up to date on the platform by subscribing to the </i><a href="https://nvda.ws/3u5KPv1"><i>newsletter</i></a><i> and following NVIDIA Omniverse on </i><a href="https://www.instagram.com/nvidiaomniverse/"><i>Instagram</i></a><i>, </i><a href="https://www.linkedin.com/showcase/nvidia-omniverse"><i>LinkedIn</i></a><i>, </i><a href="https://medium.com/@nvidiaomniverse"><i>Medium</i></a><i>, </i><a href="https://www.threads.net/@nvidiaomniverse"><i>Threads</i></a><i> and </i><a href="https://twitter.com/nvidiaomniverse"><i>Twitter</i></a><i>.</i></p>
<p><i>For more, check out our </i><a href="https://forums.developer.nvidia.com/c/omniverse/300"><i>forums</i></a><i>, </i><a href="https://discord.com/invite/XWQNJDNuaC"><i>Discord server</i></a><i>, </i><a href="https://www.twitch.tv/nvidiaomniverse"><i>Twitch</i></a><i> and </i><a href="https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA"><i>YouTube</i></a><i> channels..</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/Copy-of-nv-ov-ito-1280x680_nov-autodesk.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/Copy-of-nv-ov-ito-1280x680_nov-autodesk-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Into the Omniverse: OpenUSD Enhancements for Autodesk Maya Make 3D Workflows a Ferret-Tale]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>More Games, More Wins: PC Game Pass Included With Six-Month GeForce NOW Memberships</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-nov-16/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 16 Nov 2023 14:00:44 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68198</guid>

					<description><![CDATA[The fastest way to give the gift of cloud gaming starts this GFN Thursday: For a limited time, every six-month GeForce NOW Ultimate membership includes three months of PC Game Pass. Also, the newest GeForce NOW app update is rolling out to members, including Xbox Game Syncing and more improvements. Plus, take advantage of a <a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-nov-16/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The fastest way to give the gift of cloud gaming starts this GFN Thursday: For a limited time, every six-month <a href="https://www.nvidia.com/en-us/geforce-now/memberships/">GeForce NOW Ultimate membership</a> includes three months of PC Game Pass.</p>
<p>Also, the newest GeForce NOW app update is rolling out to members, including Xbox Game Syncing and more improvements.</p>
<p>Plus, take advantage of a heroic, new members-only <i>Guild Wars 2</i> reward. It’s all topped off by support for 18 more games in the GeForce NOW library this week.</p>
<h2><b>Give the Gift of Gaming</b></h2>
<figure id="attachment_68212" aria-describedby="caption-attachment-68212" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-68212" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-PC_Game_Pass_Titles-672x336.jpg" alt="PC Game Pass bundle" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-PC_Game_Pass_Titles-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-PC_Game_Pass_Titles-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-PC_Game_Pass_Titles-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-PC_Game_Pass_Titles-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-PC_Game_Pass_Titles-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-PC_Game_Pass_Titles-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-PC_Game_Pass_Titles-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-PC_Game_Pass_Titles-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-PC_Game_Pass_Titles.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68212" class="wp-caption-text"><em>Pair PC Game Pass with a GeForce NOW Ultimate bundle for the ultimate gaming gift.</em></figcaption></figure>
<p>Unwrap the gift of gaming: For a limited time, gamers who sign up for the six-month GeForce NOW Ultimate membership will also receive three free months of PC Game Pass — a $30 value.</p>
<p>With it, Ultimate members can play a collection of high-quality Xbox PC titles with the power of a GeForce RTX 4080 rig in the cloud. Jump into the action in iconic franchises like <i>Age of Empires</i>, <i>DOOM</i>, <i>Forza</i> and more, with support for more titles added every GFN Thursday.</p>
<p>Seamlessly launch supported favorites across nearly any device at up to 4K and 120 frames per second or at up to 240 fps with <a href="https://www.nvidia.com/en-us/geforce/technologies/reflex/">NVIDIA Reflex</a> technology in supported titles for lowest-latency streaming.</p>
<p>This special offer is only here for a limited time, so <a href="https://www.nvidia.com/en-us/geforce-now/holiday">upgrade</a> today.</p>
<h2><b>Sync’d Up</b></h2>
<figure id="attachment_68209" aria-describedby="caption-attachment-68209" style="width: 606px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-68209" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Xbox_Ubisoft-606x500.jpg" alt="Xbox and Ubisoft+ game library sync" width="606" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Xbox_Ubisoft-606x500.jpg 606w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Xbox_Ubisoft-400x330.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Xbox_Ubisoft-545x450.jpg 545w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Xbox_Ubisoft-261x215.jpg 261w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Xbox_Ubisoft-121x100.jpg 121w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Xbox_Ubisoft.jpg 623w" sizes="(max-width: 606px) 100vw, 606px" /><figcaption id="caption-attachment-68209" class="wp-caption-text"><em>Look who just joined the party!</em></figcaption></figure>
<p>With so many games ready to stream, it might be hard to decide what to play next. The latest GeForce NOW app update, currently rolling out to members, is here to help.</p>
<p>Members can now connect their Xbox accounts to GeForce NOW to sync the games they own to their GeForce NOW library. Game syncing lets members connect their digital game store accounts to GeForce NOW, so all of their supported games are part of their streaming library. Syncing an Xbox account will also add any supported titles a member has access to via PC Game Pass — perfect for members taking advantage of the latest Ultimate bundle.</p>
<p>The new update also adds benefits for Ubisoft+ subscribers. With a linked Ubisoft+ account, members can now launch supported Ubisoft+ games they already own from the GeForce NOW app, and the game will be automatically added to “My Library.” Get more details on <a href="https://nvidia.custhelp.com/app/answers/detail/a_id/5286">Ubisoft account</a> linking.</p>
<p>Version 2.0.58 also includes an expansion of the new game session diagnostic tools to help members ensure they’re streaming at optimal quality. It adds codec information to the in-stream statistics overlay and includes other miscellaneous bug fixes. The update should be available for all members soon.</p>
<h2><b>A Heroic Offering</b></h2>
<figure id="attachment_68206" aria-describedby="caption-attachment-68206" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-68206" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Guild_Wars_2_reward-672x336.jpg" alt="Guild Wars 2 reward on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Guild_Wars_2_reward-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Guild_Wars_2_reward-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Guild_Wars_2_reward-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Guild_Wars_2_reward-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Guild_Wars_2_reward-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Guild_Wars_2_reward-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Guild_Wars_2_reward-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Guild_Wars_2_reward-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Guild_Wars_2_reward.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68206" class="wp-caption-text"><em>Rewards fit for a hero.</em></figcaption></figure>
<p>This week, members can receive <i>Guild Wars 2</i> “Heroic Edition,” which includes a treasure trove of goodies, such as the base game, Legacy Armor, an 18-slot inventory expansion and four heroic Boosters. It’s the perfect way to jump into ArenaNet’s critically acclaimed, free-to-play, massively multiplayer online role-playing game.</p>
<p>It’s easy to get membership rewards for streaming games on the cloud. Visit the <a href="https://www.nvidia.com/en-us/geforce-now/rewards/">GeForce NOW Rewards portal</a> and update the settings to receive special offers and in-game goodies.</p>
<p>Members can also sign up for the GeForce NOW newsletter, which includes reward notifications, by logging into their <a href="https://www.nvidia.com/en-us/account/email-preferences">NVIDIA account</a> and selecting “Preferences” from the header. Check the “Gaming &amp; Entertainment” box and “GeForce NOW” under topic preferences.</p>
<h2><b>Ready, Set, Go</b></h2>
<figure id="attachment_68203" aria-describedby="caption-attachment-68203" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-68203" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Remnant_2_DLC-672x336.jpg" alt="Remnant II DLC on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Remnant_2_DLC-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Remnant_2_DLC-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Remnant_2_DLC-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Remnant_2_DLC-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Remnant_2_DLC-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Remnant_2_DLC-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Remnant_2_DLC-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Remnant_2_DLC-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Remnant_2_DLC.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68203" class="wp-caption-text"><em>A new DLC awakens.</em></figcaption></figure>
<p>The first downloadable content for Gearbox’s <i>Remnant 2</i> arrives in the cloud. <i>The Awakened King </i>brings a new storyline, area, archetype and more to the dark fantasy co-op shooter — stream it today to experience the awakening of the One True King as he seeks revenge against all who oppose him.</p>
<p>Catch even more action with the 18 newly supported games in the cloud:</p>
<ul>
<li><i>Spirittea </i>(New release on <a href="https://store.steampowered.com/app/1931010?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Nov. 13)</li>
<li><i>KarmaZoo </i>(New release on <a href="https://store.steampowered.com/app/1661630?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Nov. 14)</li>
<li><i>Naheulbeuk’s Dungeon Master </i>(New release on <a href="https://store.steampowered.com/app/2005160?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Nov. 15)</li>
<li><i>Warhammer Age of Sigmar: Realms of Ruin </i>(New release on <a href="https://store.steampowered.com/app/1844380?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Nov. 17)</li>
<li><i>Arcana of Paradise —The Tower </i>(<a href="https://store.steampowered.com/app/2089500/Arcana_of_Paradise_The_Tower/">Steam</a>)</li>
<li><i>Blazing Sails: Pirate Battle Royale</i> (<a href="https://www.epicgames.com/store/p/blazing-sails?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Disney Dreamlight Valley</i> (<a href="https://www.xbox.com/games/store/disney-dreamlight-valley/9NSF0BGH8D86?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Hello Neighbor 2</i> (<a href="https://www.xbox.com/games/store/hello-neighbor-2/9N961B11FJ4W?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Overcooked! 2 </i>(<a href="https://www.xbox.com/en-us/games/store/Overcooked-2/BVJLKDG2TX8H">Xbox</a>, available on PC Game Pass)</li>
<li><i>RoboCop: Rogue City </i>(New release on <a href="https://www.epicgames.com/store/p/robocop-rogue-city?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Roboquest </i>(<a href="https://www.xbox.com/games/store/roboquest-game-preview/9p47s7njgwzl?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Rune Factory 4 Special </i>(<a href="https://www.xbox.com/games/store/rune-factory-4-special---windows-edition/9N73PLHJN878?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Settlement Survival </i>(<a href="https://store.steampowered.com/app/1509510?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>SOULVARS </i>(<a href="https://store.steampowered.com/app/2087910?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>State of Decay: Year-One Survival Edition</i> (<a href="https://store.steampowered.com/app/329430?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>The Wonderful One: After School Hero </i>(<a href="https://store.steampowered.com/app/2399600?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Wolfenstein: The New Order </i>(<a href="https://www.xbox.com/games/store/wolfenstein-the-new-order-pc/9p75cbj9wt9w?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Wolfenstein: The Old Blood </i>(<a href="https://store.steampowered.com/app/350080?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.epicgames.com/store/p/wolfenstein-the-old-blood?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, <a href="https://www.xbox.com/games/store/wolfenstein-the-old-blood-pc/9pbb4qhmsdkr?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox </a>and available on PC Game Pass)</li>
</ul>
<p>What are you looking forward to streaming? Let us know on <a href="https://www.twitter.com/nvidiagfn">Twitter</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="in" dir="ltr">h̴e̴r̴e̴&#39;̴s̴ soon&#39;s the deal&#8230;</p>
<p>stay tuned <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f440.png" alt="👀" class="wp-smiley" style="height: 1em; max-height: 1em;" /><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f384.png" alt="🎄" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1724834650688758068?ref_src=twsrc%5Etfw">November 15, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/gfn-thursday-date-nv-blog-1280x680-no-cta.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/gfn-thursday-date-nv-blog-1280x680-no-cta-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[More Games, More Wins: PC Game Pass Included With Six-Month GeForce NOW Memberships]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
	</channel>
</rss>
