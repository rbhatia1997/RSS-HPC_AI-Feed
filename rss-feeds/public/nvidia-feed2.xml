<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>News Releases - NVIDIA Newsroom</title><link>https://nvidianews.nvidia.com</link><description>All News</description><language>en-us</language><pubDate>Thu, 06 Jun 2024 22:14:10 GMT</pubDate><lastBuildDate>Thu, 06 Jun 2024 22:14:10 GMT</lastBuildDate><generator>iPressroom</generator><item><title>Here Comes a New Challenger: ‘Street Fighter 6’ Joins GeForce NOW</title><link>https://blogs.nvidia.com/blog/geforce-now-thursday-street-fighter-6-xdefiant/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/6661b36e3d6332f2edb6781d_gfn-thursday-6-6-nv-blog-1280x680-no-copy-842x450/gfn-thursday-6-6-nv-blog-1280x680-no-copy-842x450_thmb.jpg" fileSize="54221" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/6661b36e3d6332f2edb6781d_gfn-thursday-6-6-nv-blog-1280x680-no-copy-842x450/gfn-thursday-6-6-nv-blog-1280x680-no-copy-842x450_thmb.jpg" alt="gfn-thursday-6-6-nv-blog-1280x680-no-copy-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Thu, 06 Jun 2024 13:02:41 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Capcom’s latest entry in the iconic Street Fighter series, Street Fighter 6, punches its way into the cloud this GFN Thursday. The game, along with Ubisoft’s XDefiant, leads six new games joining the GeForce NOW library. A new reward makes its way to the cloud gaming service’s Ultimate and Priority members. For a limited time,	<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-street-fighter-6-xdefiant/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>GeForce NOW Community</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/geforce-now-thursday-street-fighter-6-xdefiant/</guid><pubDate>Thu, 06 Jun 2024 13:00:08 GMT</pubDate></item><item><title>Creativity Accelerated: New RTX-Powered AI Hardware and Software Announced at COMPUTEX</title><link>https://blogs.nvidia.com/blog/rtx-ai-pc-studio-computex/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/666063af3d6332a404f8e36b_computex-2024-nv-blog-header-preview-1280x680-1-842x450/computex-2024-nv-blog-header-preview-1280x680-1-842x450_thmb.jpg" fileSize="41445" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/666063af3d6332a404f8e36b_computex-2024-nv-blog-header-preview-1280x680-1-842x450/computex-2024-nv-blog-header-preview-1280x680-1-842x450_thmb.jpg" alt="computex-2024-nv-blog-header-preview-1280x680-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Wed, 05 Jun 2024 13:10:11 GMT</modDate><relatedPages></relatedPages><description><![CDATA[NVIDIA launched NVIDIA Studio at COMPUTEX in 2019. Five years and more than 500 NVIDIA RTX-accelerated apps and games later, it’s bringing AI to even more creators with an array of new RTX technology integrations announced this week at COMPUTEX 2024.]]></description><author>Gerardo Delgado</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/rtx-ai-pc-studio-computex/</guid><pubDate>Wed, 05 Jun 2024 13:00:59 GMT</pubDate></item><item><title>Yotta CEO Sunil Gupta on Supercharging India’s Fast-Growing AI Market</title><link>https://blogs.nvidia.com/blog/yotta-ceo-supercharging-indias-ai-market/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202403/66041919ed6ae53d65ee6ca6_ai-podcast-2600x1472_-1-842x450/ai-podcast-2600x1472_-1-842x450_thmb.jpg" fileSize="34385" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202403/66041919ed6ae53d65ee6ca6_ai-podcast-2600x1472_-1-842x450/ai-podcast-2600x1472_-1-842x450_thmb.jpg" alt="ai-podcast-2600x1472_-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Wed, 05 Jun 2024 16:52:29 GMT</modDate><relatedPages></relatedPages><description><![CDATA[India’s AI market is expected to be massive. Yotta Data Services is setting its sights on supercharging it. In this episode of NVIDIA’s AI Podcast, Sunil Gupta, cofounder, managing director and CEO of Yotta Data Services, speaks with host Noah Kravitz about the company’s Shakti Cloud offering, which provides scalable GPU services for enterprises of	<a class="read-more" href="https://blogs.nvidia.com/blog/yotta-ceo-supercharging-indias-ai-market/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Kristen Yee</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/yotta-ceo-supercharging-indias-ai-market/</guid><pubDate>Wed, 05 Jun 2024 13:00:51 GMT</pubDate></item><item><title>SAP and NVIDIA Create AI for ‘The Most Valuable Language,’ CEOs Unveil at Sapphire Orlando</title><link>https://blogs.nvidia.com/blog/sap-sapphire-ai-omniverse/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665f3b9d3d63327d92122416_SAP_SAPPHIRE24_11938-002-842x450/SAP_SAPPHIRE24_11938-002-842x450_thmb.jpg" fileSize="33925" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665f3b9d3d63327d92122416_SAP_SAPPHIRE24_11938-002-842x450/SAP_SAPPHIRE24_11938-002-842x450_thmb.jpg" alt="SAP_SAPPHIRE24_11938-002-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Tue, 04 Jun 2024 16:06:56 GMT</modDate><relatedPages></relatedPages><description><![CDATA[German enterprise cloud leader SAP is harnessing generative AI and industrial digital twins in the development of next-generation enterprise applications for its customers. At SAP’s Sapphire event today, in Orlando, Florida, NVIDIA and the enterprise software company unveiled generative AI efforts featuring NVIDIA AI Enterprise software to offer two new capabilities for Joule, SAP’s generative	<a class="read-more" href="https://blogs.nvidia.com/blog/sap-sapphire-ai-omniverse/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Erik Pounds</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/sap-sapphire-ai-omniverse/</guid><pubDate>Tue, 04 Jun 2024 16:00:46 GMT</pubDate></item><item><title>NVIDIA and Cisco Weave Fabric for Generative AI</title><link>https://blogs.nvidia.com/blog/cisco-nexus-hyperfabric-nim/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665f31b33d6332742d071272_corp-blog-nvidia-cisco-lockup-1280x680-1-842x450/corp-blog-nvidia-cisco-lockup-1280x680-1-842x450_thmb.jpg" fileSize="6911" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665f31b33d6332742d071272_corp-blog-nvidia-cisco-lockup-1280x680-1-842x450/corp-blog-nvidia-cisco-lockup-1280x680-1-842x450_thmb.jpg" alt="corp-blog-nvidia-cisco-lockup-1280x680-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Tue, 04 Jun 2024 15:24:39 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Building and deploying AI applications at scale requires a new class of computing infrastructure — one that can handle the massive amounts of data, compute power and networking bandwidth needed by generative AI models. To better ensure these models perform optimally and efficiently, NVIDIA is teaming with Cisco to enable enterprise generative AI infrastructure. Cisco’s	<a class="read-more" href="https://blogs.nvidia.com/blog/cisco-nexus-hyperfabric-nim/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Kevin Deierling</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/cisco-nexus-hyperfabric-nim/</guid><pubDate>Tue, 04 Jun 2024 15:06:40 GMT</pubDate></item><item><title>Digital Bank Debunks Financial Fraud With Generative AI</title><link>https://blogs.nvidia.com/blog/bunq-financial-services-generative-ai/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665d6c463d6332ad80bd1b22_bunq-1280x680-1-842x450/bunq-1280x680-1-842x450_thmb.jpg" fileSize="63395" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665d6c463d6332ad80bd1b22_bunq-1280x680-1-842x450/bunq-1280x680-1-842x450_thmb.jpg" alt="bunq-1280x680-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Mon, 03 Jun 2024 07:10:01 GMT</modDate><relatedPages></relatedPages><description><![CDATA[European neobank bunq is debunking financial fraudsters with the help of NVIDIA accelerated computing and AI. Dubbed “the bank of the free,” bunq offers online banking anytime, anywhere. Through the bunq app, users can handle all their financial needs exclusively online, without needing to visit a physical bank. With more than 12 million customers and	<a class="read-more" href="https://blogs.nvidia.com/blog/bunq-financial-services-generative-ai/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Angie Lee</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/bunq-financial-services-generative-ai/</guid><pubDate>Mon, 03 Jun 2024 07:00:28 GMT</pubDate></item><item><title>‘Accelerate Everything,’ NVIDIA CEO Says Ahead of COMPUTEX</title><link>https://blogs.nvidia.com/blog/temp-computex-2024-jensen-huang/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665c7edbed6ae5363fd6c303_earth-computex-2024-842x450/earth-computex-2024-842x450_thmb.jpg" fileSize="103649" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665c7edbed6ae5363fd6c303_earth-computex-2024-842x450/earth-computex-2024-842x450_thmb.jpg" alt="earth-computex-2024-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Sun, 02 Jun 2024 14:22:44 GMT</modDate><relatedPages></relatedPages><description><![CDATA[“Generative AI is reshaping industries and opening new opportunities for innovation and growth,” NVIDIA founder and CEO Jensen Huang said in an address ahead of this week’s COMPUTEX technology conference in Taipei. “Today, we’re at the cusp of a major shift in computing,” Huang told the audience, clad in his trademark black leather jacket. “The	<a class="read-more" href="https://blogs.nvidia.com/blog/temp-computex-2024-jensen-huang/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Brian Caulfield</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/temp-computex-2024-jensen-huang/</guid><pubDate>Sun, 02 Jun 2024 14:12:00 GMT</pubDate></item><item><title>KServe Providers Dish Up NIMble Inference in Clouds and Data Centers</title><link>https://blogs.nvidia.com/blog/kserve-nim-inference/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665c72693d6332d7fc1091cc_NIM-Kubernetes-logos-1-842x450/NIM-Kubernetes-logos-1-842x450_thmb.jpg" fileSize="6845" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665c72693d6332d7fc1091cc_NIM-Kubernetes-logos-1-842x450/NIM-Kubernetes-logos-1-842x450_thmb.jpg" alt="NIM-Kubernetes-logos-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Sun, 02 Jun 2024 13:23:56 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Deploying generative AI in the enterprise is about to get easier than ever. NVIDIA NIM, a set of generative AI inference microservices, will work with KServe, open-source software that automates putting AI models to work at the scale of a cloud computing application. The combination ensures generative AI can be deployed like any other large	<a class="read-more" href="https://blogs.nvidia.com/blog/kserve-nim-inference/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Adam Tetelman</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/kserve-nim-inference/</guid><pubDate>Sun, 02 Jun 2024 13:14:59 GMT</pubDate></item><item><title>Taiwan Electronics Giants Drive Industrial Automation With NVIDIA Metropolis and NIM</title><link>https://blogs.nvidia.com/blog/computex-metropolis-nim/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665c726d3d6332d7fc1091d2_isaac-robotics-computex24-blog-3261843-1280x680-1-842x450/isaac-robotics-computex24-blog-3261843-1280x680-1-842x450_thmb.jpg" fileSize="55040" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665c726d3d6332d7fc1091d2_isaac-robotics-computex24-blog-3261843-1280x680-1-842x450/isaac-robotics-computex24-blog-3261843-1280x680-1-842x450_thmb.jpg" alt="isaac-robotics-computex24-blog-3261843-1280x680-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Sun, 02 Jun 2024 13:23:59 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Taiwan’s leading consumer electronics giants are making advances with AI automation for manufacturing, as fleets of robots and millions of cameras and sensors drive efficiencies across the smart factories of the future. Dozens of electronics manufacturing and automation specialists — including Foxconn, Pegatron and Wistron — are showcasing their use of the NVIDIA software at	<a class="read-more" href="https://blogs.nvidia.com/blog/computex-metropolis-nim/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Adam Scraba</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/computex-metropolis-nim/</guid><pubDate>Sun, 02 Jun 2024 13:12:33 GMT</pubDate></item><item><title>Foxconn Trains Robots, Streamlines Assembly With NVIDIA AI and Omniverse</title><link>https://blogs.nvidia.com/blog/foxconn-digital-twin-ai/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665c6fdc3d6332d5802420f4_robotic-factory-842x450/robotic-factory-842x450_thmb.jpg" fileSize="83873" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665c6fdc3d6332d5802420f4_robotic-factory-842x450/robotic-factory-842x450_thmb.jpg" alt="robotic-factory-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Sun, 02 Jun 2024 13:13:03 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Foxconn operates more than 170 factories around the world — the latest one a virtual plant pushing the state of the art in industrial automation. It’s the digital twin of a new factory in Guadalajara, hub of Mexico’s electronics industry. Foxconn’s engineers are defining processes and training robots in this virtual environment, so the physical	<a class="read-more" href="https://blogs.nvidia.com/blog/foxconn-digital-twin-ai/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Madison Huang</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/foxconn-digital-twin-ai/</guid><pubDate>Sun, 02 Jun 2024 13:02:56 GMT</pubDate></item><item><title>NVIDIA Enables Real-Time Healthcare, Industrial and Scientific AI Applications at the Edge With Enterprise Software Support for NVIDIA IGX With Holoscan</title><link>https://nvidianews.nvidia.com/news/real-time-healthcare-industrial-scientific-ai-applications-igx-holoscan</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/665b84cd3d633215748faa8f_igx-holoscan/igx-holoscan_thmb.jpg" fileSize="237897" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/665b84cd3d633215748faa8f_igx-holoscan/igx-holoscan_thmb.jpg" alt="IGX With Holoscan" align="left" hspace="15" vspace="5" /&gt;</image><subtitle>Medtronic, SETI Institute, Manufacturing Leaders and More Build NVIDIA IGX Systems to Supercharge AI at the Industrial Edge</subtitle><content>&lt;![CDATA[&lt;p&gt;&lt;strong&gt;&lt;span id="docs-internal-guid-3e0fa20e-7fff-84c6-efd9-27aace704ef9"&gt;&lt;span&gt;COMPUTEX&amp;mdash;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;To address the increasing need for real-time AI computing at the industrial edge, NVIDIA today announced the general software availability of NVIDIA AI Enterprise-IGX with &lt;a href="https://www.nvidia.com/en-us/clara/holoscan/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Holoscan&lt;/u&gt;&lt;/a&gt; on the &lt;a href="https://www.nvidia.com/en-us/edge-computing/products/igx/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA IGX&amp;trade; platform&lt;/u&gt;&lt;/a&gt;. Together, they empower solution providers within the medical, industrial and scientific computing sectors to develop and deploy edge AI solutions faster, with enterprise-grade software and support.&lt;/p&gt;

&lt;p&gt;NVIDIA AI Enterprise-IGX is a new offering providing enterprises with unprecedented performance, security and support for the edge computing software stack, streamlining AI-powered operations and the deployment of AI applications at scale. NVIDIA Holoscan is a sensor-processing platform for streamlining the development and deployment of AI and high-performance computing applications to deliver real-time insights.&lt;/p&gt;

&lt;p&gt;By combining NVIDIA AI Enterprise-IGX and Holoscan on IGX, NVIDIA offers an enterprise-grade platform that delivers powerful AI compute, flexible sensor integration, real-time performance and functional safety for the industrial edge &amp;mdash; cutting the time and costs required to build advanced AI solutions across industries.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;As software-defined functionality continues to transform businesses across industries, enterprises are seeking powerful edge AI solutions that can meet their unique performance and regulatory requirements,&amp;rdquo; said Deepu Talla, vice president of robotics and edge computing at NVIDIA. &amp;ldquo;The NVIDIA IGX platform&amp;rsquo;s new capabilities deliver powerful enterprise-grade software from the cloud to the industrial edge, giving customers increased performance, safety and scalability.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NVIDIA IGX Platform Expands&lt;/strong&gt;&lt;br /&gt;
In addition to the introduction of NVIDIA AI Enterprise-IGX with NVIDIA Holoscan, the NVIDIA IGX platform has undergone a &lt;a href="https://developer.nvidia.com/blog/production-ready-enterprise-grade-software-on-nvidia-igx-platform-support-for-nvidia-rtx-6000-ada-and-more/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;major refresh&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;ul type="disc"&gt;
	&lt;li style="margin-top:0.1pt;"&gt;The NVIDIA IGX Orin&amp;trade; 700, previously called the IGX Boardkit, now supports the NVIDIA RTX&amp;trade; 6000 Ada GPU as a new configuration option, delivering up to 1,705 trillion operations per second &amp;mdash; a 7x increase in AI performance compared with using an onboard iGPU. This provides even more computing power at the edge for generative AI and high-performance computing workloads.&lt;/li&gt;
	&lt;li&gt;NVIDIA IGX now supports a new product, the IGX Orin 500 system-on-module, which enables the creation of flexible carrier-board designs and custom configurations without sacrificing enterprise software support.&lt;/li&gt;
	&lt;li style="margin-bottom:0.1pt;"&gt;The &lt;a href="https://blogs.nvidia.com/blog/nvidia-certified-systems-spectrum-x-igx" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA-Certified Systems&amp;trade; program&lt;/u&gt;&lt;/a&gt; has expanded to include the IGX platform, ensuring systems built with IGX are validated to run accelerated AI workloads with optimized performance. Companies including Advantech, ADLINK, Aetina, Ahead, Cosmo Intelligent Medical Devices (a division of Cosmo Pharmaceuticals), Dedicated Computing, Leadtek, Onyx and YUAN are building NVIDIA-Certified IGX systems.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Bringing AI to the Medical Edge&lt;/strong&gt;&lt;br /&gt;
Leading medical technology companies Barco, Karl Storz, Medtronic and Moon Surgical are adopting NVIDIA IGX with Holoscan to accelerate the development of AI-powered solutions for medical diagnostics, surgical copilots, surgical robots, patient care agents and more. Additionally, Johnson &amp;amp; Johnson MedTech is working on how NVIDIA IGX with Holoscan could accelerate the development of AI for Polyphonic, Johnson &amp;amp; Johnson MedTech&amp;rsquo;s digital ecosystem for surgery.&lt;/p&gt;

&lt;p&gt;Healthcare technology provider Medtronic is leveraging NVIDIA IGX with NVIDIA Holoscan for its GI Genius&amp;trade; intelligent endoscopy module designed, developed and manufactured by Cosmo Intelligent Medical Devices. It&amp;rsquo;s the first FDA-cleared, AI-assisted colonoscopy tool to help physicians detect polyps that can lead to colorectal cancer.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;The NVIDIA IGX with Holoscan platform has significantly accelerated our AI innovation in endoscopy,&amp;rdquo; said Raj Thomas, president of endoscopy at Medtronic. &amp;ldquo;By leveraging NVIDIA&amp;#39;s advanced technology, we can focus on developing groundbreaking software applications that ultimately enhance patient outcomes and provide greater support to physicians. This collaboration underscores our commitment to pioneering advancements in medical technology for the benefit of all.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Robotic surgery company Moon Surgical is using IGX with Holoscan to power its Maestro System, a state-of-the-art surgical robotics system designed to assist surgeons with precision and control during minimally invasive procedures.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;NVIDIA&amp;rsquo;s IGX platform with Holoscan accelerated the development of our Maestro System as well as enhance Maestro&amp;rsquo;s capabilities,&amp;rdquo; said Anne Osdoit, CEO of Moon Surgical. &amp;ldquo;Our collaboration with NVIDIA has allowed us to get our intelligent robotic assistant into the hands of surgeons sooner and with more features, enabling us to get valuable feedback on our path to commercialization.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Industrial AI at the Edge&lt;/strong&gt;&lt;br /&gt;
The NVIDIA IGX platform significantly improves functional safety and high-bandwidth sensor processing, transforming factory automation and robotic collaboration with AI.&lt;/p&gt;

&lt;p&gt;ADLINK is using NVIDIA IGX to build industrial-grade edge AI solutions for its manufacturing processes.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;ADLINK leverages NVIDIA IGX and Holoscan to deliver proactive safety capabilities that ensure more efficient, seamless human and robot collaboration,&amp;rdquo; said Stephen Huang, president and chief operating officer at ADLINK. &amp;ldquo;Working with NVIDIA, we continue to drive precision, safety and latency improvements to optimize manufacturing operations like machine movement routing, robotic arm operation and charging-station monitoring all at once.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Edge AI for Exploring Extraterrestrial Worlds&lt;/strong&gt;&lt;br /&gt;
NVIDIA IGX is helping scientific researchers venture into new worlds with AI, transforming radar processing and radio astronomy with real-time edge computing capabilities.&lt;/p&gt;

&lt;p&gt;Nonprofit research organization SETI Institute is leveraging NVIDIA IGX Orin to power radio astronomy capabilities for its Hat Creek Radio Observatory, which aims to detect technologically capable extraterrestrial life.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;The SETI Institute is using the IGX Orin platform&amp;rsquo;s advanced capabilities with the Holoscan sensor-processing platform to enable transformational capabilities in radio astronomy,&amp;rdquo; said Andrew Siemion, Bernard M. Oliver Chair at SETI Institute. &amp;ldquo;We can now stream multiple terabits per second of radio telescope data directly into AI classifiers with minimal overhead and exceptional computational performance, allowing us to process more bandwidth from more antennas to detect weaker and rarer astrophysical phenomena.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Watch NVIDIA founder and CEO &lt;a href="https://www.nvidia.com/en-us/events/computex/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Jensen Huang&amp;rsquo;s COMPUTEX keynote&lt;/u&gt;&lt;/a&gt; to learn the latest on AI computing at the industrial edge.&lt;/p&gt;
]]&gt;</content><categories><category>Press Releases</category></categories><modDate>Sun, 02 Jun 2024 13:03:46 GMT</modDate><relatedPages></relatedPages><description><![CDATA[To address the increasing need for real-time AI computing at the industrial edge, NVIDIA today announced the general software availability of NVIDIA AI Enterprise-IGX with NVIDIA Holoscan on the NVIDIA IGX™ platform. Together, they empower solution providers within the medical, industrial and scientific computing sectors to develop and deploy edge AI solutions faster, with enterprise-grade software and support.]]></description><enclosure url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/igx-holoscan.jpg" length="237897" type="image/jpeg"></enclosure><guid isPermaLink="true">https://nvidianews.nvidia.com/news/real-time-healthcare-industrial-scientific-ai-applications-igx-holoscan</guid><pubDate>Sun, 02 Jun 2024 12:56:00 GMT</pubDate></item><item><title>NVIDIA Robotics Adopted by Industry Leaders for Development of Tens of Millions of AI-Powered Autonomous Machines</title><link>https://nvidianews.nvidia.com/news/robotics-industry-development-ai-autonomous-machines</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/665b84c13d633215728faa89_isaac/isaac_thmb.png" fileSize="2129540" type="image/png"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/665b84c13d633215728faa89_isaac/isaac_thmb.png" alt="Isaac" align="left" hspace="15" vspace="5" /&gt;</image><subtitle>BYD Electronics, Siemens, Teradyne Robotics and Intrinsic, an Alphabet Company, Using NVIDIA Isaac Robotics Platform for Autonomous Robot Arms, Humanoids, Mobile Robots</subtitle><content>&lt;![CDATA[&lt;p&gt;&lt;strong&gt;&lt;span id="docs-internal-guid-a75994eb-7fff-6f0b-5c4e-1963baf7d623"&gt;&lt;span&gt;COMPUTEX&amp;mdash;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;NVIDIA today announced that the world&amp;rsquo;s leaders in robot development are adopting the &lt;a href="https://developer.nvidia.com/isaac" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Isaac&amp;trade; robotics platform&lt;/u&gt;&lt;/a&gt; for the research, development and production of the next generation of AI-enabled autonomous machines and robots.&lt;/p&gt;

&lt;p&gt;BYD Electronics, Siemens, Teradyne Robotics and &lt;a href="https://www.intrinsic.ai/blog/posts/unlocking-new-value-in-industrial-automation-with-ai" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Intrinsic&lt;/u&gt;&lt;/a&gt;, an Alphabet company, are among more than a dozen robotics industry leaders globally that are integrating NVIDIA Isaac accelerated libraries, physically based simulation and AI models into their software frameworks and robot models to make factories, warehouses and distribution centers highly efficient and safer for their human coworkers, and act as intelligent assistants for repetitive or ultra-precise tasks.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;The era of robotics has arrived. Everything that moves will one day be autonomous,&amp;rdquo; said Jensen Huang, founder and CEO of NVIDIA. &amp;ldquo;We are working to accelerate generative physical AI by advancing the NVIDIA robotics stack, including Omniverse for simulation applications, Project GR00T humanoid foundation models and the Jetson Thor robotics computer.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;The Isaac platform features a suite of NVIDIA-accelerated libraries, AI foundation models and simulation technologies that are available today to robot makers to integrate into their technology stacks.&lt;/p&gt;

&lt;ul type="disc"&gt;
	&lt;li style="margin-top:0.1pt;"&gt;&lt;a href="https://developer.nvidia.com/isaac/ros" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA &lt;/u&gt;&lt;u&gt;Isaac ROS&lt;/u&gt;&lt;/a&gt; &amp;mdash; a collection of modular ROS 2 packages that brings NVIDIA-acceleration and AI models to ROS community developers.&lt;/li&gt;
	&lt;li&gt;&lt;a href="https://developer.nvidia.com/isaac/perceptor" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Isaac Perceptor&lt;/u&gt;&lt;/a&gt; &amp;mdash; a reference workflow built on Isaac ROS that provides multi-camera, 3D surround-vision capabilities for AI-based autonomous mobile robots.&lt;/li&gt;
	&lt;li&gt;&lt;a href="https://developer.nvidia.com/isaac/manipulator" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Isaac Manipulator&lt;/u&gt;&lt;/a&gt; &amp;mdash; a reference workflow built on Isaac ROS that simplifies development of AI-enabled robot arms, or manipulators, that can seamlessly perceive, understand and interact with their environments.&lt;/li&gt;
	&lt;li&gt;&lt;a href="https://developer.nvidia.com/isaac/sim" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Isaac Sim&lt;/u&gt;&lt;/a&gt;&amp;trade;&amp;nbsp;&amp;mdash; a reference application for simulating, testing and validating robots in physically based environments, and for generating synthetic data, based on the &lt;a href="https://www.nvidia.com/en-us/omniverse/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Omniverse&lt;/u&gt;&lt;/a&gt;&amp;trade; platform.&lt;/li&gt;
	&lt;li style="margin-bottom:0.1pt;"&gt;&lt;a href="https://developer.nvidia.com/isaac/sim#section-isaac-lab" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Isaac Lab&lt;/u&gt;&lt;/a&gt; &amp;mdash; a reference application in Isaac Sim optimized for reinforcement, imitation and transfer learning for AI robot foundation model training.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Isaac Ecosystem Rapidly Expands&lt;/strong&gt;&lt;br /&gt;
NVIDIA Isaac&amp;rsquo;s early adopters are leaders in robotics and autonomous machine development across Asia, Europe and North America.&lt;/p&gt;

&lt;p&gt;Siemens, global leader in industrial automation software and systems, is using NVIDIA Isaac Sim for its powerful software-in-the-loop capabilities. The Isaac technologies accelerate Siemens development and testing of advanced robotics skills such as SIMATIC Robot PickAI (PRO) and SIMATIC Robot Pack AI. The AI vision software provides cognitive AI-driven capabilities and enables industrial robot systems to autonomously and reliably pick-and-pack arbitrary items without any prior training of the AI by the user. The companies plan to expand their partnership and announce new capabilities later this year at the SPS Expo.&lt;/p&gt;

&lt;p&gt;Siemens delivers industrial-grade AI and is pushing it to the forefront of robotics by seamlessly integrating with automation solutions and making it easy to use when deployed on a NVIDIA-powered Siemens industrial PC foundation, bringing vision AI to the ecosystem of industrial robots.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;AI-powered robots will accelerate the digital transformation of industry and take over repetitive tasks that were previously impossible to automate so we can unlock human potential for more creative and valuable work,&amp;rdquo; said Roland Busch, president and CEO at Siemens AG. &amp;ldquo;Together with NVIDIA, Siemens is empowering our customers and partners to use AI to create new innovations, incorporate them as part of their industrial automation solutions and drive efficiency and competitive advantage.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Intrinsic, a software and AI robotics subsidiary of Alphabet that acquired the Open Source Robotics Corporation in late 2022, has successfully tested &lt;a href="https://blogs.nvidia.com/blog/alphabet-intrinsic-robotics-isaac-manipulator/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Isaac Manipulator in its robot-agnostic software platform&lt;/u&gt;&lt;/a&gt;. Intrinsic has demonstrated, using Manipulator, the potential for a scalable, universally applicable robotic-grasping skill to work across grippers, environments and objects.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;We couldn&amp;rsquo;t have found a better collaborator in NVIDIA, who are helping to pave the way for foundation models to have a profound impact on industrial robotics,&amp;rdquo; said Wendy Tan White, CEO of Intrinsic. &amp;ldquo;As our teams work together on integrating NVIDIA Isaac and Intrinsic&amp;rsquo;s platform, the potential value we can unlock for millions of developers and businesses is immense.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;BYD Group has a strong manufacturing footprint across four major industries, including electronics, automotive, new energy and rail transportation worldwide. Its one subsidiary, BYD Electronics (BYDE), a global leading provider of high-tech and innovative products, is developing a full range of autonomous mobile robots that provide factories with complete logistics solutions using NVIDIA Isaac Sim and Isaac Perceptor.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;BYDE has a strong focus on helping customers accelerate deployment of logistics applications,&amp;rdquo; said Chris Yotive, senior business development director of BYD Electronics. &amp;ldquo;In collaboration with NVIDIA, we have developed advanced autonomous mobile robots powered by NVIDIA Isaac that will improve worker safety, reduce production costs and enhance production intelligence for our customers.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Universal Robots (UR) and Mobile Industrial Robots (MiR), Teradyne Robotics companies, are using NVIDIA Isaac to integrate AI into automation. UR is integrating Isaac Manipulator into its PolyScope X software platform to unlock new cobot solutions. MiR is leveraging Isaac Sim to generate synthetic data and simulate its MiR1200 Pallet Jack for real-world deployments.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;The key to tackling our customers&amp;rsquo; challenges in robotics lies in the industry&amp;rsquo;s ability to work together, in one collective effort,&amp;rdquo; said Ujjwal Kumar, group president of Teradyne Robotics. &amp;ldquo;With NVIDIA Isaac&amp;rsquo;s advanced AI and simulation capabilities plugged into our large installed base of autonomous mobile robots and cobots, we will push the envelope of innovation to achieve swift solutions for multiple industries.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;The NVIDIA Isaac platform is modular, enabling companies to adopt individual or several technologies together.&lt;/p&gt;

&lt;p&gt;Companies leveraging Isaac Perceptor for development of advanced perception-based autonomous mobile robots include: &lt;a href="https://arcb.com/blog/vaux-smart-autonomy-update" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;ArcBest&lt;/u&gt;&lt;/a&gt;, BYD Electronics, &lt;a href="https://www.gideon.ai/?post_type=news_press&amp;amp;p=3680&amp;amp;preview=true" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Gideon&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://idealworks.com/en/news/en/robotics-ecosystem-nvidia-keynote-computex-2024/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;idealworks&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://rgorobotics.ai/#nvidia-rgo-collaboration" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;RGo Robotics&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Companies leveraging Isaac Manipulator for building AI-based robotic arms include: &lt;a href="https://supr.link/Tl95g" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Solomon&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.tm-robot.com/en/tm-news-post/techman-robot-to-showcase-ai-robots-built-on-nvidia-isaac-at-computex/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Techman Robot&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.prnewswire.com/news-releases/vention-to-democratize-industrial-automation-using-nvidia-ai-technologies-302161232.html" rel="nofollow" target="_blank"&gt;&lt;u&gt;Vention&lt;/u&gt;&lt;/a&gt; and Yaskawa.&lt;/p&gt;

&lt;p&gt;Over 100 companies are adopting Isaac Sim to simulate, test and validate robotic applications, including Hexagon, Husqvarna Group and MathWorks. Isaac Lab is being adopted by Agility, Boston Dynamics, Figure AI, Fourier Intelligence and Sanctuary AI.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Robotics Innovation in Action at Computex &lt;/strong&gt;&lt;br /&gt;
In his COMPUTEX keynote, Huang demonstrated robots used in transportation, healthcare and industrial manufacturing. In one demonstration, &lt;a href="https://blogs.nvidia.com/blog/foxconn-digital-twin-ai" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Foxconn&lt;/u&gt;&lt;/a&gt;, the world&amp;rsquo;s largest electronics manufacturer, showcases a &lt;a href="https://blogs.nvidia.com/blog/foxconn-digital-twin-ai" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;fully simulated autonomous factory&lt;/u&gt;&lt;/a&gt; in NVIDIA Omniverse, featuring fleets of AI robots developed by NVIDIA robotics partners, based on NVIDIA Isaac.&lt;/p&gt;

&lt;p&gt;Watch &lt;a href="https://www.nvidia.com/en-us/events/computex/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Huang&amp;rsquo;s COMPUTEX keynote&lt;/u&gt;&lt;/a&gt; to get the latest on AI and more. Read more about the &lt;a href="https://developer.nvidia.com/blog/create-design-and-deploy-robotics-applications-using-new-nvidia-isaac-foundation-models-and-workflows" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;updates available now&lt;/u&gt;&lt;/a&gt; to the NVIDIA Isaac platform.&lt;/p&gt;
]]&gt;</content><categories><category>Press Releases</category></categories><modDate>Sun, 02 Jun 2024 13:36:21 GMT</modDate><relatedPages></relatedPages><description><![CDATA[NVIDIA today announced that the world’s leaders in robot development are adopting the NVIDIA Isaac™ robotics platform for the research, development and production of the next generation of AI-enabled autonomous machines and robots.]]></description><enclosure url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/isaac.png" length="2129540" type="image/png"></enclosure><guid isPermaLink="true">https://nvidianews.nvidia.com/news/robotics-industry-development-ai-autonomous-machines</guid><pubDate>Sun, 02 Jun 2024 12:52:00 GMT</pubDate></item><item><title>Robotic Factories Supercharge Industrial Digitalization as Electronic Makers Adopt NVIDIA AI and Omniverse</title><link>https://nvidianews.nvidia.com/news/robotic-factories-industrial-digitalization-electronic-makers-ai-omniverse</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/665b84ab3d633215798faa89_omniverse-industrial-digitalization/omniverse-industrial-digitalization_thmb.png" fileSize="1328584" type="image/png"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/665b84ab3d633215798faa89_omniverse-industrial-digitalization/omniverse-industrial-digitalization_thmb.png" alt="Omniverse Industrial Digitalization" align="left" hspace="15" vspace="5" /&gt;</image><subtitle>NVIDIA Omniverse, Isaac and Metropolis Enable Delta Electronics, Foxconn, Pegatron, Wistron to Digitally Build, Simulate and Operate Factory Digital Twins</subtitle><content>&lt;![CDATA[&lt;p&gt;&lt;strong&gt;&lt;span id="docs-internal-guid-90158dea-7fff-748c-6fa0-beb32b1d96b4"&gt;&lt;span&gt;COMPUTEX&amp;mdash;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;NVIDIA today announced that major Taiwanese electronics makers are using the company&amp;rsquo;s technology to transform their factories into more autonomous facilities with a new reference workflow. The workflow combines &lt;a href="https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Metropolis&lt;/u&gt;&lt;/a&gt; vision AI, &lt;a href="https://www.nvidia.com/en-us/omniverse/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Omniverse&lt;/u&gt;&lt;/a&gt;&amp;trade; physically based rendering and simulation, and &lt;a href="https://developer.nvidia.com/isaac" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Isaac&lt;/u&gt;&lt;/a&gt;&amp;trade; AI robot development and deployment.&lt;/p&gt;

&lt;p&gt;By using the workflow to build digital twins for real-time simulation of different factory layouts, manufacturers can optimize space, processes and efficiency without costly physical changes.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;AI for manufacturing is here. Every factory is becoming more and more autonomous due to the transformational impact of generative AI and digital twin technologies,&amp;rdquo; said Deepu Talla, vice president of robotics and edge computing at NVIDIA. &amp;ldquo;With NVIDIA Omniverse, Metropolis and Isaac, the industrial ecosystem can accelerate its adoption of autonomous technologies, helping advance operational efficiencies and lower costs.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Electronics Manufacturers Adopt NVIDIA Technology to Build Robotic Facilities&lt;/strong&gt;&lt;br /&gt;
Delta Electronics, Foxconn, &lt;a href="https://svr.pegatroncorp.com/News/6" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Pegatron&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.wistron.com/en/Newsroom/2024-05-31" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Wistron&lt;/u&gt;&lt;/a&gt; are using the reference workflow to build, simulate and operate their robotics-enhanced facilities.&lt;/p&gt;

&lt;p&gt;In a COMPUTEX keynote demo, NVIDIA founder and CEO Jensen Huang demonstrated how Foxconn, one of the world&amp;rsquo;s largest electronics manufacturers, develops digital twins of its factories on NVIDIA Omniverse, a platform for virtually integrating 3D data from leading industry tools such as Teamcenter from the Siemens Xcelerator platform.&lt;/p&gt;

&lt;p&gt;Omniverse helps Foxconn&amp;rsquo;s teams optimize equipment layout for operational flow and AI cameras that will monitor worker safety with NVIDIA Metropolis. Foxconn can then use the &lt;a href="https://blogs.nvidia.com/blog/virtual-factories-industrial-digitalization/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;factory digital twins&lt;/u&gt;&lt;/a&gt; as virtual training environments to simulate, test and validate its autonomous mobile robots (AMRs) built on NVIDIA Isaac Perceptor acceleration libraries, as well as its AI robot manipulation arms, which are powered by NVIDIA Isaac Manipulator AI models.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;AI and robotics are poised to revolutionize manufacturing, enhancing safety on factory floors and driving significant operational efficiencies,&amp;rdquo; said Young Liu, CEO and chairman of Foxconn. &amp;ldquo;By integrating NVIDIA Omniverse, Metropolis and Isaac into our operations, we can create sophisticated digital twins of our factories to train robots, optimizing workflows with unprecedented precision and reducing costs.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://www.nvidia.com/en-us/case-studies/delta-electronics-industrial-innovation/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Delta Electronics&lt;/u&gt;&lt;/a&gt;, a manufacturing leader in electronics and IoT-based smart green solutions, is using &lt;a href="https://developer.nvidia.com/isaac/sim" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Isaac Sim&lt;/u&gt;&lt;/a&gt;&amp;trade;, an extensible robotics simulation platform developed on Omniverse and &lt;a href="https://www.nvidia.com/en-us/omniverse/usd/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;OpenUSD&lt;/u&gt;&lt;/a&gt;, an open and extensible ecosystem for 3D worlds, to virtually integrate its demo production lines. It then generates physically accurate, photorealistic synthetic data for training computer vision models for its NVIDIA Metropolis-powered automatic optical inspection and defect detection solutions.&lt;/p&gt;

&lt;p&gt;Pegatron, a Taiwan-based manufacturer and service provider, is deploying an NVIDIA Metropolis multi-camera workflow and launching a new suite of services that connects its NVIDIA Omniverse and Metropolis &lt;a href="https://developer.nvidia.com/blog/pegatron-simulates-and-optimizes-factory-operations-with-ai-enabled-digital-twins" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;factory digital twin workflow&lt;/u&gt;&lt;/a&gt; to &lt;a href="https://www.nvidia.com/en-us/ai-data-science/products/nemo/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA NeMo&lt;/u&gt;&lt;/a&gt;&amp;trade; and &lt;a href="https://www.nvidia.com/en-us/ai/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA NIM&lt;/u&gt;&lt;/a&gt;&amp;trade; to help factory operators &amp;ldquo;chat&amp;rdquo; in real time. The technological advances will help improve worker safety and productivity in Pegatron&amp;rsquo;s massive factory network that spans over 21 million square feet and produces over 15 million assemblies per month.&lt;/p&gt;

&lt;p&gt;Wistron, a global leader in electronics manufacturing, has &lt;a href="https://developer.nvidia.com/blog/wistron-advances-energy-efficiency-in-manufacturing-with-ai-and-nvidia-omniverse/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;built digital twins of its factories&lt;/u&gt;&lt;/a&gt; to accelerate the production of &lt;a href="https://www.nvidia.com/en-us/data-center/dgx-platform/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA DGX&lt;/u&gt;&lt;/a&gt;&amp;trade; and &lt;a href="https://www.nvidia.com/en-us/data-center/hgx/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA HGX&lt;/u&gt;&lt;/a&gt;&amp;trade; servers. Now, it is extending its use of Omniverse to develop digital twins of the data centers that are used to test and ensure the quality, performance and energy consumption of newly assembled NVIDIA HGX systems.&lt;/p&gt;

&lt;p&gt;Using NVIDIA Omniverse to simulate its facility and workflows first, Wistron brought its factory online in half the typical time &amp;mdash; just two and a half months instead of five &amp;mdash; and increased worker efficiency by more than 50% through testing and optimizing layouts.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;The combination of NVIDIA Omniverse and NVIDIA Metropolis allows us to test new layouts virtually to identify new processes and monitor real-time operations using live IoT data from every machine on the production line,&amp;rdquo; said Alec Lai, president of global manufacturing at Wistron. &amp;ldquo;Digitalizing our factory planning process has reduced end-to-end cycle times by 50%.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ecosystem Expansion to Industrial Applications&lt;/strong&gt;&lt;br /&gt;
Leading Taiwan systems integrator Kenmec is an early implementer of both Omniverse and Metropolis workflows and services for major manufacturers such as Giant Group.&lt;/p&gt;

&lt;p&gt;To help developers across the ecosystem, these digital twin workflows are available as a &lt;a href="https://resources.nvidia.com/en-us-digital-twin-reference-architecture/ov-factory-digital-twin-reference-architecture?lx=MDrctG" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;reference architecture series&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Learn more about the newly available &lt;a href="https://developer.nvidia.com/blog/create-design-and-deploy-robotics-applications-using-new-nvidia-isaac-foundation-models-and-workflows" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;updates to NVIDIA Isaac&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Watch &lt;a href="https://www.nvidia.com/en-us/events/computex/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Huang&amp;rsquo;s COMPUTEX keynote&lt;/u&gt;&lt;/a&gt; to get the latest on AI and industrial digitalization.&lt;/p&gt;
]]&gt;</content><categories><category>Press Releases</category></categories><modDate>Sun, 02 Jun 2024 12:55:40 GMT</modDate><relatedPages></relatedPages><description><![CDATA[NVIDIA today announced that major Taiwanese electronics makers are using the company’s technology to transform their factories into more autonomous facilities with a new reference workflow. The workflow combines NVIDIA Metropolis vision AI, NVIDIA Omniverse™ physically based rendering and simulation, and NVIDIA Isaac™ AI robot development and deployment.]]></description><enclosure url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/omniverse-industrial-digitalization.png" length="1328584" type="image/png"></enclosure><guid isPermaLink="true">https://nvidianews.nvidia.com/news/robotic-factories-industrial-digitalization-electronic-makers-ai-omniverse</guid><pubDate>Sun, 02 Jun 2024 12:44:00 GMT</pubDate></item><item><title>NVIDIA Brings AI Assistants to Life With GeForce RTX AI PCs</title><link>https://nvidianews.nvidia.com/news/nvidia-brings-ai-assistants-to-life-with-geforce-rtx-ai-pcs</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/665bb3a13d63323d708faa8a_rtx-ai-pc/rtx-ai-pc_thmb.png" fileSize="8150868" type="image/png"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/665bb3a13d63323d708faa8a_rtx-ai-pc/rtx-ai-pc_thmb.png" alt="RTX AI PC" align="left" hspace="15" vspace="5" /&gt;</image><subtitle>Project G-Assist, NVIDIA ACE NIMs for Digital Humans, and Generative AI Tools Deliver Advanced AI Experiences on RTX Laptops; Plus, RTX-Accelerated APIs for Small Language Models Coming to Windows Copilot Runtime</subtitle><content>&lt;![CDATA[&lt;p&gt;&lt;span id="docs-internal-guid-1948d9a2-7fff-b06a-8a2d-0f5925b43410"&gt;&lt;/span&gt;&lt;strong&gt;&lt;span id="docs-internal-guid-1948d9a2-7fff-b06a-8a2d-0f5925b43410"&gt;&lt;span&gt;COMPUTEX&amp;mdash;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;NVIDIA today announced new &lt;a href="https://www.nvidia.com/en-us/design-visualization/technologies/rtx/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA RTX&lt;/u&gt;&lt;/a&gt;&amp;trade; technology to power AI assistants and digital humans running on new &lt;a href="https://www.nvidia.com/en-us/geforce/rtx/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;GeForce RTX&lt;/u&gt;&lt;/a&gt;&amp;trade; AI laptops.&lt;/p&gt;

&lt;p&gt;NVIDIA unveiled Project G-Assist &amp;mdash; an RTX-powered AI assistant technology demo that provides context-aware help for PC games and apps. The Project G-Assist tech demo debuted with &lt;em&gt;ARK: Survival Ascended &lt;/em&gt;from Studio Wildcard. NVIDIA also introduced the first PC-based NVIDIA NIM&amp;trade; inference microservices for the &lt;a href="https://developer.nvidia.com/ace" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA ACE&lt;/u&gt;&lt;/a&gt; digital human platform.&lt;/p&gt;

&lt;p&gt;These technologies are enabled by the &lt;a href="https://developer.nvidia.com/rtx/ai-toolkit" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA RTX AI Toolkit&lt;/u&gt;&lt;/a&gt;, a new suite of tools and software development kits that aid developers in optimizing and deploying large generative AI models on Windows PCs. They join NVIDIA&amp;rsquo;s full-stack RTX AI innovations accelerating over 500 PC applications and games and 200 laptop designs from manufacturers.&lt;/p&gt;

&lt;p&gt;In addition, newly announced RTX AI PC laptops from ASUS and MSI feature up to GeForce RTX 4070 GPUs and power-efficient systems-on-a-chip with Windows 11 AI PC capabilities. These Windows 11 AI PCs will receive a free update to Copilot+ PC experiences when available.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;NVIDIA launched the era of AI PCs in 2018 with the release of RTX Tensor Core GPUs and NVIDIA DLSS,&amp;rdquo; said Jason Paul, vice president of consumer AI at NVIDIA. &amp;ldquo;Now, with Project G-Assist and NVIDIA ACE, we&amp;rsquo;re unlocking the next generation of AI-powered experiences for over 100 million RTX AI PC users.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Project G-Assist, a GeForce AI Assistant&lt;/strong&gt;&lt;br /&gt;
AI assistants are set to transform gaming and in-app experiences &amp;mdash; from offering gaming strategies and analyzing multiplayer replays to assisting with complex creative workflows. Project G-Assist is a glimpse into this future.&lt;/p&gt;

&lt;p&gt;PC games offer vast universes to explore and intricate mechanics to master, which are challenging and time-consuming feats even for the most dedicated gamers. Project G-Assist aims to put game knowledge at players&amp;rsquo; fingertips using generative AI.&lt;/p&gt;

&lt;p&gt;Project G-Assist takes voice or text inputs from the player, along with contextual information from the game screen, and runs the data through AI vision models. These models enhance the contextual awareness and app-specific understanding of a large language model (LLM) linked to a game knowledge database, and then generate a tailored response delivered as text or speech.&lt;/p&gt;

&lt;p&gt;NVIDIA partnered with Studio Wildcard to demo the technology with &lt;em&gt;ARK: Survival Ascended&lt;/em&gt;. Project G-Assist can help answer questions about creatures, items, lore, objectives, difficult bosses and more. Because Project G-Assist is context-aware, it personalizes its responses to the player&amp;rsquo;s game session.&lt;/p&gt;

&lt;p&gt;In addition, Project G-Assist can configure the player&amp;rsquo;s gaming system for optimal performance and efficiency. It can provide insights into performance metrics, optimize graphics settings depending on the user&amp;rsquo;s hardware, apply a safe overclock and even intelligently reduce power consumption while maintaining a performance target.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;First ACE PC NIM Debuts&lt;/strong&gt;&lt;br /&gt;
&lt;a href="https://nvidianews.nvidia.com/news/digital-humans-ace-generative-ai-microservices" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA ACE technology&lt;/u&gt;&lt;/a&gt; for powering digital humans is now coming to RTX AI PCs and workstations with NVIDIA NIM &amp;mdash; inference microservices that enable developers to reduce deployment times from weeks to minutes. ACE NIM microservices deliver high-quality inference running locally on devices for natural language understanding, speech synthesis, facial animation and more.&lt;/p&gt;

&lt;p&gt;At COMPUTEX, the gaming debut of NVIDIA ACE NIM on the PC will be featured in the &lt;a href="https://nvidianews.nvidia.com/news/nvidia-digital-human-technologies-bring-ai-characters-to-life-6900750" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Covert Protocol tech demo&lt;/u&gt;&lt;/a&gt;, developed in collaboration with Inworld AI. It now showcases &lt;a href="https://www.nvidia.com/en-us/ai-data-science/audio2face/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Audio2Face&lt;/u&gt;&lt;/a&gt;&amp;trade; and &lt;a href="https://developer.nvidia.com/riva" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Riva&lt;/u&gt;&lt;/a&gt; automatic speech recognition running locally on devices.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Windows Copilot Runtime to Add GPU Acceleration for Local PC SLMs&lt;/strong&gt;&lt;br /&gt;
Microsoft and NVIDIA are collaborating to help developers bring new generative AI capabilities to their Windows native and web apps. This collaboration will provide application developers with easy application programming interface (API) access to GPU-accelerated small language models (SLMs) that enable &lt;a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;retrieval-augmented generation&lt;/u&gt;&lt;/a&gt; (RAG) capabilities that run on-device as part of Windows Copilot Runtime.&lt;/p&gt;

&lt;p&gt;SLMs provide tremendous possibilities for Windows developers, including content summarization, content generation and task automation. RAG capabilities augment SLMs by giving the AI models access to domain-specific information not well represented in &amp;zwnj;base models. RAG APIs enable developers to harness application-specific data sources and tune SLM behavior and capabilities to application needs.&lt;/p&gt;

&lt;p&gt;These AI capabilities will be accelerated by NVIDIA RTX GPUs, as well as AI accelerators from other hardware vendors, providing end users with fast, responsive AI experiences across the breadth of the Windows ecosystem.&lt;/p&gt;

&lt;p&gt;The API will be released in developer preview later this year.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4x Faster, 3x Smaller Models With the RTX AI Toolkit&lt;/strong&gt;&lt;br /&gt;
The AI ecosystem has built hundreds of thousands of open-source models for app developers to leverage, but most models are pretrained for general purposes and built to run in a data center.&lt;/p&gt;

&lt;p&gt;To help developers build application-specific AI models that run on PCs, NVIDIA is introducing &lt;a href="https://developer.nvidia.com/blog/streamline-ai-powered-app-development-with-nvidia-rtx-ai-toolkit-for-windows-rtx-pcs/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;RTX AI Toolkit&lt;/u&gt;&lt;/a&gt; &amp;mdash; a suite of tools and SDKs for model customization, optimization and deployment on RTX AI PCs. RTX AI Toolkit will be available later this month for broader developer access.&lt;/p&gt;

&lt;p&gt;Developers can customize a pretrained model with open-source QLoRa tools. Then, they can use the &lt;a href="https://developer.nvidia.com/tensorrt" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA TensorRT&lt;/u&gt;&lt;/a&gt;&amp;trade; model optimizer to quantize models to consume up to 3x less RAM. NVIDIA TensorRT Cloud then optimizes the model for peak performance across the RTX GPU lineups. The result is up to 4x faster performance compared with the pretrained model.&lt;/p&gt;

&lt;p&gt;The new&amp;nbsp;&lt;a href="https://developer.nvidia.com/rtx/ai-inference-manager" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA AI Inference Manager&lt;/u&gt;&lt;/a&gt;&amp;nbsp;SDK,&amp;nbsp;now available in early access, simplifies the deployment of ACE to PCs. It preconfigures the PC with the necessary AI models, engines and dependencies while orchestrating AI inference seamlessly across PCs and the cloud.&lt;/p&gt;

&lt;p&gt;Software partners such as Adobe, Blackmagic Design and Topaz are integrating components of the RTX AI Toolkit within their popular creative apps to accelerate AI performance on RTX PCs.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;Adobe and NVIDIA continue to collaborate to deliver breakthrough customer experiences across all creative workflows, from video to imaging, design, 3D and beyond,&amp;rdquo; said Deepa Subramaniam, vice president of product marketing, Creative Cloud at Adobe. &amp;ldquo;TensorRT 10.0 on RTX PCs delivers unprecedented performance and AI-powered capabilities for creators, designers and developers, unlocking new creative possibilities for content creation in industry-leading creative tools like Photoshop.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Components of the RTX AI Toolkit, such as TensorRT-LLM, are integrated in popular developer frameworks and applications for generative AI, including Automatic1111, ComfyUI, Jan.AI, LangChain, LlamaIndex, Oobabooga and Sanctum.AI.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;AI for Content Creation&lt;/strong&gt;&lt;br /&gt;
NVIDIA is also integrating RTX AI acceleration into apps for creators, modders and video enthusiasts.&lt;/p&gt;

&lt;p&gt;Last year, NVIDIA introduced RTX acceleration using TensorRT for one of the most popular Stable Diffusion user interfaces, Automatic1111. Starting this week, RTX will also accelerate the highly popular ComfyUI, delivering up to a 60% improvement in performance over the currently shipping version, and 7x faster performance compared with the MacBook Pro M3 Max.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://www.nvidia.com/en-us/geforce/rtx-remix/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA RTX Remix&lt;/u&gt;&lt;/a&gt; is a modding platform for remastering classic DirectX 8 and DirectX 9 games with full ray tracing, NVIDIA DLSS 3.5 and physically accurate materials. RTX Remix includes a runtime renderer and the RTX Remix Toolkit app, which facilitates the modding of game assets and materials.&lt;/p&gt;

&lt;p&gt;Last year, NVIDIA made RTX Remix Runtime open source, allowing modders to &lt;a href="https://www.youtube.com/watch?v=K23Y0fOCRGQ" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;expand game compatibility&lt;/u&gt;&lt;/a&gt; and advance rendering capabilities.&lt;/p&gt;

&lt;p&gt;Since RTX Remix Toolkit launched earlier this year, 20,000 modders have used it to mod &lt;a href="https://www.moddb.com/rtx" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;classic games&lt;/u&gt;&lt;/a&gt;, resulting in over 100 RTX remasters in development on the &lt;a href="https://discord.gg/rtxremix" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;RTX Remix Showcase Discord&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This month, NVIDIA will make the RTX Remix Toolkit open source, allowing modders to streamline how assets are replaced and scenes are relit, increase supported file formats for RTX Remix&amp;rsquo;s asset ingestor and bolster RTX Remix&amp;rsquo;s AI Texture Tools with new models.&lt;/p&gt;

&lt;p&gt;In addition, NVIDIA is making the capabilities of RTX Remix Toolkit accessible via a REST API, allowing modders to livelink RTX Remix to digital content creation tools such as Blender, modding tools such as Hammer and generative AI apps such as ComfyUI. NVIDIA is also providing an SDK for RTX Remix Runtime to allow modders to deploy RTX Remix&amp;rsquo;s renderer into other applications and games beyond DirectX 8 and 9 classics.&lt;/p&gt;

&lt;p&gt;With more of the RTX Remix platform being made open source, modders across the globe can build even more stunning RTX remasters.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://blogs.nvidia.com/blog/rtx-video-hdr-remix-studio-driver/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA RTX Video&lt;/u&gt;&lt;/a&gt;, the popular AI-powered super-resolution feature supported in the Google Chrome, Microsoft Edge and Mozilla Firefox browsers, is now available as an SDK to all developers, helping them natively integrate AI for upscaling, sharpening, compression artifact reduction and high-dynamic range (HDR) conversion.&lt;/p&gt;

&lt;p&gt;Coming soon to video editing software Blackmagic Design&amp;rsquo;s DaVinci Resolve and Wondershare Filmora, RTX Video will enable video editors to upscale lower-quality video files to 4K resolution, as well as convert standard dynamic range source files into HDR. In addition, the free media player VLC media will soon add RTX Video HDR to its existing super-resolution capability.&lt;/p&gt;

&lt;p&gt;Learn more about RTX AI PCs and technology by joining &lt;a href="https://www.nvidia.com/en-us/events/computex/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA at COMPUTEX&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;
]]&gt;</content><categories><category>Press Releases</category></categories><modDate>Sun, 02 Jun 2024 12:46:36 GMT</modDate><relatedPages></relatedPages><description><![CDATA[NVIDIA today announced new NVIDIA RTX™ technology to power AI assistants and digital humans running on new GeForce RTX™ AI laptops.]]></description><enclosure url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/rtx-ai-pc.png" length="8150868" type="image/png"></enclosure><guid isPermaLink="true">https://nvidianews.nvidia.com/news/nvidia-brings-ai-assistants-to-life-with-geforce-rtx-ai-pcs</guid><pubDate>Sun, 02 Jun 2024 12:41:00 GMT</pubDate></item><item><title>Computer Industry Joins NVIDIA to Build AI Factories and Data Centers for the Next Industrial Revolution</title><link>https://nvidianews.nvidia.com/news/computer-industry-ai-factories-data-centers</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/665bb38f3d6332398e8faa8d_blackwell-ai-factories/blackwell-ai-factories_thmb.png" fileSize="980792" type="image/png"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/665bb38f3d6332398e8faa8d_blackwell-ai-factories/blackwell-ai-factories_thmb.png" alt="Blackwell - AI Factories" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><content>&lt;![CDATA[&lt;ul&gt;
	&lt;li style="text-align:left;"&gt;&lt;em&gt;Top Computer Manufacturers Unveil Array of Blackwell-Powered Systems Featuring Grace CPUs, NVIDIA Networking and Infrastructure&lt;/em&gt;&lt;/li&gt;
	&lt;li&gt;&lt;em&gt;Broad Portfolios Encompass Cloud, On-Premises, Embedded and Edge AI Systems&lt;/em&gt;&lt;/li&gt;
	&lt;li&gt;&lt;em&gt;Offerings Range From Single to Multi-GPUs, x86 to Grace, Air to Liquid Cooling&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;span id="docs-internal-guid-22366920-7fff-4a9e-9b19-9684b8287682"&gt;&lt;span&gt;COMPUTEX&amp;mdash;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;NVIDIA and the world&amp;rsquo;s top computer manufacturers today unveiled an array of NVIDIA Blackwell architecture-powered systems featuring Grace CPUs, NVIDIA networking and infrastructure for enterprises to build AI factories and data centers to drive the next wave of generative AI breakthroughs.&lt;/p&gt;

&lt;p&gt;During his COMPUTEX keynote, NVIDIA founder and CEO Jensen Huang announced that &lt;a href="https://www.asrockrack.com/general/news.asp?id=239" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;ASRock Rack&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://servers.asus.com/NEWS/ASUS-Presents-ESC-AI-POD-with-NVIDIA-GB200-NVL72-at-Computex-2024" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;ASUS&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.gigabyte.com/Press/News/2168" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;GIGABYTE&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.foxconn.com.tw/en-us/press-center/press-releases/latest-news" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Ingrasys&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://ebg.inventec.com/en/news/Press%20Release/2024/85" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Inventec&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://svr.pegatroncorp.com/News/6" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Pegatron&lt;/u&gt;&lt;/a&gt;, QCT, Supermicro, Wistron and Wiwynn will deliver cloud, on-premises, embedded and edge AI systems using NVIDIA GPUs and networking.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;The next industrial revolution has begun. Companies and countries are partnering with NVIDIA to shift the trillion-dollar traditional data centers to accelerated computing and build a new type of data center &amp;mdash; AI factories &amp;mdash; to produce a new commodity: artificial intelligence,&amp;rdquo; said Huang. &amp;ldquo;From server, networking and infrastructure manufacturers to software developers, the whole industry is gearing up for Blackwell to accelerate AI-powered innovation for every field.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;To address applications of all types, the offerings will range from single to multi-GPUs, x86- to Grace-based processors, and air- to liquid-cooling technology.&lt;/p&gt;

&lt;p&gt;Additionally, to speed up the development of systems of different sizes and configurations, the &lt;a href="https://www.nvidia.com/en-us/data-center/products/mgx/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA MGX&lt;/u&gt;&lt;/a&gt;&amp;trade; modular reference design platform now supports NVIDIA Blackwell products. This includes the new NVIDIA GB200 NVL2 platform, built to deliver unparalleled performance for mainstream large language model inference, retrieval-augmented generation and data processing.&lt;/p&gt;

&lt;p&gt;GB200 NVL2 is ideally suited for emerging market opportunities such as data analytics, on which companies spend tens of billions of dollars annually. Taking advantage of high-bandwidth memory performance provided by NVLink&lt;sup&gt;&amp;reg;&lt;/sup&gt;-C2C interconnects and dedicated decompression engines in the Blackwell architecture speeds up data processing by up to 18x, with 8x better energy efficiency compared to using x86 CPUs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Modular Reference Architecture for Accelerated Computing&lt;/strong&gt;&lt;br /&gt;
To meet the diverse accelerated computing needs of the world&amp;rsquo;s data centers, NVIDIA MGX provides computer manufacturers with a reference architecture to quickly and cost-effectively build more than 100 system design configurations.&lt;/p&gt;

&lt;p&gt;Manufacturers start with a basic system architecture for their server chassis, and then select their GPU, DPU and CPU to address different workloads. To date, more than 90 systems from over 25 partners have been released or are in development that leverage the MGX reference architecture, up from 14 systems from six partners last year. Using MGX can help slash development costs by up to three-quarters and reduce development time by two-thirds, to just six months.&lt;/p&gt;

&lt;p&gt;AMD and Intel are supporting the MGX architecture with plans to deliver, for the first time, their own CPU host processor module designs. This includes the next-generation AMD Turin platform and the Intel&lt;sup&gt;&amp;reg;&lt;/sup&gt; Xeon&lt;sup&gt;&amp;reg;&lt;/sup&gt; 6 processor with P-cores (formerly codenamed Granite Rapids). Any server system builder can use these reference designs to save development time while ensuring consistency in design and performance.&lt;/p&gt;

&lt;p&gt;NVIDIA&amp;rsquo;s latest platform, the GB200 NVL2, also leverages MGX and Blackwell. Its scale-out, single-node design enables a wide variety of system configurations and networking options to seamlessly integrate accelerated computing into existing data center infrastructure.&lt;/p&gt;

&lt;p&gt;The GB200 NVL2 joins the Blackwell product lineup, which also includes NVIDIA Blackwell Tensor Core GPUs, GB200 Grace Blackwell Superchips and the GB200 NVL72.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;An Ecosystem Unites&lt;/strong&gt;&lt;br /&gt;
NVIDIA&amp;rsquo;s comprehensive partner ecosystem includes TSMC, the world&amp;rsquo;s leading semiconductor manufacturer and an NVIDIA foundry partner, as well as global electronics makers, which provide key components to create AI factories. These include manufacturing innovations such as server racks, power delivery, cooling solutions and more from companies such as Amphenol, Asia Vital Components (AVC), Cooler Master, Colder Products Company (CPC), Danfoss, Delta Electronics and LITEON.&lt;/p&gt;

&lt;p&gt;As a result, new data center infrastructure can quickly be developed and deployed to meet the needs of the world&amp;rsquo;s enterprises &amp;mdash; and further accelerated by Blackwell technology, &lt;a href="https://www.nvidia.com/en-us/networking/quantum2/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Quantum-2&lt;/u&gt;&lt;/a&gt; or &lt;a href="https://www.nvidia.com/en-us/networking/products/infiniband/quantum-x800/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Quantum-X800 InfiniBand networking&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.nvidia.com/en-us/networking/products/ethernet/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Spectrum&amp;trade;-X Ethernet&lt;/u&gt;&lt;/a&gt; networking and &lt;a href="https://www.nvidia.com/en-us/networking/products/data-processing-unit/" rel="nofollow" target="_blank" title=""&gt;NVIDIA BlueField&lt;sup&gt;&amp;reg;&lt;/sup&gt;-3 DPUs&lt;/a&gt; &amp;mdash; in servers from leading systems makers Dell Technologies, Hewlett Packard Enterprise and Lenovo.&lt;/p&gt;

&lt;p&gt;Enterprises can also access the &lt;a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA AI Enterprise software platform&lt;/u&gt;&lt;/a&gt;, which includes &lt;a href="http://ai.nvidia.com" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA NIM&amp;trade; inference microservices&lt;/u&gt;&lt;/a&gt;, to create and run production-grade generative AI applications.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Taiwan Embraces Blackwell&lt;/strong&gt;&lt;br /&gt;
Huang also announced during his keynote that Taiwan&amp;#39;s leading companies are rapidly adopting Blackwell to bring the power of AI to their own businesses.&lt;/p&gt;

&lt;p&gt;Taiwan&amp;rsquo;s leading medical center, Chang Gung Memorial Hospital, plans to use the NVIDIA Blackwell computing platform to advance biomedical research and accelerate imaging and language applications to improve clinical workflows, ultimately enhancing patient care.&lt;/p&gt;

&lt;p&gt;Foxconn, one of the world&amp;rsquo;s largest makers of electronics, is planning to use NVIDIA Grace Blackwell to develop smart solution platforms for AI-powered electric vehicle and robotics platforms, as well as a growing number of language-based generative AI services to provide more personalized experiences to its customers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Additional Supporting Quotes&lt;/strong&gt;&lt;/p&gt;

&lt;ul type="disc"&gt;
	&lt;li&gt;&lt;strong&gt;R. Adam Norwitt, president and CEO at Amphenol: &lt;/strong&gt;&amp;ldquo;NVIDIA&amp;rsquo;s groundbreaking AI systems require advanced interconnect solutions, and Amphenol is proud to be supplying critical components. As an important partner in NVIDIA&amp;rsquo;s rich ecosystem, we are able to provide highly complex and efficient interconnect products for Blackwell accelerators to help deliver cutting-edge performance.&amp;rdquo;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;Spencer Shen, chairman and CEO at AVC: &lt;/strong&gt;&amp;ldquo;AVC plays a key role in NVIDIA products, providing efficient cooling for its AI hardware, including the latest Grace Blackwell Superchip. As AI models and workloads continue to grow, reliable thermal management is important to handle intensive AI computing &amp;mdash; and we&amp;rsquo;re with NVIDIA every step of the way.&amp;rdquo;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;Jonney Shih, chairman at ASUS: &lt;/strong&gt;&amp;ldquo;ASUS is working with NVIDIA to take enterprise AI to new heights with our powerful server lineup, which we&amp;rsquo;ll be showcasing at COMPUTEX. Using NVIDIA&amp;rsquo;s MGX and Blackwell platforms, we&amp;rsquo;re able to craft tailored data center solutions built to handle customer workloads across training, inference, data analytics and HPC.&amp;rdquo;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;Janel Wittmayer, president of Dover Corporation&amp;rsquo;s CPC&lt;/strong&gt;: &amp;ldquo;CPC&amp;rsquo;s innovative, purpose-built connector technology enables the easy and reliable connection of liquid-cooled NVIDIA GPUs in AI systems. With a shared vision of performance and quality, CPC has the capacity and expertise to supply critical technological components to support NVIDIA&amp;rsquo;s incredible growth and progress. Our connectors are central to maintaining the integrity of temperature-sensitive products, which is important when AI systems are running compute-intensive tasks. We are excited to be part of the NVIDIA ecosystem and bring our technology to new applications.&amp;rdquo;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;Andy Lin, CEO at Cooler Master&lt;/strong&gt;: &amp;ldquo;As the demand for accelerated computing continues to soar, so does demand for solutions that effectively meet energy standards for enterprises leveraging cutting-edge accelerators. As a pioneer in thermal management solutions, Cooler Master is helping unlock the full potential of the NVIDIA Blackwell platform, which will deliver incredible performance to customers.&amp;rdquo;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;Kim Fausing, CEO at Danfoss: &lt;/strong&gt;&amp;ldquo;Danfoss&amp;rsquo; focus on innovative, high-performance quick disconnect and fluid power designs makes our couplings valuable for enabling efficient, reliable and safe operation in data centers. As a vital part of NVIDIA&amp;rsquo;s AI ecosystem, our work together enables data centers to meet surging AI demands while minimizing environmental impact.&amp;rdquo;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;Ping Cheng, chairman and CEO at Delta Electronics: &lt;/strong&gt;&amp;ldquo;The ubiquitous demand for computing power has ignited a new era of accelerated performance capabilities. Through our advanced cooling and power systems, Delta has developed innovative solutions capable of enabling NVIDIA&amp;rsquo;s Blackwell platform to operate at peak performance levels, while maintaining energy and thermal efficiency.&amp;rdquo;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;Etay Lee, vice president and general manager at GIGABYTE: &lt;/strong&gt;&amp;ldquo;With our collaboration spanning nearly three decades, GIGABYTE has a deep commitment to supporting NVIDIA technologies across GPUs, CPUs, DPUs and high-speed networking. For enterprises to achieve even greater performance and energy efficiency for the compute-intensive workloads, we&amp;rsquo;re bringing to market a broad range of Blackwell-based systems.&amp;rdquo;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;Young Liu, chairman and CEO at Hon Hai Technology Group:&lt;/strong&gt; &amp;ldquo;As generative AI transforms industries, Foxconn stands ready with cutting-edge solutions to meet the most diverse and demanding computing needs. Not only do we use the latest Blackwell platform in our own servers, but we also help provide the key components to NVIDIA, giving our customers faster time-to-market.&amp;rdquo;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;Jack Tsai, president at Inventec:&lt;/strong&gt; &amp;ldquo;For nearly half a century, Inventec has been designing and manufacturing electronic products and components &amp;mdash; the lifeblood of our business. Through our NVIDIA MGX rack-based solution powered by the NVIDIA Grace Blackwell Superchip, we&amp;rsquo;re helping customers enter a new realm of AI capability and performance.&amp;rdquo;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;Anson Chiu, president at LITEON Technology:&lt;/strong&gt; &amp;ldquo;In pursuit of greener and more sustainable data centers, power management and cooling solutions are taking center stage. With the launch of the NVIDIA Blackwell platform, LITEON is releasing multiple liquid-cooling solutions that enable NVIDIA partners to unlock the future of highly efficient, environmentally friendly data centers.&amp;rdquo;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;Barry Lam, chairman at Quanta Computer: &lt;/strong&gt;&amp;ldquo;We stand at the center of an AI-driven world, where innovation is accelerating like never before. NVIDIA Blackwell is not just an engine; it is the spark igniting this industrial revolution. When defining the next era of generative AI, Quanta proudly joins NVIDIA on this amazing journey. Together, we will shape and define a new chapter of AI.&amp;rdquo;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;Charles Liang, president and CEO at Supermicro:&lt;/strong&gt; &amp;ldquo;Our building-block architecture and rack-scale, liquid-cooling solutions, combined with our in-house engineering and global production capacity of 5,000 racks per month, enable us to quickly deliver a wide range of game-changing NVIDIA AI platform-based products to AI factories worldwide. Our liquid-cooled or air-cooled high-performance systems with rack-scale design, optimized for all products based on the NVIDIA Blackwell architecture, will give customers an incredible choice of platforms to meet their needs for next-level computing, as well as a major leap into the future of AI.&amp;rdquo;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;C.C. Wei, CEO at TSMC:&lt;/strong&gt;&amp;nbsp;&amp;ldquo;TSMC works closely with NVIDIA to push the limits of semiconductor innovation that enables them to realize their visions for AI. Our industry-leading semiconductor manufacturing technologies helped shape NVIDIA&amp;rsquo;s groundbreaking GPUs, including those based on the Blackwell architecture.&amp;rdquo;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;Jeff Lin, CEO at Wistron:&lt;/strong&gt; &amp;ldquo;As a key manufacturing partner, Wistron has been on an incredible journey alongside NVIDIA delivering GPU computing technologies and AI cloud solutions to customers. Now we&amp;rsquo;re working with NVIDIA&amp;#39;s latest GPU architectures and reference designs, such as Blackwell and MGX, to quickly bring tremendous new AI computing products to market.&amp;rdquo;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;William Lin, president at Wiwynn: &lt;/strong&gt;&amp;ldquo;Wiwynn is focused on helping customers address the rising demand for massive computing power and advanced cooling solutions in the era of generative AI. With our latest lineup based on the NVIDIA Grace Blackwell and MGX platforms, we&amp;rsquo;re building optimized, rack-level, liquid-cooled AI servers tailored specifically for the demanding workloads of hyperscale cloud providers and enterprises.&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To learn more about the NVIDIA Blackwell and MGX platforms, watch &lt;a href="https://www.nvidia.com/en-us/events/computex/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Huang&amp;rsquo;s COMPUTEX keynote&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;
]]&gt;</content><categories><category>Press Releases</category></categories><modDate>Sun, 02 Jun 2024 12:39:20 GMT</modDate><relatedPages></relatedPages><description><![CDATA[NVIDIA and the world’s top computer manufacturers today unveiled an array of NVIDIA Blackwell architecture-powered systems featuring Grace CPUs, NVIDIA networking and infrastructure for enterprises to build AI factories and data centers to drive the next wave of generative AI breakthroughs.]]></description><enclosure url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/blackwell-ai-factories.png" length="980792" type="image/png"></enclosure><guid isPermaLink="true">https://nvidianews.nvidia.com/news/computer-industry-ai-factories-data-centers</guid><pubDate>Sun, 02 Jun 2024 12:35:00 GMT</pubDate></item><item><title>NVIDIA Supercharges Ethernet Networking for Generative AI</title><link>https://nvidianews.nvidia.com/news/nvidia-supercharges-ethernet-networking-for-generative-ai</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/665b84933d633215758faa89_spectrum-x/spectrum-x_thmb.jpg" fileSize="521222" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/665b84933d633215758faa89_spectrum-x/spectrum-x_thmb.jpg" alt="Spectrum-X" align="left" hspace="15" vspace="5" /&gt;</image><subtitle>Spectrum-X Adopted by Cloud Service Providers, GPU Cloud Providers and Enterprises; Broad System-Maker Support Extends NVIDIA Networking’s Reach to Every Market</subtitle><content>&lt;![CDATA[&lt;p&gt;&lt;strong&gt;&lt;span id="docs-internal-guid-7ed504cf-7fff-15dd-cd9c-ee1fd3680593"&gt;&lt;span&gt;COMPUTEX&amp;mdash;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;NVIDIA today announced widespread adoption of the &lt;a href="https://www.nvidia.com/en-us/networking/spectrumx/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Spectrum&amp;trade;-X Ethernet networking platform&lt;/u&gt;&lt;/a&gt; as well as an accelerated product release schedule.&lt;/p&gt;

&lt;p&gt;CoreWeave, GMO Internet Group, Lambda, Scaleway, STPX Global and Yotta are among the first AI cloud service providers embracing NVIDIA Spectrum-X to bring extreme networking performance to their AI infrastructures. Additionally, several NVIDIA partners have announced Spectrum-based products, including ASRock Rack, ASUS, GIGABYTE, Ingrasys, Inventec, Pegatron, QCT, Wistron and Wiwynn, which join Dell Technologies, Hewlett Packard Enterprise, Lenovo and Supermicro in incorporating the platform into their offerings.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;Rapid advancements in groundbreaking technologies like generative AI underscore the necessity for every business to prioritize networking innovation to gain a competitive edge,&amp;rdquo; said Gilad Shainer, senior vice president of networking at NVIDIA. &amp;ldquo;NVIDIA Spectrum-X revolutionizes Ethernet networking to let businesses fully harness the power of their AI infrastructures to transform their operations and their industries.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Annual Release Cadence&lt;/strong&gt;&lt;br /&gt;
Spectrum-X is the world&amp;rsquo;s first Ethernet fabric built for AI, accelerating generative AI network performance by 1.6x over traditional Ethernet fabrics.&lt;/p&gt;

&lt;p&gt;To meet the industry&amp;rsquo;s strong demand for the performance Spectrum provides, NVIDIA founder and CEO Jensen Huang today announced during his COMPUTEX keynote in Taiwan that NVIDIA plans to launch new Spectrum-X products every year, delivering increased bandwidth and ports and enhanced software feature sets and programmability to drive leading AI Ethernet networking performance.&lt;/p&gt;

&lt;p&gt;Featuring the NVIDIA Spectrum SN5600 Ethernet switch and the &lt;a href="https://www.nvidia.com/en-us/networking/products/data-processing-unit/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA BlueField&lt;sup&gt;&amp;reg;&lt;/sup&gt; -3 SuperNIC&lt;/u&gt;&lt;/a&gt;, Spectrum-X is an end-to-end platform built with the performance and features required by generative AI clouds. Leveraging adaptive routing and congestion control for maximum bandwidth and noise isolation, it offers the highest-performance Ethernet networking for AI, providing predictable outcomes for thousands of simultaneous AI jobs at every scale.&lt;/p&gt;

&lt;p&gt;Combined with &lt;a href="https://www.nvidia.com/en-us/networking/products/data-processing-unit/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA BlueField-3 DPUs&lt;/u&gt;&lt;/a&gt;, the platform enables advanced cloud multi-tenancy, GPU compute elasticity and zero-trust security. With it, cloud service providers can accelerate the development and deployment of AI solutions while improving their return on investment.&lt;/p&gt;

&lt;p&gt;Learn more about NVIDIA Spectrum-X during Huang&amp;rsquo;s &lt;a href="https://www.nvidia.com/en-us/events/computex/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;keynote address at COMPUTEX&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;
]]&gt;</content><categories><category>Press Releases</category></categories><modDate>Sun, 02 Jun 2024 12:35:37 GMT</modDate><relatedPages></relatedPages><description><![CDATA[NVIDIA today announced widespread adoption of the NVIDIA Spectrum™-X Ethernet networking platform as well as an accelerated product release schedule.]]></description><enclosure url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/spectrum-x.jpg" length="521222" type="image/jpeg"></enclosure><guid isPermaLink="true">https://nvidianews.nvidia.com/news/nvidia-supercharges-ethernet-networking-for-generative-ai</guid><pubDate>Sun, 02 Jun 2024 12:32:00 GMT</pubDate></item><item><title>Putting More Tech to the Test, NVIDIA Certifies New Categories of Gen AI-Ready Systems</title><link>https://blogs.nvidia.com/blog/nvidia-certified-systems-spectrum-x-igx/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665c6fe33d6332d580242100_nv-certified-computex-1280x680-1-842x450/nv-certified-computex-1280x680-1-842x450_thmb.jpg" fileSize="10276" type="image/png"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665c6fe33d6332d580242100_nv-certified-computex-1280x680-1-842x450/nv-certified-computex-1280x680-1-842x450_thmb.jpg" alt="nv-certified-computex-1280x680-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Sun, 02 Jun 2024 13:13:10 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Fueled by generative AI, enterprises globally are creating “AI factories,” where data comes in and intelligence comes out. Critical to this movement are validated systems and reference architectures that reduce the risk and time involved in deploying specialized infrastructure that can support complex, computationally intensive generative AI workloads. At the COMPUTEX trade show, NVIDIA today	<a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-certified-systems-spectrum-x-igx/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Anthony Larijani</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/nvidia-certified-systems-spectrum-x-igx/</guid><pubDate>Sun, 02 Jun 2024 12:30:41 GMT</pubDate></item><item><title>Leading Medical Centers in Taiwan Adopt NVIDIA Accelerated Computing to Advance Biomedical Research</title><link>https://blogs.nvidia.com/blog/medical-taiwan/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665c6fe63d6332d580242106_nhri-cgmh-image/nhri-cgmh-image_thmb.jpg" fileSize="4839" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665c6fe63d6332d580242106_nhri-cgmh-image/nhri-cgmh-image_thmb.jpg" alt="nhri-cgmh-image" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Sun, 02 Jun 2024 13:13:12 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Taiwan’s leading medical centers — the National Health Research Institute (NHRI) and Chang Gung Memorial Hospital (CGMH) — are set to advance biomedical research and healthcare for patients. The centers are embracing accelerated computing and generative AI for everything from imaging to enhancing patient care, from streamlining clinical workflows to drug discovery research. “The use	<a class="read-more" href="https://blogs.nvidia.com/blog/medical-taiwan/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Kimberly Powell</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/medical-taiwan/</guid><pubDate>Sun, 02 Jun 2024 12:30:28 GMT</pubDate></item><item><title>Gen AI Healthcare Accelerated: Dozens of Companies Adopt Meta Llama 3 NIM</title><link>https://blogs.nvidia.com/blog/temp-llama-3-nim-healthcare-generative-ai/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665c6fe03d6332d5802420fa_healthcare-llama-3-nim-computex-1280x680-1-842x450/healthcare-llama-3-nim-computex-1280x680-1-842x450_thmb.jpg" fileSize="100305" type="image/png"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202406/665c6fe03d6332d5802420fa_healthcare-llama-3-nim-computex-1280x680-1-842x450/healthcare-llama-3-nim-computex-1280x680-1-842x450_thmb.jpg" alt="healthcare-llama-3-nim-computex-1280x680-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Sun, 02 Jun 2024 13:23:04 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Meta Llama 3, Meta’s openly available state-of-the-art large language model — trained and optimized using NVIDIA accelerated computing — is dramatically boosting healthcare and life sciences workflows, helping deliver applications that aim to improve patients’ lives. Now available as a downloadable NVIDIA NIM inference microservice at ai.nvidia.com, Llama 3 is equipping healthcare developers, researchers and	<a class="read-more" href="https://blogs.nvidia.com/blog/temp-llama-3-nim-healthcare-generative-ai/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Brad Genereaux</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/temp-llama-3-nim-healthcare-generative-ai/</guid><pubDate>Sun, 02 Jun 2024 12:30:00 GMT</pubDate></item><item><title>NVIDIA NIM Revolutionizes Model Deployment, Now Available to Transform World’s Millions of Developers Into Generative AI Developers</title><link>https://nvidianews.nvidia.com/news/nvidia-nim-model-deployment-generative-ai-developers</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/665b84a23d633215768faa8a_nim/nim_thmb.png" fileSize="467271" type="image/png"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/665b84a23d633215768faa8a_nim/nim_thmb.png" alt="NIM" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><content>&lt;![CDATA[&lt;ul&gt;
	&lt;li&gt;&lt;em&gt;150+ Partners Across Every Layer of AI Ecosystem Embedding NIM Inference Microservices to Speed Enterprise AI Application Deployments From Weeks to Minutes&lt;/em&gt;&lt;/li&gt;
	&lt;li&gt;&lt;em&gt;NVIDIA Developer Program Members Gain Free Access to NIM for Research, Development and Testing&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;span id="docs-internal-guid-c793acbd-7fff-4b41-19f1-70400d19bf47"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span id="docs-internal-guid-c793acbd-7fff-4b41-19f1-70400d19bf47"&gt;&lt;span&gt;COMPUTEX&amp;mdash;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;NVIDIA today announced that the world&amp;rsquo;s 28 million developers can now download &lt;a href="https://www.nvidia.com/en-us/ai/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA NIM&lt;/u&gt;&lt;/a&gt;&amp;trade; &amp;mdash; inference microservices that provide models as optimized containers &amp;mdash; to deploy on clouds, data centers or workstations, giving them the ability to easily build generative AI applications for copilots, chatbots and more, in minutes rather than weeks.&lt;/p&gt;

&lt;p&gt;These new generative AI applications are becoming increasingly complex and often utilize multiple models with different capabilities for generating text, images, video, speech and more. NVIDIA NIM dramatically increases developer productivity by providing a simple, standardized way to add generative AI to their applications.&lt;/p&gt;

&lt;p&gt;NIM also enables enterprises to maximize their infrastructure investments. For example, running Meta Llama 3-8B in a NIM produces up to 3x more generative AI tokens on accelerated infrastructure than without NIM. This lets enterprises boost efficiency and use the same amount of compute infrastructure to generate more responses.&lt;/p&gt;

&lt;p&gt;Nearly 200 technology partners &amp;mdash; including Cadence, &lt;a href="https://blog.cloudera.com/cloudera-introduces-ai-inference-service-with-nvidia-nim/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Cloudera&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.cohesity.com/press/unlock-gen-ai-capabilities-via-nvidia-collaboration/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Cohesity&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.datastax.com/press-release/datastax-to-deliver-high-performance-rag-solution-with-20x-faster-embeddings-and-indexing-at-80-lower-cost-using-nvidia-microservices" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;DataStax&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.netapp.com/newsroom/press-releases/news-rel-20240514-813887/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NetApp&lt;/u&gt;&lt;/a&gt;, Scale AI and &lt;a href="https://news.synopsys.com/2024-03-18-Synopsys-Showcases-EDA-Performance-and-Next-Gen-Capabilities-with-NVIDIA-Accelerated-Computing,-Generative-AI-and-Omniverse" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Synopsys&lt;/u&gt;&lt;/a&gt; &amp;mdash; are integrating NIM into their platforms to speed generative AI deployments for domain-specific applications, such as copilots, code assistants and digital human avatars. &lt;a href="https://huggingface.co/blog/train-dgx-cloud" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Hugging Face&lt;/u&gt;&lt;/a&gt; is now offering NIM &amp;mdash; starting with &lt;a href="https://ai.meta.com/blog/meta-llama-3/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Meta Llama 3&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;Every enterprise is looking to add generative AI to its operations, but not every enterprise has a dedicated team of AI researchers,&amp;rdquo; said Jensen Huang, founder and CEO of NVIDIA. &amp;ldquo;Integrated into platforms everywhere, accessible to developers everywhere, running everywhere &amp;mdash; NVIDIA NIM is helping the technology industry put generative AI in reach for every organization.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Enterprises can deploy AI applications in production with NIM through the &lt;a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA AI Enterprise&lt;/u&gt;&lt;/a&gt; software platform. Starting next month, members of the &lt;a href="https://developer.nvidia.com/developer-program" rel="nofollow" target="_blank"&gt;&lt;u&gt;NVIDIA Developer Program&lt;/u&gt;&lt;/a&gt; can access NIM for free for research, development and testing on their preferred infrastructure.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;40+ &lt;/strong&gt;&lt;strong&gt;NIM Microservices Power Gen AI Models Across Modalities&lt;/strong&gt;&lt;br /&gt;
NIM containers are pre-built to speed model deployment for GPU-accelerated inference and can include &lt;a href="https://developer.nvidia.com/cuda-zone" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA CUDA&lt;/u&gt;&lt;/a&gt;&lt;sup&gt;&amp;reg;&lt;/sup&gt; software, &lt;a href="https://www.nvidia.com/en-in/ai-data-science/products/triton-inference-server/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Triton Inference Server&lt;/u&gt;&lt;/a&gt;&amp;trade; and &lt;a href="https://developer.nvidia.com/tensorrt#inference" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA TensorRT&amp;trade;-LLM&lt;/u&gt;&lt;/a&gt; software.&lt;/p&gt;

&lt;p&gt;Over 40 NVIDIA and community models are available to experience as NIM endpoints on &lt;a href="http://ai.nvidia.com" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;ai.nvidia.com&lt;/u&gt;&lt;/a&gt;, including &lt;a href="https://www.databricks.com/company/newsroom/press-releases/databricks-launches-dbrx-new-standard-efficient-open-source-models" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Databricks DBRX&lt;/u&gt;&lt;/a&gt;, Google&amp;rsquo;s open model Gemma, Meta Llama 3, Microsoft Phi-3, Mistral Large, Mixtral 8x22B and Snowflake Arctic.&lt;/p&gt;

&lt;p&gt;Developers can now access NVIDIA NIM microservices for Meta Llama 3 models from the &lt;a href="https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct%E2%80%9D" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Hugging Face&lt;/u&gt;&lt;/a&gt; AI platform. This lets developers easily access and run the Llama 3 NIM in just a few clicks using Hugging Face Inference Endpoints, powered by NVIDIA GPUs on their preferred cloud.&lt;/p&gt;

&lt;p&gt;Enterprises can use NIM to run applications for generating text, images and video, speech and digital humans. With &lt;a href="https://www.nvidia.com/en-us/clara/bionemo/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA BioNeMo&lt;/u&gt;&lt;/a&gt;&amp;trade; NIM microservices for digital biology, researchers can build novel protein structures to accelerate drug discovery.&lt;/p&gt;

&lt;p&gt;Dozens of healthcare companies are &lt;a href="https://blogs.nvidia.com/blog/llama-3-nim-healthcare-generative-ai" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;deploying NIM&lt;/u&gt;&lt;/a&gt; to power generative AI inference across a range of applications, including surgical planning, digital assistants, drug discovery and clinical trial optimization.&lt;/p&gt;

&lt;p&gt;With new &lt;a href="https://nvidianews.nvidia.com/news/digital-humans-ace-generative-ai-microservices" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA ACE NIM microservices&lt;/u&gt;&lt;/a&gt;, developers can easily build and operate interactive, lifelike digital humans in applications for customer service, telehealth, education, gaming and entertainment.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hundreds&lt;/strong&gt;&lt;strong&gt; of AI Ecosyst&lt;/strong&gt;&lt;strong&gt;em Partners Embedding NIM &lt;/strong&gt;&lt;br /&gt;
Platform providers including &lt;a href="https://ubuntu.com/blog/deploy-genai-applications-with-nvidia-nim-and-charmed-kubeflow" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Canonical&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.redhat.com/en/about/press-releases/red-hat-unveils-nvidia-nim-integration-red-hat-openshift-ai" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Red Hat&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.nutanix.com/press-releases/2024/nutanix-and-nvidia-collaborate-to-accelerate-enterprise-ai-adoption" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Nutanix&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://blogs.vmware.com/cloud-foundation/2024/05/06/ga-vpaifn/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;VMware&lt;/u&gt;&lt;/a&gt; (acquired by Broadcom) are supporting NIM on &lt;a href="https://blogs.nvidia.com/blog/kserve-nim-inference" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;open-source KServe&lt;/u&gt;&lt;/a&gt; or enterprise solutions. AI application companies &lt;a href="https://www.globenewswire.com/news-release/2024/03/18/2848236/0/en/Hippocratic-AI-Announces-Collaboration-with-NVIDIA-to-Develop-Super-Low-Latency-Empathy-Inference-for-One-of-the-World-s-First-Generative-AI-Powered-Healthcare-Agents.html" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Hippocratic AI&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.glean.com/blog/nvidia-nvbot-glean-partnership" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Glean&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.kinetica.com/blog/kinetica-the-gpu-powered-rag-engine-for-data-copilots-integrates-with-nvidia-nim" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Kinetica&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://redis.io/blog/use-redis-with-nvidia-nim-to-deploy-genai-apps-faster" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Redis&lt;/u&gt;&lt;/a&gt; are also deploying NIM to power generative AI inference.&lt;/p&gt;

&lt;p&gt;Leading AI tools and MLOps partners &amp;mdash; including Amazon SageMaker, Microsoft Azure AI, Dataiku, DataRobot, &lt;a href="https://haystack.deepset.ai/blog/haystack-nvidia-nim-rag-guide" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;deepset&lt;/u&gt;&lt;/a&gt;, Domino Data Lab, &lt;a href="https://blog.langchain.dev/nvidia-nim/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;LangChain&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.llamaindex.ai/blog/llamaindex-accelerates-enterprise-generative-ai-with-nvidia-nim" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Llama Index&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://replicate.com/blog/run-nvidia-nim-models-on-replicate" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Replicate&lt;/u&gt;&lt;/a&gt;, Run.ai, &lt;a href="https://saturncloud.io/blog/deploying-generative-ai-on-saturn-cloud-using-nvidia-inference-microservices/?utm_source=nvidia&amp;amp;utm_medium=press_release&amp;amp;utm_campaign=computexpr" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Saturn Cloud&lt;/u&gt;&lt;/a&gt;, Securiti AI and &lt;a href="https://wandb.ai/site/press-release/integration-nvidia-nim" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Weights &amp;amp; Biases&lt;/u&gt;&lt;/a&gt; &amp;mdash; have also embedded NIM into their platforms to enable developers to build and deploy domain-specific generative AI applications with optimized inference.&lt;/p&gt;

&lt;p&gt;Global system integrators and service delivery partners Accenture, Deloitte, Infosys, &lt;a href="https://www.latentview.com/press-release/latentview-analytics-accelerates-enterprise-solutions-with-nvidia-ai-enterprise/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Latentview&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://quantiphi.com/media-releases/quantiphi-unveils-generative-ai-platform-baioniqtm-integrated-with-nvidia-ai-enterprise-software-empowering-enterprise-productivity/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Quantiphi&lt;/u&gt;&lt;/a&gt;, SoftServe, Tata Consultancy Services (TCS) and Wipro have created NIM competencies to help the world&amp;rsquo;s enterprises quickly develop and deploy production AI strategies.&lt;/p&gt;

&lt;p&gt;Enterprises can run NIM-enabled applications virtually anywhere, including on &lt;a href="https://www.nvidia.com/en-us/data-center/products/certified-systems/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA-Certified Systems&lt;/u&gt;&lt;/a&gt;&amp;trade; from global infrastructure manufacturers Cisco, &lt;a href="https://www.dell.com/en-us/dt/corporate/newsroom/announcements/detailpage.press-releases~usa~2024~05~20240520-dell-technologies-expands-dell-ai-factory-with-nvidia-to-turbocharge-ai-adoption.htm" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Dell Technologies&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.hpe.com/us/en/newsroom/press-release/2024/03/hewlett-packard-enterprise-debuts-end-to-end-ai-native-portfolio-for-generative-ai.html" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Hewlett-Packard Enterprise&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://news.lenovo.com/netapp-and-lenovo-offer-converged-infrastructure-solution-optimized-for-genai/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Lenovo&lt;/u&gt;&lt;/a&gt; and Supermicro, as well as server manufacturers &lt;a href="https://www.asrockrack.com/general/news.asp?id=239" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;ASRock Rack&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://servers.asus.com/NEWS/ASUS-Presents-ESC-AI-POD-with-NVIDIA-GB200-NVL72-at-Computex-2024" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;ASUS&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.gigabyte.com/Press/News/2168" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;GIGABYTE&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.foxconn.com.tw/en-us/press-center/press-releases/latest-news" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Ingrasys&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://ebg.inventec.com/en/news/Press%20Release/2024/85" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Inventec&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://svr.pegatroncorp.com/News/6" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Pegatron&lt;/u&gt;&lt;/a&gt;, QCT, Wistron and Wiwynn. NIM microservices have also been integrated into &lt;a href="https://aws.amazon.com/about-aws/whats-new/2024/03/amazon-sagemaker-integration-nvidia-nim-microservices/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Amazon Web Services&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://nvidianews.nvidia.com/news/google-cloud-ai-development" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Google Cloud&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://news.microsoft.com/2024/03/18/microsoft-and-nvidia-announce-major-integrations-to-accelerate-generative-ai-for-enterprises-everywhere/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Azure&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://nvidianews.nvidia.com/news/oracle-nvidia-sovereign-ai" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Oracle Cloud Infrastructure&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Titans of Industry Amp Up Gener&lt;/strong&gt;&lt;strong&gt;ative AI With NIM&lt;/strong&gt;&lt;br /&gt;
Industry leaders Foxconn, Pegatron, &lt;a href="https://www.amdocs.com/insights/press-release/amdocs-unveils-generative-ai-milestones-bringing-enhanced-efficiencies" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Amdocs&lt;/u&gt;&lt;/a&gt;, Lowe&amp;rsquo;s, &lt;a href="https://www.servicenow.com/company/media/press-room/servicenow-introducing-ai-powered-employee-experience.html" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;ServiceNow&lt;/u&gt;&lt;/a&gt; and Siemens are among the businesses using NIM for generative AI applications in manufacturing, healthcare, financial services, retail, customer service and more:&lt;/p&gt;

&lt;ul type="disc"&gt;
	&lt;li style="margin-top:0.1pt; margin-bottom:0.1pt;"&gt;&lt;strong&gt;Foxconn &lt;/strong&gt;&amp;mdash; the world&amp;rsquo;s largest electronics manufacturer &amp;mdash; is using NIM in the development of domain-specific LLMs embedded into a variety of internal systems and processes in its AI factories for smart manufacturing, smart cities and smart electric vehicles.&lt;/li&gt;
	&lt;li style="margin-top:0.1pt; margin-bottom:0.1pt;"&gt;&lt;strong&gt;Pegatron &lt;/strong&gt;&amp;mdash; a Taiwanese electronics manufacturing company &amp;mdash; is leveraging NIM for Project TaME, a Taiwan Mixtral of Experts model designed to advance the development of local LLMs for industries.&lt;/li&gt;
	&lt;li style="margin-top:0.1pt; margin-bottom:0.1pt;"&gt;&lt;strong&gt;Amdocs &lt;/strong&gt;&amp;mdash; a leading global provider of software and services to communications and media companies &amp;mdash; is &lt;a href="https://www.amdocs.com/insights/press-release/amdocs-unveils-generative-ai-milestones-bringing-enhanced-efficiencies" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;using NIM&lt;/u&gt;&lt;/a&gt; to run a customer billing LLM that significantly lowers the cost of tokens, improves accuracy by up to 30% and reduces latency by 80%, driving near real-time responses.&lt;/li&gt;
	&lt;li style="margin-top:0.1pt; margin-bottom:0.1pt;"&gt;&lt;strong&gt;Lowe&amp;rsquo;s &lt;/strong&gt;&amp;mdash; a FORTUNE&lt;sup&gt;&amp;reg;&lt;/sup&gt; 50 home improvement company &amp;mdash; is using generative AI for a variety of use cases. For example, the retailer is leveraging NVIDIA NIM inference microservices to elevate experiences for associates and customers.&lt;/li&gt;
	&lt;li style="margin-top:0.1pt; margin-bottom:0.1pt;"&gt;&lt;strong&gt;ServiceNow&lt;/strong&gt; &amp;mdash; the AI platform for business transformation &amp;mdash; announced earlier this year that it was one of the first platform providers to access NIM to enable fast, scalable and more cost-effective LLM development and deployment for its customers. NIM microservices are integrated within the Now AI multimodal model and are available to customers that have ServiceNow&amp;rsquo;s generative AI experience, Now Assist, installed.&lt;/li&gt;
	&lt;li style="margin-top:0.1pt; margin-bottom:0.1pt;"&gt;&lt;strong&gt;Siemens &lt;/strong&gt;&amp;mdash; a global technology company focused on industry, infrastructure, transport and healthcare &amp;mdash; is integrating its operational technology with NIM microservices for shop floor AI workloads. It is also building an on-premises version of its Industrial Copilot for Machine Operators using NIM.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Availability&lt;/strong&gt;&lt;br /&gt;
Developers can experiment with NVIDIA microservices at &lt;a href="http://ai.nvidia.com" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;ai.nvidia.com&lt;/u&gt;&lt;/a&gt; at no charge. Enterprises can deploy production-grade NIM microservices with &lt;a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA AI Enterprise&lt;/u&gt;&lt;/a&gt; running on NVIDIA-Certified Systems and leading cloud platforms. Starting next month, members of the &lt;a href="https://developer.nvidia.com/developer-program" rel="nofollow" target="_blank"&gt;&lt;u&gt;NVIDIA Developer Program&lt;/u&gt;&lt;/a&gt; will gain free access to NIM for research and testing.&lt;/p&gt;

&lt;p&gt;Watch &lt;a href="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.nvidia.com%2Fen-us%2Fevents%2Fcomputex%2F&amp;amp;data=05%7C02%7Csmcphee%40nvidia.com%7Cfd26785e5dbb403df3ef08dc80dc0b5b%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638526929781182771%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;amp;sdata=GsW8wu%2B%2FGiXCQ6WgSUU6qoVvjjlW%2FWPJlWj8B1vELvE%3D&amp;amp;reserved=0" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Huang&amp;rsquo;s COMPUTEX keynote&lt;/u&gt;&lt;/a&gt; to learn more about NVIDIA NIM.&lt;/p&gt;
]]&gt;</content><categories><category>Press Releases</category></categories><modDate>Mon, 03 Jun 2024 20:34:10 GMT</modDate><relatedPages></relatedPages><description><![CDATA[NVIDIA today announced that the world’s 28 million developers can now download NVIDIA NIM™ — inference microservices that provide models as optimized containers — to deploy on clouds, data centers or workstations, giving them the ability to easily build generative AI applications for copilots, chatbots and more, in minutes rather than weeks.]]></description><enclosure url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20245/nim.png" length="467271" type="image/png"></enclosure><guid isPermaLink="true">https://nvidianews.nvidia.com/news/nvidia-nim-model-deployment-generative-ai-developers</guid><pubDate>Sun, 02 Jun 2024 12:13:00 GMT</pubDate></item></channel></rss>