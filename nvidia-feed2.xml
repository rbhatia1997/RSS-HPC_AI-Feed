<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>News Releases - NVIDIA Newsroom</title><link>https://nvidianews.nvidia.com</link><description>All News</description><language>en-us</language><pubDate>Tue, 30 Jul 2024 00:52:11 GMT</pubDate><lastBuildDate>Tue, 30 Jul 2024 00:52:11 GMT</lastBuildDate><generator>iPressroom</generator><item><title>Creators To Have Personalized AI Assistants, Meta CEO Mark Zuckerberg Tells NVIDIA CEO Jensen Huang</title><link>https://blogs.nvidia.com/blog/zuckerberg-huang/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a835cc3d6332aa8cb77b8f_764A8547-blog-press-1280x680-1-842x450/764A8547-blog-press-1280x680-1-842x450_thmb.jpg" fileSize="107778" type="image/png"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a835cc3d6332aa8cb77b8f_764A8547-blog-press-1280x680-1-842x450/764A8547-blog-press-1280x680-1-842x450_thmb.jpg" alt="764A8547-blog-press-1280x680-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Tue, 30 Jul 2024 00:37:36 GMT</modDate><relatedPages></relatedPages><description><![CDATA[In a highly anticipated fireside chat at SIGGRAPH 2024, NVIDIA founder and CEO Jensen Huang and Meta founder and CEO Mark Zuckerberg discussed the transformative potential of open source AI and AI assistants. Zuckerberg kicked off the discussion by announcing the launch of AI Studio, a new platform that allows users to create, share and	<a class="read-more" href="https://blogs.nvidia.com/blog/zuckerberg-huang/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Brian Caulfield</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/zuckerberg-huang/</guid><pubDate>Tue, 30 Jul 2024 00:30:28 GMT</pubDate></item><item><title>‘Everybody Will Have an AI Assistant,’ NVIDIA CEO Tells SIGGRAPH Audience</title><link>https://blogs.nvidia.com/blog/nvidia-ceo-siggraph/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a81baaed6ae501d0f64da8_764A7888-blog-press-1280x680-2-842x450/764A7888-blog-press-1280x680-2-842x450_thmb.jpg" fileSize="125758" type="image/png"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a81baaed6ae501d0f64da8_764A7888-blog-press-1280x680-2-842x450/764A7888-blog-press-1280x680-2-842x450_thmb.jpg" alt="764A7888-blog-press-1280x680-2-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Mon, 29 Jul 2024 23:29:46 GMT</modDate><relatedPages></relatedPages><description><![CDATA[The generative AI revolution — with deep roots in visual computing — is amplifying human creativity even as accelerated computing promises significant gains in energy efficiency, NVIDIA founder and CEO Jensen Huang said Monday. That makes this week&#8217;s SIGGRAPH professional graphics conference, in Denver, the logical venue to discuss what’s next. “Everybody will have an	<a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-ceo-siggraph/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Brian Caulfield</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/nvidia-ceo-siggraph/</guid><pubDate>Mon, 29 Jul 2024 22:43:00 GMT</pubDate></item><item><title>Recipe for Magic: WPP and NVIDIA Omniverse Help The Coca-Cola Company Scale Generative AI Content That Pops With Brand Authenticity</title><link>https://blogs.nvidia.com/blog/coca-cola-wpp-omniverse-generative-ai/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a8006f3d6332d8a713b15b_TCCC_master_08LATAM_taco_v001_1-842x450/TCCC_master_08LATAM_taco_v001_1-842x450_thmb.jpg" fileSize="33412" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a8006f3d6332d8a713b15b_TCCC_master_08LATAM_taco_v001_1-842x450/TCCC_master_08LATAM_taco_v001_1-842x450_thmb.jpg" alt="TCCC_master_08LATAM_taco_v001_1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Mon, 29 Jul 2024 20:49:55 GMT</modDate><relatedPages></relatedPages><description><![CDATA[When The Coca-Cola Company produces thirst-quenching marketing, the creative elements of campaigns aren’t just left to chance — there’s a recipe for the magic. Now, the beverage company, through its partnership with WPP Open X, is beginning to scale its global campaigns with generative AI from NVIDIA Omniverse and NVIDIA NIM microservices. “With NVIDIA, we	<a class="read-more" href="https://blogs.nvidia.com/blog/coca-cola-wpp-omniverse-generative-ai/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>James Mills</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/coca-cola-wpp-omniverse-generative-ai/</guid><pubDate>Mon, 29 Jul 2024 20:30:49 GMT</pubDate></item><item><title>Reality Reimagined: NVIDIA Introduces fVDB to Build Bigger Digital Models of the World</title><link>https://blogs.nvidia.com/blog/fvdb-bigger-digital-models/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a7fdd83d6332ce314c1ffd_KV_Vid2/KV_Vid2_thmb.jpg" fileSize="10139154" type="video/mp4"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a7fdd83d6332ce314c1ffd_KV_Vid2/KV_Vid2_thmb.jpg" alt="KV_Vid2" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Mon, 29 Jul 2024 20:38:50 GMT</modDate><relatedPages></relatedPages><description><![CDATA[NVIDIA announced at SIGGRAPH fVDB, a new deep-learning framework for generating AI-ready virtual representations of the real world. fVDB is built on top of OpenVDB, the industry-standard library for simulating and rendering sparse volumetric data such as water, fire, smoke and clouds. Generative physical AI, such as autonomous vehicles and robots that inhabit the real	<a class="read-more" href="https://blogs.nvidia.com/blog/fvdb-bigger-digital-models/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Ken Museth</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/fvdb-bigger-digital-models/</guid><pubDate>Mon, 29 Jul 2024 20:30:47 GMT</pubDate></item><item><title>NVIDIA Supercharges Digital Marketing With Greater Control Over Generative AI</title><link>https://blogs.nvidia.com/blog/nvidia-supercharges-marketing-agencies-generative-ai/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a7fddb3d6332ce314c2002_digital-marketing-agencies-featured-1280x680-1-842x450/digital-marketing-agencies-featured-1280x680-1-842x450_thmb.jpg" fileSize="69632" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a7fddb3d6332ce314c2002_digital-marketing-agencies-featured-1280x680-1-842x450/digital-marketing-agencies-featured-1280x680-1-842x450_thmb.jpg" alt="digital-marketing-agencies-featured-1280x680-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Mon, 29 Jul 2024 20:38:54 GMT</modDate><relatedPages></relatedPages><description><![CDATA[The world’s brands and agencies are using generative AI to create advertising and marketing content, but it doesn’t always provide the desired outputs. NVIDIA offers a comprehensive set of technologies — bringing together generative AI, NVIDIA NIM microservices, NVIDIA Omniverse and Universal Scene Description (OpenUSD) — to allow developers to build applications and workflows that	<a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-supercharges-marketing-agencies-generative-ai/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>James Mills</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/nvidia-supercharges-marketing-agencies-generative-ai/</guid><pubDate>Mon, 29 Jul 2024 20:30:46 GMT</pubDate></item><item><title>New NVIDIA Digital Human Technologies Enhance Customer Interactions Across Industries</title><link>https://blogs.nvidia.com/blog/digital-humans-siggraph-2024/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a7fde03d6332ce314c2008_sigg24-social-ace-kv-1200x628-1-842x450/sigg24-social-ace-kv-1200x628-1-842x450_thmb.jpg" fileSize="16238" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a7fde03d6332ce314c2008_sigg24-social-ace-kv-1200x628-1-842x450/sigg24-social-ace-kv-1200x628-1-842x450_thmb.jpg" alt="sigg24-social-ace-kv-1200x628-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Mon, 29 Jul 2024 20:38:58 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Generative AI is unlocking new ways for enterprises to engage customers through digital human avatars. At SIGGRAPH, NVIDIA previewed James, an interactive digital human that can connect with people using emotions, humor and more. James is based on a customer-service workflow using NVIDIA ACE, a reference design for creating custom, hyperrealistic, interactive avatars. Users will	<a class="read-more" href="https://blogs.nvidia.com/blog/digital-humans-siggraph-2024/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Ike Nnoli</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/digital-humans-siggraph-2024/</guid><pubDate>Mon, 29 Jul 2024 20:30:41 GMT</pubDate></item><item><title>Hugging Face Offers Developers Inference-as-a-Service Powered by NVIDIA NIM</title><link>https://blogs.nvidia.com/blog/hugging-face-inference-nim-microservices-dgx-cloud/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a7fde43d6332ce314c200e_nvidia-hugging-face-logos-842x450/nvidia-hugging-face-logos-842x450_thmb.jpg" fileSize="8520" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a7fde43d6332ce314c200e_nvidia-hugging-face-logos-842x450/nvidia-hugging-face-logos-842x450_thmb.jpg" alt="nvidia-hugging-face-logos-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Mon, 29 Jul 2024 20:39:02 GMT</modDate><relatedPages></relatedPages><description><![CDATA[One of the world’s largest AI communities — comprising 4 million developers on the Hugging Face platform — is gaining easy access to NVIDIA-accelerated inference on some of the most popular AI models. New inference-as-a-service capabilities will enable developers to rapidly deploy leading large language models such as the Llama 3 family and Mistral AI	<a class="read-more" href="https://blogs.nvidia.com/blog/hugging-face-inference-nim-microservices-dgx-cloud/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Alexis Bjorlin</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/hugging-face-inference-nim-microservices-dgx-cloud/</guid><pubDate>Mon, 29 Jul 2024 20:30:41 GMT</pubDate></item><item><title>AI Gets Physical: New NVIDIA NIM Microservices Bring Generative AI to Digital Environments</title><link>https://blogs.nvidia.com/blog/generative-physical-ai-nim-microservices/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a7fde73d6332ce314c2014_physicalaimicroserviceblog-842x450/physicalaimicroserviceblog-842x450_thmb.jpg" fileSize="17811" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a7fde73d6332ce314c2014_physicalaimicroserviceblog-842x450/physicalaimicroserviceblog-842x450_thmb.jpg" alt="physicalaimicroserviceblog-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Mon, 29 Jul 2024 20:39:06 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Millions of people already use generative AI to assist in writing and learning. Now, the technology can also help them more effectively navigate the physical world. NVIDIA announced at SIGGRAPH generative physical AI advancements including the NVIDIA Metropolis reference workflow for building interactive visual AI agents and new NVIDIA NIM microservices that will help developers	<a class="read-more" href="https://blogs.nvidia.com/blog/generative-physical-ai-nim-microservices/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Adam Scraba</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/generative-physical-ai-nim-microservices/</guid><pubDate>Mon, 29 Jul 2024 20:30:23 GMT</pubDate></item><item><title>For Your Edification: Shutterstock Releases Generative 3D, Getty Images Upgrades Service Powered by NVIDIA</title><link>https://blogs.nvidia.com/blog/edify-shutterstock-getty-images/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a7fdeb3d6332ce314c201a_Key-visual-of-Shutterstock-Getty-Images-Gen-AI-servcies-842x450/Key-visual-of-Shutterstock-Getty-Images-Gen-AI-servcies-842x450_thmb.jpg" fileSize="67479" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a7fdeb3d6332ce314c201a_Key-visual-of-Shutterstock-Getty-Images-Gen-AI-servcies-842x450/Key-visual-of-Shutterstock-Getty-Images-Gen-AI-servcies-842x450_thmb.jpg" alt="Key-visual-of-Shutterstock-Getty-Images-Gen-AI-servcies-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Mon, 29 Jul 2024 20:39:10 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Designers and artists have new and improved ways to boost their productivity with generative AI trained on licensed data. Shutterstock, a leading platform for creative content, launched its Generative 3D service in commercial beta. It lets creators quickly prototype 3D assets and generate 360 HDRi backgrounds that light scenes, using just text or image prompts.	<a class="read-more" href="https://blogs.nvidia.com/blog/edify-shutterstock-getty-images/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Gerardo Delgado</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/edify-shutterstock-getty-images/</guid><pubDate>Mon, 29 Jul 2024 20:30:04 GMT</pubDate></item><item><title>NVIDIA Accelerates Humanoid Robotics Development</title><link>https://nvidianews.nvidia.com/news/nvidia-accelerates-worldwide-humanoid-robotics-development</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20246/66a5de743d63328cacaf75f1_humanoid-robotics/humanoid-robotics_thmb.jpg" fileSize="875158" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20246/66a5de743d63328cacaf75f1_humanoid-robotics/humanoid-robotics_thmb.jpg" alt="Humanoid Robotics" align="left" hspace="15" vspace="5" /&gt;</image><subtitle>Developers Gain Access to New NVIDIA NIM Microservices for Robotics Simulation in Isaac Lab and Isaac Sim, OSMO Robot Cloud Compute Orchestration Service, Teleoperated Data Capture Workflow and More</subtitle><content>&lt;![CDATA[&lt;p&gt;&lt;strong&gt;SIGGRAPH&amp;mdash;&lt;/strong&gt;To accelerate humanoid development on a global scale, NVIDIA today announced it is providing the world&amp;rsquo;s leading robot manufacturers, AI model developers and software makers with a suite of services, models and computing platforms to develop, train and build the next generation of humanoid robotics.&lt;/p&gt;

&lt;p align="justify"&gt;Among the offerings are new &lt;a href="https://blogs.nvidia.com/blog/generative-physical-ai-nim-microservices/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA NIM&amp;trade; microservices&lt;/u&gt;&lt;/a&gt; and frameworks for robot simulation and learning, the &lt;a href="https://developer.nvidia.com/osmo" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA OSMO&lt;/u&gt;&lt;/a&gt; orchestration service for running multi-stage robotics workloads, and an AI- and simulation-enabled teleoperation workflow that allows developers to train robots using small amounts of human demonstration data.&lt;/p&gt;

&lt;p align="justify"&gt;&amp;ldquo;The next wave of AI is robotics and one of the most exciting developments is humanoid robots,&amp;rdquo; said Jensen Huang, founder and CEO of NVIDIA. &amp;ldquo;We&amp;rsquo;re advancing the entire NVIDIA robotics stack, opening access for worldwide humanoid developers and companies to use the platforms, acceleration libraries and AI models best suited for their needs.&amp;rdquo;&lt;/p&gt;

&lt;p align="justify"&gt;&lt;strong&gt;Accelerating Development With NVIDIA NIM and OSMO&lt;/strong&gt;&lt;br /&gt;
NIM microservices provide pre-built containers, powered by NVIDIA inference software, that enable developers to reduce deployment times from weeks to minutes. Two new AI microservices will allow roboticists to enhance simulation workflows for &lt;a href="https://www.nvidia.com/en-us/glossary/generative-physical-ai" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;generative physical AI&lt;/u&gt;&lt;/a&gt; in &lt;a href="https://developer.nvidia.com/isaac/sim" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Isaac Sim&lt;/u&gt;&lt;/a&gt;&amp;trade;, a reference application for robotics simulation built on the &lt;a href="https://www.nvidia.com/en-us/omniverse/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Omniverse&lt;/u&gt;&lt;/a&gt;&amp;trade; platform.&lt;/p&gt;

&lt;p align="justify"&gt;The MimicGen NIM microservice generates synthetic motion data based on recorded teleoperated data from spatial computing devices like Apple Vision Pro. The Robocasa NIM microservice generates robot tasks and simulation-ready environments in &lt;a href="https://nvidianews.nvidia.com/news/nvidia-expands-openusd-to-generative-ai-for-robotics-industrial-digitalization-markets" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;OpenUSD&lt;/u&gt;&lt;/a&gt;, a universal framework for developing and collaborating within 3D worlds.&lt;/p&gt;

&lt;p align="justify"&gt;NVIDIA OSMO, available now, is a cloud-native managed service that allows users to orchestrate and scale complex &amp;zwnj;robotics development workflows across distributed computing resources, whether on premises or in the cloud.&lt;/p&gt;

&lt;p align="justify"&gt;OSMO vastly simplifies robot training and simulation workflows, cutting deployment and development cycle times from months to under a week. Users can visualize and manage a range of tasks &amp;mdash; like generating &lt;a href="https://www.nvidia.com/en-us/use-cases/synthetic-data/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;synthetic data&lt;/u&gt;&lt;/a&gt;, training models, conducting &lt;a href="https://www.nvidia.com/en-us/use-cases/reinforcement-learning/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;reinforcement learning&lt;/u&gt;&lt;/a&gt; and implementing software-in-the-loop testing at scale for humanoids, autonomous mobile robots and industrial manipulators.&lt;/p&gt;

&lt;p align="justify"&gt;&lt;strong&gt;Advancing Data Capture Workflows for Humanoid Robot Developers&lt;/strong&gt;&lt;br /&gt;
Training foundation models for humanoid robots requires an incredible amount of data. One way of capturing human demonstration data is using teleoperation, but this is becoming an increasingly expensive and lengthy process.&lt;/p&gt;

&lt;p align="justify"&gt;An NVIDIA AI- and Omniverse-enabled teleoperation reference workflow, &lt;a href="https://www.youtube.com/watch?v=Bhg3uOx9ZPw" rel="nofollow" target="_blank" title="demonstrated at the SIGGRAPH computer graphics conference"&gt;demonstrated at the SIGGRAPH computer graphics conference&lt;/a&gt;, allows researchers and AI developers to generate massive amounts of synthetic motion and perception data from a minimal amount of remotely captured human demonstrations.&lt;/p&gt;

&lt;p align="justify"&gt;First, developers use Apple Vision Pro to capture a small number of teleoperated demonstrations. Then, they simulate the recordings in NVIDIA Isaac Sim and use the MimicGen NIM microservice to generate synthetic datasets from the recordings.&lt;/p&gt;

&lt;p align="justify"&gt;The developers train the &lt;a href="https://developer.nvidia.com/project-gr00t" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Project GR00T&lt;/u&gt;&lt;/a&gt; humanoid foundation model with real and synthetic data, enabling developers to save time and reduce costs. They then use the Robocasa NIM microservice in &lt;a href="https://developer.nvidia.com/blog/fast-track-robot-learning-in-simulation-using-nvidia-isaac-lab/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Isaac Lab&lt;/u&gt;&lt;/a&gt;, a framework for robot learning, to generate experiences to retrain the robot model. Throughout the workflow, NVIDIA OSMO seamlessly assigns computing jobs to different resources, saving the developers weeks of administrative tasks.&lt;/p&gt;

&lt;p align="justify"&gt;Fourier, a general-purpose robot platform company, sees the benefit of using simulation technology to synthetically generate training data.&lt;/p&gt;

&lt;p align="justify"&gt;&amp;ldquo;Developing humanoid robots is extremely complex &amp;mdash; requiring an incredible amount of real data, tediously captured from the real world,&amp;rdquo; said Alex Gu, CEO of Fourier. &amp;ldquo;NVIDIA&amp;rsquo;s new simulation and generative AI developer tools will help bootstrap and accelerate our model development workflows.&amp;rdquo;&lt;/p&gt;

&lt;p align="justify"&gt;&lt;strong&gt;Expanding Access to NVIDIA Humanoid Developer Technologies&lt;/strong&gt;&lt;br /&gt;
NVIDIA provides three computing platforms to ease humanoid robotics development: NVIDIA AI supercomputers to train the models; NVIDIA Isaac Sim built on Omniverse, where robots can learn and refine their skills in simulated worlds; and NVIDIA Jetson&amp;trade; Thor humanoid robot computers to run the models. Developers can access and use all &amp;mdash; or any part of &amp;mdash; the platforms for their specific needs.&lt;/p&gt;

&lt;p align="justify"&gt;Through a new &lt;a href="https://developer.nvidia.com/humanoid-robot-program/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Humanoid Robot Developer Program&lt;/u&gt;&lt;/a&gt;, developers can gain early access to the new offerings as well as the latest releases of NVIDIA Isaac Sim, &lt;a href="https://isaac-sim.github.io/IsaacLab/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Isaac Lab&lt;/u&gt;&lt;/a&gt;, Jetson Thor and Project GR00T general-purpose humanoid foundation models.&lt;/p&gt;

&lt;p align="justify"&gt;1x, Boston Dynamics, ByteDance Research, &lt;a href="https://fieldai.com/blog/field-ai-nvidia-partnership" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Field AI&lt;/u&gt;&lt;/a&gt;, Figure, Fourier, Galbot, LimX Dynamics, &lt;a href="https://menteebot.com/blog/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Mentee&lt;/u&gt;&lt;/a&gt;, Neura Robotics, RobotEra and Skild AI are among the first to join the early-access program.&lt;/p&gt;

&lt;p align="justify"&gt;&amp;ldquo;Boston Dynamics and NVIDIA have a long history of close collaboration to push the boundaries of what&amp;rsquo;s possible in robotics,&amp;rdquo; said Aaron Saunders, chief technology officer of Boston Dynamics. &amp;ldquo;We&amp;rsquo;re really excited to see the fruits of this work accelerating the industry at large, and the early-access program is a fantastic way to access best-in-class technology.&amp;rdquo;&lt;/p&gt;

&lt;p align="justify"&gt;&lt;strong&gt;Availability&lt;/strong&gt;&lt;br /&gt;
Developers can join the NVIDIA Humanoid Robot Developer Program now to get access to NVIDIA OSMO and Isaac Lab, and will soon gain access to NVIDIA NIM microservices.&lt;/p&gt;

&lt;p align="justify"&gt;Learn more about the latest in generative AI and accelerated computing by &lt;a href="https://www.nvidia.com/en-us/events/siggraph/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;tuning in to Huang&amp;rsquo;s fireside chats&lt;/u&gt;&lt;/a&gt; at SIGGRAPH, the premier computer graphics conference, running through Aug. 1 in Denver.&lt;/p&gt;
]]&gt;</content><categories><category>Press Releases</category></categories><modDate>Mon, 29 Jul 2024 20:35:02 GMT</modDate><relatedPages></relatedPages><description><![CDATA[To accelerate humanoid development on a global scale, NVIDIA today announced it is providing the world’s leading robot manufacturers, AI model developers and software makers with a suite of services, models and computing platforms to develop, train and build the next generation of humanoid robotics.]]></description><enclosure url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20246/humanoid-robotics.jpeg" length="875158" type="image/jpeg"></enclosure><guid isPermaLink="true">https://nvidianews.nvidia.com/news/nvidia-accelerates-worldwide-humanoid-robotics-development</guid><pubDate>Mon, 29 Jul 2024 20:30:00 GMT</pubDate></item><item><title>NVIDIA Announces Generative AI Models and NIM Microservices for OpenUSD Language, Geometry, Physics and Materials</title><link>https://nvidianews.nvidia.com/news/nvidia-announces-generative-ai-models-and-nim-microservices-for-openusd</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20246/66a5e1673d63328cabaf75ee_openusd-to-industrial-digitalization/openusd-to-industrial-digitalization_thmb.jpg" fileSize="1043516" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20246/66a5e1673d63328cabaf75ee_openusd-to-industrial-digitalization/openusd-to-industrial-digitalization_thmb.jpg" alt="OpenUSD to Industrial Digitalization" align="left" hspace="15" vspace="5" /&gt;</image><subtitle>New Services Accelerate Universal Scene Description-Based Workflows and Development of Industrial Digital Twins and Robotics</subtitle><content>&lt;![CDATA[&lt;p&gt;&lt;strong&gt;SIGGRAPH&lt;/strong&gt;&amp;mdash;NVIDIA today announced major advancements to &lt;a href="https://www.nvidia.com/en-us/omniverse/usd/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Universal Scene Description, or OpenUSD&lt;/u&gt;&lt;/a&gt;, that will expand adoption of the universal 3D data interchange framework to robotics, industrial design and engineering, and accelerate developers&amp;rsquo; abilities to build highly accurate virtual worlds for the next evolution of AI.&lt;/p&gt;

&lt;p align="left"&gt;Through new OpenUSD-based generative AI and NVIDIA-accelerated development frameworks built on the &lt;a href="https://www.nvidia.com/en-us/omniverse/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Omniverse&lt;/u&gt;&lt;/a&gt;&amp;trade; platform, more industries can now develop applications for visualizing industrial design and engineering projects, and for simulating environments to build the next wave of &lt;a href="https://nvidianews.nvidia.com/news/nvidia-accelerates-worldwide-humanoid-robotics-development" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;physical AI and robots&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The new offerings include &lt;a href="https://build.nvidia.com/explore/simulation" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA NIM&amp;trade; microservices&lt;/u&gt;&lt;/a&gt; for AI models that can generate OpenUSD language to answer user queries, generate OpenUSD Python code, apply materials to 3D objects, and understand 3D space and physics to help accelerate digital twin development. In addition, new USD connectors to robotics and industrial simulation data formats and developer tools let users stream massive, fully &lt;a href="https://www.nvidia.com/en-us/design-visualization/technologies/rtx/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA RTX&lt;/u&gt;&lt;/a&gt;&amp;trade; ray-traced datasets to Apple Vision Pro.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;The generative AI boom for heavy industries is here,&amp;rdquo; said Rev Lebaredian, vice president of Omniverse and simulation technology at NVIDIA. &amp;ldquo;Until recently, digital worlds have been primarily used by creative industries; now, with the enhancements and accessibility NVIDIA NIM microservices are bringing to OpenUSD, industries of all kinds can build physically based virtual worlds and digital twins to drive innovation while preparing for the next wave of AI: robotics.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Generative AI Comes to USD With NVIDIA NIM&lt;/strong&gt;&lt;br /&gt;
The world&amp;rsquo;s first generative AI models for OpenUSD development, developed by NVIDIA, will be available as &lt;a href="https://build.nvidia.com/explore/simulation" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA NIM microservices&lt;/u&gt;&lt;/a&gt;. The models enable developers to incorporate generative AI copilots and agents into USD workflows, broadening the possibilities in 3D worlds and helping speed the adoption of USD across a new range of &lt;a href="https://www.nvidia.com/en-us/industries/industrial-sector/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;industrial sectors&lt;/u&gt;&lt;/a&gt;, like manufacturing, automotive and robotics.&lt;/p&gt;

&lt;p&gt;The microservices available in preview are:&lt;/p&gt;

&lt;ul type="disc"&gt;
	&lt;li&gt;&lt;a href="https://build.nvidia.com/nvidia/usdcode-llama3-70b-instruct" rel="nofollow" target="_blank" title=""&gt;&lt;strong&gt;&lt;u&gt;USD Code NIM&lt;/u&gt;&lt;/strong&gt;&lt;/a&gt; microservice &amp;mdash; answers general knowledge OpenUSD questions and automatically generates OpenUSD-Python code based on text prompts that can then be inputted into an OpenUSD viewing app, such as usdview from Pixar, or an NVIDIA Omniverse Kit-based application to visualize the corresponding 3D data.&lt;/li&gt;
	&lt;li&gt;&lt;a href="https://build.nvidia.com/nvidia/usdsearch" rel="nofollow" target="_blank" title=""&gt;&lt;strong&gt;&lt;u&gt;USD Search NIM&lt;/u&gt;&lt;/strong&gt;&lt;/a&gt; microservice &amp;mdash; enables developers to search through massive libraries of OpenUSD, 3D and image data using natural language or image inputs.&lt;/li&gt;
	&lt;li&gt;&lt;a href="https://build.nvidia.com/nvidia/usdvalidate" rel="nofollow" target="_blank" title=""&gt;&lt;strong&gt;&lt;u&gt;USD Validate NIM&lt;/u&gt;&lt;/strong&gt;&lt;/a&gt; microservice &amp;mdash; checks the compatibility of uploaded files against OpenUSD release versions and generates a fully RTX-rendered, path-traced image, powered by &lt;a href="https://www.nvidia.com/en-us/omniverse/cloud/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Omniverse Cloud APIs&lt;/u&gt;&lt;/a&gt;, or application programming interfaces.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Newly announced microservices that will be available soon are:&lt;/p&gt;

&lt;ul type="disc"&gt;
	&lt;li&gt;&lt;strong&gt;USD Layout NIM&lt;/strong&gt; microservice &amp;mdash; enables users to assemble OpenUSD-based scenes from a series of text prompts based on spatial intelligence.&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;USD SmartMaterial NIM&lt;/strong&gt; microservice &amp;mdash; predicts and applies a realistic material to a computer-aided design object.&lt;/li&gt;
	&lt;li&gt;&lt;a href="https://blogs.nvidia.com/blog/fvdb-bigger-digital-models/" rel="nofollow" target="_blank" title=""&gt;&lt;strong&gt;&lt;u&gt;fVDB&lt;/u&gt;&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt; Mesh Generation &lt;/strong&gt;&lt;strong&gt;NIM&lt;/strong&gt; microservice &amp;mdash; generates an OpenUSD-based mesh, rendered by Omniverse Cloud APIs, from point-cloud data.&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;fVDB Physics Super-Res NIM&lt;/strong&gt; microservice &amp;mdash; performs AI super resolution on a frame or sequence of frames to generate an OpenUSD-based, high-resolution physics simulation.&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;fVDB NeRF-XL NIM &lt;/strong&gt;microservice &amp;mdash; generates large-scale neural radiance fields in OpenUSD using Omniverse Cloud APIs.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href="https://blogs.nvidia.com/blog/foxconn-digital-twin-ai/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Foxconn&lt;/u&gt;&lt;/a&gt;, a global manufacturing leader with more than 170 factories worldwide, is already benefiting from NVIDIA&amp;rsquo;s computing platform, using NIM microservices and Omniverse to create a &lt;a href="https://www.nvidia.com/en-us/omniverse/solutions/digital-twins/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;digital twin&lt;/u&gt;&lt;/a&gt; of a factory under development.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;Digital twins will help us accelerate the next wave of industrial manufacturing and autonomous machines,&amp;rdquo; said Zhe Shi, chief digital officer and head of the Smart Manufacturing platform at Foxconn. &amp;ldquo;NVIDIA Omniverse and the new NIM microservices will democratize the ability to develop digital twins and help our teams build physically based virtual factories faster than ever.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://www.nvidia.com/en-us/industries/media-and-entertainment/wpp/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;WPP&lt;/u&gt;&lt;/a&gt;, a world leader in marketing and communications services company, is an early adopter of USD Search and USD Code NIM microservices, implementing them in its generative AI-enabled content creation pipeline, built on NVIDIA Omniverse, for customers such as &lt;a href="https://blogs.nvidia.com/blog/coca-cola-wpp-omniverse-generative-ai" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;The Coca-Cola Company&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;The beauty of the innovation is how compatible it is with the way we work, and that it leverages open standards &amp;mdash; accelerating not only future work, but allowing us to continue to build on and extend the usefulness of all our previous investments in standards like OpenUSD,&amp;rdquo; said Stephan Pretorius, chief technology officer at WPP. &amp;ldquo;Using NVIDIA NIM microservices with NVIDIA Omniverse has made it possible for us to launch innovative new production tools with companies like The Coca-Cola Company at unprecedented speed.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;USD Connectors Bring Generative AI to More Industries&lt;/strong&gt;&lt;br /&gt;
A series of new USD connectors for robotics data formats and streaming to Apple Vision Pro opens the portals of OpenUSD interoperability and advanced authoring to more industries.&lt;/p&gt;

&lt;p&gt;NVIDIA and &lt;a href="https://www.nvidia.com/en-us/industries/industrial-sector/siemens/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Siemens&lt;/u&gt;&lt;/a&gt;, a global leader in industrial automation and software, are extending their collaboration to facilitate more industrial workloads using OpenUSD. Siemens will integrate OpenUSD pipelines with its Simcenter portfolio of simulation technologies to support evidence-based decision-making and collaboration among key stakeholders.&lt;/p&gt;

&lt;p&gt;This integration enables high-fidelity, real-time, photorealistic visualization of complex simulation data, providing deeper insights into a product&amp;rsquo;s performance within its real-world operating environment. The work will build on Siemens&amp;rsquo; efforts to incorporate Omniverse into its Teamcenter Product Lifecycle Management portfolio.&lt;/p&gt;

&lt;p&gt;NVIDIA also released a connector from Unified Robotics Description Format to OpenUSD, letting roboticists seamlessly bring their robot data across applications, including for design, simulation and &lt;a href="https://www.nvidia.com/en-us/use-cases/reinforcement-learning/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;reinforcement learning&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To further advance &lt;a href="https://www.nvidia.com/en-us/accelerated-applications/usd-ecosystem/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;OpenUSD ecosystem&lt;/u&gt;&lt;/a&gt; expansion, NVIDIA announced the &lt;a href="https://docs.omniverse.nvidia.com/usd-exchange-sdk.html" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;OpenUSD Exchange software development kit&lt;/u&gt;&lt;/a&gt;, enabling developers to build their own robust OpenUSD data connectors.&lt;/p&gt;

&lt;p&gt;New developer tools and APIs to stream large-scale OpenUSD scenes from an application built on the Omniverse platform to &lt;a href="https://www.youtube.com/watch?v=jX4RsRwg7VA&amp;amp;ab_channel=NVIDIAOmniverse" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Apple Vision Pro&lt;/u&gt;&lt;/a&gt; via the &lt;a href="https://www.nvidia.com/en-us/omniverse/solutions/stream-3d-apps/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Graphics Delivery Network&lt;/u&gt;&lt;/a&gt; are now available in &lt;a href="https://www.nvidia.com/en-us/omniverse/apple-vision-pro-notify/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;early access&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;OpenUSD is revolutionizing the way we create and interact with 3D content,&amp;rdquo; said Steve May, chief technology officer of Pixar and chairman of the Alliance for OpenUSD (AOUSD). &amp;ldquo;Now, with these new services and APIs for OpenUSD built by NVIDIA, we expect to see accelerated growth and adoption of USD, paving the way for new users and industries to more easily engage with our ecosystem.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;OpenUSD Ecosystem Momentum&lt;/strong&gt;&lt;br /&gt;
Last year, NVIDIA &lt;a href="https://www.linuxfoundation.org/press/announcing-alliance-for-open-usd-aousd" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;cofounded the AOUSD&lt;/u&gt;&lt;/a&gt; along with Pixar, Adobe, Apple and Autodesk. Through AOUSD, NVIDIA and other collaborators have &lt;a href="https://aousd.org/uncategorized/alliance-for-openusd-announces-new-interest-groups-sony-membership-and-core-specifications-updates/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;announced&lt;/u&gt;&lt;/a&gt; a new OpenUSD &lt;a href="https://aousd.org/blog/new-release-of-openusd/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;release&lt;/u&gt;&lt;/a&gt;, progress on an OpenUSD &lt;a href="https://aousd.org/blog/aousd-core-specification-updates/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;core specification&lt;/u&gt;&lt;/a&gt; and new members.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Availability&lt;/strong&gt;&lt;br /&gt;
The USD Search, USD Code and USD Validate NIM microservices are available in preview on the &lt;a href="https://build.nvidia.com/search?term=usd" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA API catalog&lt;/u&gt;&lt;/a&gt;. The OpenUSD to URDF connector is now available with &lt;a href="https://developer.nvidia.com/isaac/sim" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Isaac Sim&lt;/u&gt;&lt;/a&gt;&amp;trade;.&lt;/p&gt;

&lt;p&gt;Developers can get started &lt;a href="https://developer.nvidia.com/blog/integrate-generative-ai-into-openusd-workflows-using-new-nvidia-omniverse-developer-tools/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;integrating generative AI into OpenUSD workflows with new Omniverse developer tools&lt;/u&gt;&lt;/a&gt; and a reference workflow for &lt;a href="https://developer.nvidia.com/blog/how-to-build-a-generative-ai-enabled-synthetic-data-pipeline-with-openusd/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;building a generative AI-enabled synthetic data pipeline with OpenUSD&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Learn more about the latest in generative AI and accelerated computing by &lt;a href="https://www.nvidia.com/en-us/events/siggraph/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;tuning in to NVIDIA founder and CEO Jensen Huang&amp;rsquo;s fireside chats&lt;/u&gt;&lt;/a&gt; at SIGGRAPH, the premier computer graphics conference, running through Aug. 1 in Denver.&lt;/p&gt;
]]&gt;</content><categories><category>Press Releases</category></categories><modDate>Mon, 29 Jul 2024 20:35:17 GMT</modDate><relatedPages></relatedPages><description><![CDATA[SIGGRAPH—NVIDIA today announced major advancements to Universal Scene Description, or OpenUSD, that will expand adoption of the universal 3D data interchange framework to robotics, industrial design and engineering, and accelerate developers’ abilities to build highly accurate virtual worlds for the next evolution of AI.]]></description><enclosure url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20246/openusd-to-industrial-digitalization.jpeg" length="1043516" type="image/jpeg"></enclosure><guid isPermaLink="true">https://nvidianews.nvidia.com/news/nvidia-announces-generative-ai-models-and-nim-microservices-for-openusd</guid><pubDate>Mon, 29 Jul 2024 20:30:00 GMT</pubDate></item><item><title>Unleash the Dragonborn: ‘Elder Scrolls V: Skyrim Special Edition’ Joins GeForce NOW</title><link>https://blogs.nvidia.com/blog/geforce-now-thursday-elder-scrolls-skyrim/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a24d693d63325b68b625a5_gfn-thursday-7-11-nv-blog-1280x680-no-copy-1-842x450/gfn-thursday-7-11-nv-blog-1280x680-no-copy-1-842x450_thmb.jpg" fileSize="30881" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a24d693d63325b68b625a5_gfn-thursday-7-11-nv-blog-1280x680-no-copy-1-842x450/gfn-thursday-7-11-nv-blog-1280x680-no-copy-1-842x450_thmb.jpg" alt="gfn-thursday-7-11-nv-blog-1280x680-no-copy-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Thu, 25 Jul 2024 13:04:44 GMT</modDate><relatedPages></relatedPages><description><![CDATA[“Hey, you. You’re finally awake.” It’s the summer of Elder Scrolls — whether a seasoned Dragonborn or a new adventurer, dive into the legendary world of Tamriel this GFN Thursday as The Elder Scrolls V: Skyrim Special Edition joins the cloud. Epic adventures await, along with nine new games joining the GeForce NOW library this	<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-elder-scrolls-skyrim/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>GeForce NOW Community</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/geforce-now-thursday-elder-scrolls-skyrim/</guid><pubDate>Thu, 25 Jul 2024 13:00:02 GMT</pubDate></item><item><title>Demystifying AI-Assisted Artistry With Adobe Apps Using NVIDIA RTX</title><link>https://blogs.nvidia.com/blog/ai-decoded-adobe-firefly-creative-cloud-rtx/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a0fd3e3d63323675d23d35_adobe-apps-nv-blog-1280x680-1-842x450/adobe-apps-nv-blog-1280x680-1-842x450_thmb.jpg" fileSize="15526" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/66a0fd3e3d63323675d23d35_adobe-apps-nv-blog-1280x680-1-842x450/adobe-apps-nv-blog-1280x680-1-842x450_thmb.jpg" alt="adobe-apps-nv-blog-1280x680-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Wed, 24 Jul 2024 13:10:25 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Adobe Creative Cloud applications, which tap NVIDIA RTX GPUs, are designed to enhance the creativity of users, empowering them to work faster and focus on their craft.]]></description><author>Gerardo Delgado</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/ai-decoded-adobe-firefly-creative-cloud-rtx/</guid><pubDate>Wed, 24 Jul 2024 13:00:56 GMT</pubDate></item><item><title>How Georgia Tech’s AI Makerspace Is Preparing the Future Workforce for AI</title><link>https://blogs.nvidia.com/blog/georgia-tech-ai-makerspace-supercomputer/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202403/66041919ed6ae53d65ee6ca6_ai-podcast-2600x1472_-1-842x450/ai-podcast-2600x1472_-1-842x450_thmb.jpg" fileSize="34385" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202403/66041919ed6ae53d65ee6ca6_ai-podcast-2600x1472_-1-842x450/ai-podcast-2600x1472_-1-842x450_thmb.jpg" alt="ai-podcast-2600x1472_-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Wed, 24 Jul 2024 13:10:27 GMT</modDate><relatedPages></relatedPages><description><![CDATA[AI is set to transform the workforce — and the Georgia Institute of Technology’s new AI Makerspace is helping tens of thousands of students get ahead of the curve. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Arijit Raychowdhury, a professor and Steve W. Cedex school chair of electrical engineering at	<a class="read-more" href="https://blogs.nvidia.com/blog/georgia-tech-ai-makerspace-supercomputer/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Kristen Yee</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/georgia-tech-ai-makerspace-supercomputer/</guid><pubDate>Wed, 24 Jul 2024 13:00:41 GMT</pubDate></item><item><title>How NVIDIA AI Foundry Lets Enterprises Forge Custom Generative AI Models</title><link>https://blogs.nvidia.com/blog/ai-foundry-enterprise-generative-ai/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/669fc9b63d6332711323b7a4_ai-foundry-842x450/ai-foundry-842x450_thmb.jpg" fileSize="24440" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/669fc9b63d6332711323b7a4_ai-foundry-842x450/ai-foundry-842x450_thmb.jpg" alt="ai-foundry-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Tue, 23 Jul 2024 15:18:17 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Businesses seeking to harness the power of AI need customized models tailored to their specific industry needs. NVIDIA AI Foundry is a service that enables enterprises to use data, accelerated computing and software tools to create and deploy custom models that can supercharge their generative AI initiatives. Just as TSMC manufactures chips designed by other	<a class="read-more" href="https://blogs.nvidia.com/blog/ai-foundry-enterprise-generative-ai/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Kari Briski</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/ai-foundry-enterprise-generative-ai/</guid><pubDate>Tue, 23 Jul 2024 15:15:59 GMT</pubDate></item><item><title>AI, Go Fetch! New NVIDIA NeMo Retriever Microservices Boost LLM Accuracy and Throughput</title><link>https://blogs.nvidia.com/blog/nemo-retriever-microservices/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/669fc9bb3d6332711323b7aa_nemo-retriever-nim-featured-842x450/nemo-retriever-nim-featured-842x450_thmb.jpg" fileSize="12716" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/669fc9bb3d6332711323b7aa_nemo-retriever-nim-featured-842x450/nemo-retriever-nim-featured-842x450_thmb.jpg" alt="nemo-retriever-nim-featured-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Tue, 23 Jul 2024 15:18:22 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Generative AI applications have little, or sometimes negative, value without accuracy — and accuracy is rooted in data. To help developers efficiently fetch the best proprietary data to generate knowledgeable responses for their AI applications, NVIDIA today announced four new NVIDIA NeMo Retriever NIM inference microservices. Combined with NVIDIA NIM inference microservices for the Llama	<a class="read-more" href="https://blogs.nvidia.com/blog/nemo-retriever-microservices/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Erik Pounds</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/nemo-retriever-microservices/</guid><pubDate>Tue, 23 Jul 2024 15:15:16 GMT</pubDate></item><item><title>NVIDIA AI Foundry Builds Custom Llama 3.1 Generative AI Models for the World’s Enterprises</title><link>https://nvidianews.nvidia.com/news/nvidia-ai-foundry-custom-llama-generative-models</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20246/669fcb2b3d633269dd067274_NVIDIA+AI+Foundry+-+Llama+3.1+press+release+image+-+1280x680/NVIDIA+AI+Foundry+-+Llama+3.1+press+release+image+-+1280x680_thmb.png" fileSize="324760" type="image/png"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20246/669fcb2b3d633269dd067274_NVIDIA+AI+Foundry+-+Llama+3.1+press+release+image+-+1280x680/NVIDIA+AI+Foundry+-+Llama+3.1+press+release+image+-+1280x680_thmb.png" alt="NVIDIA AI Foundry for Custom Llama 3.1 Generative AI Models" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><content>&lt;![CDATA[&lt;ul&gt;
	&lt;li&gt;&lt;em&gt;Enterprises and Nations Can Now Build &amp;lsquo;Supermodels&amp;rsquo; With NVIDIA AI Foundry Using Their Own Data Paired With Llama 3.1 405B and NVIDIA Nemotron Models&lt;/em&gt;&lt;/li&gt;
	&lt;li&gt;&lt;em&gt;NVIDIA AI Foundry Offers Comprehensive Generative AI Model Service Spanning Curation, Synthetic Data Generation, Fine-Tuning, Retrieval, Guardrails and Evaluation to Deploy Custom Llama 3.1 NVIDIA NIM Microservices With New NVIDIA NeMo Retriever Microservices for Accurate Responses&lt;/em&gt;&lt;/li&gt;
	&lt;li&gt;&lt;em&gt;Accenture First to Use New Service to Build Custom Llama 3.1 Models for Clients; Aramco, AT&amp;amp;T, Uber and Other Industry Leaders Among First to Access New Llama NVIDIA NIM Microservices&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;NVIDIA today announced a new &lt;a href="https://www.nvidia.com/en-us/ai/foundry/?ncid=ref-pr-188783" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA AI Foundry&lt;/u&gt;&lt;/a&gt; service and &lt;a href="https://www.nvidia.com/en-us/ai/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA NIM&lt;/u&gt;&lt;/a&gt;&amp;trade; inference microservices to supercharge generative AI for the world&amp;rsquo;s enterprises with the &lt;a href="https://ai.meta.com/blog/meta-llama-3-1/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Llama 3.1&lt;/u&gt;&lt;/a&gt; collection of openly available models, also introduced today.&lt;/p&gt;

&lt;p&gt;With NVIDIA AI Foundry, enterprises and nations can now create custom &amp;ldquo;supermodels&amp;rdquo; for their domain-specific industry use cases using Llama 3.1 and NVIDIA software, computing and expertise. Enterprises can train these supermodels with proprietary data as well as synthetic data generated from Llama 3.1 405B and the &lt;a href="https://blogs.nvidia.com/blog/nemotron-4-synthetic-data-generation-llm-training/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Nemotron&lt;/u&gt;&lt;/a&gt;&amp;trade; Reward model.&lt;/p&gt;

&lt;p&gt;NVIDIA AI Foundry is powered by the &lt;a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA DGX&amp;trade; Cloud&lt;/u&gt;&lt;/a&gt; AI platform, which is co-engineered with the world&amp;rsquo;s leading public clouds, to give enterprises significant compute resources that easily scale as AI demands change.&lt;/p&gt;

&lt;p&gt;The new offerings come at a time when enterprises, as well as nations developing sovereign AI strategies, want to build custom large language models with domain-specific knowledge for generative AI applications that reflect their unique business or culture.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;Meta&amp;rsquo;s openly available Llama 3.1 models mark a pivotal moment for the adoption of generative AI within the world&amp;rsquo;s enterprises,&amp;rdquo; said Jensen Huang, founder and CEO of NVIDIA. &amp;ldquo;Llama 3.1 opens the floodgates for every enterprise and industry to build state-of-the-art generative AI applications. NVIDIA AI Foundry has integrated Llama 3.1 throughout and is ready to help enterprises build and deploy custom Llama supermodels.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&amp;ldquo;The new Llama 3.1 models are a super-important step for open source AI,&amp;rdquo; said Mark Zuckerberg, founder and CEO of Meta. &amp;ldquo;With NVIDIA AI Foundry, companies can easily create and customize the state-of-the-art AI services people want and deploy them with NVIDIA NIM. I&amp;rsquo;m excited to get this in people&amp;rsquo;s hands.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;To supercharge enterprise deployments of Llama 3.1 models for production AI, &lt;a href="https://www.nvidia.com/en-us/ai/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA NIM&lt;/u&gt;&lt;/a&gt; inference microservices for Llama 3.1 models are now available for download from &lt;a href="http://ai.nvidia.com" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;ai.nvidia.com&lt;/u&gt;&lt;/a&gt;. NIM microservices are the fastest way to deploy Llama 3.1 models in production and power up to 2.5x higher throughput than running inference without NIM.&lt;/p&gt;

&lt;p&gt;Enterprises can pair Llama 3.1 NIM microservices with new &lt;a href="https://blogs.nvidia.com/blog/nemo-retriever-microservices" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA NeMo Retriever NIM microservices&lt;/u&gt;&lt;/a&gt; to create state-of-the-art retrieval pipelines for AI copilots, assistants and &lt;a href="https://www.nvidia.com/en-us/use-cases/digital-humans/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;digital human avatars&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Accenture Pioneers Custom Llama Supermodels for Enterprises With AI Foundry&lt;/strong&gt;&lt;br /&gt;
Global professional services firm &lt;a href="https://newsroom.accenture.com/news/2024/accenture-pioneers-custom-llama-llm-models-with-nvidia-ai-foundry" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Accenture&lt;/u&gt;&lt;/a&gt; is first to adopt NVIDIA AI Foundry to build custom Llama 3.1 models using the Accenture AI Refinery&amp;trade; framework, both for its own use as well as for clients seeking to deploy generative AI applications that reflect their culture, languages and industries.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;The world&amp;rsquo;s leading enterprises see how generative AI is transforming every industry and are eager to deploy applications powered by custom models,&amp;rdquo; said Julie Sweet, chair and CEO of Accenture. &amp;ldquo;Accenture has been working with NVIDIA NIM inference microservices for our internal AI applications, and now, using NVIDIA AI Foundry, we can help clients quickly create and deploy custom Llama 3.1 models to power transformative AI applications for their own business priorities.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;NVIDIA AI Foundry provides an end-to-end service for quickly building custom supermodels. It combines NVIDIA software, infrastructure and expertise with open community models, technology and support from the NVIDIA AI ecosystem.&lt;/p&gt;

&lt;p&gt;With NVIDIA AI Foundry, enterprises can create custom models using Llama 3.1 models and the &lt;a href="https://www.nvidia.com/en-us/ai-data-science/products/nemo/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA NeMo&lt;/u&gt;&lt;/a&gt; platform &amp;mdash; including the NVIDIA Nemotron-4 340B Reward model, ranked first on the &lt;a href="https://huggingface.co/spaces/allenai/reward-bench" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;Hugging Face RewardBench&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Once custom models are created, enterprises can create NVIDIA NIM inference microservices to run them in production using their preferred MLOps and AIOps platforms on their preferred cloud platforms and &lt;a href="https://www.nvidia.com/en-us/data-center/products/certified-systems/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA-Certified Systems&lt;/u&gt;&lt;/a&gt;&amp;trade; from global server manufacturers.&lt;/p&gt;

&lt;p&gt;NVIDIA AI Enterprise experts and global system integrator partners work with AI Foundry customers to accelerate the entire process, from development to deployment.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NVIDIA Nemotron Powers Advanced Model Customization&lt;/strong&gt;&lt;br /&gt;
Enterprises that need additional training data for creating a domain-specific model can use Llama 3.1 405B and Nemotron-4 340B together to generate &lt;a href="https://blogs.nvidia.com/blog/what-is-synthetic-data/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;synthetic data&lt;/u&gt;&lt;/a&gt; to boost model accuracy when creating custom Llama supermodels.&lt;/p&gt;

&lt;p&gt;Customers that have their own training data can customize Llama 3.1 models with NVIDIA NeMo for domain-adaptive pretraining, or DAPT, to further increase model accuracy.&lt;/p&gt;

&lt;p&gt;NVIDIA and Meta have also teamed to provide a distillation recipe for Llama 3.1 that developers can use to build smaller custom Llama 3.1 models for generative AI applications. This enables enterprises to run Llama-powered AI applications on a broader range of accelerated infrastructure, such as AI workstations and laptops.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Industry-Leading Enterprises Supercharge AI With NVIDIA and Llama&lt;/strong&gt;&lt;br /&gt;
Companies across healthcare, energy, financial services, retail, transportation and telecommunications are already working with NVIDIA NIM microservices for Llama. Among the first to access the new NIM microservices for Llama 3.1 are Aramco, AT&amp;amp;T and Uber.&lt;/p&gt;

&lt;p&gt;Trained on over 16,000 &lt;a href="https://www.nvidia.com/en-us/data-center/h100/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA H100&lt;/u&gt;&lt;/a&gt; Tensor Core GPUs and optimized for NVIDIA accelerated computing and software &amp;mdash; in the data center, in the cloud and locally on workstations with &lt;a href="https://www.nvidia.com/en-us/design-visualization/desktop-graphics/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA RTX&lt;/u&gt;&lt;/a&gt;&amp;trade; GPUs or PCs with &lt;a href="https://www.nvidia.com/en-us/geforce/rtx/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;GeForce RTX&lt;/u&gt;&lt;/a&gt; GPUs &amp;mdash; the Llama 3.1 collection of multilingual LLMs is a collection of generative AI models in 8B-, 70B- and 405B-parameter sizes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;New NeMo Retriever RAG Microservices Boost Accuracy and Performance&lt;/strong&gt;&lt;br /&gt;
Using new NVIDIA NeMo Retriever NIM inference microservices for retrieval-augmented generation (&lt;a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;RAG&lt;/u&gt;&lt;/a&gt;), organizations can enhance response accuracy when deploying customized Llama supermodels and Llama NIM microservices in production.&lt;/p&gt;

&lt;p&gt;Combined with NVIDIA NIM inference microservices for Llama 3.1 405B, NeMo Retriever NIM microservices deliver the highest open and commercial text Q&amp;amp;A retrieval accuracy for RAG pipelines.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Enterprise Ecosystem Ready to Power Llama 3.1 and NeMo Retriever NIM Deployments&lt;/strong&gt;&lt;br /&gt;
Hundreds of NVIDIA NIM partners providing enterprise, data and infrastructure platforms can now integrate the new microservices in their AI solutions to supercharge generative AI for the NVIDIA community of more than 5 million developers and 19,000 startups.&lt;/p&gt;

&lt;p&gt;Production support for Llama 3.1 NIM and NeMo Retriever NIM microservices is available through &lt;a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA AI Enterprise&lt;/u&gt;&lt;/a&gt;. Members of the &lt;a href="https://developer.nvidia.com/join-nvidia-developer-program/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Developer Program&lt;/u&gt;&lt;/a&gt; will soon be able to access NIM microservices for free for research, development and testing on their preferred infrastructure.&lt;/p&gt;
]]&gt;</content><categories><category>Press Releases</category></categories><modDate>Tue, 23 Jul 2024 15:25:13 GMT</modDate><relatedPages></relatedPages><description><![CDATA[NVIDIA today announced a new NVIDIA AI Foundry service and NVIDIA NIM™ inference microservices to supercharge generative AI for the world’s enterprises with the Llama 3.1 collection of openly available models, also introduced today.]]></description><enclosure url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/20246/NVIDIA+AI+Foundry+-+Llama+3.1+press+release+image+-+1280x680.png" length="324760" type="image/png"></enclosure><guid isPermaLink="true">https://nvidianews.nvidia.com/news/nvidia-ai-foundry-custom-llama-generative-models</guid><pubDate>Tue, 23 Jul 2024 15:15:00 GMT</pubDate></item><item><title>NVIDIA’s AI Masters Sweep KDD Cup 2024 Data Science Competition</title><link>https://blogs.nvidia.com/blog/nvidia-ai-masters-kdd-cup-2024/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/669ee261ed6ae53a046be0d0_sigg24-llm-image-AI-Masters-842x450/sigg24-llm-image-AI-Masters-842x450_thmb.jpg" fileSize="84553" type="image/png"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/669ee261ed6ae53a046be0d0_sigg24-llm-image-AI-Masters-842x450/sigg24-llm-image-AI-Masters-842x450_thmb.jpg" alt="sigg24-llm-image-AI-Masters-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Mon, 22 Jul 2024 23:03:33 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Team NVIDIA has triumphed at the Amazon KDD Cup 2024, securing first place Friday across all five competition tracks. The team — consisting of NVIDIANs Ahmet Erdem, Benedikt Schifferer, Chris Deotte, Gilberto Titericz, Ivan Sorokin and Simon Jegou — demonstrated its prowess in generative AI, winning in categories that included text generation, multiple-choice questions, name	<a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-ai-masters-kdd-cup-2024/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Brian Caulfield</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/nvidia-ai-masters-kdd-cup-2024/</guid><pubDate>Mon, 22 Jul 2024 22:47:00 GMT</pubDate></item><item><title>Sustainable Strides: How AI and Accelerated Computing Are Driving Energy Efficiency</title><link>https://blogs.nvidia.com/blog/accelerated-ai-energy-efficiency/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/669e8b743d6332a2b5811f64_Slide1-842x450/Slide1-842x450_thmb.jpg" fileSize="35106" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/669e8b743d6332a2b5811f64_Slide1-842x450/Slide1-842x450_thmb.jpg" alt="Slide1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Mon, 22 Jul 2024 16:40:24 GMT</modDate><relatedPages></relatedPages><description><![CDATA[AI and accelerated computing — twin engines NVIDIA continuously improves — are delivering energy efficiency for many industries. It’s progress the wider community is starting to acknowledge. “Even if the predictions that data centers will soon account for 4% of global energy consumption become a reality, AI is having a major impact on reducing the	<a class="read-more" href="https://blogs.nvidia.com/blog/accelerated-ai-energy-efficiency/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Dion Harris</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/accelerated-ai-energy-efficiency/</guid><pubDate>Mon, 22 Jul 2024 12:00:18 GMT</pubDate></item><item><title>Byte-Sized Courses: NVIDIA Offers Self-Paced Career Development in AI and Data Science</title><link>https://blogs.nvidia.com/blog/ai-data-science-career-development/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/669a8f303d63321d81c757bb_IMG_7082-1-842x450/IMG_7082-1-842x450_thmb.jpg" fileSize="56168" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202407/669a8f303d63321d81c757bb_IMG_7082-1-842x450/IMG_7082-1-842x450_thmb.jpg" alt="IMG_7082-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Fri, 19 Jul 2024 16:07:16 GMT</modDate><relatedPages></relatedPages><description><![CDATA[AI has seen unprecedented growth — spurring the need for new training and education resources for students and industry professionals. NVIDIA’s latest on-demand webinar, Essential Training and Tips to Accelerate Your Career in AI, featured a panel discussion with industry experts on fostering career growth and learning in AI and other advanced technologies. Over 1,800	<a class="read-more" href="https://blogs.nvidia.com/blog/ai-data-science-career-development/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description><author>Andy Bui</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/ai-data-science-career-development/</guid><pubDate>Fri, 19 Jul 2024 16:00:14 GMT</pubDate></item></channel></rss>