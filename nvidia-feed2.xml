<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>News Releases - NVIDIA Newsroom</title><link>https://nvidianews.nvidia.com</link><description>All News</description><language>en-us</language><pubDate>Wed, 13 Dec 2023 17:10:09 GMT</pubDate><lastBuildDate>Wed, 13 Dec 2023 17:10:09 GMT</lastBuildDate><generator>iPressroom</generator><item><title>How Is AI Used in Fraud Detection?</title><link>https://blogs.nvidia.com/blog/ai-fraud-detection-rapids-triton-tensorrt-nemo/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/6579e4a33d6332f729c6bbd9_AIfrauddetection/AIfrauddetection_thmb.jpg" fileSize="26011" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/6579e4a33d6332f729c6bbd9_AIfrauddetection/AIfrauddetection_thmb.jpg" alt="AIfrauddetection" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Wed, 13 Dec 2023 17:06:49 GMT</modDate><relatedPages></relatedPages><description><![CDATA[The Wild West had gunslingers, bank robberies and bounties — today’s digital frontier has identity theft, credit card fraud and chargebacks. Cashing in on financial fraud has become a multibillion-dollar criminal enterprise. And generative AI in the hands of fraudsters only promises to make this more profitable. Credit card losses worldwide are expected to reach <a class="read-more" href="https://blogs.nvidia.com/blog/ai-fraud-detection-rapids-triton-tensorrt-nemo/">Read article &#62;</a>]]></description><author>Kevin Levitt</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/ai-fraud-detection-rapids-triton-tensorrt-nemo/</guid><pubDate>Wed, 13 Dec 2023 17:00:43 GMT</pubDate></item><item><title>Pie From the Sky: Drone Startup Delivers Pizza, Meds and Side of Excitement</title><link>https://blogs.nvidia.com/blog/zipline-drone-jetson-inception/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/6579d65b3d6332eb660c6254_Zip-package-drop_no_cross_red_wing-copy-1-842x450/Zip-package-drop_no_cross_red_wing-copy-1-842x450_thmb.jpg" fileSize="15398" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/6579d65b3d6332eb660c6254_Zip-package-drop_no_cross_red_wing-copy-1-842x450/Zip-package-drop_no_cross_red_wing-copy-1-842x450_thmb.jpg" alt="Zip-package-drop_no_cross_red_wing-copy-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Wed, 13 Dec 2023 16:05:51 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Zipline isn’t just some pie-in-the-sky drone startup. The San Francisco-based company has completed more than 800,000 deliveries in seven countries since its start in 2011. It recently added services for Seattle’s Pagliacci Pizza, vitamin and supplement giant GNC, and large health systems like Intermountain Health, OhioHealth and Michigan Medicine. Zipline developed its drones — which <a class="read-more" href="https://blogs.nvidia.com/blog/zipline-drone-jetson-inception/">Read article &#62;</a>]]></description><author>Scott Martin</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/zipline-drone-jetson-inception/</guid><pubDate>Wed, 13 Dec 2023 16:00:11 GMT</pubDate></item><item><title>Meet NANA, Moonshine Studio’s AI-Powered Receptionist Avatar</title><link>https://blogs.nvidia.com/blog/studio-moonshine-blender-marvelous-designer-adobe-unreal-engine/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/65786868ed6ae54e9cc6e3b9_studio-ints-eric-chiang-wk87-blog-header-img-1280x680-1/studio-ints-eric-chiang-wk87-blog-header-img-1280x680-1_thmb.jpg" fileSize="1866950" type="video/mp4"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/65786868ed6ae54e9cc6e3b9_studio-ints-eric-chiang-wk87-blog-header-img-1280x680-1/studio-ints-eric-chiang-wk87-blog-header-img-1280x680-1_thmb.jpg" alt="studio-ints-eric-chiang-wk87-blog-header-img-1280x680-1" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Tue, 12 Dec 2023 14:04:38 GMT</modDate><relatedPages></relatedPages><description><![CDATA[The creative team at Moonshine Studio — an artist-focused visual effects (VFX) studio specializing in animation and motion design — was tasked to solve a problem.]]></description><author>Gerardo Delgado</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/studio-moonshine-blender-marvelous-designer-adobe-unreal-engine/</guid><pubDate>Tue, 12 Dec 2023 14:00:49 GMT</pubDate></item><item><title>How NVIDIA Fuels the AI Revolution With Investments in Game Changers and Market Makers</title><link>https://blogs.nvidia.com/blog/nvidia-investments/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/6577328fed6ae55b832c5d0f_nvidia-headquarters-1/nvidia-headquarters-1_thmb.jpg" fileSize="73950" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/6577328fed6ae55b832c5d0f_nvidia-headquarters-1/nvidia-headquarters-1_thmb.jpg" alt="nvidia-headquarters-1" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Mon, 11 Dec 2023 16:02:27 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Great companies thrive on stories. Sid Siddeek, who runs NVIDIA’s venture capital arm, knows this well. Siddeek still remembers one of his first jobs, schlepping presentation materials from one investor meeting to another, helping the startup’s CEO and management team get the story out while working from a trailer that “shook when the door opened,” <a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-investments/">Read article &#62;</a>]]></description><author>Liz Archibald</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/nvidia-investments/</guid><pubDate>Mon, 11 Dec 2023 16:00:01 GMT</pubDate></item><item><title>500 Games and Apps Now Powered by RTX: A DLSS and Ray-Tracing Milestone</title><link>https://blogs.nvidia.com/blog/500-geforce-rtx/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/65721d113d6332f16148455a_gf-article-thumb-1200x630%402x-842x450/gf-article-thumb-1200x630%402x-842x450_thmb.jpg" fileSize="52005" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/65721d113d6332f16148455a_gf-article-thumb-1200x630%402x-842x450/gf-article-thumb-1200x630%402x-842x450_thmb.jpg" alt="gf-article-thumb-1200x630@2x-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Thu, 07 Dec 2023 19:29:25 GMT</modDate><relatedPages></relatedPages><description><![CDATA[We’re celebrating a milestone this week with 500 RTX games and applications utilizing NVIDIA DLSS, ray tracing or AI technologies. It’s an achievement anchored by NVIDIA’s revolutionary RTX technology, which has transformed gaming graphics and performance. The journey began in 2018 at an electrifying event in Cologne. In a steel and concrete music venue amidst <a class="read-more" href="https://blogs.nvidia.com/blog/500-geforce-rtx/">Read article &#62;</a>]]></description><author>Keoki Young</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/500-geforce-rtx/</guid><pubDate>Thu, 07 Dec 2023 19:23:30 GMT</pubDate></item><item><title>Meet the Omnivore: SiBORG Lab Elevates Approach to Accessibility Using OpenUSD and NVIDIA Omniverse</title><link>https://blogs.nvidia.com/blog/mathew-schwartz-openusd-omniverse/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/6571ed8f3d6332c6b45a7872_CrutchesClip/CrutchesClip_thmb.jpg" fileSize="5967619" type="video/quicktime"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/6571ed8f3d6332c6b45a7872_CrutchesClip/CrutchesClip_thmb.jpg" alt="CrutchesClip" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Thu, 07 Dec 2023 16:06:41 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Accessibility is a key element that all designers must consider before constructing a space or product — but the evaluation process has traditionally been tedious and time-consuming. Mathew Schwartz, an assistant professor in architecture and design at the New Jersey Institute of Technology, is using the NVIDIA Omniverse platform and the Universal Scene Description framework, <a class="read-more" href="https://blogs.nvidia.com/blog/mathew-schwartz-openusd-omniverse/">Read article &#62;</a>]]></description><author>Nicole Castro</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/mathew-schwartz-openusd-omniverse/</guid><pubDate>Thu, 07 Dec 2023 16:00:02 GMT</pubDate></item><item><title>Good Fortunes: ‘The Day Before’ Leads 17 Games on GeForce NOW</title><link>https://blogs.nvidia.com/blog/the-day-before-avatar-ori/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/6571d0cf3d6332ad99988894_gfn-thursday-the-day-before-nv-blog-1280x680-no-cta-1-842x450/gfn-thursday-the-day-before-nv-blog-1280x680-no-cta-1-842x450_thmb.jpg" fileSize="26131" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/6571d0cf3d6332ad99988894_gfn-thursday-the-day-before-nv-blog-1280x680-no-cta-1-842x450/gfn-thursday-the-day-before-nv-blog-1280x680-no-cta-1-842x450_thmb.jpg" alt="gfn-thursday-the-day-before-nv-blog-1280x680-no-cta-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Thu, 07 Dec 2023 14:04:03 GMT</modDate><relatedPages></relatedPages><description><![CDATA[It’s a fortuitous GFN Thursday with 17 new games joining the GeForce NOW library, including The Day Before, Avatar: Frontiers of Pandora and the 100th PC Game Pass title to join the cloud — Ori and the Will of the Wisps. This week also marks a milestone: over 500 games and applications now support RTX <a class="read-more" href="https://blogs.nvidia.com/blog/the-day-before-avatar-ori/">Read article &#62;</a>]]></description><author>GeForce NOW Community</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/the-day-before-avatar-ori/</guid><pubDate>Thu, 07 Dec 2023 14:00:20 GMT</pubDate></item><item><title>Visual AI Takes Flight at Canada’s Largest, Busiest Airport</title><link>https://blogs.nvidia.com/blog/zensors-visual-ai/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/6570e2753d6332c76a2f53ab_people-airport-842x450/people-airport-842x450_thmb.jpg" fileSize="75565" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/6570e2753d6332c76a2f53ab_people-airport-842x450/people-airport-842x450_thmb.jpg" alt="people-airport-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Wed, 06 Dec 2023 21:07:02 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Toronto Pearson International Airport, in Ontario, Canada, is the country’s largest and busiest airport, serving some 50 million passengers each year. To enhance traveler experiences, the airport in June deployed the Zensors AI platform, which uses anonymized footage from existing security cameras to generate spatial data that helps optimize operations in real time. A member <a class="read-more" href="https://blogs.nvidia.com/blog/zensors-visual-ai/">Read article &#62;</a>]]></description><author>Angie Lee</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/zensors-visual-ai/</guid><pubDate>Wed, 06 Dec 2023 21:00:39 GMT</pubDate></item><item><title>17 Predictions for 2024: From RAG to Riches to Beatlemania and National Treasures</title><link>https://blogs.nvidia.com/blog/2024-ai-predictions/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/65709afbed6ae56af91ade67_2024predictionfeature-842x450/2024predictionfeature-842x450_thmb.jpg" fileSize="74991" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/65709afbed6ae56af91ade67_2024predictionfeature-842x450/2024predictionfeature-842x450_thmb.jpg" alt="2024predictionfeature-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Wed, 06 Dec 2023 16:02:07 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Move over, Merriam-Webster: Enterprises this year found plenty of candidates to add for word of the year. “Generative AI” and “generative pretrained transformer” were followed by terms such as “large language models” and “retrieval-augmented generation” (RAG) as whole industries turned their attention to transformative new technologies. Generative AI started the year as a blip on <a class="read-more" href="https://blogs.nvidia.com/blog/2024-ai-predictions/">Read article &#62;</a>]]></description><author>Cliff Edwards</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/2024-ai-predictions/</guid><pubDate>Wed, 06 Dec 2023 16:00:38 GMT</pubDate></item><item><title>AV 2.0, the Next Big Wayve in Self-Driving Cars</title><link>https://blogs.nvidia.com/blog/av-2-0-wayve/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/657080d23d63326c53bab981_wayve-842x450/wayve-842x450_thmb.jpg" fileSize="36321" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/657080d23d63326c53bab981_wayve-842x450/wayve-842x450_thmb.jpg" alt="wayve-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Wed, 06 Dec 2023 14:10:31 GMT</modDate><relatedPages></relatedPages><description><![CDATA[A new era of autonomous vehicle technology, known as AV 2.0, has emerged, marked by large, unified AI models that can control multiple parts of the vehicle stack, from perception and planning to control. Wayve, a London-based autonomous driving technology company, is leading the surf. In the latest episode of NVIDIA’s AI Podcast, host Katie <a class="read-more" href="https://blogs.nvidia.com/blog/av-2-0-wayve/">Read article &#62;</a>]]></description><author>Kristen Yee</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/av-2-0-wayve/</guid><pubDate>Wed, 06 Dec 2023 14:00:21 GMT</pubDate></item><item><title>‘Christmas Rush’ 3D Scene Brings Holiday Cheer This Week ‘In the NVIDIA Studio’</title><link>https://blogs.nvidia.com/blog/studio-balov-adobe-photoshop-blender/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/656f2e353d633226f4643213_studio-ints-bozo-balov-wk86-blog-header-img-1280x680-1/studio-ints-bozo-balov-wk86-blog-header-img-1280x680-1_thmb.jpg" fileSize="1790346" type="video/mp4"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202312/656f2e353d633226f4643213_studio-ints-bozo-balov-wk86-blog-header-img-1280x680-1/studio-ints-bozo-balov-wk86-blog-header-img-1280x680-1_thmb.jpg" alt="studio-ints-bozo-balov-wk86-blog-header-img-1280x680-1" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Tue, 05 Dec 2023 14:05:43 GMT</modDate><relatedPages></relatedPages><description><![CDATA[‘Tis the season for friends, family and beautifully rendered Santa animations from this week’s In the NVIDIA Studio artist, 3D expert Božo Balov.]]></description><author>Gerardo Delgado</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/studio-balov-adobe-photoshop-blender/</guid><pubDate>Tue, 05 Dec 2023 14:00:46 GMT</pubDate></item><item><title>Bringing Personality to Pixels, Inworld Levels Up Game Characters Using Generative AI</title><link>https://blogs.nvidia.com/blog/generative-ai-npcs/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202311/656e14f23d63321ce8fae55d_Inworld-AI-Header-842x450/Inworld-AI-Header-842x450_thmb.jpg" fileSize="13782" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202311/656e14f23d63321ce8fae55d_Inworld-AI-Header-842x450/Inworld-AI-Header-842x450_thmb.jpg" alt="Inworld-AI-Header-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Mon, 04 Dec 2023 18:06:53 GMT</modDate><relatedPages></relatedPages><description><![CDATA[To enhance the gaming experience, studios and developers spend tremendous effort creating photorealistic, immersive in-game environments. But non-playable characters (NPCs) often get left behind. Many behave in ways that lack depth and realism, making their interactions repetitive and forgettable. Inworld AI is changing the game by using generative AI to drive NPC behaviors that are <a class="read-more" href="https://blogs.nvidia.com/blog/generative-ai-npcs/">Read article &#62;</a>]]></description><author>JJ Kim</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/generative-ai-npcs/</guid><pubDate>Mon, 04 Dec 2023 18:00:09 GMT</pubDate></item><item><title>Why GPUs Are Great for AI</title><link>https://blogs.nvidia.com/blog/why-gpus-are-great-for-ai/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202311/656df845ed6ae56d2d9dfa6b_NVIDIA-AI-platform-x1280-842x450/NVIDIA-AI-platform-x1280-842x450_thmb.jpg" fileSize="21533" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202311/656df845ed6ae56d2d9dfa6b_NVIDIA-AI-platform-x1280-842x450/NVIDIA-AI-platform-x1280-842x450_thmb.jpg" alt="NVIDIA-AI-platform-x1280-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Mon, 04 Dec 2023 16:04:12 GMT</modDate><relatedPages></relatedPages><description><![CDATA[GPUs have been called the rare Earth metals — even the gold — of artificial intelligence, because they’re foundational for today’s generative AI era. Three technical reasons, and many stories, explain why that’s so. Each reason has multiple facets well worth exploring, but at a high level: GPUs employ parallel processing. GPU systems scale up <a class="read-more" href="https://blogs.nvidia.com/blog/why-gpus-are-great-for-ai/">Read article &#62;</a>]]></description><author>Rick Merritt</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/why-gpus-are-great-for-ai/</guid><pubDate>Mon, 04 Dec 2023 16:00:36 GMT</pubDate></item><item><title>‘Call of Duty’ Comes to GeForce NOW</title><link>https://blogs.nvidia.com/blog/geforce-now-thursday-call-of-duty/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202311/656897d3ed6ae525db98f1ac_GFN_Thursday-Nov_30-842x450/GFN_Thursday-Nov_30-842x450_thmb.jpg" fileSize="29903" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202311/656897d3ed6ae525db98f1ac_GFN_Thursday-Nov_30-842x450/GFN_Thursday-Nov_30-842x450_thmb.jpg" alt="GFN_Thursday-Nov_30-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Thu, 30 Nov 2023 14:10:31 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Let the games begin — this GFN Thursday brings the highly anticipated Call of Duty: Modern Warfare III to the cloud, the first Activision title on GeForce NOW as part of the NVIDIA and Microsoft partnership. It’s joined by Call of Duty: Modern Warfare II and Call of Duty: Warzone — all three titles can <a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-call-of-duty/">Read article &#62;</a>]]></description><author>GeForce NOW Community</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/geforce-now-thursday-call-of-duty/</guid><pubDate>Thu, 30 Nov 2023 14:00:53 GMT</pubDate></item><item><title>Embracing Transformation: AWS and NVIDIA Forge Ahead in Generative AI and Cloud Innovation</title><link>https://blogs.nvidia.com/blog/aws-nvidia/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202310/6568c07c3d6332d4906efbf9_AWS-Selipsky-NVIDIA-Huang/AWS-Selipsky-NVIDIA-Huang_thmb.jpg" fileSize="201420" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202310/6568c07c3d6332d4906efbf9_AWS-Selipsky-NVIDIA-Huang/AWS-Selipsky-NVIDIA-Huang_thmb.jpg" alt="AWS-Selipsky-NVIDIA-Huang" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Thu, 30 Nov 2023 17:05:06 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Amazon Web Services and NVIDIA will bring the latest generative AI technologies to enterprises worldwide. Combining AI and cloud computing, NVIDIA founder and CEO Jensen Huang joined AWS CEO Adam Selipsky Tuesday on stage at AWS re:Invent 2023 at the Venetian Expo Center in Las Vegas. Selipsky said he was “thrilled” to announce the expansion <a class="read-more" href="https://blogs.nvidia.com/blog/aws-nvidia/">Read article &#62;</a>]]></description><author>Brian Caulfield</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/aws-nvidia/</guid><pubDate>Tue, 28 Nov 2023 19:28:00 GMT</pubDate></item><item><title>NVIDIA BioNeMo Enables Generative AI for Drug Discovery on AWS</title><link>https://blogs.nvidia.com/blog/bionemo-on-aws-generative-ai-drug-discovery/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202311/656623433d63328e933447d0_hc-corp-blog-aws23-bionemo-1280x680-1-842x450/hc-corp-blog-aws23-bionemo-1280x680-1-842x450_thmb.jpg" fileSize="13345" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202311/656623433d63328e933447d0_hc-corp-blog-aws23-bionemo-1280x680-1-842x450/hc-corp-blog-aws23-bionemo-1280x680-1-842x450_thmb.jpg" alt="hc-corp-blog-aws23-bionemo-1280x680-1-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Tue, 28 Nov 2023 17:28:38 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Researchers and developers at leading pharmaceutical and techbio companies can now easily deploy NVIDIA Clara software and services for accelerated healthcare through Amazon Web Services. Announced today at AWS re:Invent, the initiative gives healthcare and life sciences developers using AWS cloud resources the flexibility to integrate NVIDIA-accelerated offerings such as NVIDIA BioNeMo — a generative <a class="read-more" href="https://blogs.nvidia.com/blog/bionemo-on-aws-generative-ai-drug-discovery/">Read article &#62;</a>]]></description><author>Kimberly Powell</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/bionemo-on-aws-generative-ai-drug-discovery/</guid><pubDate>Tue, 28 Nov 2023 17:21:33 GMT</pubDate></item><item><title>NVIDIA GPUs on AWS to Offer 2x Simulation Leap in Omniverse Isaac Sim, Accelerating Smarter Robots</title><link>https://blogs.nvidia.com/blog/gpu-aws-omniverse-isaac-sim-robots/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202311/6566234e3d63328e933447d6_AWS-reinvent-robotics-blog-key-visual-842x450/AWS-reinvent-robotics-blog-key-visual-842x450_thmb.jpg" fileSize="140559" type="image/png"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202311/6566234e3d63328e933447d6_AWS-reinvent-robotics-blog-key-visual-842x450/AWS-reinvent-robotics-blog-key-visual-842x450_thmb.jpg" alt="AWS-reinvent-robotics-blog-key-visual-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Tue, 28 Nov 2023 17:28:50 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Developing more intelligent robots in the cloud is about to get a speed multiplier. NVIDIA Isaac Sim and NVIDIA L40S GPUs are coming to Amazon Web Services, enabling developers to build and deploy accelerated robotics applications in the cloud. Isaac Sim, an extensible simulator for AI-enabled robots, is built on the NVIDIA Omniverse development platform <a class="read-more" href="https://blogs.nvidia.com/blog/gpu-aws-omniverse-isaac-sim-robots/">Read article &#62;</a>]]></description><author>Gerard Andrews</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/gpu-aws-omniverse-isaac-sim-robots/</guid><pubDate>Tue, 28 Nov 2023 17:20:12 GMT</pubDate></item><item><title>NVIDIA Powers Training for Some of the Largest Amazon Titan Foundation Models</title><link>https://blogs.nvidia.com/blog/nemo-amazon-titan/</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202311/656623603d63328e933447dc_Amazon-Titan-logo-KV-842x450/Amazon-Titan-logo-KV-842x450_thmb.jpg" fileSize="9937" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202311/656623603d63328e933447dc_Amazon-Titan-logo-KV-842x450/Amazon-Titan-logo-KV-842x450_thmb.jpg" alt="Amazon-Titan-logo-KV-842x450" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><categories><category>Blogs</category></categories><modDate>Tue, 28 Nov 2023 17:29:06 GMT</modDate><relatedPages></relatedPages><description><![CDATA[Everything about large language models is big — giant models train on massive datasets across thousands of NVIDIA GPUs. That can pose a lot of big challenges for companies pursuing generative AI. NVIDIA NeMo, a framework for building, customizing and running LLMs, helps overcome these challenges. A team of experienced scientists and developers at Amazon <a class="read-more" href="https://blogs.nvidia.com/blog/nemo-amazon-titan/">Read article &#62;</a>]]></description><author>Nirmala De</author><guid isPermaLink="true">https://blogs.nvidia.com/blog/nemo-amazon-titan/</guid><pubDate>Tue, 28 Nov 2023 17:19:07 GMT</pubDate></item><item><title>NVIDIA Brings Business Intelligence to Chatbots, Copilots and Summarization Tools With Enterprise-Grade Generative AI Microservice</title><link>https://nvidianews.nvidia.com/news/nemo-retriever-generative-ai-microservice</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202310/6566211e3d6332d4866ef6a3_NVIDIA+NeMo+Retriever+image/NVIDIA+NeMo+Retriever+image_thmb.jpg" fileSize="169276" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202310/6566211e3d6332d4866ef6a3_NVIDIA+NeMo+Retriever+image/NVIDIA+NeMo+Retriever+image_thmb.jpg" alt="NVIDIA NeMo Retriever" align="left" hspace="15" vspace="5" /&gt;</image><subtitle>Cadence, Dropbox, SAP, ServiceNow First to Access NVIDIA NeMo Retriever to Optimize Semantic Retrieval for Accurate AI Inference</subtitle><content>&lt;![CDATA[&lt;p align="left"&gt;&lt;strong&gt;AWS re:Invent&amp;mdash;&lt;/strong&gt;NVIDIA today announced a generative AI microservice that lets enterprises connect custom large language models to enterprise data to deliver highly accurate responses for their AI applications.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://developer.nvidia.com/blog/build-enterprise-grade-retrieval-augmented-generation-applications-with-nvidia-nemo-retriever" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA NeMo&amp;trade; Retriever&lt;/u&gt;&lt;/a&gt; &amp;mdash; a new offering in the &lt;a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/" rel="" target="" title=""&gt;&lt;u&gt;NVIDIA NeMo&lt;/u&gt;&lt;/a&gt; family of frameworks and tools for building, customizing and deploying generative AI models &amp;mdash; helps organizations enhance their generative AI applications with enterprise-grade &lt;a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;retrieval-augmented generation&lt;/u&gt;&lt;/a&gt; (RAG) capabilities.&lt;/p&gt;

&lt;p&gt;As a semantic-retrieval microservice, NeMo Retriever helps generative AI applications provide more accurate responses through NVIDIA-optimized algorithms. Developers using the microservice can connect their AI applications to business data wherever it resides across clouds and data centers. It adds NVIDIA-optimized RAG capabilities to &lt;a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;AI foundries&lt;/u&gt;&lt;/a&gt; and is part of the &lt;a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA AI Enterprise&lt;/u&gt;&lt;/a&gt; software platform, available in &lt;a href="https://aws.amazon.com/marketplace/pp/prodview-ozgjkov6vq3l6" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;AWS Marketplace&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Cadence, Dropbox, SAP and ServiceNow are among the pioneers working with NVIDIA to build production-ready RAG capabilities into their custom generative AI applications and services.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;Generative AI applications with RAG capabilities are the next killer app of the enterprise,&amp;rdquo; said Jensen Huang, founder and CEO of NVIDIA. &amp;ldquo;With NVIDIA NeMo Retriever, developers can create customized generative AI chatbots, copilots and summarization tools that can access their business data to transform productivity with accurate and valuable generative AI intelligence.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Global Leaders Enhance LLM Accuracy With NeMo Retriever&lt;/strong&gt;&lt;br /&gt;
Electronic systems design leader Cadence serves companies across hyperscale computing, 5G communications, automotive, mobile, aerospace, consumer and healthcare markets. It is working with NVIDIA to develop RAG features for generative AI applications in industrial electronics design.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;Generative AI introduces innovative approaches to address customer needs, such as tools to uncover potential flaws early in the design process,&amp;rdquo; said Anirudh Devgan, president and CEO of Cadence. &amp;ldquo;Our researchers are working with NVIDIA to use NeMo Retriever to further boost the accuracy and relevance of generative AI applications to reveal issues and help customers get high-quality products to market faster.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cracking the Code for Accurate Generative AI Applications&lt;/strong&gt;&lt;br /&gt;
Unlike open-source RAG toolkits, NeMo Retriever supports production-ready generative AI with commercially viable models, API stability, security patches and enterprise support.&lt;/p&gt;

&lt;p&gt;NVIDIA-optimized algorithms power the highest accuracy results in Retriever&amp;rsquo;s embedding models. The optimized embedding models capture relationships between words, enabling LLMs to process and analyze textual data.&lt;/p&gt;

&lt;p&gt;Using NeMo Retriever, enterprises can connect their LLMs to multiple data sources and knowledge bases, so that users can easily interact with data and receive accurate, up-to-date answers using simple, conversational prompts. Businesses using Retriever-powered applications can allow users to securely gain access to information spanning numerous data modalities, such as text, PDFs, images and videos.&lt;/p&gt;

&lt;p&gt;Enterprises can use NeMo Retriever to achieve more accurate results with less training, speeding time to market and supporting energy efficiency in the development of generative AI applications.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reliable, Simple, Secure Deployment With NVIDIA AI Enterprise&lt;/strong&gt;&lt;br /&gt;
Companies can deploy NeMo Retriever-powered applications to run during inference on NVIDIA-accelerated computing on virtually any data center or cloud. NVIDIA AI Enterprise supports accelerated, high-performance inference with NVIDIA NeMo, &lt;a href="https://www.nvidia.com/en-us/ai-data-science/products/triton-inference-server/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA Triton Inference Server&lt;/u&gt;&lt;/a&gt;&amp;trade;, &lt;a href="https://developer.nvidia.com/tensorrt" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA TensorRT&lt;/u&gt;&lt;/a&gt;&amp;trade;, &lt;a href="https://developer.nvidia.com/tensorrt#inference" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA TensorRT-LLM&lt;/u&gt;&lt;/a&gt; and other &lt;a href="https://www.nvidia.com/en-us/ai-data-science/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA AI&lt;/u&gt;&lt;/a&gt; software.&lt;/p&gt;

&lt;p&gt;To maximize inference performance, developers can run their models on &lt;a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-supercharges-large-language-model-inference-on-nvidia-h100-gpus/" rel="nofollow" target="_blank" title=""&gt;&lt;u&gt;NVIDIA GH200 Grace Hopper Superchips with TensorRT-LLM software&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Availability&lt;/strong&gt;&lt;br /&gt;
Developers can sign up for &lt;a href="https://developer.nvidia.com/nemo-microservices-early-access" rel="" target="" title=""&gt;early access to NVIDIA NeMo Retriever&lt;/a&gt;.&lt;/p&gt;
]]&gt;</content><categories><category>Press Releases</category></categories><modDate>Tue, 28 Nov 2023 17:32:22 GMT</modDate><relatedPages></relatedPages><description><![CDATA[AWS re:Invent—NVIDIA today announced a generative AI microservice that lets enterprises connect custom large language models to enterprise data to deliver highly accurate responses for their AI applications.]]></description><enclosure url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202310/NVIDIA+NeMo+Retriever+image.jpg" length="169276" type="image/jpeg"></enclosure><guid isPermaLink="true">https://nvidianews.nvidia.com/news/nemo-retriever-generative-ai-microservice</guid><pubDate>Tue, 28 Nov 2023 17:14:00 GMT</pubDate></item><item><title>AWS and NVIDIA Announce Strategic Collaboration to Offer New Supercomputing Infrastructure, Software and Services for Generative AI</title><link>https://nvidianews.nvidia.com/news/aws-nvidia-strategic-collaboration-for-generative-ai</link><media:content url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202310/656575f43d6332d4996ef697_NVIDIA+DGX+Cloud+image/NVIDIA+DGX+Cloud+image_thmb.jpg" fileSize="439713" type="image/jpeg"></media:content><contentType>releases</contentType><image>&lt;img src="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202310/656575f43d6332d4996ef697_NVIDIA+DGX+Cloud+image/NVIDIA+DGX+Cloud+image_thmb.jpg" alt="NVIDIA DGX Cloud" align="left" hspace="15" vspace="5" /&gt;</image><subtitle></subtitle><content>&lt;![CDATA[&lt;ul&gt;
	&lt;li&gt;&lt;em&gt;AWS to offer first cloud AI supercomputer with NVIDIA Grace Hopper Superchip and AWS UltraCluster scalability&lt;/em&gt;&lt;/li&gt;
	&lt;li&gt;&lt;em&gt;NVIDIA DGX Cloud&lt;/em&gt;&amp;mdash;&lt;em&gt;first to feature NVIDIA GH200 NVL32&lt;/em&gt;&amp;mdash;&lt;em&gt;coming to AWS&lt;/em&gt;&lt;/li&gt;
	&lt;li&gt;&lt;em&gt;Companies partner on Project Ceiba&amp;mdash;the world&amp;rsquo;s fastest GPU-powered AI supercomputer and newest NVIDIA DGX Cloud supercomputer for NVIDIA AI R&amp;amp;D and custom model development&lt;/em&gt;&lt;/li&gt;
	&lt;li&gt;&lt;em&gt;New Amazon EC2 instances powered by NVIDIA GH200, H200, L40S and L4 GPUs supercharge generative AI, HPC, design and simulation workloads&lt;/em&gt;&lt;/li&gt;
	&lt;li&gt;&lt;em&gt;NVIDIA software on &lt;/em&gt;&lt;em&gt;AWS&lt;/em&gt;&amp;mdash;&lt;em&gt;NeMo&lt;/em&gt;&lt;em&gt; LLM framework, NeMo Retriever and &lt;/em&gt;&lt;em&gt;BioNeMo&lt;/em&gt;&amp;mdash;&lt;em&gt;to&lt;/em&gt;&lt;em&gt; boost generative AI development for custom models, semantic retrieval and drug discovery&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;AWS re:Invent&amp;mdash;&lt;/strong&gt;Amazon Web Services, Inc. (AWS), an Amazon.com, Inc. company (NASDAQ: AMZN), and NVIDIA (NASDAQ: NVDA) today announced an expansion of their strategic collaboration to deliver the most-advanced infrastructure, software and services to power customers&amp;rsquo; generative artificial intelligence (AI) innovations.&lt;/p&gt;

&lt;p&gt;The companies will bring together the best of NVIDIA and AWS technologies&amp;mdash;from NVIDIA&amp;rsquo;s newest multi-node systems featuring next-generation GPUs, CPUs and AI software, to AWS Nitro System advanced virtualization and security, Elastic Fabric Adapter (EFA) interconnect, and UltraCluster scalability&amp;mdash;that are ideal for training foundation models and building generative AI applications.&lt;/p&gt;

&lt;p&gt;The expanded collaboration builds on a longstanding relationship that has fueled the generative AI era by offering early machine learning (ML) pioneers the compute performance required to advance the state-of-the-art in these technologies.&lt;/p&gt;

&lt;p&gt;As part of the expanded collaboration to supercharge generative AI across all industries:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;AWS will be the first cloud provider to bring NVIDIA&amp;reg; GH200 Grace Hopper Superchips with new multi-node NVLink&amp;trade; technology to the cloud. The &lt;a href="https://developer.nvidia.com/blog/one-giant-superchip-for-llms-recommenders-and-gnns-introducing-nvidia-gh200-nvl32/" rel="" target="" title=""&gt;new NVIDIA GH200 NVL32 multi-node platform&lt;/a&gt; connects 32 Grace Hopper Superchips with NVIDIA NVLink and NVSwitch&amp;trade; technologies into one instance. The platform will be available on Amazon Elastic Compute Cloud (Amazon EC2) instances connected with Amazon&amp;rsquo;s powerful networking (EFA), supported by advanced virtualization (AWS Nitro System), and hyper-scale clustering (Amazon EC2 UltraClusters), enabling joint customers to scale to thousands of GH200 Superchips.&lt;/li&gt;
	&lt;li&gt;NVIDIA and AWS will collaborate to host &lt;a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/"&gt;NVIDIA DGX&amp;trade; Cloud&lt;/a&gt;&amp;mdash;NVIDIA&amp;rsquo;s AI-training-as-a-service&amp;mdash;on AWS. It will be the first DGX Cloud featuring GH200 NVL32, providing developers the largest shared memory in a single instance. DGX Cloud on AWS will accelerate training of cutting-edge generative AI and large language models that can reach beyond 1 trillion parameters.&lt;/li&gt;
	&lt;li&gt;NVIDIA and AWS are partnering on Project Ceiba to design the world&amp;rsquo;s fastest GPU-powered AI supercomputer&amp;mdash;an at-scale system with GH200 NVL32 and Amazon EFA interconnect hosted by AWS for NVIDIA&amp;rsquo;s own research and development team. This first-of-its-kind supercomputer&amp;mdash;featuring 16,384 NVIDIA GH200 Superchips and capable of processing 65 exaflops of AI&amp;mdash;will be used by NVIDIA to propel its next wave of generative AI innovation.&lt;/li&gt;
	&lt;li&gt;AWS will introduce three additional new Amazon EC2 instances: P5e instances, powered by &lt;a href="https://www.nvidia.com/en-us/data-center/h200/"&gt;NVIDIA H200 Tensor Core GPUs&lt;/a&gt;, for large-scale and cutting-edge generative AI and HPC workloads, and G6 and G6e instances, powered by &lt;a href="https://www.nvidia.com/en-us/data-center/l4/"&gt;NVIDIA L4 GPUs&lt;/a&gt; and &lt;a href="https://www.nvidia.com/en-us/data-center/l40s/"&gt;NVIDIA L40S GPUs&lt;/a&gt;, respectively, for a wide set of applications such as AI fine-tuning, inference, graphics and video workloads. G6e instances are particularly suitable for developing 3D workflows, digital twins and other applications using &lt;a href="https://www.nvidia.com/en-us/omniverse/"&gt;NVIDIA Omniverse&amp;trade;&lt;/a&gt;, a platform for connecting and building generative AI-enabled 3D applications.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;ldquo;AWS and NVIDIA have collaborated for more than 13 years, beginning with the world&amp;rsquo;s first GPU cloud instance. Today, we offer the widest range of NVIDIA GPU solutions for workloads including graphics, gaming, high performance computing, machine learning, and now, generative AI,&amp;rdquo; said Adam Selipsky, CEO at AWS. &amp;ldquo;We continue to innovate with NVIDIA to make AWS the best place to run GPUs, combining next-gen NVIDIA Grace Hopper Superchips with AWS&amp;rsquo;s EFA powerful networking, EC2 UltraClusters&amp;rsquo; hyper-scale clustering, and Nitro&amp;rsquo;s advanced virtualization capabilities.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&amp;ldquo;Generative AI is transforming cloud workloads and putting accelerated computing at the foundation of diverse content generation,&amp;rdquo; said Jensen Huang, founder and CEO of NVIDIA. &amp;ldquo;Driven by a common mission to deliver cost-effective state-of-the-art generative AI to every customer, NVIDIA and AWS are collaborating across the entire computing stack, spanning AI infrastructure, acceleration libraries, foundation models, to generative AI services.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;New Amazon EC2 Instances Combine State-of-the-Art from NVIDIA and AWS&lt;/strong&gt;&lt;br /&gt;
AWS will be the first cloud provider to offer NVIDIA GH200 Grace Hopper Superchips with multi-node NVLink technology. Each GH200 Superchip combines an Arm-based Grace CPU with an NVIDIA Hopper&amp;trade; architecture GPU on the same module. A single Amazon EC2 instance with GH200 NVL32 can provide up to 20 TB of shared memory to power terabyte-scale workloads.&lt;/p&gt;

&lt;p&gt;These instances will take advantage of AWS&amp;rsquo;s third-generation Elastic Fabric Adapter (EFA) interconnect, providing up to 400 Gbps per Superchip of low-latency, high-bandwidth networking throughput, enabling customers to scale to thousands of GH200 Superchips in EC2 UltraClusters.&lt;/p&gt;

&lt;p&gt;AWS instances with GH200 NVL32 will provide customers on-demand access to supercomputer-class performance, which is critical for large-scale AI/ML workloads that need to be distributed across multiple nodes for complex generative AI workloads&amp;mdash;spanning FMs, recommender systems, and vector databases.&lt;/p&gt;

&lt;p&gt;NVIDIA GH200-powered EC2 instances will feature 4.5 TB of HBM3e memory&amp;mdash;a 7.2x increase compared to current generation H100-powered EC2 P5d instances&amp;mdash;allowing customers to run larger models, while improving training performance. Additionally, CPU-to-GPU memory interconnect provides up to 7x higher bandwidth than PCIe, enabling chip-to-chip communications that extend the total memory available for applications.&lt;/p&gt;

&lt;p&gt;AWS instances with GH200 NVL32 will be the first AI infrastructure on AWS to feature liquid cooling to help ensure densely-packed server racks can efficiently operate at maximum performance.&lt;/p&gt;

&lt;p&gt;EC2 instances with GH200 NVL32 will also benefit from the AWS Nitro System, the underlying platform for next-generation EC2 instances. The Nitro System offloads I/O for functions from the host CPU/GPU to specialized hardware to deliver more consistent performance, while its enhanced security protects customer code and data during processing.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;AWS First to Host NVIDIA DGX Cloud Powered by Grace Hopper&lt;/strong&gt;&lt;br /&gt;
AWS will team up with NVIDIA to host NVIDIA DGX Cloud powered by GH200 NVL32 NVLink infrastructure. NVIDIA DGX Cloud is an AI supercomputing service that gives enterprises fast access to multi-node supercomputing for training the most complex LLM and generative AI models, with integrated &lt;a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/"&gt;NVIDIA AI Enterprise&lt;/a&gt; software, and direct access to NVIDIA AI experts.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Massive Project Ceiba Supercomputer to Supercharge NVIDIA&amp;rsquo;s AI Development&lt;/strong&gt;&lt;br /&gt;
The Project Ceiba supercomputer that AWS and NVIDIA are collaborating on will be integrated with AWS services, such as Amazon Virtual Private Cloud (VPC) encrypted networking and Amazon Elastic Block Store high-performance block storage, giving NVIDIA access to a comprehensive set of AWS capabilities.&lt;/p&gt;

&lt;p&gt;NVIDIA will use the supercomputer for research and development to advance AI for LLMs, graphics and simulation, digital biology, robotics, self-driving cars, Earth-2 climate prediction and more.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NVIDIA and AWS Supercharge Generative AI, HPC, Design and Simulation&lt;/strong&gt;&lt;br /&gt;
To power the development, training and inference of the largest LLMs, AWS P5e instances will feature NVIDIA&amp;rsquo;s latest H200 GPUs that offer 141 GB of HBM3e GPU memory, which is 1.8x larger and 1.4x faster than H100 GPUs. This boost in GPU memory, along with up to 3,200 Gbps of EFA networking enabled by the AWS Nitro System, will enable customers to continue to build, train and deploy their cutting-edge models on AWS.&lt;/p&gt;

&lt;p&gt;To deliver cost-effective, energy-efficient solutions for video, AI and graphics workloads, AWS announced new Amazon EC2 G6e instances featuring NVIDIA L40S GPUs and G6 instances powered by L4 GPUs. The new offerings can help startups, enterprises and researchers meet their AI and high-fidelity graphics needs.&lt;/p&gt;

&lt;p&gt;G6e instances are built to handle complex workloads such as generative AI and digital twin applications. Using NVIDIA Omniverse, photorealistic 3D simulations can be developed, contextualized and enhanced using real-time data from services such as AWS IoT TwinMaker, intelligent chatbots, assistants, search and summarization. Amazon Robotics and Amazon Fulfillment Centers will be able to integrate digital twins built with NVIDIA Omniverse and AWS IoT TwinMaker to optimize warehouse design and flow, train more intelligent robot assistants and improve deliveries to customers.&lt;/p&gt;

&lt;p&gt;L40S GPUs deliver up to 1.45 petaflops of FP8 performance and feature Ray Tracing cores that offer up to 209 teraflops of ray-tracing performance. L4 GPUs featured in G6 instances will deliver a lower-cost, energy-efficient solution for deploying AI models for natural language processing, language translation, AI video and image analysis, speech recognition, and personalization. L40S GPUs also accelerate graphics workloads, such as creating and rendering real-time, cinematic-quality graphics and game streaming. All three instances will be available in the coming year.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NVIDIA Software on AWS Boosts Generative AI Development&lt;/strong&gt;&lt;br /&gt;
In addition, NVIDIA announced software on AWS to boost generative AI development. &lt;a href="https://nvidianews.nvidia.com/news/nemo-retriever-generative-ai-microservice"&gt;NVIDIA NeMo&amp;trade; Retriever microservice&lt;/a&gt; offers new tools to create highly accurate chatbots and summarization tools using accelerated semantic retrieval. &lt;a href="https://blogs.nvidia.com/blog/bionemo-on-aws-generative-ai-drug-discovery/"&gt;NVIDIA BioNeMo&amp;trade;, available on Amazon SageMaker&lt;/a&gt; now and coming to AWS on NVIDIA DGX Cloud, enables pharmaceutical companies to speed drug discovery by simplifying and accelerating the training of models using their own data.&lt;/p&gt;

&lt;p&gt;NVIDIA software on AWS is helping Amazon bring new innovations to its services and operations. &lt;a href="https://blogs.nvidia.com/blog/nemo-amazon-titan/"&gt;A&lt;/a&gt;&lt;a href="https://blogs.nvidia.com/blog/nemo-amazon-titan/"&gt;WS is using the NVIDIA NeMo framework&lt;/a&gt; to train select next-generation Amazon Titan LLMs. &lt;a href="https://blogs.nvidia.com/blog/gpu-aws-omniverse-isaac-sim-robots/"&gt;Amazon Robotics has begun leveraging NVIDIA Omniverse Isaac&lt;/a&gt; to build digital twins for automating, optimizing and planning its autonomous warehouses in virtual environments before deploying them into the real world.&lt;/p&gt;
]]&gt;</content><categories></categories><modDate>Thu, 30 Nov 2023 18:02:07 GMT</modDate><relatedPages></relatedPages><description><![CDATA[At AWS re:Invent, Amazon Web Services, Inc., an Amazon.com, Inc. company, and NVIDIA today announced an expansion of their strategic collaboration to deliver the most-advanced infrastructure, software and services to power customers’ generative artificial intelligence innovations.]]></description><enclosure url="https://s3.amazonaws.com/cms.ipressroom.com/219/files/202310/NVIDIA+DGX+Cloud+image.jpg" length="439713" type="image/jpeg"></enclosure><guid isPermaLink="true">https://nvidianews.nvidia.com/news/aws-nvidia-strategic-collaboration-for-generative-ai</guid><pubDate>Tue, 28 Nov 2023 17:13:00 GMT</pubDate></item></channel></rss>