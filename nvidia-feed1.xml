<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Mon, 24 Jun 2024 16:40:05 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.5.4</generator>
	<item>
		<title>Crack the Case With ‚ÄòTell Me Why‚Äô and ‚ÄòAs Dusk Falls‚Äô on GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-tell-me-why-as-dusk-falls/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 20 Jun 2024 13:00:27 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72692</guid>

					<description><![CDATA[Sit back and settle in for some epic storytelling. Tell Me Why and As Dusk Falls ‚Äî award-winning, narrative-driven games from Xbox Studios ‚Äî add to the 1,900+ games in the GeForce NOW library, ready to stream from the cloud.¬† Members can find more adventures with four new titles available this week. Experience a Metallica	<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-tell-me-why-as-dusk-falls/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Sit back and settle in for some epic storytelling. <i>Tell Me Why</i> and <i>As Dusk Falls</i> ‚Äî award-winning, narrative-driven games from Xbox Studios ‚Äî add to the 1,900+ games in the <a target="_blank" href="http://play.geforcenow.com">GeForce NOW library</a>, ready to stream from the cloud.<a target="_blank" href="http://play.geforcenow.com">¬†</a></p>
<p>Members can find more adventures with four new titles available this week.</p>
<p>Experience a Metallica concert like no other in <a target="_blank" href="https://www.fortnite.com/news/metallica-lights-up-fortnite-with-a-new-music-experience-festival-season-and-more">‚ÄúMetallica: Fuel. Fire. Fury.‚Äù</a> This journey through six fan-favorite songs features gameplay that matches the intensity. ‚ÄúMetallica: Fuel. Fire. Fury.‚Äù will have six different showtimes running June 22-23 in <i>Fortnite</i>. Anyone can get a front-row seat to the interactive music experience by streaming on their mobile device, powered by <a target="_blank" href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a>.</p>
<h2><b>Unravel the Mystery</b></h2>
<p>Whether uncovering family mysteries in Alaska or navigating small-town secrets in Arizona, gamers are set to be drawn into richly woven stories with <i>Tell Me Why</i> and <i>Ask Dusk Falls</i> joining the cloud this week<i>.</i></p>
<figure id="attachment_72699" aria-describedby="caption-attachment-72699" style="width: 672px" class="wp-caption aligncenter"><img fetchpriority="high" decoding="async" class="size-large wp-image-72699" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Tell_Me_Why-672x378.jpg" alt="Tell Me Why on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Tell_Me_Why-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Tell_Me_Why-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Tell_Me_Why-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Tell_Me_Why-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Tell_Me_Why-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Tell_Me_Why-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Tell_Me_Why-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Tell_Me_Why-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Tell_Me_Why-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72699" class="wp-caption-text"><em>Ain‚Äôt nothing but a great game.</em></figcaption></figure>
<p><i>Tell Me Why</i> ‚Äî an episodic adventure game from Dontnod Entertainment, the creators of the beloved <i>Life Is Strange</i> series ‚Äî follows twins Tyler and Alyson Ronan as they reunite after a decade to uncover the mysteries of their troubled childhoods in the fictional town of Delos Crossing, Alaska. Experience true-to-life characters, mature themes and gripping choices.</p>
<figure id="attachment_72696" aria-describedby="caption-attachment-72696" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" class="size-large wp-image-72696" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-As_Dusk_Falls-672x378.jpg" alt="As Dusk Falls on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-As_Dusk_Falls-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-As_Dusk_Falls-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-As_Dusk_Falls-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-As_Dusk_Falls-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-As_Dusk_Falls-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-As_Dusk_Falls-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-As_Dusk_Falls-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-As_Dusk_Falls-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-As_Dusk_Falls-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72696" class="wp-caption-text"><em>Every family has secrets.</em></figcaption></figure>
<p>Dive into the intertwined lives of two families over three decades in <i>As Dusk Falls</i> from INTERIOR/NIGHT. Set in small-town Arizona in the 1990s, the game‚Äôs unique art style blends 2D character illustrations with 3D environments, creating a visually striking experience. Players‚Äô choices significantly impact the storyline, making each playthrough unique.</p>
<p>GeForce NOW members can now stream these award-winning titles on a variety of devices, including PCs, Macs, <a target="_blank" href="https://www.nvidia.com/en-us/shield/">SHIELD TVs</a> and Android devices. Upgrade to a <a target="_blank" href="http://geforcenow.com/membership">Priority or Ultimate membership</a> to enjoy enhanced streaming quality and performance, including up to 4K resolution and 120 frames per second on supported devices. Jump into these emotionally rich narratives and discover the power of choice in shaping the characters‚Äô destinies.</p>
<h2><b>Wake Up to New Games</b></h2>
<figure id="attachment_72693" aria-describedby="caption-attachment-72693" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" class="size-large wp-image-72693" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Still_Wakes_The_Deep-672x336.jpg" alt="Still Wakes the Deep on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Still_Wakes_The_Deep-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Still_Wakes_The_Deep-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Still_Wakes_The_Deep-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Still_Wakes_The_Deep-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Still_Wakes_The_Deep-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Still_Wakes_The_Deep-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Still_Wakes_The_Deep-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Still_Wakes_The_Deep-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Still_Wakes_The_Deep.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72693" class="wp-caption-text"><em>Run!</em></figcaption></figure>
<p>In <i>Still Wakes the Deep</i> from The Chinese Room and Secret Mode, play as an offshore oil rig worker fighting for dear life through a vicious storm, perilous surroundings and the dark, freezing North Sea waters. All lines of communication have been severed. All exits are gone. All that remains is the need to face the unknowable horror aboard. Live the terror and escape the rig, all from the cloud.</p>
<p>Check out the list of new games this week:</p>
<ul>
<li><i>Still Wakes the Deep </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1622910?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a target="_blank" href="https://www.xbox.com/games/store/1622910?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass, June 18)</li>
<li><i>Skye: The Misty Isle </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1710180?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, June 19)</li>
<li><i>As Dusk Falls </i>(<a target="_blank" href="https://store.steampowered.com/app/1341820?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a target="_blank" href="https://www.xbox.com/games/store/as-dusk-falls/9NR7XDNVP5SW?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Tell Me Why </i>(<a target="_blank" href="https://store.steampowered.com/app/1180660?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a target="_blank" href="https://www.xbox.com/games/store/tell-me-why/9NBL0XKVCN5L?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
</ul>
<figure id="attachment_72702" aria-describedby="caption-attachment-72702" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-72702" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Greetings_From_GFN-672x357.png" alt="Greetings From GFN" width="672" height="357" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Greetings_From_GFN-672x357.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Greetings_From_GFN-400x213.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Greetings_From_GFN-768x408.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Greetings_From_GFN-842x447.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Greetings_From_GFN-406x215.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Greetings_From_GFN-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Greetings_From_GFN.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72702" class="wp-caption-text"><em>Make sure to catch #GreetingFromGFN.</em></figcaption></figure>
<p>Plus, #GreetingsFromGFN continues on @NVIDIAGFN social media accounts, with members sharing their favorite locations to visit in the cloud.</p>
<p>What are you planning to play this weekend? Let us know on <a target="_blank" href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">What&#39;s a game that&#39;s still giving you nightmares? <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f628.png" alt="üò®" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f329.png" alt="üå©" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a target="_blank" href="https://twitter.com/NVIDIAGFN/status/1803095326980460884?ref_src=twsrc%5Etfw">June 18, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-thursday-6-20-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-thursday-6-20-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Crack the Case With ‚ÄòTell Me Why‚Äô and ‚ÄòAs Dusk Falls‚Äô on GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Decoding How NVIDIA AI Workbench Powers App Development</title>
		<link>https://blogs.nvidia.com/blog/ai-decoded-workbench-hybrid-rag/</link>
		
		<dc:creator><![CDATA[Jesse Clayton]]></dc:creator>
		<pubDate>Wed, 19 Jun 2024 13:00:25 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[AI Decoded]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72261</guid>

					<description><![CDATA[NVIDIA AI Workbench simplifies AI developer workflows by helping users build their own RAG projects, customize models and more.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><i>Editor‚Äôs note: This post is part of the </i><a href="https://blogs.nvidia.com/blog/tag/ai-decoded/"><i>AI Decoded series</i></a><i>, which demystifies AI by making the technology more accessible and showcases new hardware, software, tools and accelerations for NVIDIA RTX PC and workstation users.</i></p>
<p>The demand for tools to simplify and optimize <a target="_blank" href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> development is skyrocketing. Applications based on <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">retrieval-augmented generation (RAG)</a> ‚Äî a technique for enhancing the accuracy and reliability of generative AI models with facts fetched from specified external sources ‚Äî and customized models are enabling developers to tune AI models to their specific needs.</p>
<p>While such work may have required a complex setup in the past, new tools are making it easier than ever.</p>
<p><a target="_blank" href="https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/workbench/">NVIDIA AI Workbench</a> simplifies AI developer workflows by helping users build their own RAG projects, customize models and more. It‚Äôs part of the <a target="_blank" href="https://developer.nvidia.com/blog/streamline-ai-powered-app-development-with-nvidia-rtx-ai-toolkit-for-windows-rtx-pcs/">RTX AI Toolkit</a> ‚Äî a suite of tools and software development kits for customizing, optimizing and deploying AI capabilities ‚Äî launched at <a target="_blank" href="https://www.nvidia.com/en-us/events/computex/">COMPUTEX</a> earlier this month. AI Workbench removes the complexity of technical tasks that can derail experts and halt beginners.</p>
<h2><b>What Is NVIDIA AI Workbench?</b></h2>
<p>Available for free, NVIDIA AI Workbench enables users to develop, experiment with, test and prototype AI applications across GPU systems of their choice ‚Äî from laptops and workstations to data center and cloud. It offers a new approach for creating, using and sharing GPU-enabled development environments across people and systems.</p>
<p>A simple <a target="_blank" href="https://docs.nvidia.com/ai-workbench/user-guide/latest/installation/overview.html">installation</a> gets users up and running with AI Workbench on a local or remote machine in just minutes. Users can then start a new project or replicate one from <a target="_blank" href="https://github.com/nvidia?q=workbench&amp;type=all&amp;language=&amp;sort">the examples on GitHub</a>. Everything works through GitHub or GitLab, so users can easily collaborate and distribute work. Learn more about <a target="_blank" href="https://docs.nvidia.com/ai-workbench/user-guide/latest/overview/introduction.html">getting started with AI Workbench</a>.</p>
<h2><b>How AI Workbench Helps Address AI Project Challenges</b></h2>
<p>Developing AI workloads can require manual, often complex processes, right from the start.</p>
<p>Setting up GPUs, updating drivers and managing versioning incompatibilities can be cumbersome. Reproducing projects across different systems can require replicating manual processes over and over. Inconsistencies when replicating projects, like issues with data fragmentation and version control, can hinder collaboration. Varied setup processes, moving credentials and secrets, and changes in the environment, data, models and file locations can all limit the portability of projects.</p>
<p>AI Workbench makes it easier for data scientists and developers to manage their work and collaborate across heterogeneous platforms. It integrates and automates various aspects of the development process, offering:<b></b></p>
<ul>
<li><b>Ease of setup:</b> AI Workbench streamlines the process of setting up a developer environment that‚Äôs GPU-accelerated, even for users with limited technical knowledge.</li>
<li><b>Seamless collaboration: </b>AI Workbench integrates with version-control and project-management tools like GitHub and GitLab, reducing friction when collaborating.</li>
<li><b>Consistency when scaling from local to cloud:</b> AI Workbench ensures consistency across multiple environments, supporting scaling up or down from local workstations or PCs to data centers or the cloud.<b></b></li>
</ul>
<h2><b>RAG for Documents, Easier Than Ever</b></h2>
<p>NVIDIA offers sample development <a target="_blank" href="https://docs.nvidia.com/ai-workbench/user-guide/latest/overview/projects.html">Workbench Projects</a> to help users get started with AI Workbench. The <a target="_blank" href="https://github.com/NVIDIA/workbench-example-hybrid-rag">hybrid RAG Workbench Project</a> is one example: It runs a custom, text-based RAG web application with a user‚Äôs documents on their local workstation, PC or remote system.</p>
<p>Every Workbench Project runs in a ‚Äúcontainer‚Äù ‚Äî software that includes all the necessary components to run the AI application. The hybrid RAG sample pairs a Gradio chat interface frontend on the host machine with a containerized RAG server ‚Äî the backend that services a user‚Äôs request and routes queries to and from the vector database and the selected <a target="_blank" href="https://www.nvidia.com/en-us/glossary/large-language-models/">large language model</a>.</p>
<p>This Workbench Project supports a wide variety of LLMs <a target="_blank" href="https://github.com/NVIDIA/workbench-example-hybrid-rag?tab=readme-ov-file#table-1-default-supported-models-by-inference-mode">available on NVIDIA‚Äôs GitHub page</a>. Plus, the hybrid nature of the project lets users select where to run inference.</p>
<figure id="attachment_72265" aria-describedby="caption-attachment-72265" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/06/git-based-projects.png"><img loading="lazy" decoding="async" class="size-large wp-image-72265" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/git-based-projects-672x382.png" alt="" width="672" height="382" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/git-based-projects-672x382.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/git-based-projects-400x228.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/git-based-projects-768x437.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/git-based-projects-791x450.png 791w, https://blogs.nvidia.com/wp-content/uploads/2024/06/git-based-projects-378x215.png 378w, https://blogs.nvidia.com/wp-content/uploads/2024/06/git-based-projects-176x100.png 176w, https://blogs.nvidia.com/wp-content/uploads/2024/06/git-based-projects-1280x728.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/06/git-based-projects.png 1413w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-72265" class="wp-caption-text">Workbench Projects let users version the development environment and code.</figcaption></figure>
<p>Developers can run the embedding model on the host machine and run inference locally on a Hugging Face Text Generation Inference server, on target cloud resources using NVIDIA inference endpoints like the <a target="_blank" href="http://build.nvidia.com">NVIDIA API catalog</a>, or with self-hosting microservices such as <a target="_blank" href="https://www.nvidia.com/en-us/ai/">NVIDIA NIM</a> or third-party services.</p>
<p>The hybrid RAG Workbench Project also includes:</p>
<ul>
<li><b>Performance metrics:</b> Users can evaluate how RAG- and non-RAG-based user queries perform across each inference mode. Tracked metrics include Retrieval Time, Time to First Token (TTFT) and Token Velocity.</li>
<li><b>Retrieval transparency:</b> A panel shows the exact snippets of text ‚Äî retrieved from the most contextually relevant content in the vector database ‚Äî that are being fed into the LLM and improving the response‚Äôs relevance to a user‚Äôs query.</li>
<li><b>Response customization:</b> Responses can be tweaked with a variety of parameters, such as maximum tokens to generate, temperature and frequency penalty.</li>
</ul>
<p>To get started with this project, simply <a target="_blank" href="https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/workbench/">install AI Workbench</a> on a local system. The hybrid RAG Workbench Project can be brought from GitHub into the user‚Äôs account and duplicated to the local system.</p>
<p>More resources are available in the <a target="_blank" href="https://docs.nvidia.com/ai-workbench/user-guide/latest/quickstart/example-projects.html">AI Decoded user guide</a>. In addition, community members provide helpful video tutorials, like the one from Joe Freeman below.</p>
<p><iframe loading="lazy" title="NVIDIA AI Workbench Topology running on Windows, WSL and Linux  with an example" width="500" height="281" src="https://www.youtube.com/embed/MTA3D4LJfc0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<h2><b>Customize, Optimize, Deploy</b></h2>
<p>Developers often seek to customize AI models for specific use cases. Fine-tuning, a technique that changes the model by training it with additional data, can be useful for style transfer or changing model behavior. AI Workbench helps with fine-tuning, as well.</p>
<p>The <a target="_blank" href="https://github.com/NVIDIA/RTX-AI-Toolkit/blob/main/tutorial-llama3-finetune.md">Llama-factory AI Workbench Project</a> enables QLoRa, a fine-tuning method that minimizes memory requirements, for a variety of models, as well as model quantization via a simple graphical user interface. Developers can use public or their own datasets to meet the needs of their applications.</p>
<p>Once fine-tuning is complete, the model can be quantized for improved performance and a smaller memory footprint, then deployed to native Windows applications for local inference or to NVIDIA NIM for cloud inference. Find a complete tutorial for this project on the <a target="_blank" href="https://github.com/NVIDIA/RTX-AI-Toolkit">NVIDIA RTX AI Toolkit repository</a>.</p>
<h2><b>Truly Hybrid ‚Äî Run AI Workloads Anywhere</b></h2>
<p>The Hybrid-RAG Workbench Project described above is hybrid in more than one way. In addition to offering a choice of inference mode, the project can be run locally on NVIDIA RTX workstations and GeForce RTX PCs, or scaled up to remote cloud servers and data centers.</p>
<p>The ability to run projects on systems of the user‚Äôs choice ‚Äî without the overhead of setting up the infrastructure ‚Äî extends to all Workbench Projects. Find more examples and instructions for fine-tuning and customization in the AI Workbench <a target="_blank" href="https://docs.nvidia.com/ai-workbench/user-guide/latest/quickstart/quickstart-basic.html">quick-start guide</a>.</p>
<p><i>Generative AI is transforming gaming, videoconferencing and interactive experiences of all kinds. Make sense of what‚Äôs new and what‚Äôs next by subscribing to the </i><a target="_blank" href="https://www.nvidia.com/en-us/ai-on-rtx/?modal=subscribe-ai"><i>AI Decoded newsletter</i></a><i>.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/ai-workbench-nv-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/ai-workbench-nv-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Decoding How NVIDIA AI Workbench Powers App Development]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Light Bulb Moment: NVIDIA CEO Sees Bright Future for AI-Powered Electric Grid</title>
		<link>https://blogs.nvidia.com/blog/ai-electric-grid-edison/</link>
		
		<dc:creator><![CDATA[Rick Merritt]]></dc:creator>
		<pubDate>Tue, 18 Jun 2024 23:40:22 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Digital Twin]]></category>
		<category><![CDATA[Energy]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[New GPU Uses]]></category>
		<category><![CDATA[NVIDIA Jetson]]></category>
		<category><![CDATA[Omniverse]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72246</guid>

					<description><![CDATA[The electric grid and the utilities managing it have an important role to play in the next industrial revolution that‚Äôs being driven by AI and accelerated computing, said NVIDIA founder and CEO Jensen Huang Tuesday at the annual meeting of the Edison Electric Institute (EEI), an association of U.S. and international utilities. ‚ÄúThe future of	<a class="read-more" href="https://blogs.nvidia.com/blog/ai-electric-grid-edison/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>The electric grid and the utilities managing it have an important role to play in the next industrial revolution that‚Äôs being driven by AI and accelerated computing, said NVIDIA founder and CEO Jensen Huang Tuesday at the annual meeting of the Edison Electric Institute (EEI), an association of U.S. and international utilities.</p>
<p>‚ÄúThe future of digital intelligence is quite bright, and so the future of the energy sector is bright, too,‚Äù said Huang in a conversation before an audience of more than a thousand utility and energy industry executives.</p>
<p>Like other companies, utilities will apply AI to increase employee productivity, but ‚Äúthe greatest impact and return is in applying AI in the delivery of energy over the grid,‚Äù said Huang, in conversation with Pedro Pizarro, the chair of EEI and president and CEO of Edison International, the parent company of Southern California Edison, one of the nation‚Äôs largest electric utilities.</p>
<p>For example, Huang described how grids will use AI-powered smart meters to let customers sell their excess electricity to neighbors.</p>
<p>‚ÄúYou will connect resources and users, just like Google, so your power grid becomes a smart network with a digital layer like an app store for energy,‚Äù he said.</p>
<p>‚ÄúMy sense is, like previous industrial revolutions, [AI] will drive productivity to levels that we‚Äôve never seen,‚Äù he added.</p>
<p>A video of the talk will be available here soon.</p>
<h2><b>AI Lights Up Electric Grids</b></h2>
<p>Today, electric grids are mainly one-way systems that link a few big power plants to many users. They‚Äôll increasingly become two-way, flexible and distributed networks with solar and wind farms connecting homes and buildings that sport solar panels, batteries and electric vehicle chargers.</p>
<p>It‚Äôs a big job that requires autonomous control systems that process and analyze in real time a massive amount of data ‚Äî work well suited to AI and <a href="https://blogs.nvidia.com/blog/what-is-accelerated-computing/">accelerated computing</a>.</p>
<p>AI is being applied to use cases across electric grids, thanks to a wide ecosystem of companies using NVIDIA‚Äôs technologies.</p>
<p>In a recent <a target="_blank" href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s61864/">GTC session</a>, utility vendor Hubbell and startup Utilidata, a member of the <a target="_blank" href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a> program, described a new generation of smart meters using the <a target="_blank" href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/">NVIDIA Jetson</a> platform that utilities will deploy to process and analyze real-time grid data using AI models at the edge. Deloitte <a target="_blank" href="https://www.prnewswire.com/news-releases/deloitte-and-utilidata-establish-first-of-its-kind-collaboration-to-revolutionize-the-us-power-grid-for-a-sustainable-future-302175120.html">announced</a> today its support for the effort.</p>
<p>Siemens Energy detailed in <a target="_blank" href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62524/">a separate GTC session</a> its work with AI and <a target="_blank" href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> creating digital twins of transformers in substations to improve predictive maintenance, boosting grid resilience. And <a target="_blank" href="https://resources.nvidia.com/en-us-energy-utilities/maximize-wind-energy">a video</a> reports on how Siemens Gamesa used Omniverse and accelerated computing to optimize turbine placements for a large wind farm.</p>
<p>‚ÄúDeploying AI and advanced computing technologies developed by NVIDIA enables faster and better grid modernization and we, in turn, can deliver for our customers,‚Äù said Maria Pope, CEO of Portland General Electric in Oregon.</p>
<h2><b>NVIDIA Delivers 45,000x Gain in Energy Efficiency</b></h2>
<p>The advances come as NVIDIA drives down the costs and energy needed to deploy AI.</p>
<p>Over the last eight years, NVIDIA increased <a target="_blank" href="https://www.nvidia.com/en-us/glossary/energy-efficiency/">energy efficiency</a> of running AI inference on state-of-the-art large language models a whopping 45,000x, Huang said in his recent <a target="_blank" href="https://www.youtube.com/watch?v=pKXDVsWZmUU">keynote</a> at COMPUTEX.</p>
<p><a target="_blank" href="https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/">NVIDIA Blackwell architecture GPUs</a> will provide 20x greater energy efficiency than CPUs for AI and <a target="_blank" href="https://www.nvidia.com/en-us/glossary/high-performance-computing/">high-performance computing</a>. If all CPU servers for these jobs transitioned to GPUs, users would save 37 terawatt-hours a year, the equivalent of 25 million metric tons of carbon dioxide and the electricity use of 5 million homes.</p>
<p>That‚Äôs why NVIDIA-powered systems swept the top six spots and took seven of the top 10 in <a href="https://blogs.nvidia.com/blog/green500-energy-efficient-supercomputers/">the latest ranking</a> of the <a target="_blank" href="https://top500.org/lists/green500/2024/06/">Green500</a>, a list of the world‚Äôs most energy-efficient supercomputers.</p>
<p>In addition, <a href="https://blogs.nvidia.com/blog/ai-energy-study/">a recent report</a> calls for governments to accelerate adoption of AI as a significant new tool to drive energy efficiency across many industries. It cited examples of utilities adopting AI to make the electric grid more efficient.</p>
<p>Learn more about how <a target="_blank" href="https://www.nvidia.com/en-us/industries/energy/power-utilities/">utilities are deploying AI</a> and accelerated computing to improve operations, saving cost and energy.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/Final-Edison-fireside-chat-with-Jensen-Huang.jpg"
			type="image/jpeg"
			width="1461"
			height="779"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/Final-Edison-fireside-chat-with-Jensen-Huang-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Light Bulb Moment: NVIDIA CEO Sees Bright Future for AI-Powered Electric Grid]]></media:title>
			<media:description type="html">Jensen Huang in fireside chat at the Edison Electric Institute</media:description>
			</media:content>
			</item>
		<item>
		<title>Seamless in Seattle: NVIDIA Research Showcases Advancements in Visual Generative AI at CVPR</title>
		<link>https://blogs.nvidia.com/blog/visual-generative-ai-cvpr-research/</link>
		
		<dc:creator><![CDATA[Isha Salian]]></dc:creator>
		<pubDate>Mon, 17 Jun 2024 13:00:36 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[NVIDIA Research]]></category>
		<category><![CDATA[Open Source]]></category>
		<category><![CDATA[Synthetic Data Generation]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72167</guid>

					<description><![CDATA[NVIDIA researchers are at the forefront of the rapidly advancing field of visual generative AI, developing new techniques to create and interpret images, videos and 3D environments. More than 50 of these projects will be showcased at the Computer Vision and Pattern Recognition (CVPR) conference, taking place June 17-21 in Seattle. Two of the papers	<a class="read-more" href="https://blogs.nvidia.com/blog/visual-generative-ai-cvpr-research/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>NVIDIA researchers are at the forefront of the rapidly advancing field of visual generative AI, developing new techniques to create and interpret images, videos and 3D environments.</p>
<p>More than 50 of these projects will be showcased at the <a target="_blank" href="https://www.nvidia.com/en-us/events/cvpr/">Computer Vision and Pattern Recognition (CVPR)</a> conference, taking place June 17-21 in Seattle. Two of the papers ‚Äî one on the <a target="_blank" href="https://github.com/NVlabs/edm2">training dynamics of diffusion models</a> and another on <a target="_blank" href="https://arxiv.org/abs/2403.16439">high-definition maps for autonomous vehicles</a> ‚Äî are finalists for CVPR‚Äôs Best Paper Awards.</p>
<p>NVIDIA is also the <a href="https://blogs.nvidia.com/blog/auto-research-cvpr-2024/">winner of the CVPR Autonomous Grand Challenge‚Äôs End-to-End Driving at Scale</a> track ‚Äî a significant milestone that demonstrates the company‚Äôs use of generative AI for comprehensive self-driving models. The winning submission, which outperformed more than 450 entries worldwide, also received CVPR‚Äôs Innovation Award.</p>
<p>NVIDIA‚Äôs research at CVPR includes a text-to-image model that can be easily customized to depict a specific object or character, a new model for object pose estimation, a technique to edit neural radiance fields (<a href="https://blogs.nvidia.com/blog/ai-decoded-instant-nerf/">NeRFs</a>) and a visual language model that can understand memes. Additional papers introduce domain-specific innovations for industries including automotive, healthcare and robotics.</p>
<p>Collectively, the work introduces powerful AI models that could enable creators to more quickly bring their artistic visions to life, accelerate the training of autonomous robots for manufacturing, and support healthcare professionals by helping process radiology reports.</p>
<p>‚ÄúArtificial intelligence, and generative AI in particular, represents a pivotal technological advancement,‚Äù said Jan Kautz, vice president of learning and perception research at NVIDIA. ‚ÄúAt CVPR, NVIDIA Research is sharing how we‚Äôre pushing the boundaries of what‚Äôs possible ‚Äî from powerful image generation models that could supercharge professional creators to autonomous driving software that could help enable next-generation self-driving cars.‚Äù</p>
<p>At CVPR, NVIDIA also announced <a target="_blank" href="https://nvidianews.nvidia.com/news/omniverse-microservices-physical-ai">NVIDIA Omniverse Cloud Sensor RTX</a>, a set of microservices that enable physically accurate sensor simulation to accelerate the development of fully autonomous machines of every kind.</p>
<h2><b>Forget Fine-Tuning: JeDi Simplifies Custom Image Generation</b></h2>
<p>Creators harnessing diffusion models, the most popular method for generating images based on text prompts, often have a specific character or object in mind ‚Äî they may, for example, be developing a storyboard around an animated mouse or brainstorming an ad campaign for a specific toy.</p>
<p>Prior research has enabled these creators to personalize the output of diffusion models to focus on a specific subject using fine-tuning ‚Äî where a user trains the model on a custom dataset ‚Äî but the process can be time-consuming and inaccessible for general users.</p>
<p><a target="_blank" href="https://research.nvidia.com/labs/dir/jedi/">JeDi</a>, a paper by researchers from Johns Hopkins University, Toyota Technological Institute at Chicago and NVIDIA, proposes a new technique that allows users to easily personalize the output of a diffusion model within a couple of seconds using reference images. The team found that the model achieves state-of-the-art quality, significantly outperforming existing fine-tuning-based and fine-tuning-free methods.</p>
<p>JeDi can also be combined with <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">retrieval-augmented generation</a>, or RAG, to generate visuals specific to a database, such as a brand‚Äôs product catalog.</p>
<div style="width: 1452px;" class="wp-video"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video class="wp-video-shortcode" id="video-72167-1" width="1452" height="680" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/JeDi-cow-sculpture.mp4?_=1" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/06/JeDi-cow-sculpture.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/06/JeDi-cow-sculpture.mp4</a></video></div>
<p>&nbsp;</p>
<h2><b>New Foundation Model Perfects the Pose</b></h2>
<p>NVIDIA researchers at CVPR are also presenting <a target="_blank" href="https://nvlabs.github.io/FoundationPose/">FoundationPose</a>, a <a href="https://blogs.nvidia.com/blog/what-are-foundation-models/">foundation model</a> for object pose estimation and tracking that can be instantly applied to new objects during inference, without the need for fine-tuning.</p>
<p>The model, which <a target="_blank" href="https://bop.felk.cvut.cz/leaderboards/pose-estimation-unseen-bop23/core-datasets/">set a new record</a> on a popular benchmark for object pose estimation, uses either a small set of reference images or a 3D representation of an object to understand its shape. It can then identify and track how that object moves and rotates in 3D across a video, even in poor lighting conditions or complex scenes with visual obstructions.</p>
<p>FoundationPose could be used in industrial applications to help autonomous robots identify and track the objects they interact with. It could also be used in augmented reality applications where an AI model is used to overlay visuals on a live scene.</p>
<p><iframe loading="lazy" title="ar maze" width="500" height="281" src="https://www.youtube.com/embed/IvXSd4r12G8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<h2><b>NeRFDeformer Transforms 3D Scenes With a Single Snapshot</b></h2>
<p>A NeRF is an AI model that can render a 3D scene based on a series of 2D images taken from different positions in the environment. In fields like robotics, NeRFs can be used to generate immersive 3D renders of complex real-world scenes, such as a cluttered room or a construction site. However, to make any changes, developers would need to manually define how the scene has transformed ‚Äî or remake the NeRF entirely.</p>
<p>Researchers from the University of Illinois Urbana-Champaign and NVIDIA have simplified the process with NeRFDeformer. The method, being presented at CVPR, can successfully transform an existing NeRF using a single RGB-D image, which is a combination of a normal photo and a depth map that captures how far each object in a scene is from the camera.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-72222" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/Screenshot-2024-06-05-at-5.05.51-PM.png" alt="" width="1316" height="794" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/Screenshot-2024-06-05-at-5.05.51-PM.png 1316w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Screenshot-2024-06-05-at-5.05.51-PM-400x241.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Screenshot-2024-06-05-at-5.05.51-PM-672x405.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Screenshot-2024-06-05-at-5.05.51-PM-768x463.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Screenshot-2024-06-05-at-5.05.51-PM-746x450.png 746w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Screenshot-2024-06-05-at-5.05.51-PM-356x215.png 356w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Screenshot-2024-06-05-at-5.05.51-PM-166x100.png 166w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Screenshot-2024-06-05-at-5.05.51-PM-1280x772.png 1280w" sizes="(max-width: 1316px) 100vw, 1316px" /></p>
<h2><b>VILA Visual Language Model Gets the Picture</b></h2>
<p>A CVPR research collaboration between NVIDIA and the Massachusetts Institute of Technology is advancing the state of the art for vision language models, which are generative AI models that can process videos, images and text.</p>
<p>The group developed <a target="_blank" href="https://arxiv.org/abs/2312.07533">VILA</a>, a family of open-source visual language models that outperforms prior neural networks <a target="_blank" href="https://mmmu-benchmark.github.io/#leaderboard">on key benchmarks</a> that test how well AI models answer questions about images. VILA‚Äôs unique pretraining process unlocked new model capabilities, including enhanced world knowledge, stronger in-context learning and the ability to reason across multiple images.</p>
<figure id="attachment_72225" aria-describedby="caption-attachment-72225" style="width: 1999px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-full wp-image-72225" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/VILA.png" alt="figure showing how VILA can reason based on multiple images" width="1999" height="809" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/VILA.png 1999w, https://blogs.nvidia.com/wp-content/uploads/2024/06/VILA-400x162.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/VILA-672x272.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/VILA-768x311.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/VILA-1536x622.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/VILA-842x341.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/06/VILA-406x164.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/06/VILA-188x76.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/06/VILA-1280x518.png 1280w" sizes="(max-width: 1999px) 100vw, 1999px" /><figcaption id="caption-attachment-72225" class="wp-caption-text">VILA can understand memes and reason based on multiple images or video frames.</figcaption></figure>
<p>The VILA model family can be optimized for inference using the <a target="_blank" href="https://developer.nvidia.com/blog/optimizing-inference-on-llms-with-tensorrt-llm-now-publicly-available/">NVIDIA TensorRT-LLM</a> open-source library and can be deployed on NVIDIA GPUs in data centers, workstations and even <a target="_blank" href="https://developer.nvidia.com/blog/visual-language-intelligence-and-edge-ai-2-0/">edge devices</a>.</p>
<p>Read more about VILA on the <a target="_blank" href="https://developer.nvidia.com/blog/visual-language-models-on-nvidia-hardware-with-vila/">NVIDIA Technical Blog</a> and <a target="_blank" href="https://github.com/NVlabs/VILA">GitHub</a>.</p>
<h2><b>Generative AI Fuels Autonomous Driving, Smart City Research</b></h2>
<p>A dozen of the NVIDIA-authored CVPR papers focus on autonomous vehicle research. Other AV-related highlights include:</p>
<ul>
<li style="font-weight: 300;" aria-level="1"><a target="_blank" href="http://research.nvidia.com/labs/av-applied-research">NVIDIA‚Äôs AV applied research</a>, which <a href="https://blogs.nvidia.com/blog/auto-research-cvpr-2024/">won the CVPR Autonomous Grand Challenge</a>, is featured in <a target="_blank" href="https://www.youtube.com/watch?v=wfpLLSz5iWY">this demo</a>.</li>
<li style="font-weight: 300;" aria-level="1"><a target="_blank" href="https://research.nvidia.com/labs/toronto-ai/">Sanja Fidler</a>, vice president of AI research at NVIDIA, will present on vision language models at the <a target="_blank" href="https://cvpr2024.wad.vision/">Workshop on Autonomous Driving</a> on June 17.</li>
<li style="font-weight: 300;" aria-level="1"><a target="_blank" href="https://arxiv.org/abs/2403.16439">Producing and Leveraging Online Map Uncertainty in Trajectory Prediction</a>, a paper authored by researchers from the University of Toronto and NVIDIA, has been selected as one of 24 finalists for CVPR‚Äôs best paper award.</li>
</ul>
<p>Also at CVPR, NVIDIA contributed the largest ever indoor synthetic dataset to the <a href="https://blogs.nvidia.com/blog/ai-city-challenge-omniverse-cvpr/">AI City Challenge</a>, helping researchers and developers advance the development of solutions for smart cities and industrial automation. The challenge‚Äôs datasets were generated using <a target="_blank" href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, a platform of APIs, SDKs and services that enable developers to build <a target="_blank" href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description (OpenUSD)</a>-based applications and workflows.</p>
<p><a target="_blank" href="https://www.nvidia.com/en-us/research/">NVIDIA Research</a> has hundreds of scientists and engineers worldwide, with teams focused on topics including AI, computer graphics, computer vision, self-driving cars and robotics. Learn more about <a target="_blank" href="https://www.nvidia.com/en-us/events/cvpr/">NVIDIA Research at CVPR</a>.</p>
]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/06/JeDi-cow-sculpture.mp4" length="4129498" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/cat-astronaut.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/cat-astronaut-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Seamless in Seattle: NVIDIA Research Showcases Advancements in Visual Generative AI at CVPR]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Research Wins CVPR Autonomous Grand Challenge for End-to-End Driving</title>
		<link>https://blogs.nvidia.com/blog/auto-research-cvpr-2024/</link>
		
		<dc:creator><![CDATA[Danny Shapiro]]></dc:creator>
		<pubDate>Mon, 17 Jun 2024 13:00:10 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[NVIDIA DGX]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<category><![CDATA[NVIDIA Research]]></category>
		<category><![CDATA[Omniverse]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72147</guid>

					<description><![CDATA[Making moves to accelerate self-driving car development, NVIDIA was today named an Autonomous Grand Challenge winner at the Computer Vision and Pattern Recognition (CVPR) conference, running this week in Seattle. Building on last year‚Äôs win in 3D Occupancy Prediction, NVIDIA Research topped the leaderboard this year in the End-to-End Driving at Scale category with its	<a class="read-more" href="https://blogs.nvidia.com/blog/auto-research-cvpr-2024/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Making moves to accelerate self-driving car development, NVIDIA was today named an Autonomous Grand Challenge winner at the <a href="https://www.nvidia.com/en-us/events/cvpr/" target="_blank" rel="noopener">Computer Vision and Pattern Recognition</a> (CVPR) conference, running this week in Seattle.</p>
<p>Building on last year‚Äôs win in <a href="https://blogs.nvidia.com/blog/autonomous-driving-challenge-cvpr/" target="_blank" rel="noopener">3D Occupancy Prediction</a>, <a href="https://www.nvidia.com/en-us/research/" target="_blank" rel="noopener">NVIDIA Research</a> topped the leaderboard this year in the <a href="https://opendrivelab.com/challenge2024/#end_to_end_driving_at_scale" target="_blank" rel="noopener">End-to-End Driving at Scale category</a> with its Hydra-MDP model, outperforming more than 400 entries worldwide.</p>
<p>This milestone shows the importance of <a href="https://www.nvidia.com/en-us/glossary/generative-ai/" target="_blank" rel="noopener">generative AI</a> in building applications for physical AI deployments in autonomous vehicle (AV) development. The technology can also be applied to industrial environments, healthcare, robotics and other areas.</p>
<p>The winning submission received CVPR‚Äôs Innovation Award as well, recognizing NVIDIA‚Äôs approach to improving ‚Äúany end-to-end driving model using learned open-loop proxy metrics.‚Äù</p>
<p>In addition, NVIDIA announced <a href="https://nvidianews.nvidia.com/news/omniverse-microservices-physical-ai" target="_blank" rel="noopener">NVIDIA Omniverse Cloud Sensor RTX</a>, a set of microservices that enable physically accurate sensor simulation to accelerate the development of fully autonomous machines of every kind.</p>
<h2><b>How End-to-End Driving Works</b></h2>
<p>The race to develop self-driving cars isn‚Äôt a sprint but more a never-ending triathlon, with three distinct yet crucial parts operating simultaneously: AI training, simulation and autonomous driving. Each requires its own accelerated computing platform, and together, the full-stack systems purpose-built for these steps form a powerful triad that enables continuous development cycles, always improving in performance and safety.</p>
<p>To accomplish this, a model is first trained on an AI supercomputer such as <a href="https://www.nvidia.com/en-us/data-center/dgx-platform/" target="_blank" rel="noopener">NVIDIA DGX</a>. It‚Äôs then tested and validated in simulation ‚Äî using the <a href="https://www.nvidia.com/en-us/omniverse/" target="_blank" rel="noopener">NVIDIA Omniverse</a> platform and running on an <a target="_blank" href="https://www.nvidia.com/en-us/data-center/products/ovx/">NVIDIA OVX</a> system ‚Äî before entering the vehicle, where, lastly, the <a href="https://www.nvidia.com/en-us/deep-learning-ai/products/agx-systems/" target="_blank" rel="noopener">NVIDIA DRIVE AGX</a> platform processes sensor data through the model in real time.</p>
<p>Building an autonomous system to navigate safely in the complex physical world is extremely challenging. The system needs to perceive and understand its surrounding environment holistically, then make correct, safe decisions in a fraction of a second. This requires human-like situational awareness to handle potentially dangerous or rare scenarios.</p>
<p>AV software development has traditionally been based on a modular approach, with separate components for object detection and tracking, trajectory prediction, and path planning and control.</p>
<p>End-to-end autonomous driving systems streamline this process using a unified model to take in sensor input and produce vehicle trajectories, helping avoid overcomplicated pipelines and providing a more holistic, data-driven approach to handle real-world scenarios.</p>
<p>Watch a video about the Hydra-MDP model, winner of the CVPR Autonomous Grand Challenge for End-to-End Driving:</p>
<p><iframe loading="lazy" title="NVIDIA Research Wins CVPR Autonomous Grand Challenge for End-to-End Driving" width="500" height="281" src="https://www.youtube.com/embed/wfpLLSz5iWY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<h2><b>Navigating the Grand Challenge¬†</b></h2>
<p>This year‚Äôs CVPR challenge asked participants to develop an end-to-end AV model, trained using the nuPlan dataset, to generate driving trajectory based on sensor data.</p>
<p>The models were submitted for testing inside the open-source NAVSIM simulator and were tasked with navigating thousands of scenarios they hadn‚Äôt experienced yet. Model performance was scored based on metrics for safety, passenger comfort and deviation from the original recorded trajectory.</p>
<p>NVIDIA Research‚Äôs winning end-to-end model ingests camera and lidar data, as well as the vehicle‚Äôs trajectory history, to generate a safe, optimal vehicle path for five seconds post-sensor input.</p>
<p>The workflow NVIDIA researchers used to win the competition can be replicated in high-fidelity simulated environments with NVIDIA Omniverse. This means AV simulation developers can recreate the workflow in a physically accurate environment before testing their AVs in the real world. NVIDIA Omniverse Cloud Sensor RTX microservices will be available later this year. <a href="https://developer.nvidia.com/omniverse/join" target="_blank" rel="noopener">Sign up</a> for early access.</p>
<p>In addition, NVIDIA ranked second for its submission to the CVPR Autonomous Grand Challenge for <a href="https://opendrivelab.com/challenge2024/#driving_with_language" target="_blank" rel="noopener">Driving with Language</a>. NVIDIA‚Äôs approach connects vision language models and autonomous driving systems, integrating the power of <a href="https://www.nvidia.com/en-us/glossary/large-language-models/" target="_blank" rel="noopener">large language models</a> to help make decisions and achieve generalizable, explainable driving behavior.</p>
<h2><b>Learn More at CVPR¬†</b></h2>
<p>More than <a href="https://www.nvidia.com/en-us/events/cvpr/" target="_blank" rel="noopener">50 NVIDIA papers</a> were accepted to this year‚Äôs CVPR, on topics spanning automotive, healthcare, robotics and more. Over a dozen papers will cover NVIDIA automotive-related research, including:</p>
<ul>
<li><a href="https://arxiv.org/html/2406.06978v1" target="_blank" rel="noopener">Hydra-MDP: End-to-End Multimodal Planning With Multi-Target Hydra-Distillation</a>
<ul>
<li><a target="_blank" href="https://arxiv.org/html/2406.06978v1">Winner of CVPR‚Äôs </a><a target="_blank" href="https://opendrivelab.com/challenge2024/#end_to_end_driving_at_scale">End-to-End Driving at Scale challenge</a></li>
<li>Read the <a href="https://developer.nvidia.com/blog/end-to-end-driving-at-scale-with-hydra-mdp/" target="_blank" rel="noopener">NVIDIA technical blog</a></li>
</ul>
</li>
<li><a href="https://arxiv.org/abs/2403.16439" target="_blank" rel="noopener">Producing and Leveraging Online Map Uncertainty in Trajectory Prediction</a>
<ul>
<li>CVPR best paper award finalist</li>
</ul>
</li>
<li><a href="https://arxiv.org/abs/2402.05932" target="_blank" rel="noopener">Driving Everywhere With Large Language Model Policy Adaptation</a>
<ul>
<li>See <a href="https://www.youtube.com/watch?v=fQ3HJbEkP4U" target="_blank" rel="noopener">DRIVE Labs: LLM-Based Road Rules Guide Simplifies Driving</a></li>
</ul>
</li>
<li><a href="https://arxiv.org/abs/2312.03031" target="_blank" rel="noopener">Is Ego Status All You Need for Open-Loop End-to-End Autonomous Driving?</a></li>
<li><a href="https://arxiv.org/abs/2403.09230" target="_blank" rel="noopener">Improving Distant 3D Object Detection Using 2D Box Supervision</a></li>
<li><a href="https://arxiv.org/abs/2312.05247" target="_blank" rel="noopener">Dynamic LiDAR Resimulation Using Compositional Neural Fields</a></li>
<li><a href="https://arxiv.org/abs/2312.01696" target="_blank" rel="noopener">BEVNeXt: Reviving Dense BEV Frameworks for 3D Object Detection</a></li>
<li><a href="https://xinshuoweng.github.io/paradrive/" target="_blank" rel="noopener">PARA-Drive: Parallelized Architecture for Real-Time Autonomous Driving</a></li>
</ul>
<p>Sanja Fidler, vice president of AI research at NVIDIA, will speak on vision language models at the CVPR <a href="https://cvpr2024.wad.vision" target="_blank" rel="noopener">Workshop on Autonomous Driving</a>.</p>
<p><i>Learn more about </i><a href="https://www.nvidia.com/en-us/research/" target="_blank" rel="noopener"><i>NVIDIA Research</i></a><i>, a global team of hundreds of scientists and engineers focused on topics including AI, computer graphics, computer vision, self-driving cars and robotics.</i></p>
<p><em>See </em><a target="_blank" href="https://www.nvidia.com/en-us/about-nvidia/legal-info/"><em>notice</em></a><em> regarding software product information.</em></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/cvpr-auto.gif"
			type="image/gif"
			width="1200"
			height="700"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/cvpr-auto-842x450.gif"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Research Wins CVPR Autonomous Grand Challenge for End-to-End Driving]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Advances Physical AI at CVPR With Largest Indoor Synthetic Dataset</title>
		<link>https://blogs.nvidia.com/blog/ai-city-challenge-omniverse-cvpr/</link>
		
		<dc:creator><![CDATA[Akhil Docca]]></dc:creator>
		<pubDate>Mon, 17 Jun 2024 13:00:09 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[NVIDIA Isaac Sim]]></category>
		<category><![CDATA[NVIDIA Research]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<category><![CDATA[Synthetic Data Generation]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72204</guid>

					<description><![CDATA[NVIDIA contributed the largest ever indoor synthetic dataset to the Computer Vision and Pattern Recognition (CVPR) conference‚Äôs annual AI City Challenge ‚Äî helping researchers and developers advance the development of solutions for smart cities and industrial automation. The challenge, garnering over 700 teams from nearly 50 countries, tasks participants to develop AI models to enhance	<a class="read-more" href="https://blogs.nvidia.com/blog/ai-city-challenge-omniverse-cvpr/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>NVIDIA contributed the largest ever indoor synthetic dataset to the <a target="_blank" href="https://www.nvidia.com/en-us/events/cvpr/">Computer Vision and Pattern Recognition (CVPR)</a> conference‚Äôs annual <a target="_blank" href="https://www.aicitychallenge.org/">AI City Challenge</a> ‚Äî helping researchers and developers advance the development of solutions for smart cities and industrial automation.</p>
<p>The challenge, garnering over 700 teams from nearly 50 countries, tasks participants to develop AI models to enhance operational efficiency in physical settings, such as retail and warehouse environments, and intelligent traffic systems.</p>
<p>Teams tested their models on the datasets that were generated using <a target="_blank" href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, a platform of application programming interfaces (APIs), software development kits (SDKs) and services that enable developers to build <a target="_blank" href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description (OpenUSD)</a>-based applications and workflows.</p>
<h2><b>Creating and Simulating Digital Twins for Large Spaces</b></h2>
<p>In large indoor spaces like factories and warehouses, daily activities involve a steady stream of people, small vehicles and future autonomous robots. Developers need solutions that can observe and measure activities, optimize operational efficiency, and prioritize human safety in complex, large-scale settings.</p>
<p>Researchers are addressing that need with computer vision models that can perceive and understand the physical world. It can be used in applications like <a target="_blank" href="https://www.youtube.com/watch?v=l5M4sqaRd6w">multi-camera tracking</a>, in which a model tracks multiple entities within a given environment.</p>
<p>To ensure their accuracy, the models must be trained on large, ground-truth datasets for a variety of real-world scenarios. But collecting that data can be a challenging, time-consuming and costly process.</p>
<p>AI researchers are turning to physically based simulations ‚Äî such as digital twins of the physical world ‚Äî to enhance AI simulation and training. These virtual environments can help generate <a target="_blank" href="https://www.nvidia.com/en-us/use-cases/synthetic-data/">synthetic data</a> used to train AI models. Simulation also provides a way to run a multitude of ‚Äúwhat-if‚Äù scenarios in a safe environment while addressing privacy and AI bias issues.</p>
<p>Creating synthetic data is important for AI training because it offers a large, scalable, and expandable amount of data. Teams can generate a diverse set of training data by changing many parameters including lighting, object locations, textures and colors.</p>
<h2><b>Building Synthetic Datasets for the AI City Challenge</b></h2>
<p>This year‚Äôs AI City Challenge consists of five computer vision challenge tracks that span traffic management to worker safety.</p>
<p>NVIDIA contributed datasets for the first track, Multi-Camera Person Tracking, which saw the highest participation, with over 400 teams. The challenge used a benchmark and the largest synthetic dataset of its kind ‚Äî comprising 212 hours of 1080p videos at 30 frames per second spanning 90 scenes across six virtual environments, including a warehouse, retail store and hospital.</p>
<p>Created in Omniverse, these scenes simulated nearly 1,000 cameras and featured around 2,500 digital human characters. It also provided a way for the researchers to generate data of the right size and fidelity to achieve the desired outcomes.</p>
<p>The benchmarks were created using Omniverse Replicator in <a target="_blank" href="https://developer.nvidia.com/isaac/sim">NVIDIA Isaac Sim</a>, a reference application that enables developers to design, simulate and train AI for robots, smart spaces or autonomous machines in physically based virtual environments built on NVIDIA Omniverse.</p>
<p><a target="_blank" href="https://docs.omniverse.nvidia.com/isaacsim/latest/replicator_tutorials/tutorial_replicator_omni_replicator_agent.html">Omniverse Replicator</a>, an SDK for building synthetic data generation pipelines, automated many manual tasks involved in generating quality synthetic data, including domain randomization, camera placement and calibration, character movement, and semantic labeling of data and ground-truth for benchmarking.</p>
<p>Ten institutions and organizations are collaborating with NVIDIA for the AI City Challenge:</p>
<ul>
<li>Australian National University, Australia</li>
<li>Emirates Center for Mobility Research, UAE</li>
<li>Indian Institute of Technology Kanpur, India</li>
<li>Iowa State University, U.S.</li>
<li>Johns Hopkins University, U.S.</li>
<li>National Yung-Ming Chiao-Tung University, Taiwan</li>
<li>Santa Clara University, U.S.</li>
<li>The United Arab Emirates University, UAE</li>
<li>University at Albany ‚Äì SUNY, U.S.</li>
<li>Woven by Toyota, Japan</li>
</ul>
<h2><b>Driving the Future of Generative Physical AI¬†</b></h2>
<p>Researchers and companies around the world are developing infrastructure automation and robots powered by physical AI ‚Äî which are models that can understand instructions and autonomously perform complex tasks in the real world.</p>
<p><a target="_blank" href="https://www.youtube.com/watch?v=AYSfcgVv9-U">Generative physical AI</a> uses reinforcement learning in simulated environments, where it perceives the world using accurately simulated sensors, performs actions grounded by laws of physics, and receives feedback to reason about the next set of actions.</p>
<p>Developers can tap into developer SDKs and APIs, such as the NVIDIA Metropolis developer stack ‚Äî which includes a <a target="_blank" href="https://developer.nvidia.com/blog/optimize-processes-for-large-spaces-with-the-multi-camera-tracking-workflow/">multi-camera tracking reference workflow</a> ‚Äî to add enhanced perception capabilities for factories, warehouses and retail operations. And with <a target="_blank" href="https://developer.nvidia.com/blog/supercharge-robotics-workflows-with-ai-and-simulation-using-nvidia-isaac-sim-4-0-and-nvidia-isaac-lab/">the latest release of NVIDIA Isaac Sim</a>, developers can supercharge robotics workflows by simulating and training AI-based robots in physically based virtual spaces before real-world deployment.</p>
<p>Researchers and developers are also combining high-fidelity, physics-based simulation with advanced AI to bridge the gap between<a target="_blank" href="https://developer.nvidia.com/blog/closing-the-sim-to-real-gap-training-spot-quadruped-locomotion-with-nvidia-isaac-lab/"> simulated training and real-world application</a>. This helps ensure that synthetic training environments closely mimic real-world conditions for more seamless robot deployment.</p>
<p>NVIDIA is taking the accuracy and scale of simulations further with the recently <a target="_blank" href="https://nvidianews.nvidia.com/news/omniverse-microservices-physical-ai">announced NVIDIA Omniverse Cloud Sensor RTX</a>, a set of microservices that enable physically accurate sensor simulation to accelerate the development of fully autonomous machines.</p>
<p>This technology will allow autonomous systems, whether a factory, vehicle or robot, to gather essential data to effectively perceive, navigate and interact with the real world. Using these microservices, developers can run large-scale tests on sensor perception within realistic, virtual environments, significantly reducing the time and cost associated with real-world testing.</p>
<p>Omniverse Cloud Sensor RTX microservices will be available later this year. <a target="_blank" href="https://developer.nvidia.com/omniverse/join">Sign up</a> for early access.</p>
<h2><b>Showcasing Advanced AI With Research</b></h2>
<p>Participants submitted research papers for the AI City Challenge and a few achieved top rankings, including:</p>
<ul>
<li><a target="_blank" href="https://openaccess.thecvf.com/content/CVPR2024W/AICity/papers/Yoshida_Overlap_Suppression_Clustering__for_Offline_Multi-Camera_People_Tracking_CVPRW_2024_paper.pdf">Overlap Suppression Clustering for Offline Multi-Camera People Tracking</a>: This paper introduces a tracking method that includes identifying individuals within a single camera&#8217;s view, selecting clear images for easier recognition, grouping similar appearances, and helping to clarify identities in challenging situations.</li>
<li><a target="_blank" href="https://openaccess.thecvf.com/content/CVPR2024W/AICity/papers/Xie_A_Robust_Online_Multi-Camera_People_Tracking_System_With_Geometric_Consistency_CVPRW_2024_paper.pdf">A Robust Online Multi-Camera People Tracking System With Geometric Consistency and State-aware Re-ID Correction</a>: This research presents a new system that uses geometric and appearance data to improve tracking accuracy, and includes a mechanism that adjusts identification features to fix tracking errors.</li>
<li><a target="_blank" href="https://openaccess.thecvf.com/content/CVPR2024W/AICity/papers/Kim_Cluster_Self-Refinement_for_Enhanced_Online_Multi-Camera_People_Tracking_CVPRW_2024_paper.pdf">Cluster Self-Refinement for Enhanced Online Multi-Camera People Tracking</a>: This research paper addresses specific challenges faced in online tracking, such as the storage of poor-quality data and errors in identity assignment.</li>
</ul>
<p>All accepted papers will be presented at the <a target="_blank" href="https://cvpr.thecvf.com/virtual/2024/workshop/23656">AI City Challenge 2024 Workshop</a>, taking place on June 17.</p>
<p>At CVPR 2024, NVIDIA Research will present over 50 papers, introducing generative physical AI breakthroughs with potential applications in areas like autonomous vehicle development and robotics.</p>
<p>Papers that used NVIDIA Omniverse to generate synthetic data or digital twins of environments for model simulation, testing and validation include:</p>
<ul>
<li><a target="_blank" href="https://arxiv.org/abs/2312.08344">FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects</a>: FoundationPose is a versatile model for estimating and tracking the 3D position and orientation of objects. The model operates by using a few reference images or a 3D representation to accurately understand an object&#8217;s shape.</li>
<li><a target="_blank" href="https://arxiv.org/abs/2404.01440">Neural Implicit Representation for Building Digital Twins of Unknown Articulated Objects</a>: This research paper presents a method for creating digital models of objects from two 3D scans, improving accuracy by analyzing how movable parts connect and move between positions.</li>
<li><a target="_blank" href="https://arxiv.org/abs/2405.09546">BEHAVIOR Vision Suite: Customizable Dataset Generation via Simulation</a>: The BEHAVIOR Vision Suite generates customizable synthetic data for computer vision research, allowing researchers to adjust settings like lighting and object placement.</li>
</ul>
<p>Read more about NVIDIA Research at <a target="_blank" href="https://www.nvidia.com/en-us/events/cvpr/">CVPR</a>, and learn more about the <a target="_blank" href="https://www.aicitychallenge.org/">AI City Challenge</a>.</p>
<p><i>Get started with NVIDIA Omniverse by downloading the standard license </i><a target="_blank" href="https://www.nvidia.com/en-us/omniverse/download/"><i>free</i></a><i>, access </i><a target="_blank" href="https://developer.nvidia.com/usd"><i>OpenUSD</i></a><i> resources and learn how </i><a target="_blank" href="https://www.nvidia.com/en-us/omniverse/enterprise/"><i>Omniverse Enterprise can connect teams</i></a><i>. Follow Omniverse on </i><a target="_blank" href="https://www.instagram.com/nvidiaomniverse/"><i>Instagram</i></a><i>, </i><a target="_blank" href="https://medium.com/@nvidiaomniverse"><i>Medium</i></a><i>, </i><a target="_blank" href="https://www.linkedin.com/showcase/nvidia-omniverse/"><i>LinkedIn</i></a><i> and </i><a target="_blank" href="https://twitter.com/nvidiaomniverse"><i>X</i></a><i>. For more, join the </i><a target="_blank" href="https://www.nvidia.com/en-us/omniverse/community/"><i>Omniverse community</i></a><i> on the </i><a target="_blank" href="https://forums.developer.nvidia.com/c/omniverse/300"><i>forums</i></a><i>, </i><a target="_blank" href="https://discord.com/invite/XWQNJDNuaC"><i>Discord server</i></a><i>, </i><a target="_blank" href="https://www.twitch.tv/nvidiaomniverse"><i>Twitch</i></a><i> and </i><a target="_blank" href="https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA"><i>YouTube</i></a><i> channels.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/nv-ov-ai-city-4up-16x9-1280x680-1.jpeg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/nv-ov-ai-city-4up-16x9-1280x680-1-842x450.jpeg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Advances Physical AI at CVPR With Largest Indoor Synthetic Dataset]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>‚ÄòBelieve in Something Unconventional, Something Unexplored,‚Äô NVIDIA CEO Tells Caltech Grads</title>
		<link>https://blogs.nvidia.com/blog/jensen-huang-caltech-commencement-address/</link>
		
		<dc:creator><![CDATA[Isha Salian]]></dc:creator>
		<pubDate>Sat, 15 Jun 2024 23:20:04 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Education]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72198</guid>

					<description><![CDATA[NVIDIA founder and CEO Jensen Huang on Friday encouraged Caltech graduates to pursue their craft with dedication and resilience ‚Äî and to view setbacks as new opportunities. ‚ÄúI hope you believe in something. Something unconventional, something unexplored. But let it be informed, and let it be reasoned, and dedicate yourself to making that happen,‚Äù he	<a class="read-more" href="https://blogs.nvidia.com/blog/jensen-huang-caltech-commencement-address/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>NVIDIA founder and CEO Jensen Huang on Friday encouraged Caltech graduates to pursue their craft with dedication and resilience ‚Äî and to view setbacks as new opportunities.</p>
<p>‚ÄúI hope you believe in something. Something unconventional, something unexplored. But let it be informed, and let it be reasoned, and dedicate yourself to making that happen,‚Äù he said. ‚ÄúYou may find your GPU. You may find your CUDA. You may find your generative AI. You may find your NVIDIA.‚Äù</p>
<p>Trading his signature leather jacket for black and yellow academic regalia, Huang addressed the nearly 600 graduates at their commencement ceremony in Pasadena, Calif., starting with the tale of the computing industry‚Äôs decades-long evolution to reach this pivotal moment of AI transformation.</p>
<p>‚ÄúComputers today are the single most important instrument of knowledge, and it‚Äôs foundational to every single industry in every field of science,‚Äù Huang said. ‚ÄúAs you enter industry, it‚Äôs important you know what‚Äôs happening.‚Äù</p>
<p>He shared how, over a decade ago, NVIDIA ‚Äî a small company at the time ‚Äî bet on deep learning, investing billions of dollars and years of engineering resources to reinvent every computing layer.</p>
<p>‚ÄúNo one knew how far deep learning could scale, and if we didn‚Äôt build it, we‚Äôd never know,‚Äù Huang said. Referencing the famous line from <i>Field of Dreams</i> ‚Äî if you build it, he will come ‚Äî he said, ‚ÄúOur logic is: If we don‚Äôt build it, they can‚Äôt come.‚Äù</p>
<p>Looking to the future, Huang said, the next wave of AI is robotics, a field where NVIDIA‚Äôs journey resulted from a series of setbacks.</p>
<p>He reflected on a period in NVIDIA‚Äôs past when the company each year built new products that ‚Äúwould be incredibly successful, generate enormous amounts of excitement. And then one year later, we were kicked out of those markets.‚Äù</p>
<p>These roadblocks pushed NVIDIA to seek out untapped areas ‚Äî what Huang refers to as ‚Äúzero-billion-dollar markets.‚Äù</p>
<p>‚ÄúWith no more markets to turn to, we decided to build something where we are sure there are no customers,‚Äù Huang said. ‚ÄúBecause one of the things you can definitely guarantee is where there are no customers, there are also no competitors.‚Äù</p>
<p>Robotics was that new market. NVIDIA built the first robotics computer, Huang said, processing a deep learning algorithm. Over a decade later, that pivot has given the company the opportunity to create the next wave of AI.</p>
<p>‚ÄúOne setback after another, we shook it off and skated to the next opportunity. Each time, we gain skills and strengthen our character,‚Äù Huang said. ‚ÄúNo setback that comes our way doesn‚Äôt look like an opportunity these days.‚Äù</p>
<p>Huang stressed the importance of resilience and agility as superpowers that strengthen character.</p>
<p>‚ÄúThe world can be unfair and deal you with tough cards. Swiftly shake it off,‚Äù he said, with a tongue-in-cheek reference to one of Taylor Swift‚Äôs biggest hits. ‚ÄúThere‚Äôs another opportunity out there ‚Äî or create one.‚Äù</p>
<p>Huang concluded by sharing a story from his travels to Japan, where, as he watched a gardener painstakingly tending to Kyoto‚Äôs famous moss garden, he realized that when a person is dedicated to their craft and prioritizes doing their life‚Äôs work, they always have plenty of time.</p>
<p>‚ÄúPrioritize your life,‚Äù he said, ‚Äúand you will have plenty of time to do the important things.‚Äù</p>
<p><iframe loading="lazy" title="Caltech&#039;s 130th Commencement Ceremony" width="500" height="281" src="https://www.youtube.com/embed/-qXDdToZHzE?start=3137&#038;feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p><i>Main image courtesy of Caltech.¬†</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/Commencement-2024-JN_IMG_6568_blogcrop.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/Commencement-2024-JN_IMG_6568_blogcrop-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[‚ÄòBelieve in Something Unconventional, Something Unexplored,‚Äô NVIDIA CEO Tells Caltech Grads]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Releases Open Synthetic Data Generation Pipeline for Training Large Language Models</title>
		<link>https://blogs.nvidia.com/blog/nemotron-4-synthetic-data-generation-llm-training/</link>
		
		<dc:creator><![CDATA[Ankit Patel]]></dc:creator>
		<pubDate>Fri, 14 Jun 2024 15:51:33 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[NVIDIA NIM]]></category>
		<category><![CDATA[Synthetic Data Generation]]></category>
		<category><![CDATA[TensorRT]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72165</guid>

					<description><![CDATA[NVIDIA today announced Nemotron-4 340B, a family of open models that developers can use to generate synthetic data for training large language models (LLMs) for commercial applications across healthcare, finance, manufacturing, retail and every other industry. High-quality training data plays a critical role in the performance, accuracy and quality of responses from a custom LLM	<a class="read-more" href="https://blogs.nvidia.com/blog/nemotron-4-synthetic-data-generation-llm-training/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p dir="ltr">NVIDIA today announced Nemotron-4 340B, a family of open models that developers can use to generate synthetic data for training large language models (LLMs) for commercial applications across healthcare, finance, manufacturing, retail and every other industry.</p>
<p dir="ltr">High-quality training data plays a critical role in the performance, accuracy and quality of responses from a custom LLM ‚Äî but robust datasets can be prohibitively expensive and difficult to access.</p>
<p dir="ltr">Through a uniquely permissive <a href="https://developer.download.nvidia.com/licenses/nvidia-open-model-license-agreement-june-2024.pdf" target="_blank" rel="noopener">open model license</a>, Nemotron-4 340B gives developers a free, scalable way to generate synthetic data that can help build powerful LLMs.</p>
<p dir="ltr">The Nemotron-4 340B family includes base, instruct and reward models that form a pipeline to generate synthetic data used for training and refining LLMs. The models are optimized to work with <a href="https://github.com/NVIDIA/NeMo" target="_blank" rel="noopener">NVIDIA NeMo</a>, an open-source framework for end-to-end model training, including data curation, customization and evaluation. They‚Äôre also optimized for inference with the open-source <a href="https://github.com/NVIDIA/TensorRT-LLM" target="_blank" rel="noopener">NVIDIA TensorRT-LLM</a> library.</p>
<p dir="ltr">Nemotron-4 340B can be downloaded now from the <a target="_blank" href="https://catalog.ngc.nvidia.com/models?filters=&amp;orderBy=scoreDESC&amp;query=nemotron-4-340b">NVIDIA NGC</a> catalog and <a href="https://huggingface.co/collections/nvidia/nemotron-4-340b-666b7ebaf1b3867caf2f1911" target="_blank" rel="noopener">Hugging Face</a>. Developers will soon be able to access the models at <a href="http://ai.nvidia.com/" target="_blank" rel="noopener">ai.nvidia.com</a>, where they‚Äôll be packaged as an <a href="https://developer.nvidia.com/blog/nvidia-nim-offers-optimized-inference-microservices-for-deploying-ai-models-at-scale/" target="_blank" rel="noopener">NVIDIA NIM</a> microservice with a standard application programming interface that can be deployed anywhere.</p>
<h2 dir="ltr">Navigating Nemotron to Generate Synthetic Data</h2>
<p dir="ltr">LLMs can help developers generate synthetic training data in scenarios where access to large, diverse labeled datasets is limited.</p>
<p dir="ltr">The <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/nemotron-4-340b-instruct" target="_blank" rel="noopener">Nemotron-4 340B Instruct</a> model creates diverse synthetic data that mimics the characteristics of real-world data, helping improve data quality to increase the performance and robustness of custom LLMs across various domains.</p>
<p dir="ltr">Then, to boost the quality of the AI-generated data, developers can use the <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/nemotron-4-340b-reward" target="_blank" rel="noopener">Nemotron-4 340B Reward</a> model to filter for high-quality responses. Nemotron-4 340B Reward grades responses on five attributes: helpfulness, correctness, coherence, complexity and verbosity. It‚Äôs currently first place on the <a target="_blank" href="https://huggingface.co/spaces/allenai/reward-bench">Hugging Face RewardBench leaderboard</a>, created by <a href="https://allenai.org/" target="_blank" rel="noopener">AI2</a>, for evaluating the capabilities, safety and pitfalls of reward models.</p>
<figure id="attachment_72168" aria-describedby="caption-attachment-72168" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/06/Synthetic-Data-Generation-Pipeline-scaled.jpg"><img loading="lazy" decoding="async" class="wp-image-72168 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/Synthetic-Data-Generation-Pipeline-672x378.jpg" alt="nemotron synthetic data generation pipeline diagram" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/Synthetic-Data-Generation-Pipeline-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Synthetic-Data-Generation-Pipeline-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Synthetic-Data-Generation-Pipeline-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Synthetic-Data-Generation-Pipeline-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Synthetic-Data-Generation-Pipeline-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Synthetic-Data-Generation-Pipeline-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Synthetic-Data-Generation-Pipeline-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Synthetic-Data-Generation-Pipeline-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Synthetic-Data-Generation-Pipeline-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-72168" class="wp-caption-text">In this synthetic data generation pipeline, (1) the Nemotron-4 340B Instruct model is first used to produce synthetic text-based output. An evaluator model, (2) Nemotron-4 340B Reward, then assesses this generated text ‚Äî providing feedback that guides iterative improvements and ensures the synthetic data is accurate, relevant and aligned with specific requirements.</figcaption></figure>
<p dir="ltr">Researchers can also create their own instruct or reward models by customizing the <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/nemotron-4-340b-base" target="_blank" rel="noopener">Nemotron-4 340B Base</a> model using their proprietary data, combined with the included <a href="https://huggingface.co/datasets/nvidia/HelpSteer2" target="_blank" rel="noopener">HelpSteer2 dataset</a>.</p>
<h2 dir="ltr">Fine-Tuning With NeMo, Optimizing for Inference With TensorRT-LLM</h2>
<p dir="ltr">Using open-source NVIDIA NeMo and NVIDIA TensorRT-LLM, developers can optimize the efficiency of their instruct and reward models to generate synthetic data and to score responses.</p>
<p dir="ltr">All Nemotron-4 340B models are optimized with TensorRT-LLM to take advantage of tensor parallelism, a type of model parallelism in which individual weight matrices are split across multiple GPUs and servers, enabling efficient inference at scale.</p>
<p dir="ltr">Nemotron-4 340B Base, trained on 9 trillion tokens, can be customized using the NeMo framework to adapt to specific use cases or domains. This fine-tuning process benefits from extensive pretraining data and yields more accurate outputs for specific downstream tasks.</p>
<p dir="ltr">A variety of customization methods are available through the NeMo framework, including supervised fine-tuning and parameter-efficient fine-tuning methods such as low-rank adaptation, or LoRA.</p>
<p dir="ltr">To boost model quality, developers can align their models with <a href="https://github.com/NVIDIA/NeMo-Aligner" target="_blank" rel="noopener">NeMo Aligner</a> and datasets annotated by Nemotron-4 340B Reward. Alignment is a key step in training LLMs, where a model‚Äôs behavior is fine-tuned using algorithms like reinforcement learning from human feedback (RLHF) to ensure its outputs are safe, accurate, contextually appropriate and consistent with its intended goals.</p>
<p dir="ltr">Businesses seeking enterprise-grade support and security for production environments can also access NeMo and TensorRT-LLM through the cloud-native <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/" target="_blank" rel="noopener">NVIDIA AI Enterprise</a> software platform, which provides accelerated and efficient runtimes for generative AI foundation models.</p>
<h2 dir="ltr">Evaluating Model Security and Getting Started</h2>
<p dir="ltr">The Nemotron-4 340B Instruct model underwent extensive safety evaluation, including adversarial tests, and performed well across a wide range of risk indicators. Users should still perform careful evaluation of the model‚Äôs outputs to ensure the synthetically generated data is suitable, safe and accurate for their use case.</p>
<p dir="ltr">For more information on model security and safety evaluation, read the model card.</p>
<p dir="ltr">Download Nemotron-4 340B models via <a target="_blank" href="https://catalog.ngc.nvidia.com/models?filters=&amp;orderBy=scoreDESC&amp;query=nemotron-4-340b"><span>NVIDIA NGC</span></a><span> and </span><a href="https://huggingface.co/collections/nvidia/nemotron-4-340b-666b7ebaf1b3867caf2f1911" target="_blank" rel="noopener">Hugging Face</a>. For more details, read the <a target="_blank" href="https://research.nvidia.com/publication/2024-06_nemotron-4-340b">research papers on the model</a> and <a href="https://arxiv.org/abs/2406.08673" target="_blank" rel="noopener">dataset</a>.</p>
<p><i>See </i><a href="https://www.nvidia.com/en-eu/about-nvidia/terms-of-service/" target="_blank" rel="noopener"><i>notice</i></a><i> regarding software product information.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/llm-blog-customization-techniques-2847735-1280x680-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/llm-blog-customization-techniques-2847735-1280x680-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Releases Open Synthetic Data Generation Pipeline for Training Large Language Models]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>‚ÄòThe Proudest Refugee‚Äô: How Veronica Miller Charts Her Own Path at NVIDIA</title>
		<link>https://blogs.nvidia.com/blog/nvidia-life-veronica-miller/</link>
		
		<dc:creator><![CDATA[Haley Hirai]]></dc:creator>
		<pubDate>Fri, 14 Jun 2024 13:00:11 +0000</pubDate>
				<category><![CDATA[NVIDIA Life]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72096</guid>

					<description><![CDATA[When she was five years old, Veronica Miller (n√©e Teklai) and her family left their homeland of Eritrea, in the Horn of Africa, to escape an ongoing war with Ethiopia and create a new life in the U.S. She grew up in East Orange, New Jersey, watching others judge her parents and turn them away	<a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-life-veronica-miller/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>When she was five years old, Veronica Miller (n√©e Teklai) and her family left their homeland of Eritrea, in the Horn of Africa, to escape an ongoing war with Ethiopia and create a new life in the U.S.</p>
<p>She grew up in East Orange, New Jersey, watching others judge her parents and turn them away from jobs they were qualified for because of their appearance, their accented English or their unfamiliar names.</p>
<p>After working in the shipping industry for 20 years, Miller‚Äôs dad eventually became a New York City cab driver, an often-dangerous job in the 1980s. Her mom, despite earning a computer science degree in the U.S., trained to become a home health aide, where jobs were more available.</p>
<p>‚ÄúMy parents‚Äô resilience and courage made my life possible,‚Äù Miller said.<a href="https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF3787-scaled.jpg"><img loading="lazy" decoding="async" class="alignright wp-image-72099 size-medium" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF3787-267x400.jpg" alt="" width="267" height="400" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF3787-267x400.jpg 267w, https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF3787-333x500.jpg 333w, https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF3787-768x1152.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF3787-1024x1536.jpg 1024w, https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF3787-scaled.jpg 1365w, https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF3787-300x450.jpg 300w, https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF3787-143x215.jpg 143w, https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF3787-67x100.jpg 67w, https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF3787-1280x1920.jpg 1280w" sizes="(max-width: 267px) 100vw, 267px" /></a></p>
<p>After graduating from Ramapo College of New Jersey with a degree in international business, Miller worked at large automotive companies in client support, production support and project management.</p>
<p>Now working as a technical program manager in product security at NVIDIA, she feels like her family‚Äôs journey has come full circle.</p>
<p>‚ÄúIt‚Äôs the honor of my life being here at NVIDIA: I‚Äôm the proudest refugee,‚Äù she said.</p>
<p>In her role, Miller functions like a conductor in an orchestra. She works with engineers to bridge gaps and understand challenges to define solutions ‚Äî always trying to create opportunities to turn a ‚Äúno‚Äù into a ‚Äúyes‚Äù through collaboration.</p>
<p>At NVIDIA, Miller feels like she can be herself, helping her thrive. She no longer feels the pressure to conform to fit in, allowing her creativity to flow freely and solve problems.</p>
<p>‚ÄúPreviously in my career, I never wore my hair curly. After someone once asked to touch my curly hair, I believed it would be easier to make myself look like everyone else. I thought it was the best way to let my work be the focus instead of my hair,‚Äù she said. ‚ÄúNVIDIA is the first employer that encouraged me to bring my full self to work.‚Äù</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF4399-scaled.jpg"><img loading="lazy" decoding="async" class="alignleft wp-image-72105 size-medium" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF4399-400x267.jpg" alt="" width="400" height="267" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF4399-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF4399-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF4399-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF4399-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF4399-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF4399-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF4399-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF4399-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/06/webDSCF4399-1280x853.jpg 1280w" sizes="(max-width: 400px) 100vw, 400px" /></a></p>
<p>Outside of work, Miller and her husband, Nathan, are passionate about paying it forward and helping local youth in Trenton, New Jersey. Together, they‚Äôve developed The Miller Family Foundation to help with community needs, including education. The foundation‚Äôs scholarship fund has donated $20,000 to low-income high school students to provide support for college tuition and career mentorship.</p>
<p>‚ÄúI truly believe anyone could get here. There wasn‚Äôt anyone that showed me the path. It was belief in myself, a ton of research and endless hard work,‚Äù she said. ‚ÄúWe‚Äôre in a special place where my husband and I can give the next generation some of the financial support and career guidance we didn‚Äôt have.‚Äù</p>
<p><i>Learn more about </i><a target="_blank" href="https://www.nvidia.com/en-us/about-nvidia/careers/life-at-nvidia/"><i>NVIDIA life, culture and careers</i></a><i>.¬†</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/Featured-Photo-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1365"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/Featured-Photo-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[‚ÄòThe Proudest Refugee‚Äô: How Veronica Miller Charts Her Own Path at NVIDIA]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Cloud Ahoy! Treasure Awaits With ‚ÄòSea of Thieves‚Äô on GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-sea-of-thieves/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 13 Jun 2024 13:00:05 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72150</guid>

					<description><![CDATA[Set sail for adventure, pirates. Sea of Thieves makes waves in the cloud this week. It‚Äôs an adventure-filled GFN Thursday with four new games joining the GeForce NOW library. Plus, members are sharing their favorite locations they can access from the cloud. Follow along all month on @NVIDIAGFN social media accounts and post your own	<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-sea-of-thieves/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Set sail for adventure, pirates. <i>Sea of Thieves </i>makes waves in the cloud this week. It‚Äôs an adventure-filled GFN Thursday with four new games joining the <a target="_blank" href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> library.</p>
<figure id="attachment_72154" aria-describedby="caption-attachment-72154" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-72154" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/gfgfn-right.png-672x357.png" alt="#GreetingsfromGFN" width="672" height="357" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/gfgfn-right.png-672x357.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/gfgfn-right.png-400x213.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/gfgfn-right.png-768x408.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/gfgfn-right.png-842x447.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/06/gfgfn-right.png-406x215.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/06/gfgfn-right.png-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/06/gfgfn-right.png.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72154" class="wp-caption-text"><em>#GreetingsFromGFN by Cloud Gaming Photography.</em></figcaption></figure>
<p>Plus, members are sharing their favorite locations they can access from the cloud. Follow along all month on @NVIDIAGFN social media accounts and post your own favorite cloud screenshots using #GreetingsfromGFN.</p>
<h2><b>Seas the Day</b></h2>
<p>Live the pirate life in the smash-hit pirate adventure game from Rare and Xbox Game Studios. <i>Sea of Thieves</i> takes place in an open world where players can explore the vast seas, engage in ship battles, hunt for treasure and embark on exciting quests.</p>
<figure id="attachment_72160" aria-describedby="caption-attachment-72160" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-72160" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sea_of_Thieves-672x378.jpg" alt="Sea of Thieves on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sea_of_Thieves-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sea_of_Thieves-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sea_of_Thieves-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sea_of_Thieves-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sea_of_Thieves-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sea_of_Thieves-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sea_of_Thieves-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sea_of_Thieves-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sea_of_Thieves-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72160" class="wp-caption-text"><em>Come sea what‚Äôs possible in the cloud.</em></figcaption></figure>
<p>The <i>Sea of Thieves</i> environment is always changing, as various seasons bring new features to the game and offer rich rewards for pirates old and new. Visit uncharted islands in search of treasure, dive deep into narrative-focused Tall Tales, take part in events and forge a path to become a true Pirate Legend. The newest season features the mysterious Sunken City, Cursed Sloop skeleton ships and fresh cosmetics.</p>
<p>Every pirate needs a crew, so grab some mateys and carve a fearsome reputation across the open seas, or adventure solo to keep all the bountiful treasure. Make the journey more rewarding with a <a target="_blank" href="https://www.nvidia.com/en-us/geforce-now/memberships/">GeForce NOW Ultimate membership</a>, and play with gamers across the world with up to eight-hour gaming sessions for a kraken good time.</p>
<h2><b>New Games Zoom Onto the Cloud</b></h2>
<figure id="attachment_72157" aria-describedby="caption-attachment-72157" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-72157" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Disney_Speedstorm-672x336.jpg" alt="Disney Speedstorm on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Disney_Speedstorm-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Disney_Speedstorm-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Disney_Speedstorm-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Disney_Speedstorm-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Disney_Speedstorm-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Disney_Speedstorm-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Disney_Speedstorm-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Disney_Speedstorm-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Disney_Speedstorm.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72157" class="wp-caption-text"><em>Take the tracks by storm.</em></figcaption></figure>
<p>Drift into the ultimate hero-based combat racing game in <i>Disney Speedstorm</i>, a free-to-play kart-racing game that features characters and high-speed circuits inspired by beloved Disney and Pixar worlds. Customize racers and karts, master each character‚Äôs unique skills and engage in thrilling multiplayer races. Whether exploring the docks of the Pirates‚Äô Island track from <i>Pirates of the Caribbean</i> or the wilds of the Jungle Ruins map from <i>The Jungle Book</i>, players can experience iconic environments in the game.</p>
<p>Check out the list of new games this week:</p>
<ul>
<li><i>SunnySide </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1746930?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, June 14)</li>
<li><i>Disney Speedstorm </i>(<a target="_blank" href="https://store.steampowered.com/app/1537830?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a target="_blank" href="https://www.xbox.com/games/store/disney-speedstorm/9pmr3t9nsf8w?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Sea of Thieves </i>(<a target="_blank" href="https://store.steampowered.com/app/1172620?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a target="_blank" href="https://www.xbox.com/games/store/sea-of-thieves-2023-edition/9P2N57MC619K?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Bodycam </i>(<a target="_blank" href="https://store.steampowered.com/app/2406770/Bodycam/">Steam</a>)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a target="_blank" href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Oar you looking forward to tomorrow? <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/2600.png" alt="‚òÄ" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f329.png" alt="üå©" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a target="_blank" href="https://twitter.com/NVIDIAGFN/status/1800921002148253965?ref_src=twsrc%5Etfw">June 12, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p>&nbsp;</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-thursday-6-6-nv-blog-1280x680-no-copy-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-thursday-6-6-nv-blog-1280x680-no-copy-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Cloud Ahoy! Treasure Awaits With ‚ÄòSea of Thieves‚Äô on GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Every Company‚Äôs Data Is Their ‚ÄòGold Mine,‚Äô NVIDIA CEO Says at Databricks Data + AI Summit</title>
		<link>https://blogs.nvidia.com/blog/databricks-data-ai/</link>
		
		<dc:creator><![CDATA[Anne Hecht]]></dc:creator>
		<pubDate>Wed, 12 Jun 2024 20:25:33 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Generative AI]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72122</guid>

					<description><![CDATA[Accelerated computing is transforming data processing and analytics for enterprises, declared NVIDIA founder and CEO Jensen Huang Wednesday during an on-stage chat with Databricks cofounder and CEO Ali Ghodsi at the Databricks Data + AI Summit 2024. &#8220;Every company‚Äôs business data is their gold mine,‚Äù Huang said, explaining that every company has enormous amounts of	<a class="read-more" href="https://blogs.nvidia.com/blog/databricks-data-ai/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Accelerated computing is transforming data processing and analytics for enterprises, declared NVIDIA founder and CEO Jensen Huang Wednesday during an on-stage chat with Databricks cofounder and CEO Ali Ghodsi at the <a target="_blank" href="https://www.databricks.com/dataaisummit">Databricks Data + AI Summit 2024</a>.</p>
<p>&#8220;Every company‚Äôs business data is their gold mine,‚Äù Huang said, explaining that every company has enormous amounts of data, but extracting insights and distilling intelligence from it has been challenging.</p>
<p><iframe loading="lazy" title="YouTube video player" src="https://www.youtube.com/embed/SAsoWmMhX3Q?si=XL2clmsl3yIimqzn" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<h2>Databricks Leverages NVIDIA‚Äôs Full Stack to Accelerate Generative AI Applications</h2>
<p>To unlock all that intelligence, Huang and Ghodsi announced the integration of <a href="https://blogs.nvidia.com/blog/what-is-accelerated-computing/">NVIDIA‚Äôs accelerated computing</a> with Databricks Photon, Databricks‚Äô engine for fast data processing, designed to power Databricks SQL with top-tier performance and cost efficiency.</p>
<p>‚ÄúThis is a big announcement,‚Äù Huang said, adding that accelerated computing and generative AI are the two most important technological trends today. ‚ÄúNVIDIA and Databricks are going to partner to combine our skills in these areas and bring them to all of you.‚Äù</p>
<p>Huang shared that it‚Äôs taken NVIDIA five years to build a set of libraries that make it possible to accelerate Photon, allowing users to ‚Äúwrangle data faster, more cost-effectively and consume a lot less energy.‚Äù</p>
<p>‚ÄúWe are super-excited to partner with you to use GPU acceleration on the Photon engine to enhance core data processing and get them to also run on NVIDIA GPUs,‚Äù Ghodsi said.</p>
<h2>Creating Generative AI Factories With NVIDIA NIM</h2>
<p>NVIDIA and Databricks also announced that Databricks‚Äô open-source model DBRX is now available as an <a target="_blank" href="http://ai.nvidia.com">NVIDIA NIM</a> microservice hosted on the NVIDIA API catalog.</p>
<p>NVIDIA NIM inference microservices provide models as fully optimized, pre-built containers for deployment anywhere.</p>
<p>&#8220;Creating these endpoints is complicated,‚Äù Huang explained. ‚ÄúWe optimized everything into a microservice, which runs on every cloud and on premises.‚Äù</p>
<p>Microservices dramatically increase enterprise developer productivity by providing a simple, standardized way to add generative AI models to applications.</p>
<p>Launched in March, DBRX was built entirely on top of Databricks, leveraging all the tools and techniques available to Databricks customers and partners, and was trained with <a target="_blank" href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a>, a scalable end-to-end AI platform for developers.</p>
<p>Organizations can customize DBRX with enterprise data to create high-quality, organization-specific models or use it to build a custom DBRX-style mixture of expert models as a reference architecture.</p>
<p>Huang said that accelerating data processing is a huge opportunity, encouraging everyone to put accelerated computing and generative AI to work.</p>
<p>‚ÄúWhatever you do, just start ‚Äî you have to engage in this incredibly fast-moving train,‚Äù Huang said. ‚ÄúRemember, generative AI is growing exponentially ‚Äî you don‚Äôt want to wait and observe an exponential trend, because in a couple of years, you‚Äôll be so far behind.‚Äù</p>
<h2>Joining the Conversation</h2>
<p>Attendees at the summit are encouraged to participate in sessions and engage with NVIDIA experts to learn more about how NVIDIA and Databricks are driving the future of AI and data intelligence.</p>
<p>Key sessions, taking place June 13, include:</p>
<ul>
<li>‚ÄúDevelopment and Deployment of Generative AI with NVIDIA‚Äù at 12:30 p.m. PT</li>
<li>‚ÄúArchitecture Analysis for ETL Processing: CPU vs. GPU‚Äù at 4:30 p.m. PT;</li>
<li>‚ÄúSpark RAPIDS ML: GPU Accelerated Distributed ML in Spark Clusters‚Äù at 1:30 p.m. PT</li>
</ul>
<p><iframe loading="lazy" title="YouTube video player" src="https://www.youtube.com/embed/SAsoWmMhX3Q?si=XL2clmsl3yIimqzn" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/databricks-jhh-2-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1365"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/databricks-jhh-2-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Every Company‚Äôs Data Is Their ‚ÄòGold Mine,‚Äô NVIDIA CEO Says at Databricks Data + AI Summit]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Scaling to New Heights: NVIDIA MLPerf Training Results Showcase Unprecedented Performance and Elasticity</title>
		<link>https://blogs.nvidia.com/blog/mlperf-training-benchmarks/</link>
		
		<dc:creator><![CDATA[Dave Salvator]]></dc:creator>
		<pubDate>Wed, 12 Jun 2024 15:00:30 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Networking]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[NVIDIA Hopper Architecture]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72098</guid>

					<description><![CDATA[The full-stack NVIDIA accelerated computing platform has once again demonstrated exceptional performance in the latest MLPerf Training v4.0 benchmarks. NVIDIA more than tripled the performance on the large language model (LLM) benchmark, based on GPT-3 175B, compared to the record-setting NVIDIA submission made last year. Using an AI supercomputer featuring 11,616 NVIDIA H100 Tensor Core	<a class="read-more" href="https://blogs.nvidia.com/blog/mlperf-training-benchmarks/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>The full-stack NVIDIA accelerated computing platform has once again demonstrated exceptional performance in the latest MLPerf Training v4.0 benchmarks.</p>
<p>NVIDIA more than tripled the performance on the large language model (LLM) benchmark, based on GPT-3 175B, compared to the record-setting NVIDIA submission made last year. Using an AI supercomputer featuring 11,616 <a target="_blank" href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100 Tensor Core GPUs</a> connected with <a target="_blank" href="https://www.nvidia.com/en-us/networking/quantum2/">NVIDIA Quantum-2 InfiniBand</a> networking, NVIDIA¬† achieved this remarkable feat through larger scale ‚Äî more than triple that of the 3,584 H100 GPU submission a year ago ‚Äî and extensive full-stack engineering.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/06/MLPerf-4-training-results-scaled.jpg"><img loading="lazy" decoding="async" class="aligncenter size-large wp-image-72193" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/MLPerf-4-training-results-672x410.jpg" alt="NVIDIA Hopper GPUs lead MLPerf 4.0 results in AI training" width="672" height="410" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/MLPerf-4-training-results-672x410.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/MLPerf-4-training-results-400x244.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/MLPerf-4-training-results-768x469.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/MLPerf-4-training-results-1536x938.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/MLPerf-4-training-results-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/06/MLPerf-4-training-results-737x450.jpg 737w, https://blogs.nvidia.com/wp-content/uploads/2024/06/MLPerf-4-training-results-352x215.jpg 352w, https://blogs.nvidia.com/wp-content/uploads/2024/06/MLPerf-4-training-results-164x100.jpg 164w, https://blogs.nvidia.com/wp-content/uploads/2024/06/MLPerf-4-training-results-1280x782.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<p>Thanks to the scalability of the NVIDIA AI platform, Eos can now train massive AI models like GPT-3 175B even faster, and this great AI performance translates into significant business opportunities. For example, in NVIDIA‚Äôs recent earnings call, we described how LLM service providers can turn a single dollar invested into seven dollars in just four years running the Llama 3 70B model on NVIDIA HGX H200 servers. This return assumes an LLM service provider serving Llama 3 70B at $0.60/M tokens, with an HGX H200 server throughput of <a href="https://blogs.nvidia.com/blog/meta-llama3-inference-acceleration/">24,000 tokens/second</a>.</p>
<h2><b>NVIDIA</b> <b>H200 GPU Supercharges Generative AI and HPC¬†</b></h2>
<p>The NVIDIA H200 Tensor GPU builds upon the strength of the Hopper architecture, with 141GB of HBM3 memory and over 40% more memory bandwidth compared to the H100 GPU. Pushing the boundaries of what‚Äôs possible in AI training, the NVIDIA H200 Tensor Core GPU extended the H100‚Äôs performance by up to 47% in its MLPerf Training debut.</p>
<h2><b>NVIDIA Software Drives Unmatched Performance Gains</b></h2>
<p>Additionally, our submissions using a 512 H100 GPU configuration are now up to 27% faster compared to just one year ago due to numerous optimizations to the NVIDIA software stack. This improvement highlights how continuous software enhancements can significantly boost performance, even with the same hardware.</p>
<p>This work also delivered nearly perfect scaling. As the number of GPUs increased by 3.2x ‚Äî going from 3,584 H100 GPUs last year to 11,616 H100 GPUs with this submission ‚Äî so did the delivered performance.</p>
<p>Learn more about these optimizations on the <a target="_blank" href="https://developer.nvidia.com/blog/nvidia-sets-new-generative-ai-performance-and-scale-records-in-mlperf-training-v4-0/">NVIDIA Technical Blog</a>.</p>
<h2><b>Excelling at LLM Fine-Tuning</b></h2>
<p>As enterprises seek to customize pretrained large language models, LLM fine-tuning is becoming a key industry workload. MLPerf introduced a new LLM fine-tuning benchmark this round, based on the popular low-rank adaptation (LoRA) technique applied to Meta Llama 2 70B.</p>
<p>The NVIDIA platform excelled at this task, scaling from eight to 1,024 GPUs, with the largest-scale NVIDIA submission completing the benchmark in a record 1.5 minutes.</p>
<h2><b>Accelerating Stable Diffusion and GNN Training</b></h2>
<p>NVIDIA also accelerated Stable Diffusion v2 training performance by up to 80% at the same system scales submitted last round. These advances reflect numerous enhancements to the NVIDIA software stack, showcasing how software and hardware improvements go hand-in-hand to deliver top-tier performance.</p>
<p>On the new graph neural network (GNN) test based on R-GAT, the NVIDIA platform with H100 GPUs excelled at both small and large scales. The H200 delivered a 47% boost on single-node GNN training compared to the H100. This showcases the powerful performance and high efficiency of NVIDIA GPUs, which make them ideal for a wide range of AI applications.</p>
<h2><b>Broad Ecosystem Support</b></h2>
<p>Reflecting the breadth of the NVIDIA AI ecosystem, 10 NVIDIA partners submitted results, including ASUS, Dell Technologies, Fujitsu, GIGABYTE, Hewlett Packard Enterprise, Lenovo, Oracle, Quanta Cloud Technology, Supermicro and Sustainable Metal Cloud. This broad participation, and their own impressive benchmark results, underscores the widespread adoption and trust in NVIDIA‚Äôs AI platform across the industry.</p>
<p><a target="_blank" href="https://mlcommons.org/">MLCommons</a>‚Äô ongoing work to bring benchmarking best practices to AI computing is vital. By enabling peer-reviewed comparisons of AI and HPC platforms, and keeping pace with the rapid changes that characterize AI computing, MLCommons provides companies everywhere with crucial data that can help guide important purchasing decisions.</p>
<p>And with the <a target="_blank" href="https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/">NVIDIA Blackwell</a> platform, next-level AI performance on trillion-parameter generative AI models for both training and inference is coming soon.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/hpc-promo-corp-blog-mlperf-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/hpc-promo-corp-blog-mlperf-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Scaling to New Heights: NVIDIA MLPerf Training Results Showcase Unprecedented Performance and Elasticity]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>TOPS of the Class: Decoding AI Performance on RTX AI PCs and Workstations</title>
		<link>https://blogs.nvidia.com/blog/ai-decoded-tops/</link>
		
		<dc:creator><![CDATA[Jesse Clayton]]></dc:creator>
		<pubDate>Wed, 12 Jun 2024 13:00:25 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[AI Decoded]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Conversational AI]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72090</guid>

					<description><![CDATA[The era of the AI PC is here, and it‚Äôs powered by NVIDIA RTX and GeForce RTX technologies. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><i>Editor‚Äôs note: This post is part of the </i><a href="https://blogs.nvidia.com/blog/tag/ai-decoded/" target="_blank" rel="noopener"><i>AI Decoded series</i></a><i>, which demystifies AI by making the technology more accessible, and showcases new hardware, software, tools and accelerations for RTX PC users.</i></p>
<p>The era of the AI PC is here, and it‚Äôs powered by <a href="https://www.nvidia.com/en-us/design-visualization/desktop-graphics/" target="_blank" rel="noopener">NVIDIA RTX</a> and <a href="https://www.nvidia.com/en-us/geforce/rtx/" target="_blank" rel="noopener">GeForce RTX</a> technologies. With it comes a new way to evaluate performance for AI-accelerated tasks, and a new language that can be daunting to decipher when choosing between the desktops and laptops available.</p>
<p>While PC gamers understand frames per second (FPS) and similar stats, measuring AI performance requires new metrics.</p>
<h2><b>Coming Out on TOPS</b></h2>
<p>The first baseline is TOPS, or trillions of operations per second. Trillions is the important word here ‚Äî the processing numbers behind <a href="https://www.nvidia.com/en-us/glossary/generative-ai/" target="_blank" rel="noopener">generative AI</a> tasks are absolutely massive. Think of TOPS as a raw performance metric, similar to an engine‚Äôs horsepower rating. More is better.</p>
<p>Compare, for example, the recently announced Copilot+ PC lineup by Microsoft, which includes neural processing units (NPUs) able to perform upwards of 40 TOPS. Performing 40 TOPS is sufficient for some light AI-assisted tasks, like asking a local chatbot where yesterday‚Äôs notes are.</p>
<p>But many generative AI tasks are more demanding. NVIDIA RTX and GeForce RTX GPUs deliver unprecedented performance across all generative tasks ‚Äî the GeForce RTX 4090 GPU offers more than 1,300 TOPS. This is the kind of horsepower needed to handle AI-assisted digital content creation, AI super resolution in PC gaming, generating images from text or video, querying local <a href="https://blogs.nvidia.com/blog/what-are-large-language-models-used-for/" target="_blank" rel="noopener">large language models</a> (LLMs) and more.</p>
<h2><b>Insert Tokens to Play</b></h2>
<p>TOPS is only the beginning of the story. LLM performance is measured in the number of tokens generated by the model.</p>
<p>Tokens are the output of the LLM. A token can be a word in a sentence, or even a smaller fragment like punctuation or whitespace. Performance for AI-accelerated tasks can be measured in ‚Äútokens per second.‚Äù</p>
<p>Another important factor is batch size, or the number of inputs processed simultaneously in a single inference pass. As an LLM will sit at the core of many modern AI systems, the ability to handle multiple inputs (e.g. from a single application or across multiple applications) will be a key differentiator. While larger batch sizes improve performance for concurrent inputs, they also require more memory, especially when combined with larger models.</p>
<figure id="attachment_72118" aria-describedby="caption-attachment-72118" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/06/NV-chart.png"><img loading="lazy" decoding="async" class="size-large wp-image-72118" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/NV-chart-672x322.png" alt="" width="672" height="322" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/NV-chart-672x322.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/NV-chart-400x192.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/NV-chart-768x368.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/NV-chart-1536x737.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/NV-chart-842x404.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/06/NV-chart-406x195.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/06/NV-chart-188x90.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/06/NV-chart-1280x614.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/06/NV-chart.png 1880w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-72118" class="wp-caption-text">The more you batch, the more (time) you save.</figcaption></figure>
<p>RTX GPUs are exceptionally well-suited for LLMs due to their large amounts of dedicated video random access memory (VRAM), Tensor Cores and <a href="https://developer.nvidia.com/tensorrt#section-inference-for-llms" target="_blank" rel="noopener">TensorRT-LLM</a> software.</p>
<p>GeForce RTX GPUs offer up to 24GB of high-speed VRAM, and NVIDIA RTX GPUs up to 48GB, which can handle larger models and enable higher batch sizes. RTX GPUs also take advantage of Tensor Cores ‚Äî dedicated AI accelerators that dramatically speed up the computationally intensive operations required for deep learning and generative AI models. That maximum performance is easily accessed when an application uses the <a href="https://developer.nvidia.com/tensorrt" target="_blank" rel="noopener">NVIDIA TensorRT</a> software development kit (SDK), which unlocks the highest-performance generative AI on the more than 100 million Windows PCs and workstations powered by RTX GPUs.</p>
<p>The combination of memory, dedicated AI accelerators and optimized software gives RTX GPUs massive throughput gains, especially as batch sizes increase.</p>
<h2><b>Text-to-Image, Faster Than Ever</b></h2>
<p>Measuring image generation speed is another way to evaluate performance. One of the most straightforward ways uses Stable Diffusion, a popular image-based AI model that allows users to easily convert text descriptions into complex visual representations.</p>
<p><iframe loading="lazy" title="Accelerate Stable Diffusion with NVIDIA RTX GPUs" width="500" height="281" src="https://www.youtube.com/embed/fUAEBoJCJW8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>With Stable Diffusion, users can quickly create and refine images from text prompts to achieve their desired output. When using an RTX GPU, these results can be generated faster than processing the AI model on a CPU or NPU.</p>
<p>That performance is <a href="https://blogs.nvidia.com/blog/ai-decoded-tensorrt-stable-diffusion-automatic1111/" target="_blank" rel="noopener">even higher</a> when using the <a href="https://github.com/NVIDIA/Stable-Diffusion-WebUI-TensorRT" target="_blank" rel="noopener">TensorRT extension</a> for the popular Automatic1111 interface. RTX users can generate images from prompts up to 2x faster with the SDXL Base checkpoint ‚Äî significantly streamlining Stable Diffusion workflows.</p>
<p>ComfyUI, another popular Stable Diffusion user interface, added <a href="https://github.com/comfyanonymous/ComfyUI_TensorRT" target="_blank" rel="noopener">TensorRT acceleration</a> last week. RTX users can now generate images from prompts up to 60% faster, and can even convert these images to videos using Stable Video Diffuson up to 70% faster with TensorRT.</p>
<p><iframe loading="lazy" title="Generate Images Faster with Stable Diffusion and RTX" width="500" height="281" src="https://www.youtube.com/embed/64QEVfbPHyg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>TensorRT acceleration can be put to the test in the new UL Procyon AI Image Generation benchmark, which delivers speedups of 50% on a GeForce RTX 4080 SUPER GPU compared with the fastest non-TensorRT implementation.</p>
<p>TensorRT acceleration will soon be released for Stable Diffusion 3 ‚Äî Stability AI‚Äôs new, highly anticipated text-to-image model ‚Äî boosting performance by 50%. Plus, the new <a href="https://developer.nvidia.com/blog/accelerate-generative-ai-inference-performance-with-nvidia-tensorrt-model-optimizer-now-publicly-available/" target="_blank" rel="noopener">TensorRT-Model Optimizer</a> enables accelerating performance even further. This results in a 70% speedup compared with the non-TensorRT implementation, along with a 50% reduction in memory consumption.</p>
<p>Of course, seeing is believing ‚Äî the true test is in the real-world use case of iterating on an original prompt. Users can refine image generation by tweaking prompts significantly faster on RTX GPUs, taking seconds per iteration compared with minutes on a Macbook Pro M3 Max. Plus, users get both speed and security with everything remaining private when running locally on an RTX-powered PC or workstation.</p>
<h2><b>The Results Are in and Open Sourced</b></h2>
<p>But don‚Äôt just take our word for it. The team of AI researchers and engineers behind the open-source <a href="http://jan.ai" target="_blank" rel="noopener">Jan.ai</a> recently integrated <a href="https://github.com/NVIDIA/TensorRT-LLM" target="_blank" rel="noopener">TensorRT-LLM</a> into its local chatbot app, then <a href="https://jan.ai/post/benchmarking-nvidia-tensorrt-llm" target="_blank" rel="noopener">tested</a> these optimizations for themselves.</p>
<figure id="attachment_72112" aria-describedby="caption-attachment-72112" style="width: 648px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/06/Chart.png"><img loading="lazy" decoding="async" class="size-full wp-image-72112" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/Chart.png" alt="" width="648" height="437" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/Chart.png 648w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Chart-400x270.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Chart-319x215.png 319w, https://blogs.nvidia.com/wp-content/uploads/2024/06/Chart-148x100.png 148w" sizes="(max-width: 648px) 100vw, 648px" /></a><figcaption id="caption-attachment-72112" class="wp-caption-text">Source: Jan.ai</figcaption></figure>
<p>The researchers tested its implementation of TensorRT-LLM against the open-source llama.cpp inference engine across a variety of GPUs and CPUs used by the community. They found that TensorRT is ‚Äú30-70% faster than llama.cpp on the same hardware,‚Äù as well as more efficient on consecutive processing runs. The team also included its methodology, inviting others to measure generative AI performance for themselves.</p>
<p>From games to generative AI, speed wins. TOPS, images per second, tokens per second and batch size are all considerations when determining performance champs.</p>
<p><i>Generative AI is transforming gaming, videoconferencing and interactive experiences of all kinds. Make sense of what‚Äôs new and what‚Äôs next by subscribing to the </i><a target="_blank" href="https://www.nvidia.com/en-us/ai-on-rtx/?modal=subscribe-ai"><i>AI Decoded newsletter</i></a><i>.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/AI-perf-nv-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/AI-perf-nv-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[TOPS of the Class: Decoding AI Performance on RTX AI PCs and Workstations]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Nerding About NeRFs: How Neural Radiance Fields Transform 2D Images Into Hyperrealistic 3D Models</title>
		<link>https://blogs.nvidia.com/blog/neural-radiance-fields-3d-models/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Wed, 12 Jun 2024 13:00:12 +0000</pubDate>
				<category><![CDATA[The AI Podcast]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72094</guid>

					<description><![CDATA[Let‚Äôs talk about NeRFs ‚Äî no, not the neon-colored foam dart blasters, but neural radiance fields, a technology that might just change the nature of images forever. In this episode of NVIDIA‚Äôs AI Podcast recorded live at GTC, host Noah Kravitz speaks with Michael Rubloff, founder and managing editor of radiancefields.com, about radiance field-based technologies.	<a class="read-more" href="https://blogs.nvidia.com/blog/neural-radiance-fields-3d-models/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Let‚Äôs talk about NeRFs ‚Äî no, not the neon-colored foam dart blasters, but neural radiance fields, a technology that might just change the nature of images forever. In this episode of NVIDIA‚Äôs <a href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">AI Podcast</a> recorded live at GTC, host Noah Kravitz speaks with Michael Rubloff, founder and managing editor of <a href="http://radiancefields.com" target="_blank" rel="noopener">radiancefields.com</a>, about radiance field-based technologies. NeRFs allow users to take a series of 2D images or video to create a hyperrealistic 3D model ‚Äî something like a photograph of a scene, but that can be looked at from multiple angles. Tune in to learn more about the technology‚Äôs creative and commercial applications and how it might transform the way people capture and experience the world.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1844347677%3Fsecret_token%3Ds-seIzfk7GvkQ&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> ¬∑ <a style="color: #cccccc; text-decoration: none;" title="Michael Rubloff Explains How Neural Radiance Fields Turn 2D Images Into 3D Models - Ep. 226" href="https://soundcloud.com/theaipodcast/nerf/s-seIzfk7GvkQ" target="_blank" rel="noopener">Michael Rubloff Explains How Neural Radiance Fields Turn 2D Images Into 3D Models &#8211; Ep. 226</a></div>
<p>Watch the replay of Rubloff‚Äôs <a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62751/" target="_blank" rel="noopener">GTC session</a> on the intersection of generative AI and extended reality.</p>
<h2><b>Time Stamps</b></h2>
<p>1:18: What are NeRFs?<br />
3:01: How do NeRFs work?<br />
3:44: What&#8217;s the difference between NeRFs and Gaussian splatting?<br />
4:36: How are NeRFs being used?<br />
7:22: What is a radiance field?<br />
14:18: How might radiance fields affect creative applications?<br />
17:50: Examples of NeRFs in action in the media right now<br />
21:00: Rubloff&#8217;s insight on where NeRFs will go in the future</p>
<h2><b>You Might Also Like‚Ä¶</b></h2>
<p><a href="https://soundcloud.com/theaipodcast/mediamonks-lewis-smithingham" target="_blank" rel="noopener"><b>Media.Monks‚Äô Lewis Smithingham on Enhancing Media and Marketing With AI &#8211; Ep. 222</b></a></p>
<p>Meet Media.Monks‚Äô Wormhole, an alien-like, conversational robot with a quirky personality and the ability to offer keen marketing expertise. Lewis Smithingham, senior vice president of innovation and special ops at Media.Monks, a global marketing and advertising company, discusses the creation of Wormhole and AI‚Äôs potential to enhance media and entertainment.</p>
<p><a href="https://soundcloud.com/theaipodcast/robin-wang" target="_blank" rel="noopener"><b>Living Optics CEO Robin Wang on Democratizing Hyperspectral Imaging &#8211; Ep. 219 </b><b><br />
</b><br />
</a>Step into the realm of the unseen with Robin Wang, CEO of Living Optics. The startup cofounder discusses the power of Living Optics‚Äô hyperspectral imaging camera, which can capture visual data across 96 colors, reveals details invisible to the human eye.</p>
<p><a href="https://soundcloud.com/theaipodcast/pinar-demirdag-cuebric" target="_blank" rel="noopener"><b>Exploring Filmmaking With Cuebric‚Äôs AI: Insights from Pinar Seyhan Demirdag &#8211; Ep. 214</b></a></p>
<p>Pinar Seyhan Demirdag, co-founder and CEO of Cuebric, which is on a mission to offer new filmmaking and content creation solutions through immersive, two-and-a-half-dimensional cinematic environments.</p>
<p><a href="https://soundcloud.com/theaipodcast/ai-deepdub" target="_blank" rel="noopener"><b>Deepdub‚Äôs Ofir Krakowski on Redefining Dubbing From Hollywood to Bollywood &#8211; Ep. 202</b></a></p>
<p>Deepdub acts as a digital bridge, providing access to content by using generative AI to break down language and cultural barriers. The Israel-based startup‚Äôs co-founder and CEO, Ofir Krakowski, describes how Deepdub uses AI-driven dubbing to help entertainment companies boost efficiency and cut costs while increasing accessibility.</p>
<h2><b>Subscribe to the AI Podcast</b></h2>
<p>Get the<a href="https://blogs.nvidia.com/ai-podcast/" target="_blank" rel="noopener"> AI Podcast</a> through<a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439" target="_blank" rel="noopener"> iTunes</a>, <a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm" target="_blank" rel="noopener">Google Play</a>, <a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast" target="_blank" rel="noopener">Amazon Music</a>, <a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us" target="_blank" rel="noopener">Castbox</a>, DoggCatcher, <a href="https://overcast.fm/itunes1186480811/the-ai-podcast" target="_blank" rel="noopener">Overcast</a>,<a href="https://player.fm/series/the-ai-podcast" target="_blank" rel="noopener"> PlayerFM</a>, Pocket Casts, <a href="http://www.podbay.fm/show/1186480811" target="_blank" rel="noopener">Podbay</a>, <a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast" target="_blank" rel="noopener">PodBean</a>, PodCruncher, PodKicker, <a href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">Soundcloud</a>, <a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L" target="_blank" rel="noopener">Spotify</a>, <a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr" target="_blank" rel="noopener">Stitcher</a> and <a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/" target="_blank" rel="noopener">TuneIn</a>.</p>
<p>Make the AI Podcast better: Have a few minutes to spare? Fill out <a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short" target="_blank" rel="noopener">this listener survey</a>.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/ski_video.gif"
			type="image/gif"
			width="654"
			height="368"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/ski_video.gif"
			width="654"
			height="368"
			/>
			<media:title type="html"><![CDATA[Nerding About NeRFs: How Neural Radiance Fields Transform 2D Images Into Hyperrealistic 3D Models]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Why Accelerated Data Processing Is Crucial for AI Innovation in Every Industry</title>
		<link>https://blogs.nvidia.com/blog/accelerated-data-processing-ai-industry-innovation/</link>
		
		<dc:creator><![CDATA[Ben Oliveri]]></dc:creator>
		<pubDate>Fri, 07 Jun 2024 15:00:19 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[Data Science]]></category>
		<category><![CDATA[Financial Services]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[Industrial and Manufacturing]]></category>
		<category><![CDATA[RAPIDS]]></category>
		<category><![CDATA[Telecommunications]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72077</guid>

					<description><![CDATA[Across industries, AI is supercharging innovation with machine-powered computation. In finance, bankers are using AI to detect fraud more quickly and keep accounts safe, telecommunications providers are improving networks to deliver superior service, scientists are developing novel treatments for rare diseases, utility companies are building cleaner, more reliable energy grids and automotive companies are making	<a class="read-more" href="https://blogs.nvidia.com/blog/accelerated-data-processing-ai-industry-innovation/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Across industries, AI is supercharging innovation with machine-powered computation. In finance, bankers are using AI to detect fraud more quickly and keep accounts safe, telecommunications providers are improving networks to deliver superior service, scientists are developing novel treatments for rare diseases, utility companies are building cleaner, more reliable energy grids and automotive companies are making self-driving cars safer and more accessible.</p>
<p>The backbone of top AI use cases is data. Effective and precise AI models require training on extensive datasets. Enterprises seeking to harness the power of AI must establish a data pipeline that involves extracting data from diverse sources, transforming it into a consistent format and storing it efficiently.</p>
<p>Data scientists work to refine datasets through multiple experiments to fine-tune AI models for optimal performance in real-world applications. These applications, from voice assistants to personalized recommendation systems, require rapid processing of large data volumes to deliver real-time performance.</p>
<p>As AI models become more complex and begin to handle diverse data types such as text, audio, images, and video, the need for rapid data processing becomes more critical. Organizations that continue to rely on legacy CPU-based computing are struggling with hampered innovation and performance due to data bottlenecks, escalating data center costs, and insufficient computing capabilities.</p>
<p>Many businesses are turning to <a href="https://blogs.nvidia.com/blog/what-is-accelerated-computing/">accelerated computing</a> to integrate AI into their operations. This method leverages GPUs, specialized hardware, software, and parallel computing techniques to boost computing performance by as much as 150x and <a href="https://blogs.nvidia.com/blog/gpu-energy-efficiency-nersc/">increase energy efficiency by up to 42x</a>.</p>
<p>Leading companies across different sectors are using accelerated data processing to spearhead groundbreaking AI initiatives.</p>
<h2><b>Finance Organizations Detect Fraud in a Fraction of a Second</b></h2>
<p>Financial organizations face a significant challenge in detecting patterns of fraud due to the vast amount of transactional data that requires rapid analysis. Additionally, the scarcity of labeled data for actual instances of fraud poses a difficulty in training AI models. Conventional data science pipelines lack the required acceleration to handle the large data volumes associated with fraud detection. This leads to slower processing times that hinder real-time data analysis and fraud detection capabilities.</p>
<p>To overcome these challenges, <a target="_blank" href="https://resources.nvidia.com/en-us-financial-services-industry/american-express-adopts-ai">American Express</a>, which handles more than 8 billion transactions per year, uses accelerated computing to train and deploy long short-term memory (LSTM) models. These models excel in sequential analysis and detection of anomalies, and can adapt and learn from new data, making them ideal for combating fraud.</p>
<p>Leveraging parallel computing techniques on GPUs, American Express significantly speeds up the training of its LSTM models. GPUs also enable live models to process huge volumes of transactional data to make high-performance computations to detect fraud in real time.</p>
<p>The system operates within two milliseconds of latency to better protect customers and merchants, delivering a 50x improvement over a CPU-based configuration. By combining the accelerated LSTM deep neural network with its existing methods, American Express has improved fraud detection accuracy by up to 6% in specific segments.</p>
<p>Financial companies can also use accelerated computing to reduce data processing costs. Running data-heavy Spark3 workloads on NVIDIA GPUs, PayPal confirmed the potential to <a target="_blank" href="https://resources.nvidia.com/en-us-financial-services-industry/gtc24-s62506">reduce cloud costs by up to 70%</a> for big data processing and AI applications.</p>
<p>By processing data more efficiently, financial institutions can detect fraud in real time, enabling faster decision-making without disrupting transaction flow and minimizing the risk of financial loss.</p>
<h2><b>Telcos Simplify Complex Routing Operations</b></h2>
<p>Telecommunications providers generate immense amounts of data from various sources, including network devices, customer interactions, billing systems, and network performance and maintenance.</p>
<p>Managing national networks that handle hundreds of petabytes of data every day requires complex technician routing to ensure service delivery. To optimize technician dispatch, advanced routing engines perform trillions of computations, taking into account factors like weather, technician skills, customer requests and fleet distribution. Success in these operations depends on meticulous data preparation and sufficient computing power.</p>
<p>AT&amp;T, which operates one of the nation‚Äôs largest field dispatch teams to service its customers, is enhancing data-heavy routing operations with NVIDIA cuOpt, which relies on heuristics, metaheuristics and optimizations to calculate complex vehicle routing problems.</p>
<p>In early trials, <a target="_blank" href="https://nvidianews.nvidia.com/news/at-t-supercharges-operations-with-nvidia-ai">cuOpt delivered routing solutions in 10 seconds</a>, achieving a 90% reduction in cloud costs and enabling technicians to complete more service calls daily. <a target="_blank" href="https://www.nvidia.com/en-us/deep-learning-ai/software/rapids/">NVIDIA RAPIDS</a>, a suite of software libraries that enables acceleration of data science and analytics pipelines, further accelerates cuOpt, allowing companies to integrate local search heuristics and metaheuristics like Tabu search for continuous route optimization.</p>
<p>AT&amp;T is adopting <a target="_blank" href="https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/apache-spark-3/">NVIDIA RAPIDS Accelerator for Apache Spark</a> to enhance the performance of Spark-based AI and data pipelines. This has helped the company boost operational efficiency on everything from training AI models to maintaining network quality to reducing customer churn and improving fraud detection. With RAPIDS Accelerator, AT&amp;T is reducing its cloud computing spend for target workloads while enabling faster performance and reducing its carbon footprint.</p>
<p>Accelerated data pipelines and processing will be critical as telcos seek to improve operational efficiency while delivering the highest possible service quality.</p>
<h2><b>Biomedical Researchers Condense Drug Discovery Timelines</b></h2>
<p>As researchers utilize technology to study the roughly 25,000 genes in the human genome to understand their relationship with diseases, there has been an explosion of medical data and peer-reviewed research papers. Biomedical researchers rely on these papers to narrow down the field of study for novel treatments. However, conducting literature reviews of such a massive and expanding body of relevant research has become an impossible task.</p>
<p>AstraZeneca, a leading pharmaceutical company, developed a Biological Insights Knowledge Graph (BIKG) to aid scientists across the drug discovery process, from literature reviews to screen hit rating, target identification and more. This graph integrates public and internal databases with information from scientific literature, modeling between 10 million and 1 billion complex biological relationships.</p>
<p>BIKG has been effectively used for gene ranking, aiding scientists in hypothesizing high-potential targets for novel disease treatments. <a target="_blank" href="https://www.nvidia.com/en-us/on-demand/session/gtcfall21-a31252/">At NVIDIA GTC</a>, the AstraZeneca team presented a project that successfully identified genes linked to resistance in lung cancer treatments.</p>
<p>To narrow down potential genes, data scientists and biological researchers collaborated to define the criteria and gene features ideal for targeting in treatment development. They trained a machine learning algorithm to search the BIKG databases for genes with the designated features mentioned in literature as treatable. Utilizing NVIDIA RAPIDS for faster computations, the team reduced the initial gene pool from 3,000 to just 40 target genes, a task that previously took months but now takes mere seconds.</p>
<p>By supplementing drug development with accelerated computing and AI, pharmaceutical companies and researchers can finally use the enormous troves of data building up in the medical field to develop novel drugs faster and more safely, ultimately having a life-saving impact.</p>
<h2><b>Utility Companies Build the Future of Clean Energy¬†</b></h2>
<p>There‚Äôs been a significant push to shift to carbon-neutral energy sources in the energy sector. With the cost of harnessing renewable resources such as solar energy falling drastically over the last 10 years, the opportunity to make real progress toward a clean energy future has never been greater.</p>
<p>However, this shift toward integrating clean energy from wind farms, solar farms and home batteries has introduced new complexities in grid management. As energy infrastructure diversifies and two-way power flows must be accommodated, managing the grid has become more data-intensive. New smart grids are now required to handle high-voltage areas for vehicle charging. They must also manage the availability of distributed stored energy sources and adapt to variations in usage across the network.</p>
<p><a target="_blank" href="https://resources.nvidia.com/en-us-energy-utilities/gtc24-s61864">Utilidata, a prominent grid-edge software company</a>, has collaborated with NVIDIA to develop a distributed AI platform, Karman, for the grid edge using a custom NVIDIA Jetson Orin edge AI module. This custom chip and platform, embedded in electricity meters, transforms each meter into a data collection and control point, capable of handling thousands of data points per second.</p>
<p>Karman processes real-time, high-resolution data from meters at the network‚Äôs edge. This enables utility companies to gain detailed insights into grid conditions, predict usage and seamlessly integrate distributed energy resources in seconds, rather than minutes or hours. Additionally, with inference models on edge devices, network operators can anticipate and quickly identify line faults to predict potential outages and conduct preventative maintenance to increase grid reliability.</p>
<p>Through the integration of AI and accelerated data analytics, Karman helps utility providers transform existing infrastructure into efficient smart grids. This allows for tailored, localized electricity distribution to meet fluctuating demand patterns without extensive physical infrastructure upgrades, facilitating a more cost-effective modernization of the grid.</p>
<h2><b>Automakers Enable Safer, More Accessible, Self-Driving Vehicles</b></h2>
<p>As auto companies strive for full self-driving capabilities, vehicles must be able to detect objects and navigate in real time. This requires high-speed data processing tasks, including feeding live data from cameras, lidar, radar and GPS into AI models that make navigation decisions to keep roads safe.</p>
<p>The autonomous driving inference workflow is complex and includes multiple AI models along with necessary preprocessing and postprocessing steps. Traditionally, these steps were handled on the client side using CPUs. However, this can lead to significant bottlenecks in processing speeds, which is an unacceptable drawback for an application where fast processing equates to safety.</p>
<p>To enhance the efficiency of autonomous driving workflows, <a target="_blank" href="https://resources.nvidia.com/en-us-automotive-resource-library/nio">electric vehicle manufacturer NIO</a> integrated NVIDIA Triton Inference Server into its inference pipeline. NVIDIA Triton is open-source, multi-framework, inference-serving software. By centralizing data processing tasks, NIO reduced latency by 6x in some core areas and increased overall data throughput by up to 5x.</p>
<p>NIO‚Äôs GPU-centric approach made it easier to update and deploy new AI models without the need to change anything on the vehicles themselves. Additionally, the company could use multiple AI models at the same time on the same set of images without having to send data back and forth over a network, which saved on data transfer costs and improved performance.</p>
<p>By using accelerated data processing, autonomous vehicle software developers ensure they can reach a high-performance standard to avoid traffic accidents, lower transportation costs and improve mobility for users.</p>
<h2><b>Retailers Improve Demand Forecasting</b></h2>
<p>In the fast-paced retail environment, the ability to process and analyze data quickly is critical to adjusting inventory levels, personalizing customer interactions and optimizing pricing strategies on the fly. The larger a retailer is and the more products it carries, the more complex and compute-intensive its data operations will be.</p>
<p>Walmart, the largest retailer in the world, turned to accelerated computing to significantly improve forecasting accuracy for 500 million item-by-store combinations across 4,500 stores.</p>
<p>As Walmart‚Äôs data science team built more robust machine learning algorithms to take on this mammoth forecasting challenge, the existing computing environment began to falter, with jobs failing to complete or generating inaccurate results. The company found that data scientists were having to remove features from algorithms just so they would run to completion.</p>
<p>To improve its forecasting operations, <a href="https://blogs.nvidia.com/blog/walmart-nvidia/">Walmart started using NVIDIA GPUs and RAPIDs</a>. The company now uses a forecasting model with 350 data features to predict sales across all product categories. These features encompass sales data, promotional events, and external factors like weather conditions and major events like the Super Bowl, which influence demand.</p>
<p>Advanced models helped Walmart improve forecast accuracy from 94% to 97% while eliminating an estimated $100 million in fresh produce waste and reducing stockout and markdown scenarios. GPUs also ran models 100x faster with jobs complete in just four hours, an operation that would‚Äôve taken several weeks in a CPU environment.</p>
<p>By shifting data-intensive operations to GPUs and accelerated computing, retailers can lower both their cost and their carbon footprint while delivering best-fit choices and lower prices to shoppers.</p>
<h2><b>Public Sector Improves Disaster Preparedness¬†</b></h2>
<p>Drones and satellites capture huge amounts of aerial image data that public and private organizations use to predict weather patterns, track animal migrations and observe environmental changes. This data is invaluable for research and planning, enabling more informed decision-making in fields like agriculture, disaster management and efforts to combat climate change. However, the value of this imagery can be limited if it lacks specific location metadata.</p>
<p>A federal agency working with NVIDIA needed a way to automatically pinpoint the location of images missing geospatial metadata, which is essential for missions such as search and rescue, responding to natural disasters and monitoring the environment. However, identifying a small area within a larger region using an aerial image without metadata is extremely challenging, akin to locating a needle in a haystack. Algorithms designed to help with geolocation must address variations in image lighting and differences due to images being taken at various times, dates and angles.</p>
<p>To identify non-geotagged aerial images, NVIDIA, Booz Allen and the government agency collaborated on a solution that uses computer vision algorithms to extract information from image pixel data to scale the image similarity search problem.</p>
<p>When attempting to solve this problem, an NVIDIA solutions architect first used a Python-based application. Initially running on CPUs, processing took more than 24 hours. GPUs supercharged this to just minutes, performing thousands of data operations in parallel versus only a handful of operations on a CPU. By shifting the application code to CuPy, an open-sourced GPU-accelerated library, the application experienced a remarkable 1.8-million-x speedup, returning results in 67 microseconds.</p>
<p>With a solution that can process images and the data of large land masses in just minutes, organizations can gain access to the critical information needed to respond more quickly and effectively to emergencies and plan proactively, potentially saving lives and safeguarding the environment.</p>
<h2><b>Accelerate AI Initiatives and Deliver Business Results</b></h2>
<p>Companies using accelerated computing for data processing are advancing AI initiatives and positioning themselves to innovate and perform at higher levels than their peers.</p>
<p>Accelerated computing handles larger datasets more efficiently, enables faster model training and selection of optimal algorithms, and facilitates more precise results for live AI solutions.</p>
<p>Enterprises that use it can achieve superior price-performance ratios compared to traditional CPU-based systems and enhance their ability to deliver outstanding results and experiences to customers, employees and partners.</p>
<p><i>Learn how </i><a target="_blank" href="https://www.nvidia.com/en-us/data-center/solutions/accelerated-computing/"><i>accelerated computing</i></a><i> helps organizations achieve AI objectives and drive innovation.¬†</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/industries-corp-blog-data-processing-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/industries-corp-blog-data-processing-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Why Accelerated Data Processing Is Crucial for AI Innovation in Every Industry]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Here Comes a New Challenger: ‚ÄòStreet Fighter 6‚Äô Joins GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-street-fighter-6-xdefiant/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 06 Jun 2024 13:00:08 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72048</guid>

					<description><![CDATA[Capcom‚Äôs latest entry in the iconic Street Fighter series, Street Fighter 6, punches its way into the cloud this GFN Thursday. The game, along with Ubisoft‚Äôs XDefiant, leads six new games joining the GeForce NOW library. A new reward makes its way to the cloud gaming service‚Äôs Ultimate and Priority members. For a limited time,	<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-street-fighter-6-xdefiant/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Capcom‚Äôs latest entry in the iconic <i>Street Fighter</i> series, <i>Street Fighter 6</i>, punches its way into the cloud this GFN Thursday. The game, along with Ubisoft‚Äôs <i>XDefiant</i>, leads six new games joining the <a target="_blank" href="http://play.geforcenow.com">GeForce NOW library</a>.</p>
<p>A new reward makes its way to the cloud gaming service‚Äôs <a target="_blank" href="https://www.nvidia.com/en-us/geforce-now/memberships/">Ultimate and Priority members</a>. For a limited time, GeForce NOW members who are new to Xbox PC Game Pass can get three months of Microsoft‚Äôs subscription service free, just by opting into the <a target="_blank" href="https://www.nvidia.com/en-us/geforce-now/rewards/">GeForce NOW Rewards program</a>.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">A beautiful place to be <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/2764.png" alt="‚ù§" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <br />A Plague Tale Requiem ( please don&#39;t feed the rats if you see them ) on GeForce Now Ultimate <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f329.png" alt="üå©" class="wp-smiley" style="height: 1em; max-height: 1em;" /><img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f329.png" alt="üå©" class="wp-smiley" style="height: 1em; max-height: 1em;" /> ( <a target="_blank" href="https://twitter.com/NVIDIAGFN?ref_src=twsrc%5Etfw">@NVIDIAGFN</a> )</p>
<p><img src="https://s.w.org/images/core/emoji/15.0.3/72x72/2708.png" alt="‚úà" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a target="_blank" href="https://twitter.com/hashtag/GreetingsFromGFN?src=hash&amp;ref_src=twsrc%5Etfw">#GreetingsFromGFN</a> <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/2708.png" alt="‚úà" class="wp-smiley" style="height: 1em; max-height: 1em;" /><a target="_blank" href="https://twitter.com/hashtag/VirtualPhotography?src=hash&amp;ref_src=twsrc%5Etfw">#VirtualPhotography</a><a target="_blank" href="https://twitter.com/hashtag/VGPUnite?src=hash&amp;ref_src=twsrc%5Etfw">#VGPUnite</a> <a target="_blank" href="https://twitter.com/hashtag/VPRT?src=hash&amp;ref_src=twsrc%5Etfw">#VPRT</a> <a target="_blank" href="https://twitter.com/hashtag/GFNShare?src=hash&amp;ref_src=twsrc%5Etfw">#GFNShare</a> <a target="_blank" href="https://twitter.com/hashtag/GFNAmbassador?src=hash&amp;ref_src=twsrc%5Etfw">#GFNAmbassador</a> <a target="_blank" href="https://t.co/sYeBOyozRb">pic.twitter.com/sYeBOyozRb</a></p>
<p>&mdash; Giraphone (@giraph_1) <a target="_blank" href="https://twitter.com/giraph_1/status/1797913842753933325?ref_src=twsrc%5Etfw">June 4, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p>Plus, make sure to follow @NVIDIAGFN on X to see picturesque in-game locations from where members are sending their #GreetingsfromGFN.</p>
<h2><b>Get Ready to Rumble</b></h2>
<figure id="attachment_72052" aria-describedby="caption-attachment-72052" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-72052" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Street_Fighter_6-672x378.jpg" alt="Street Fighter 6 on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Street_Fighter_6-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Street_Fighter_6-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Street_Fighter_6-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Street_Fighter_6-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Street_Fighter_6-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Street_Fighter_6-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Street_Fighter_6-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Street_Fighter_6-1280x720.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Street_Fighter_6.jpg 1920w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72052" class="wp-caption-text"><em>Are Ryu ready?</em></figcaption></figure>
<p>Unleash the ultimate Hadoken with <i>Street Fighter 6</i> on GeForce NOW. The renowned 2D fighting game returns with intense battles, special moves, combos and Super Art attacks to defeat opponents. With a roster of 22 iconic fighters, including classic World Warriors like Ryu, Chun-Li, Guile and Akuma, plus all-new characters like Kimberly, Jamie, Marisa and Manon, there‚Äôs no better time to hit the streets.</p>
<p>The newest installment introduces innovative features and enhanced visuals across three distinct game modes ‚Äî Fighting Ground, World Tour and Battle Hub ‚Äî for gamers to level up and put their skills to the test. The game‚Äôs blend of classic mechanics and fresh enhancements is captivating longtime fans and newcomers alike.</p>
<p>Become a World Warrior in the cloud with a GeForce NOW Ultimate membership and stream all the fighting glory at up to stunning 4K resolution. Witness every punch, kick and Hadoken with others by hopping online for some head-to-head competition.</p>
<h2><b>Defying Gravity</b></h2>
<figure id="attachment_72056" aria-describedby="caption-attachment-72056" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-72056" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-XDefiant-672x336.jpg" alt="XDefiant on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-XDefiant-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-XDefiant-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-XDefiant-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-XDefiant-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-XDefiant-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-XDefiant-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-XDefiant-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-XDefiant-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-XDefiant.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72056" class="wp-caption-text"><em>Discover which faction will reign supreme in ‚ÄúXDefiant.‚Äù</em></figcaption></figure>
<p><i>XDefiant</i>, a free-to-play first-person shooter, combines intense gunplay with strategic team dynamics. Set in a world where factions inspired by iconic Ubisoft franchises clash, the game enables players to customize their loadouts and engage in fast-paced battles. Choose stealthy tactics or all-out aggression for a diverse and thrilling multiplayer experience.</p>
<p>Prepare for adrenaline-fueled firefights and tactical showdowns at up to 240 frames per second with an Ultimate membership. Every frame counts in the fight against other factions.</p>
<h2><b>Get in the Pass Lane</b></h2>
<figure id="attachment_72063" aria-describedby="caption-attachment-72063" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-72063" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-pc-game-pass-reward-tw-li-2048x1024-1-672x336.jpg" alt="PC Game Pass member reward on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-pc-game-pass-reward-tw-li-2048x1024-1-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-pc-game-pass-reward-tw-li-2048x1024-1-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-pc-game-pass-reward-tw-li-2048x1024-1-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-pc-game-pass-reward-tw-li-2048x1024-1-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-pc-game-pass-reward-tw-li-2048x1024-1-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-pc-game-pass-reward-tw-li-2048x1024-1-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-pc-game-pass-reward-tw-li-2048x1024-1-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-pc-game-pass-reward-tw-li-2048x1024-1-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-pc-game-pass-reward-tw-li-2048x1024-1.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72063" class="wp-caption-text"><em>It‚Äôs rewarding to be a GeForce NOW member.</em></figcaption></figure>
<p>Get ready for a summer of gaming. GeForce NOW Ultimate and Priority members new to PC Game Pass and part of the GeForce NOW Rewards program can now receive three free months of Microsoft‚Äôs service.</p>
<p>With PC Game Pass and GeForce NOW, members can play high-quality Xbox PC titles with the power of an <a target="_blank" href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA GeForce RTX</a> server in the cloud. Jump into the action in iconic franchises like <i>Starfield</i>, <i>Forza Motorsport</i> and <i>Remnant II</i> with support for more titles added every GFN Thursday.</p>
<p>This special offer is available for a limited time, and only for GeForce NOW members new to PC Game Pass.</p>
<h2><b>Mischief Managed</b></h2>
<figure id="attachment_72059" aria-describedby="caption-attachment-72059" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-72059" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sneak_Out-672x336.jpg" alt="Sneak out on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sneak_Out-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sneak_Out-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sneak_Out-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sneak_Out-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sneak_Out-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sneak_Out-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sneak_Out-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sneak_Out-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/06/GFN_Thursday-Sneak_Out.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-72059" class="wp-caption-text"><em>Hide and seek on an epic scale.</em></figcaption></figure>
<p>Get into all kinds of mischief and fun in <i>Sneak Out </i>from Kinguin Studios. Enter the Haunted Castle and prepare to hunt, hide or prank, causing all kinds of hilarious mayhem while trying to win a deadly game of hide and seek.</p>
<p>Check out the list of new games this week:</p>
<ul>
<li><i>Killer Klowns from Outer Space: The Game </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1556100?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, June 4)</li>
<li><i>Autopsy Simulator </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/1283230?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, June 6)</li>
<li><i>Chornobyl Liquidators</i> (New release on <a target="_blank" href="https://store.steampowered.com/app/1113010?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, June 6)</li>
<li><i>Sneak Out </i>(New release on <a target="_blank" href="https://store.steampowered.com/app/2410490?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, June 6)</li>
<li><i>Farm Together 2 </i>(<a target="_blank" href="https://store.steampowered.com/app/2418520?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Street Fighter 6</i> (<a target="_blank" href="https://store.steampowered.com/app/1364780?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>XDefiant</i> (Ubisoft)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a target="_blank" href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr"><img src="https://s.w.org/images/core/emoji/15.0.3/72x72/2b07.png" alt="‚¨á" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/2198.png" alt="‚Üò" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/27a1.png" alt="‚û°" class="wp-smiley" style="height: 1em; max-height: 1em;" />  + Punch</p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f329.png" alt="üå©" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a target="_blank" href="https://twitter.com/NVIDIAGFN/status/1798384284811542932?ref_src=twsrc%5Etfw">June 5, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-thursday-6-6-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/gfn-thursday-6-6-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Here Comes a New Challenger: ‚ÄòStreet Fighter 6‚Äô Joins GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Creativity Accelerated: New RTX-Powered AI Hardware and Software Announced at COMPUTEX</title>
		<link>https://blogs.nvidia.com/blog/rtx-ai-pc-studio-computex/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Wed, 05 Jun 2024 13:00:59 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[AI Decoded]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio Driver]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72029</guid>

					<description><![CDATA[NVIDIA launched NVIDIA Studio at COMPUTEX in 2019. Five years and more than 500 NVIDIA RTX-accelerated apps and games later, it‚Äôs bringing AI to even more creators with an array of new RTX technology integrations announced this week at COMPUTEX 2024.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>NVIDIA launched <a href="https://www.nvidia.com/en-us/studio/" target="_blank" rel="noopener">NVIDIA Studio</a> at COMPUTEX in 2019. Five years and more than 500 NVIDIA RTX-accelerated apps and games later, it‚Äôs bringing AI to even more creators with an array of new RTX technology integrations announced this week at COMPUTEX 2024.</p>
<p><iframe loading="lazy" title="Multiply Your AI Performance with NVIDIA GeForce RTX AI PCs" width="500" height="281" src="https://www.youtube.com/embed/vrkXR2ZjGGI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Newly announced <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/" target="_blank" rel="noopener">NVIDIA GeForce RTX</a> AI laptops ‚Äî including the ASUS ProArt PX13 and P16 and MSI Stealth 16 AI+ laptops ‚Äî will feature dedicated RTX Tensor Cores to accelerate AI performance and power-efficient systems-on-a-chip with Windows 11 AI PC features. They join over 200 laptops already accelerated with RTX AI technology.</p>
<p>NVIDIA RTX Video, a collection of technologies including <a href="https://blogs.nvidia.com/blog/rtx-video-super-resolution/" target="_blank" rel="noopener">RTX Video Super Resolution</a> and <a href="https://blogs.nvidia.com/blog/rtx-video-hdr-remix-studio-driver/" target="_blank" rel="noopener">RTX Video HDR</a> that enhance video content streamed in browsers like Google Chrome, Microsoft Edge and Mozilla Firefox, is coming to the free VLC Media Player. And for the first time in June, creators can enjoy these AI-enhanced video effects in popular creative apps like DaVinci Resolve and Wondershare Filmora.</p>
<p>DaVinci Resolve and Cyberlink PowerDirector are adding NVIDIA‚Äôs new H.265 Ultra-High-Quality (UHQ) mode, which uses the <a href="https://developer.nvidia.com/video-codec-sdk" target="_blank" rel="noopener">NVIDIA NVENC</a> to increase high-efficiency video coding (HEVC) and encoding efficiency by 10%.</p>
<p><a href="https://www.nvidia.com/en-us/geforce/rtx-remix/" target="_blank" rel="noopener">NVIDIA RTX Remix</a>, a modding platform for remastering classic games with RTX, will soon be made open source, allowing more modders to streamline how assets are replaced and scenes are relit. RTX Remix will also be made accessible via a new REST application programming interface (API) to connect the platform to other modding tools like Blender and Hammer.</p>
<p>Creative apps are continuing to adopt AI-powered <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/" target="_blank" rel="noopener">NVIDIA DLSS</a> for higher-quality ray-traced visuals in the viewport, with 3D modeling platform Womp being the latest to integrate DLSS 3.5 with Ray Reconstruction.</p>
<p>NVIDIA unveiled <a href="https://www.nvidia.com/en-us/geforce/news/g-assist-ai-assistant/" target="_blank" rel="noopener">Project G-Assist</a>, an RTX-powered AI-assistant technology demo that provides context-aware help for PC games and apps.</p>
<p>The new <a href="https://www.nvidia.com/en-us/geforce/news/nvidia-app-beta-update-av1-performance-tuning/" target="_blank" rel="noopener">NVIDIA app beta update</a> adds 120 frames per second AV1 video capture and one-click performance-tuning.</p>
<p>And the latest <a href="https://www.nvidia.com/en-us/geforce/game-ready-drivers/" target="_blank" rel="noopener">Game Ready Driver</a> and <a href="https://www.nvidia.com/en-us/studio/" target="_blank" rel="noopener">NVIDIA Studio Driver</a> are available for installation today.</p>
<h2><b>Video Gets the AI Treatment</b></h2>
<p><a href="https://blogs.nvidia.com/blog/rtx-video-hdr-remix-studio-driver/" target="_blank" rel="noopener">RTX Video</a> is a collection of real-time, AI-based video enhancements ‚Äî powered by RTX GPUs equipped with AI Tensor Cores ‚Äî to dramatically improve video quality.</p>
<p><iframe loading="lazy" title="Introducing RTX Video Super Resolution - 4K AI Upscaling for Chrome &amp; Edge Video" width="500" height="281" src="https://www.youtube.com/embed/XA-tQpQqD7U?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>It includes RTX Video Super Resolution ‚Äî an upscaling technology that removes compression artifacts and generates additional pixels to improve video sharpness and clarity up to 4K ‚Äî and RTX Video HDR, which transforms standard dynamic range videos into stunning high-dynamic range on HDR10 displays.</p>
<p><iframe loading="lazy" title="Introducing RTX Video HDR: AI-Upscale Video to HDR Quality" width="500" height="281" src="https://www.youtube.com/embed/FHAjydnpos8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>NVIDIA has released the <a href="https://developer.nvidia.com/rtx-video-sdk" target="_blank" rel="noopener">RTX Video software development kit</a>, which allows app developers to add RTX Video effects to creator workflows.</p>
<p>Blackmagic Design‚Äôs DaVinci Resolve, a powerful video editing app with color correction, visual effects,¬†graphics and audio post-production capabilities, will be one of the first to integrate RTX Video. The integration is being demoed on the COMPUTEX show floor.</p>
<p><iframe loading="lazy" title="Faster Video Editing in DaVinci Resolve with AI-Powered RTX Video Technology" width="500" height="281" src="https://www.youtube.com/embed/U7dYsgy7VDM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Wondershare Filmora, a video editing app with AI tools and pro-level social media video editing features, will support RTX Video HDR, coming soon.</p>
<figure id="attachment_72033" aria-describedby="caption-attachment-72033" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-hdr-side-by-side-1280w.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-72033" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-hdr-side-by-side-1280w-672x379.jpg" alt="" width="672" height="379" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-hdr-side-by-side-1280w-672x379.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-hdr-side-by-side-1280w-400x226.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-hdr-side-by-side-1280w-768x433.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-hdr-side-by-side-1280w-798x450.jpg 798w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-hdr-side-by-side-1280w-381x215.jpg 381w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-hdr-side-by-side-1280w-177x100.jpg 177w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-hdr-side-by-side-1280w.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-72033" class="wp-caption-text">Wondershare Filmora will soon support RTX Video HDR.</figcaption></figure>
<p>VLC Media Player ‚Äî an open-source, cross-platform media player, has added RTX Video HDR in its <a href="https://www.videolan.org/vlc/features.html" target="_blank" rel="noopener">latest beta release</a>, following its recently added support for <a href="https://blogs.nvidia.com/blog/ai-decoded-rtxvideo-firefox/" target="_blank" rel="noopener">Mozilla Firefox</a>.</p>
<figure id="attachment_72036" aria-describedby="caption-attachment-72036" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-perf-chart-1280w.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-72036" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-perf-chart-1280w-672x338.jpg" alt="" width="672" height="338" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-perf-chart-1280w-672x338.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-perf-chart-1280w-400x201.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-perf-chart-1280w-768x386.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-perf-chart-1280w-842x424.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-perf-chart-1280w-406x204.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-perf-chart-1280w-188x95.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-perf-chart-1280w.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-72036" class="wp-caption-text">NVIDIA hardware encoders deliver a generational boost in encoding efficiency to HEVC. Performance tested on dual Xeon Gold-6140@2.3GHz running NVIDIA L4 Tensor Core GPUs with driver 520.65.</figcaption></figure>
<p>NVIDIA also released a new UHQ mode in NVENC, a dedicated hardware encoder on RTX GPUs, for the HEVC video compression standard (also known as H.265). The new mode increases compression by 10% without diminishing quality, making NVENC HEVC 34% more efficient than the typically used x264 Medium compression standard.</p>
<p>DaVinci Resolve and Cyberlink PowerDirector video editing software will be adding support for the new UHQ mode in their next updates. Stay tuned for official launch dates.</p>
<h2>RTX Remix Open Sources Creator Toolkit</h2>
<p><a href="https://www.nvidia.com/en-us/geforce/rtx-remix/" target="_blank" rel="noopener">NVIDIA RTX Remix</a> allows modders to easily capture game assets, automatically enhance materials with generative AI tools and create stunning RTX remasters with full ray tracing.</p>
<p>RTX Remix open beta recently added DLSS 3.5 support featuring Ray Reconstruction, an AI model that creates higher-quality images for intensive ray-traced games and apps.</p>
<p>Later this month, NVIDIA will make the RTX Remix Toolkit open source, allowing more modders to streamline how assets are replaced and scenes are relit. The company is also increasing the supported file formats for RTX Remix‚Äôs asset ingestor and bolstering RTX Remix‚Äôs AI Texture Tools with new models.</p>
<figure id="attachment_72039" aria-describedby="caption-attachment-72039" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-rtx-remix-1280w.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-72039" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-rtx-remix-1280w-672x379.jpg" alt="" width="672" height="379" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-rtx-remix-1280w-672x379.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-rtx-remix-1280w-400x226.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-rtx-remix-1280w-768x433.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-rtx-remix-1280w-798x450.jpg 798w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-rtx-remix-1280w-381x215.jpg 381w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-rtx-remix-1280w-177x100.jpg 177w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-rtx-remix-1280w.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-72039" class="wp-caption-text">The RTX Remix toolkit is now completely open source.</figcaption></figure>
<p>NVIDIA is also making the capabilities of RTX Remix accessible via a new powerful REST API, allowing modders to livelink RTX Remix to other DCC tools such as Blender and modding tools such as Hammer. NVIDIA is also providing an SDK for the RTX Remix runtime to allow modders to deploy RTX Remix‚Äôs renderer into other applications and games beyond DirectX 8 and 9 classics.</p>
<h2><b>Catch Some Rays</b></h2>
<p><a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/" target="_blank" rel="noopener">NVIDIA DLSS</a> 3.5 with Ray Reconstruction enhances ray-traced image quality on NVIDIA RTX and GeForce RTX GPUs by replacing hand-tuned denoisers with an NVIDIA supercomputer-trained AI network that generates higher-quality pixels in between sampled rays.</p>
<p>Previewing content in the viewport, even with high-end hardware, can sometimes offer less-than-ideal image quality, as traditional denoisers require hand-tuning for every scene. With DLSS 3.5, the AI neural network recognizes a wide variety of scenes, producing high-quality preview images and drastically reducing time spent rendering.</p>
<p>The free browser-based 3D modeling platform <a href="https://beta.womp.com/discover?preview=777651" target="_blank" rel="noopener">Womp has added DLSS 3.5</a> to enhance interactive, photorealistic modeling in the viewport.</p>
<figure id="attachment_72067" aria-describedby="caption-attachment-72067" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-dlss2-1280w.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-72067" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-dlss2-1280w-672x255.jpg" alt="" width="672" height="255" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-dlss2-1280w-672x255.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-dlss2-1280w-400x152.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-dlss2-1280w-768x291.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-dlss2-1280w-842x319.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-dlss2-1280w-406x154.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-dlss2-1280w-188x71.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/06/studio-itns-rokaarh-wk112-dlss2-1280w.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-72067" class="wp-caption-text">DLSS 3.5 with Ray Reconstruction unlocks sharper visuals in the viewport.</figcaption></figure>
<p>Chaos Vantage and D5 Render, two popular professional-grade 3D apps that feature real-time preview modes with ray tracing, have also seen drastic performance increases with DLSS 3.5 ‚Äî up to a 60% boost from Ray Reconstruction and 4x from all DLSS technologies.</p>
<h2><b>Tools That Accelerate AI Apps</b></h2>
<p>The vast ecosystem of open-source AI models currently available are usually pretrained for general purposes and run in data centers.</p>
<p>To create more effective app-specific AI tools that run on local PCs, NVIDIA has introduced the RTX AI Toolkit ‚Äî an end-to-end workflow for the customization, optimization and deployment of AI models on RTX AI PCs.</p>
<p>Partners such as Adobe, Topaz and Blackmagic Design are integrating RTX AI Toolkit within their popular creative apps to accelerate AI performance on RTX PCs.</p>
<p>Developers can learn more on the <a href="https://developer.nvidia.com/blog/streamline-ai-powered-app-development-with-nvidia-rtx-ai-toolkit-for-windows-rtx-pcs/" target="_blank" rel="noopener">NVIDIA Technical Blog</a>.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/computex-2024-nv-blog-header-preview-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/computex-2024-nv-blog-header-preview-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Creativity Accelerated: New RTX-Powered AI Hardware and Software Announced at COMPUTEX]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Yotta CEO Sunil Gupta on Supercharging India‚Äôs Fast-Growing AI Market</title>
		<link>https://blogs.nvidia.com/blog/yotta-ceo-supercharging-indias-ai-market/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Wed, 05 Jun 2024 13:00:51 +0000</pubDate>
				<category><![CDATA[The AI Podcast]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=72028</guid>

					<description><![CDATA[India‚Äôs AI market is expected to be massive. Yotta Data Services is setting its sights on supercharging it. In this episode of NVIDIA‚Äôs AI Podcast, Sunil Gupta, cofounder, managing director and CEO of Yotta Data Services, speaks with host Noah Kravitz about the company‚Äôs Shakti Cloud offering, which provides scalable GPU services for enterprises of	<a class="read-more" href="https://blogs.nvidia.com/blog/yotta-ceo-supercharging-indias-ai-market/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>India‚Äôs AI market is expected to be massive. Yotta Data Services is setting its sights on supercharging it. In this episode of NVIDIA‚Äôs <a href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">AI Podcast</a>, Sunil Gupta, cofounder, managing director and CEO of Yotta Data Services, speaks with host Noah Kravitz about the company‚Äôs Shakti Cloud offering, which provides scalable GPU services for enterprises of all sizes. Yotta is the first Indian cloud services provider in the <a href="https://www.nvidia.com/en-us/about-nvidia/partners/" target="_blank" rel="noopener">NVIDIA Partner Network</a>, and its Shakti Cloud is India‚Äôs fastest AI supercomputing infrastructure, with 16 exaflops of compute capacity supported by over 16,000 <a href="https://www.nvidia.com/en-us/data-center/h100/" target="_blank" rel="noopener">NVIDIA H100 Tensor Core GPUs</a>. Tune in to hear Gupta‚Äôs insights on India‚Äôs potential as a major AI market and how to balance data center growth with sustainability and <a href="https://www.nvidia.com/en-us/glossary/energy-efficiency/#:~:text=Energy%20efficiency%20refers%20to%20a,or%20function%20within%20acceptable%20limits." target="_blank" rel="noopener">energy efficiency</a>.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1837778895%3Fsecret_token%3Ds-gJGZMXVJTxc&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> ¬∑ <a style="color: #cccccc; text-decoration: none;" title="Yotta CEO Sunil Gupta on Supercharging India‚Äôs Fast-Growing AI Market - Ep. 225" href="https://soundcloud.com/theaipodcast/yotta-ceo-sunil-gupta/s-gJGZMXVJTxc" target="_blank" rel="noopener">Yotta CEO Sunil Gupta on Supercharging India‚Äôs Fast-Growing AI Market &#8211; Ep. 225</a></div>
<p>Stay tuned for more AI Podcast episodes recorded live from GTC.</p>
<h2><b>Time Stamps</b></h2>
<p>1:18: Background on Yotta<br />
2:58: What is Shakti Cloud?<br />
6:44: What does Shakti Cloud mean for India‚Äôs tech sector?<br />
10:36: The self-service, scalable capabilities of Shakti Cloud<br />
19:48: Balancing data center growth with sustainability<br />
24:35: Yotta‚Äôs work with NVIDIA<br />
27:48: What‚Äôs next for Yotta?</p>
<h2><b>You Might Also Like‚Ä¶</b></h2>
<p><a href="https://soundcloud.com/theaipodcast/arthur-adam-wenchel" target="_blank" rel="noopener"><b>Performance AI: Insights From Arthur‚Äôs Adam Wenchel &#8211; Ep. 221</b></a></p>
<p>In this episode of the NVIDIA AI Podcast, recorded live at the GTC 2024, host Noah Kravitz sits down with Adam Wenchel, co-founder and CEO of Arthur, about the company‚Äôs technology, which enhances the performance of AI systems across various metrics like accuracy, explainability and fairness.</p>
<p><a href="https://soundcloud.com/theaipodcast/ai-alan-chalker" target="_blank" rel="noopener"><b>How the Ohio Supercomputing Center Drives the Future of Computing &#8211; Ep. 213</b><b><br />
</b><br />
</a>NASCAR races are all about speed, but even the fastest cars need to factor in safety, especially as rules and tracks change. The Ohio Supercomputer Center is ready to help. In this episode of NVIDIA‚Äôs AI Podcast, host Noah Kravitz speaks with Alan Chalker, the director of strategic programs at the OSC, about all things supercomputing.</p>
<p><a href="https://soundcloud.com/theaipodcast/replit-ceo-amjad-masad" target="_blank" rel="noopener"><b>Replit CEO Amjad Masad on Empowering the Next Billion Software Creators &#8211; Ep. 201</b></a></p>
<p>Replit aims to empower the next billion software creators. In this week‚Äôs episode of NVIDIA‚Äôs AI Podcast, host Noah Kraviz dives into a conversation with Replit CEO Amjad Masad about bridging the gap between ideas and software, a task simplified by advances in generative AI.</p>
<p><a href="https://soundcloud.com/theaipodcast/renderedai" target="_blank" rel="noopener"><b>Rendered.ai CEO Nathan Kundtz on Using AI to Build Better AI &#8211; Ep. 177</b></a></p>
<p>Data is the fuel that makes artificial intelligence run. Training machine learning and AI systems requires data, but compiling quality real-world data for AI and ML can be difficult and expensive. That‚Äôs where synthetic data comes in. In this episode of NVIDIA‚Äôs AI Podcast, Nathan Kundtz, founder and CEO of Rendered.ai, speaks with host Noah Kravtiz about a platform as a service for creating synthetic data to train AI models.</p>
<h2><b>Subscribe to the AI Podcast</b></h2>
<p>Get the<a href="https://blogs.nvidia.com/ai-podcast/" target="_blank" rel="noopener"> AI Podcast</a> through<a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439" target="_blank" rel="noopener"> iTunes</a>,<a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm" target="_blank" rel="noopener"> Google Play</a>, <a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast" target="_blank" rel="noopener">Amazon Music, </a><a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us" target="_blank" rel="noopener">Castbox</a>, DoggCatcher, <a href="https://overcast.fm/itunes1186480811/the-ai-podcast" target="_blank" rel="noopener">Overcast</a>, <a href="https://player.fm/series/the-ai-podcast" target="_blank" rel="noopener">PlayerFM</a>, Pocket Casts, <a href="http://www.podbay.fm/show/1186480811" target="_blank" rel="noopener">Podbay</a>,<a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast" target="_blank" rel="noopener"> PodBean</a>, PodCruncher, PodKicker, <a href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">Soundcloud</a>, <a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L" target="_blank" rel="noopener">Spotify</a>, <a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr" target="_blank" rel="noopener">Stitcher</a> and <a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/" target="_blank" rel="noopener">TuneIn</a>.</p>
<p>Make the AI Podcast better: Have a few minutes to spare? Fill out <a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short" target="_blank" rel="noopener">this listener survey</a>.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2021/08/ai-podcast-2600x1472_-1-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1159"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2021/08/ai-podcast-2600x1472_-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Yotta CEO Sunil Gupta on Supercharging India‚Äôs Fast-Growing AI Market]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
	</channel>
</rss>
