<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Fri, 22 Mar 2024 16:15:15 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.4.3</generator>
	<item>
		<title>AI’s New Frontier: From Daydreams to Digital Deeds</title>
		<link>https://blogs.nvidia.com/blog/chat-catanzaro-qiu/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Thu, 21 Mar 2024 23:00:05 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70702</guid>

					<description><![CDATA[Imagine a world where you can whisper your digital wishes into your device, and poof, it happens. That world may be coming sooner than you think. But if you’re worried about AI doing your thinking for you, you might be waiting for a while. In a fireside chat Wednesday at NVIDIA GTC, the global AI		<a class="read-more" href="https://blogs.nvidia.com/blog/chat-catanzaro-qiu/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Imagine a world where you can whisper your digital wishes into your device, and poof, it happens.</p>
<p>That world may be coming sooner than you think. But if you’re worried about AI doing your thinking for you, you might be waiting for a while.</p>
<p>In a fireside chat Wednesday at <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>, the global AI conference, Kanjun Qiu, CEO of Imbue, and Bryan Catanzaro, vice president of applied deep learning research at NVIDIA, challenged many of the clichés that have long dominated conversations about AI.</p>
<p>Launched in October 2022, Imbue made headlines with its Series B fundraiser last year, raising over $200 million at a $1 billion valuation.</p>
<p><b>Bridging the Gap Between ‘Idea and Execution’</b><b><br />
</b><br />
The discussion highlighted not only Imbue’s approach toward building practical AI agents able to automate menial, unrewarding work, but also painted a vivid picture of what the next chapter in AI innovation might hold.</p>
<p>“Our lives are full of so much friction &#8230; every single person’s vision can come to life,” Qiu said. “The barrier between idea and execution can be much smaller.”</p>
<p>Catanzaro’s reflections on the practical difficulties of using AI for simple tasks, such as his own challenges trying to get his digital assistant to help him find his next meeting, underscored the current limitations in human-AI interaction.</p>
<p>It turns out that figuring out where and when to go to a meeting, while easy for a human assistant, isn’t easy to automate.</p>
<p>“We tend to underestimate the things that we do naturally and overestimate the things that require reasoning,” Catanzaro observed. “One of the things humans deal with well is ambiguity.”</p>
<p>This set the stage for a broader discussion of the need for AI to move beyond mere code generation and become a dynamic, intuitive interface between humans and computers.</p>
<p>Qiu said the idea that AI can be a magical assistant, one that knows everything about you “isn’t necessarily the right paradigm.”</p>
<p>That’s because delegation is hard.</p>
<p>“When I’m delegating something, even to a human, I have to think a lot about ‘okay, how can I package this up so that the person will do the right thing?’”</p>
<p>Instead, the better model might be telling your computer to do anything you want. So you’re “telling your computer to do stuff and the agent is a middle layer,” she said.</p>
<p>Such agents will need to be able to interact with people — something often described as “reasoning,” the two observed — and communicate with computers — or “code.”</p>
<p><b>A Vision for Empowerment Through Technology</b></p>
<p>Qiu and Catanzaro — who often completed each other’s sentences during the 45-minute conversation — compared AI’s potential to democratize software creation to the Industrial Revolution’s impact on manufacturing.</p>
<p>The parts needed for a steam engine, for example, once took years to create. Now they can be ordered off the shelf for a small sum.</p>
<p>Both speakers emphasized the importance of creating intuitive interfaces that allow individuals from nontechnical backgrounds to engage with computers more effectively, fostering a more inclusive digital landscape.</p>
<p>That means going beyond coding, which is done in text-heavy environments such as an Integrated Development Environment, or even using text-based chats.</p>
<p>“The interface to agents, a lot of them today, is like a chat interface. It’s not a very good interface, in a lot of ways, very restrictive. And so there are much better ways of working with these systems,” Qiu said.</p>
<p><b>The Future of Personal Computing</b></p>
<p>Qiu and Catanzaro discussed the role that virtual worlds will play in this, and how they could serve as interfaces for human-technology interaction.</p>
<p>“I think it’s pretty clear that AI is going to help build virtual worlds,” said Catanzaro. “I think the maybe more controversial part is virtual worlds are going to be necessary for humans to interact with AI.”</p>
<p>People have an almost primal fear of being displaced, Catanzaro said, but what’s much more likely is that our capabilities will be amplified as the technology fades into the background.</p>
<p>Catanzaro compared it to the adoption of electricity. A century ago, people talked a lot about electricity. Now that it’s ubiquitous, it’s no longer the focus of broader conversations, even as it makes our day-to-day lives better.</p>
<p>“I think of it as really being able to [help us] control information environments &#8230; once we have control over information environments, we’ll feel a lot more empowered,” Qiu said. “Every single person’s vision can come to life.”</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/FiresideChat-KanjunQiu-BryanCatanzaro-2603-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1365"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/FiresideChat-KanjunQiu-BryanCatanzaro-2603-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI’s New Frontier: From Daydreams to Digital Deeds]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Here Be Dragons: ‘Dragon’s Dogma 2’ Comes to GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-dragons-dogma-2/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 21 Mar 2024 13:00:58 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70674</guid>

					<description><![CDATA[Arise for a new adventure with Dragon’s Dogma 2, leading two new titles joining the GeForce NOW library this week. Set Forth, Arisen Time to go on a grand adventure, Arisen! Dragon’s Dogma 2, the long-awaited sequel to Capcom’s legendary action role-playing game, streams this week on GeForce NOW. The game challenges players to choose		<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-dragons-dogma-2/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Arise for a new adventure with <i>Dragon’s Dogma 2</i>, leading two new titles joining the <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> library this week.</p>
<h2><b>Set Forth, Arisen</b></h2>
<figure id="attachment_70678" aria-describedby="caption-attachment-70678" style="width: 672px" class="wp-caption aligncenter"><img fetchpriority="high" decoding="async" class="size-large wp-image-70678" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-672x378.jpg" alt="Dragon's Dogma 2" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70678" class="wp-caption-text"><em>Fulfill a forgotten destiny in “Dragon’s Dogma 2” from Capcom.</em></figcaption></figure>
<p>Time to go on a grand adventure, Arisen!</p>
<p><i>Dragon’s Dogma 2</i>, the long-awaited sequel to Capcom’s legendary action role-playing game, streams this week on GeForce NOW.</p>
<p>The game challenges players to choose their own experience, including their Arisen’s appearance, vocation, party, approaches to different situations and more. Wield swords, bows and magick across an immersive fantasy world full of life and battle. But players won’t be alone. Recruit Pawns — mysterious otherworldly beings — to aid in battle and work with other players’ Pawns to fight the diverse monsters inhabiting the ever-changing lands.</p>
<p>Upgrade to a GeForce NOW Ultimate membership to stream <i>Dragon’s Dogma 2</i> from NVIDIA GeForce RTX 4080 servers in the cloud for the highest performance, even on low-powered devices. Ultimate members also get exclusive access to servers to get right into gaming without waiting for any downloads.</p>
<h2><b>New Games, New Challenges</b></h2>
<figure id="attachment_70681" aria-describedby="caption-attachment-70681" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" class="size-large wp-image-70681" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-672x336.jpg" alt="Battlefield 2042 S7 on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70681" class="wp-caption-text"><em>No holding back.</em></figcaption></figure>
<p><i>Battlefield 2042: Season 7 </i>Turning Point is here. Do whatever it takes to battle for Earth’s most valuable resource — water — in a Chilean desert. Deploy on a new map, Haven, focused on suburban combat, and revisit a fan-favorite front: Stadium. Gear up with new hardware like the SCZ-3 SMG or the Predator SRAW, and jump into a battle for ultimate power.</p>
<p>Then, look forward to the following list of games this week:</p>
<ul>
<li><i>Alone in the Dark </i>(New release on <a href="https://store.steampowered.com/app/1310410?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, March 20)</li>
<li><i>Dragon’s Dogma 2 </i>(New release on <a href="https://store.steampowered.com/app/2054970?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, March 21)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">we got that 𝙙𝙤𝙜 in us</p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1770480417872744761?ref_src=twsrc%5Etfw">March 20, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/gfn-thursday-3-21-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/gfn-thursday-3-21-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Here Be Dragons: ‘Dragon’s Dogma 2’ Comes to GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Instant Latte: NVIDIA Gen AI Research Brews 3D Shapes in Under a Second</title>
		<link>https://blogs.nvidia.com/blog/latte-3d-generative-ai-research/</link>
		
		<dc:creator><![CDATA[Isha Salian]]></dc:creator>
		<pubDate>Thu, 21 Mar 2024 13:00:51 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[NVIDIA Research]]></category>
		<category><![CDATA[Synthetic Data Generation]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70638</guid>

					<description><![CDATA[NVIDIA researchers have pumped a double shot of acceleration into their latest text-to-3D generative AI model, dubbed LATTE3D. Like a virtual 3D printer, LATTE3D turns text prompts into 3D representations of objects and animals within a second. Crafted in a popular format used for standard rendering applications, the generated shapes can be easily served up		<a class="read-more" href="https://blogs.nvidia.com/blog/latte-3d-generative-ai-research/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>NVIDIA researchers have pumped a double shot of acceleration into their latest text-to-3D <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> model, dubbed LATTE3D.</p>
<p>Like a virtual 3D printer, <a href="https://research.nvidia.com/labs/toronto-ai/LATTE3D/">LATTE3D</a> turns text prompts into 3D representations of objects and animals within a second.</p>
<p>Crafted in a popular format used for standard rendering applications, the generated shapes can be easily served up in virtual environments for developing video games, ad campaigns, design projects or virtual training grounds for robotics.</p>
<p>“A year ago, it took an hour for AI models to generate 3D visuals of this quality — and the current state of the art is now around 10 to 12 seconds,” said Sanja Fidler, vice president of AI research at NVIDIA, whose Toronto-based AI lab team developed LATTE3D. “We can now produce results an order of magnitude faster, putting near-real-time text-to-3D generation within reach for creators across industries.”</p>
<p>This advancement means that LATTE3D can produce 3D shapes near instantly when running inference on a single GPU, such as the <a href="https://www.nvidia.com/en-us/design-visualization/rtx-a6000/">NVIDIA RTX A6000</a>, which was used for the NVIDIA Research demo.</p>
<p><iframe title="LATTE3D Text to 3D Generative AI Model from NVIDIA Research" width="500" height="281" src="https://www.youtube.com/embed/yZtSS3980z4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Ideate, Generate, Iterate: Shortening the Cycle</b></h2>
<p>Instead of starting a design from scratch or combing through a 3D asset library, a creator could use LATTE3D to generate detailed objects as quickly as ideas pop into their head.</p>
<p>The model generates a few different 3D shape options based on each text prompt, giving a creator options. Selected objects can be optimized for higher quality within a few minutes. Then, users can export the shape into graphics software applications or platforms such as <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, which enables <a href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description (OpenUSD)</a>-based 3D workflows and applications.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-70649" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-scaled.jpg" alt="" width="2048" height="2048" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-400x400.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-500x500.jpg 500w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-768x768.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-1536x1536.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-450x450.jpg 450w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-215x215.jpg 215w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-1280x1280.jpg 1280w" sizes="(max-width: 2048px) 100vw, 2048px" /></p>
<p>While the researchers trained LATTE3D on two specific datasets — animals and everyday objects — developers could use the same model architecture to train the AI on other data types.</p>
<p>If trained on a dataset of 3D plants, for example, a version of LATTE3D could help a landscape designer quickly fill out a garden rendering with trees, flowering bushes and succulents while brainstorming with a client. If trained on household objects, the model could generate items to fill in 3D simulations of homes, which developers could use to train personal assistant robots before they’re tested and deployed in the real world.</p>
<p>LATTE3D was trained using <a href="https://www.nvidia.com/en-us/data-center/a100/">NVIDIA A100 Tensor Core GPUs</a>. In addition to 3D shapes, the model was trained on diverse text prompts generated using ChatGPT to improve the model’s ability to handle the various phrases a user might come up with to describe a particular 3D object — for example, understanding that prompts featuring various canine species should all generate doglike shapes.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-70646" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs.jpg" alt="" width="1999" height="426" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs.jpg 1999w, https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs-400x85.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs-672x143.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs-768x164.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs-1536x327.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs-842x179.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs-406x87.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs-188x40.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs-1280x273.jpg 1280w" sizes="(max-width: 1999px) 100vw, 1999px" /></p>
<p><a href="https://www.nvidia.com/en-us/research/">NVIDIA Research</a> comprises hundreds of scientists and engineers worldwide, with teams focused on topics including AI, computer graphics, computer vision, self-driving cars and robotics.</p>
<p>Researchers shared work at <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a> this week that advances the state of the art for training diffusion models. Read more <a href="https://developer.nvidia.com/blog/rethinking-how-to-train-diffusion-models/">on the NVIDIA Technical Blog</a>, and see the full list of <a href="https://www.nvidia.com/gtc/sessions/ai-research--thought-leadership/">NVIDIA Research sessions at GTC</a>, running in San Jose, Calif., and online through March 21.</p>
<p><i>For the latest NVIDIA AI news, watch the replay of NVIDIA founder and CEO Jensen Huang’s keynote address at GTC: </i></p>
<p><iframe loading="lazy" title="GTC March 2024 Keynote with NVIDIA CEO Jensen Huang" width="500" height="281" src="https://www.youtube.com/embed/Y2F8yisiS6E?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/Latte3D_turtle_side_by_side.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/Latte3D_turtle_side_by_side-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Instant Latte: NVIDIA Gen AI Research Brews 3D Shapes in Under a Second]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>‘You Transformed the World,’ NVIDIA CEO Tells Researchers Behind Landmark AI Paper</title>
		<link>https://blogs.nvidia.com/blog/gtc-2024-transformer-ai-research-panel-jensen/</link>
		
		<dc:creator><![CDATA[Isha Salian]]></dc:creator>
		<pubDate>Thu, 21 Mar 2024 13:00:45 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70685</guid>

					<description><![CDATA[Of GTC’s 900+ sessions, the most wildly popular was a conversation hosted by NVIDIA founder and CEO Jensen Huang with seven of the authors of the legendary research paper that introduced the aptly named transformer — a neural network architecture that went on to change the deep learning landscape and enable today’s era of generative		<a class="read-more" href="https://blogs.nvidia.com/blog/gtc-2024-transformer-ai-research-panel-jensen/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Of <a href="https://www.nvidia.com/gtc/">GTC</a>’s 900+ sessions, the most wildly popular was a conversation hosted by NVIDIA founder and CEO Jensen Huang with seven of the authors of the legendary research paper that introduced the aptly named <a href="https://blogs.nvidia.com/blog/what-is-a-transformer-model/">transformer</a> — a neural network architecture that went on to change the deep learning landscape and enable today’s era of generative AI.</p>
<p>“Everything that we’re enjoying today can be traced back to that moment,” Huang said to a packed room with hundreds of attendees, who heard him speak with the authors of “<a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention Is All You Need</a>.”</p>
<p>Sharing the stage for the first time, the research luminaries reflected on the factors that led to their original paper, which has been cited more than 100,000 times since it was first published and presented at the NeurIPS AI conference. They also discussed their latest projects and offered insights into future directions for the field of generative AI.</p>
<p>While they started as Google researchers, the collaborators are now spread across the industry, most as founders of their own AI companies.</p>
<p>“We have a whole industry that is grateful for the work that you guys did,” Huang said.</p>
<figure id="attachment_70689" aria-describedby="caption-attachment-70689" style="width: 2048px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-full wp-image-70689" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-scaled.jpg" alt="" width="2048" height="1365" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-1280x853.jpg 1280w" sizes="(max-width: 2048px) 100vw, 2048px" /><figcaption id="caption-attachment-70689" class="wp-caption-text">From L to R: Lukasz Kaiser, Noam Shazeer, Aidan Gomez, Jensen Huang, Llion Jones, Jakob Uszkoreit, Ashish Vaswani and Illia Polosukhin.</figcaption></figure>
<h2><b>Origins of the Transformer Model</b></h2>
<p>The research team initially sought to overcome the limitations of <a href="https://blogs.nvidia.com/blog/whats-the-difference-between-a-cnn-and-an-rnn/">recurrent neural networks</a>, or RNNs, which were then the state of the art for processing language data.</p>
<p>Noam Shazeer, cofounder and CEO of Character.AI, compared RNNs to the steam engine and transformers to the improved efficiency of internal combustion.</p>
<p>“We could have done the industrial revolution on the steam engine, but it would just have been a pain,” he said. “Things went way, way better with internal combustion.”</p>
<p>“Now we’re just waiting for the fusion,” quipped Illia Polosukhin, cofounder of blockchain company NEAR Protocol.</p>
<p>The paper’s title came from a realization that attention mechanisms — an element of neural networks that enable them to determine the relationship between different parts of input data — were the most critical component of their model’s performance.</p>
<p>“We had very recently started throwing bits of the model away, just to see how much worse it would get. And to our surprise it started getting better,” said Llion Jones, cofounder and chief technology officer at Sakana AI.</p>
<p>Having a name as general as “transformers” spoke to the team’s ambitions to build AI models that could process and transform every data type — including text, images, audio, tensors and biological data.</p>
<p>“That North Star, it was there on day zero, and so it’s been really exciting and gratifying to watch that come to fruition,” said Aidan Gomez, cofounder and CEO of Cohere. “We’re actually seeing it happen now.”</p>
<figure id="attachment_70692" aria-describedby="caption-attachment-70692" style="width: 2048px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-full wp-image-70692" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-scaled.jpg" alt="" width="2048" height="1365" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-1280x853.jpg 1280w" sizes="(max-width: 2048px) 100vw, 2048px" /><figcaption id="caption-attachment-70692" class="wp-caption-text">Packed house at the San Jose Convention Center.</figcaption></figure>
<h2><b>Envisioning the Road Ahead </b></h2>
<p>Adaptive computation, where a model adjusts how much computing power is used based on the complexity of a given problem, is a key factor the researchers see improving in future AI models.</p>
<p>“It’s really about spending the right amount of effort and ultimately energy on a given problem,” said Jakob Uszkoreit, cofounder and CEO of biological software company Inceptive. “You don’t want to spend too much on a problem that’s easy or too little on a problem that’s hard.”</p>
<p>A math problem like two plus two, for example, shouldn’t be run through a trillion-parameter transformer model — it should run on a basic calculator, the group agreed.</p>
<p>They’re also looking forward to the next generation of AI models.</p>
<p>“I think the world needs something better than the transformer,” said Gomez. “I think all of us here hope it gets succeeded by something that will carry us to a new plateau of performance.”</p>
<p>“You don’t want to miss these next 10 years,” Huang said. “Unbelievable new capabilities will be invented.”</p>
<p>The conversation concluded with Huang presenting each researcher with a framed cover plate of the <a href="https://www.nvidia.com/en-gb/data-center/dgx-systems/dgx-1/">NVIDIA DGX-1</a> AI supercomputer, signed with the message, “You transformed the world.”</p>
<figure id="attachment_70695" aria-describedby="caption-attachment-70695" style="width: 2048px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-70695 size-full" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-scaled.jpg" alt="" width="2048" height="1365" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-1280x853.jpg 1280w" sizes="(max-width: 2048px) 100vw, 2048px" /><figcaption id="caption-attachment-70695" class="wp-caption-text">Jensen presents lead author Ashish Vaswani with a signed DGX-1 cover.</figcaption></figure>
<p>There’s still time to catch the <a href="https://www.nvidia.com/gtc/session-catalog/?search=S63046&amp;tab.allsessions=1700692987788001F1cG">session replay</a> by registering for a <a href="https://www.nvidia.com/gtc/pricing/">virtual GTC pass</a> — it’s free.</p>
<p>To discover the latest in generative AI, watch Huang’s GTC keynote address:</p>
<p><iframe loading="lazy" title="GTC March 2024 Keynote with NVIDIA CEO Jensen Huang" width="500" height="281" src="https://www.youtube.com/embed/Y2F8yisiS6E?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6747_blogcrop.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6747_blogcrop-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[‘You Transformed the World,’ NVIDIA CEO Tells Researchers Behind Landmark AI Paper]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI Decoded From GTC: The Latest Developer Tools and Apps Accelerating AI on PC and Workstation</title>
		<link>https://blogs.nvidia.com/blog/ai-decoded-gtc-chatrtx-workbench-nim/</link>
		
		<dc:creator><![CDATA[Jesse Clayton]]></dc:creator>
		<pubDate>Wed, 20 Mar 2024 13:00:02 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[AI Decoded]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[RTX Mobile Workstations]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70653</guid>

					<description><![CDATA[NVIDIA’s RTX AI platform includes tools and software development kits that help Windows developers create cutting-edge generative AI features to deliver the best performance on AI PCs and workstations.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of the </i><a href="https://blogs.nvidia.com/blog/tag/ai-decoded/"><i>AI Decoded series</i></a><i>, which demystifies AI by making the technology more accessible, and which showcases new hardware, software, tools and accelerations for RTX PC users.</i></p>
<p>NVIDIA’s RTX AI platform includes tools and software development kits that help Windows developers create cutting-edge generative AI features to deliver the best performance on AI PCs and workstations.</p>
<p>At GTC — NVIDIA’s annual technology conference — a dream team of industry luminaries, developers and researchers have come together to learn from one another, fueling what’s next in AI and accelerated computing.</p>
<p>This special edition of AI Decoded from GTC spotlights the best AI tools currently available and looks at what’s ahead for the 100 million RTX PC and workstation users and developers.</p>
<p><a href="https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/">Chat with RTX</a>, the tech demo and developer reference project that quickly and easily allows users to connect a powerful LLM to their own data, showcased new capabilities and new models in the GTC exhibit hall.</p>
<p>The winners of the <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/rtx-developer-contest/">Gen AI on RTX PCs contest</a> were announced Monday. OutlookLLM, Rocket League BotChat and CLARA were highlighted in one of the AI Decoded talks in the <a href="https://www.nvidia.com/gtc/exhibits/#:~:text=Generative%20AI%20Theater">generative AI theater</a> and each are accelerated by <a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-supercharges-large-language-model-inference-on-nvidia-h100-gpus/">NVIDIA TensorRT-LLM</a>. Two other AI Decoded talks included using generative AI in content creation and a deep dive on Chat with RTX.</p>
<p>Developer frameworks and interfaces with TensorRT-LLM integration continue to grow as Jan.ai, Langchain, LlamaIndex and Oobabooga will all soon be accelerated — helping to grow the already more than 500 AI applications for RTX PCs and workstations.</p>
<p>NVIDIA NIM microservices are coming to RTX PCs and workstations. They provide pre-built containers, with industry standard APIs, enabling developers to accelerate deployment on RTX PCs and workstations. <a href="https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/workbench/">NVIDIA AI Workbench</a>, an easy-to-use developer toolkit to manage AI model customization and optimization workflows, is now generally available for RTX developers.</p>
<p>These ecosystem integrations and tools will accelerate development of new Windows apps and features. And today’s contest winners are an inspiring glimpse into what that content will look like.</p>
<h2><b>Hear More, See More, Chat More</b></h2>
<p>Chat with RTX, or ChatRTX for short, uses <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">retrieval-augmented generation</a>, NVIDIA TensorRT-LLM software and NVIDIA RTX acceleration to bring local generative AI capabilities to RTX-powered Windows systems. Users can quickly and easily connect local files as a dataset to an open large language model like Mistral or Llama 2, enabling queries for quick, contextually relevant answers.</p>
<p><iframe loading="lazy" title="Create A Personalized AI Chatbot with ChatRTX" width="500" height="281" src="https://www.youtube.com/embed/fc_NSAu41b0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Moving beyond text, ChatRTX will soon add support for voice, images and new models.</p>
<p>Users will be able to talk to ChatRTX with Whisper — an automatic speech recognition system that uses AI to process spoken language. When the feature becomes available, ChatRTX will be able to “understand” spoken language, and provide text responses.</p>
<p>A future update will also add support for photos. By integrating OpenAI’s CLIP — Contrastive Language-Image Pre-training — users will be able to search by words, terms or phrases to find photos in their private library.</p>
<p>In addition to Google’s Gemma, ChatGLM will get support in a future update.</p>
<p>Developers can start with the latest version of the <a href="https://github.com/NVIDIA/trt-llm-rag-windows">developer reference project on GitHub</a>.</p>
<h2><b>Generative AI for the Win</b></h2>
<p>The <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/rtx-developer-contest/">NVIDIA Generative AI on NVIDIA RTX developer contest</a> prompted developers to build a Windows app or plug-in.</p>
<div class="simplePullQuote right"><p>“I found that playing against bots that react to game events with in-game messages in near real time adds a new level of entertainment to the game, and I’m excited to share my approach to incorporating AI into gaming as a participant in this developer contest. The target audience for my project is anyone who plays <i>Rocket League</i> with RTX hardware.” — <a href="https://briancaffey.github.io/2024/02/17/rocket-league-botchat-nvidia-generative-ai-on-rtx-pcs-developer-contest/">Brian Caffey</a>, Rocket League BotChat developer</p>
</div>
<p>Submissions were judged on three criteria, including a short demo video posted to social media, relative impact and ease of use of the project, and how effectively NVIDIA’s technology stack was used in the project. <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/rtx-developer-contest/winners/">Each of the three winners</a> received a pass to GTC, including a spot in the NVIDIA Deep Learning Institute GenAI/LLM courses, and a GeForce RTX 4090 GPU to power future development work.</p>
<p><a href="https://github.com/fgblanch/OutlookLLM">OutlookLLM</a> gives Outlook users generative AI features — such as email composition — securely and privately in their email client on RTX PCs and workstations. It uses a local LLM served via TensorRT-LLM.</p>
<p><a href="https://github.com/briancaffey/RocketLeagueBotChat">Rocket League BotChat</a>, for the popular <i>Rocket League</i> game, is a plug-in that allows bots to send contextual in-game chat messages based on a log of game events, such as scoring a goal or making a save. Designed to be used only in offline games against bot players, the plug-in is configurable in many ways via its settings menu.</p>
<p><a href="https://github.com/0xMatthew/CLARA">CLARA</a> (short for Command Line Assistant with RTX Acceleration) is designed to enhance the command line interface of PowerShell by translating plain English instructions into actionable commands. The extension runs locally, quickly and keeps users in their PowerShell context. Once it’s enabled, users type their English instructions and press the tab button to invoke CLARA. Installation is straightforward, and there are options for both script-based and manual setup.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr"><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f389.png" alt="🎉" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Congratulations to the <a href="https://twitter.com/hashtag/GenAIonRTX?src=hash&amp;ref_src=twsrc%5Etfw">#GenAIonRTX</a> <a href="https://twitter.com/hashtag/DevContest?src=hash&amp;ref_src=twsrc%5Etfw">#DevContest</a> winners:</p>
<p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f3c6.png" alt="🏆" class="wp-smiley" style="height: 1em; max-height: 1em;" /> CLARA &#8211; Talk with computers in human language &#8211; Matthew Yaeger<br /><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f3c6.png" alt="🏆" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Rocket League BotChat &#8211; Generate in-game chat messages &#8211; Brian Caffey<br /><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f3c6.png" alt="🏆" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Outlook LLM &#8211; Compose emails securely with AI &#8211; Francisco Gonzalez Blanch</p>
<p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f447.png" alt="👇" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="https://t.co/i52w5Pn1n9">pic.twitter.com/i52w5Pn1n9</a></p>
<p>&mdash; NVIDIA AI Developer (@NVIDIAAIDev) <a href="https://twitter.com/NVIDIAAIDev/status/1770125161242493200?ref_src=twsrc%5Etfw">March 19, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<h2><b>From the Generative AI Theater</b></h2>
<p>GTC attendees can attend three AI Decoded talks on Wednesday, March 20 at the generative AI theater. These 15-minute sessions will guide the audience through ChatRTX and how developers can productize their own personalized chatbot; how each of the three contest winners’ showed some of the possibilities for generative AI apps on RTX systems; and a celebration of artists, the tools and methods they use powered by NVIDIA technology.</p>
<p>In the creator session, Lee Fraser, senior developer relations manager for generative AI media and entertainment at NVIDIA, will explore why generative AI has become so popular. He’ll show off new workflows and how creators can rapidly explore ideas. Artists to be featured include Steve Talkowski, Sophia Crespo, Lim Wenhui, Erik Paynter, Vanessa Rosa and Refik Anadol.</p>
<p>Anadol also has an installation at the show that combines data visualization and imagery based on that data.</p>
<h1><b>Ecosystem of Acceleration</b></h1>
<p>Top creative app developers, like Blackmagic Design and Topaz Labs have integrated RTX AI acceleration in their software. TensorRT doubles the speed of AI effects like rotoscoping, denoising, super-resolution and video stabilization in the DaVinci Resolve and Topaz apps.</p>
<p>“Blackmagic Design and NVIDIA’s ongoing collaborations to run AI models on RTX AI PCs will produce a new wave of groundbreaking features that give users the power to create captivating and immersive content, faster.” — Rohit Gupta, director of software development at Blackmagic Design</p>
<p><iframe loading="lazy" title="Faster Video Editing Using NVIDIA RTX GPUs &amp; AI (DaVinci Resolve)" width="500" height="281" src="https://www.youtube.com/embed/KxBXwa3rYpU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>TensorRT-LLM is being integrated with popular developer frameworks and ecosystems such as LangChain, LlamaIndex, Oobabooga and Jan.AI. Developers and enthusiasts can easily access the performance benefits of TensorRT-LLM through top LLM frameworks to build and deploy generative AI apps to both local and cloud GPUs.</p>
<p>Enthusiasts can also try out their favorite LLMs — accelerated with TensorRT-LLM on RTX systems — through the Oobabooga and Jan.AI chat interfaces.</p>
<h2><b>AI That’s NIMble, AI That’s Quick</b></h2>
<p>Developers and tinkerers can tap into NIM microservices. These pre-built AI “containers,” with industry-standard APIs, provide an optimized solution that helps to reduce deployment times from weeks to minutes. They can be used with more than two dozen popular models from NVIDIA, Getty Images, Google, Meta, Microsoft, Shutterstock and more.</p>
<p>NVIDIA AI Workbench is now generally available, helping developers quickly create, test and customize pretrained generative AI models and LLMs on RTX GPUs. It offers streamlined access to popular repositories like Hugging Face, GitHub and <a href="https://catalog.ngc.nvidia.com/">NVIDIA NGC</a>, along with a simplified user interface that enables developers to easily reproduce, collaborate on and migrate projects.</p>
<p>Projects can be easily scaled up when additional performance is needed — whether to the data center, a public cloud or <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a> — and then brought back to local RTX systems on a PC or workstation for inference and light customization. AI Workbench is a free download and provides example projects to help developers get started quickly.</p>
<p>These tools, and many others announced and shown at GTC, are helping developers drive innovative AI solutions.</p>
<p>From the Blackwell platform’s arrival, to a digital twin for Earth’s climate, it’s been a GTC to remember. For RTX PC and workstation users and developers, it was also a glimpse into what’s next for generative AI.</p>
<p><i>See </i><a href="https://www.nvidia.com/en-us/about-nvidia/legal-info/"><i>notice</i></a><i> regarding software product information.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/ai-decoded-week-3-nv-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/ai-decoded-week-3-nv-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI Decoded From GTC: The Latest Developer Tools and Apps Accelerating AI on PC and Workstation]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Secure by Design: NVIDIA AIOps Partner Ecosystem Blends AI for Businesses</title>
		<link>https://blogs.nvidia.com/blog/aiops-partners-gtc-2024/</link>
		
		<dc:creator><![CDATA[Michael Balint]]></dc:creator>
		<pubDate>Tue, 19 Mar 2024 16:33:43 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cybersecurity]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70624</guid>

					<description><![CDATA[In today’s complex business environments, IT teams face a constant flow of challenges, from simple issues like employee account lockouts to critical security threats. These situations demand both quick fixes and strategic defenses, making the job of maintaining smooth and secure operations ever tougher. That’s where AIOps comes in, blending artificial intelligence with IT operations		<a class="read-more" href="https://blogs.nvidia.com/blog/aiops-partners-gtc-2024/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>In today’s complex business environments, IT teams face a constant flow of challenges, from simple issues like employee account lockouts to critical security threats. These situations demand both quick fixes and strategic defenses, making the job of maintaining smooth and secure operations ever tougher.</p>
<p>That’s where AIOps comes in, blending artificial intelligence with IT operations to not only automate routine tasks, but also enhance security measures. This efficient approach allows teams to quickly deal with minor issues and, more importantly, to identify and respond to security threats faster and with greater accuracy than before.</p>
<p>By using machine learning, AIOps becomes a crucial tool in not just streamlining operations but also in strengthening security across the board. It’s proving to be a game-changer for businesses looking to integrate advanced AI into their teams, helping them stay a step ahead of potential security risks.</p>
<p>According to <a href="https://www.idc.com/getdoc.jsp?containerId=US51160523&amp;pageType=PRINTFRIENDLY">IDC</a>, the IT operations management software market is expected to grow at a rate of 10.3% annually, reaching a projected revenue of $28.4 billion by 2027. This growth underscores the increasing reliance on AIOps for operational efficiency and as a critical component of modern cybersecurity strategies.</p>
<p>As the rapid growth of machine learning operations continues to transform the era of generative AI, a broad ecosystem of NVIDIA partners are offering AIOps solutions that leverage NVIDIA AI to improve IT operations.</p>
<p>NVIDIA is helping a broad ecosystem of AIOps partners with accelerated compute and AI software. This includes <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a>, a cloud-native stack that can run anywhere and provides a basis for AIOps through software like NVIDIA NIM for accelerated inference of AI modes, <a href="https://developer.nvidia.com/morpheus-cybersecurity">NVIDIA Morpheus</a> for AI-based cybersecurity and <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/">NVIDIA NeMo</a> for custom generative AI. This software facilitates GenAI-based chatbot, summarization and search functionality.</p>
<p>AIOps providers using NVIDIA AI include:</p>
<ul>
<li>
<p class="x_MsoNormal"><strong>Dynatrace</strong> <a title="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.dynatrace.com%2Fplatform%2Fartificial-intelligence%2F&amp;data=05%7C02%7Ckyee%40nvidia.com%7Ce4328bc6511f4bcff98b08dc4838e462%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638464656432041971%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=YLynb7v2FCfwP3vtxEY%2BIxjt10zG8NRVjk0O617lj2U%3D&amp;reserved=0" href="https://www.dynatrace.com/platform/artificial-intelligence/" data-outlook-id="a9a7bdfc-c629-4e03-8303-21af2b8f0843">Davis hypermodal AI</a> advances AIOps by integrating causal, predictive and generative AI techniques with the addition of Davis CoPilot. This combination enhances observability and security across IT, development, security and business operations by offering precise and actionable, AI-driven answers and automation.</p>
</li>
<li><b>Elastic</b> offers <a href="https://www.elastic.co/elasticsearch/elasticsearch-relevance-engine">Elasticsearch Relevance Engine (ESRE)</a> for semantic and vector search, which integrates with popular LLMs like GPT-4 to power AI Assistants in their Observability and Security solutions. The Observability AI Assistant is a next-generation AI Ops capability that helps IT teams understand complex systems, monitor health and automate remediation of operational issues<b>.</b></li>
<li><b>New Relic</b> is advancing AIOps by leveraging its <a href="https://newrelic.com/platform/applied-intelligence">machine learning</a>,<a href="https://newrelic.com/platform/new-relic-ai"> generative AI assistant frameworks</a> and longstanding expertise in observability. Its machine learning and advanced logic helps IT teams reduce alerting noise, improve mean time to detect and mean time to repair, automate root cause analysis and generate retrospectives. Its GenAI assistant, New Relic AI, accelerates issue resolution by allowing users to identify, explain and resolve errors without switching contexts, and suggests and applies code fixes directly in a developer’s integrated development environment. It also extends incident visibility and prevention to non-technical teams by automatically producing high-level system health reports, analyzing and summarizing dashboards and answering plain-language questions about a user’s applications, infrastructure and services. New Relic also provides full-stack observability for AI-powered applications benefitting from NVIDIA GPUs.</li>
<li><b>PagerDuty</b> has introduced a new feature in <a href="https://www.pagerduty.com/platform/generative-ai/">PagerDuty Copilot</a>, integrating a generative AI assistant within Slack to offer insights from incident start to resolution, streamlining the incident lifecycle and reducing manual task loads for IT teams.</li>
<li><b>ServiceNow</b>’s <a href="https://www.servicenow.com/products/predictive-aiops.html">commitment to creating a proactive IT operations</a> encompasses automating insights for rapid incident response, optimizing service management and detecting anomalies. Now, in collaboration with NVIDIA, it is pushing into generative AI to further innovate technology service and operations.</li>
<li><b>Splunk’s</b> technology platform<a href="https://www.splunk.com/en_us/solutions/splunk-artificial-intelligence.html"> applies artificial intelligence and machine learning</a> to automate the processes of identifying, diagnosing and resolving operational issues and threats, thereby enhancing IT efficiency and security posture. Splunk<a href="https://www.splunk.com/en_us/products/it-service-intelligence.html"> IT Service Intelligence</a> serves as Splunk’s primary AIOps offering, providing embedded AI-driven incident prediction, detection and resolution all from one place.</li>
</ul>
<p>Cloud service providers including Amazon Web Services (AWS), Google Cloud and Microsoft Azure enable organizations to automate and optimize their IT operations, leveraging the scale and flexibility of cloud resources.</p>
<ul>
<li><b>AWS</b> offers a suite of services conducive to AIOps, including Amazon CloudWatch for monitoring and observability; AWS CloudTrail for tracking user activity and API usage; Amazon SageMaker for creating repeatable and responsible machine learning workflows; and AWS Lambda for serverless computing, allowing for the automation of response actions based on triggers.</li>
<li><b>Google Cloud</b> supports AIOps through services like Google Cloud Operations, which provides monitoring, logging and diagnostics across applications on the cloud and on-premises. Google Cloud’s AI and machine learning products include Vertex AI for model training and prediction and BigQuery for fast SQL queries using the processing power of Google’s infrastructure.</li>
<li><b>Microsoft Azure</b> facilitates AIOps with Azure Monitor for comprehensive monitoring of applications, services and infrastructure. Azure Monitor’s built-in AIOps capabilities help predict capacity usage, enable autoscaling, identify application performance issues and detect anomalous behaviors in virtual machines, containers and other resources. Microsoft Azure Machine Learning (AzureML) offers a cloud-based MLOps environment for training, deploying and managing machine learning models responsibly, securely and at scale.</li>
</ul>
<p>Platforms specializing in MLOps primarily focus on streamlining the lifecycle of machine learning models, from development to deployment and monitoring. While the core mission centers on making machine learning more accessible, efficient and scalable, their technologies and methodologies indirectly support AIOps by enhancing AI capabilities within IT operations: <b></b></p>
<ul>
<li><b>Anyscale’s </b>platform, based on Ray, allows for the easy scaling of AI and machine learning applications, including those used in AIOps for tasks like anomaly detection and automated remediation. By facilitating distributed computing, Anyscale helps AIOps systems process large volumes of operational data more efficiently, enabling real-time analytics and decision-making.</li>
<li><b>Dataiku</b> can be used to create models that predict IT system failures or optimize resource allocation, with features that allow IT teams to quickly deploy and iterate on these models in production environments.</li>
<li><b>Dataloop’s</b> platform delivers full data lifecycle management and a flexible way to plug in AI models for an end-to-end workflow, allowing users to develop AI applications using their data.</li>
<li><b>DataRobot</b> is a full AI lifecycle platform that enables IT operations teams to rapidly build, deploy and govern AI solutions, improving operational efficiency and performance.</li>
<li><b>Domino Data Lab’s</b> platform lets enterprises and their data scientists build, deploy and manage AI on a unified, end-to-end platform. Data, tools, compute, models and projects across all environments are centrally managed so teams can collaborate, monitor production models and standardize best practices for governed AI innovation. This approach is vital for AIOps as it balances the self-service needed by data science teams with complete reproducibility, granular cost tracking and proactive governance for IT operational needs.</li>
<li><b>Weights &amp; Biases</b> provides tools for experiment tracking, model optimization, and collaboration, crucial for developing and fine-tuning AI models used in AIOps. By offering detailed insights into model performance and facilitating collaboration across teams, Weights &amp; Biases helps ensure that AI models deployed for IT operations are both effective and transparent.</li>
</ul>
<p>Learn more about NVIDIA’s partner ecosystem and their work at <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/aiops-corp-blog-1280x680-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/aiops-corp-blog-1280x680-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Secure by Design: NVIDIA AIOps Partner Ecosystem Blends AI for Businesses]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Climate Pioneers: 3 Startups Harnessing NVIDIA’s AI and Earth-2 Platforms</title>
		<link>https://blogs.nvidia.com/blog/climate-startups-ai-earth-2/</link>
		
		<dc:creator><![CDATA[Tenika Versey Walker]]></dc:creator>
		<pubDate>Tue, 19 Mar 2024 16:00:13 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Climate]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[NVIDIA Modulus]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Scientific Visualization]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70597</guid>

					<description><![CDATA[To help mitigate climate change — one of humanity’s greatest challenges — researchers are turning to AI and sustainable computing to accelerate and operationalize their work. At this week’s NVIDIA GTC global AI conference, startups, enterprises and scientists are highlighting their environmental sustainability initiatives and latest climate innovations. Many are using NVIDIA Earth-2, a full-stack,		<a class="read-more" href="https://blogs.nvidia.com/blog/climate-startups-ai-earth-2/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>To help mitigate climate change — one of humanity’s greatest challenges — researchers are turning to AI and <a href="https://blogs.nvidia.com/blog/what-is-green-computing/" target="_blank" rel="noopener">sustainable computing</a> to accelerate and operationalize their work.</p>
<p>At this week’s <a href="https://www.nvidia.com/gtc/" target="_blank" rel="noopener">NVIDIA GTC</a> global AI conference, startups, enterprises and scientists are highlighting their environmental sustainability initiatives and latest climate innovations. Many are using <a href="https://www.nvidia.com/en-us/high-performance-computing/earth-2/" target="_blank" rel="noopener">NVIDIA Earth-2</a>, a full-stack, open platform for accelerating climate and weather simulation and predictions.</p>
<p>Earth-2 comprises GPU-accelerated numerical weather and climate prediction models, including ICON and IFS; state-of-the-art AI-driven weather models, such as FourCastNet, GraphCast and Deep Learning Weather Prediction, offered through the <a href="https://developer.nvidia.com/modulus" target="_blank" rel="noopener">NVIDIA Modulus</a> framework; and large-scale, interactive, high-resolution data visualization and simulation enabled by the <a href="https://www.nvidia.com/en-us/omniverse/" target="_blank" rel="noopener">NVIDIA Omniverse</a> platform. These capabilities are also available via cloud APIs, or application programming interfaces.</p>
<p>Various members of <a href="https://www.nvidia.com/en-us/startups/" target="_blank" rel="noopener">NVIDIA Inception</a> — a free, global program for cutting-edge startups — are pioneering climate AI advancements with Earth-2. It’s critical work, as extreme-weather events are <a href="https://authors.library.caltech.edu/records/k959a-53q45" target="_blank" rel="noopener">expected</a> to take a million lives and cost $1.7 trillion per year by 2050.</p>
<h2><b>Tomorrow.io Powers Weather Predictions of Tomorrow</b></h2>
<p><img loading="lazy" decoding="async" class="alignright size-full wp-image-70604" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/tomorrow.io_.jpeg" alt="" width="512" height="358" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/tomorrow.io_.jpeg 512w, https://blogs.nvidia.com/wp-content/uploads/2024/03/tomorrow.io_-400x280.jpeg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/tomorrow.io_-307x215.jpeg 307w, https://blogs.nvidia.com/wp-content/uploads/2024/03/tomorrow.io_-143x100.jpeg 143w" sizes="(max-width: 512px) 100vw, 512px" /></p>
<p>Boston-based <a href="http://tomorrow.io" target="_blank" rel="noopener">Tomorrow.io</a> provides actionable, weather-related insights to countries, businesses and individuals by applying advanced AI and machine learning models to a proprietary global dataset collected from satellites, radar and other sensors. Its weather intelligence and climate adaptation platform delivers high-resolution, accurate weather forecasts across time zones for both short- and long-term projections.</p>
<p>The startup is using Earth-2 to study the potential impacts of its suite of satellites on global model forecasts. By conducting observing-system simulation experiments, or OSSEs, with Earth-2 AI forecast models, Tomorrow.io can identify the optimal configurations of satellites and other instruments to improve weather-forecasting conditions. The work ultimately aims to offer users precision and simplicity, helping them easily understand complex weather situations and make the right operational decisions at the right time.</p>
<p>Learn more about Tomorrow.io’s work with Earth-2 by joining the GTC session, “<a href="https://www.nvidia.com/gtc/session-catalog/?search=tenika&amp;tab.allsessions=1700692987788001F1cG&amp;search=tenika#/session/1696445353484001C0A2" target="_blank" rel="noopener">Global Strategies: Startups, Venture Capital, and Climate Change Solutions</a>,” taking place today, March 19, at 3 p.m. PT, at the San Jose Convention Center and online.</p>
<h2><b>ClimaSens Advances Flood-Risk Management With AI</b></h2>
<p><a href="https://climasens.com/" target="_blank" rel="noopener">ClimaSens</a>, based in Melbourne, Australia, and New York, fuses historical, real-time and future climate and weather information using advanced AI models. FloodSens, its upcoming flood risk analysis model, informs clients about the probability of flooding from rainfall, offering high-resolution assessments of flash flooding, riverine flooding and all types of flooding in between.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-large wp-image-70607" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-672x210.png" alt="" width="672" height="210" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-672x210.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-400x125.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-768x240.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-1536x480.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-842x263.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-406x127.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-188x59.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-1280x400.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></p>
<p>FloodSens, now in beta, was developed using Earth-2 APIs and the FourCastNet model for high-fidelity, physically accurate representations of future weather conditions, as well as an ensemble of other models for assessing the probabilities of low-likelihood, high-impact flooding events. Through this work, the startup aims to enable a more resilient, sustainable future for communities worldwide.</p>
<h2><b>North.io Garners Ocean Insights With AI and Accelerated Modeling</b></h2>
<p><img loading="lazy" decoding="async" class="alignright size-full wp-image-70611" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/north.io_.jpeg" alt="" width="512" height="288" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/north.io_.jpeg 512w, https://blogs.nvidia.com/wp-content/uploads/2024/03/north.io_-400x225.jpeg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/north.io_-382x215.jpeg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/03/north.io_-178x100.jpeg 178w" sizes="(max-width: 512px) 100vw, 512px" />Based in Kiel, Germany, <a href="http://north.io" target="_blank" rel="noopener">north.io</a> is helping to map the Earth’s largest carbon sink: oceans. Only about 25% of the ocean floor — a critical source of the world’s renewable energy and food security — has been mapped so far.</p>
<p>North.io is collecting and analyzing massive amounts of data from autonomous underwater vehicles (AUVs) and making it accessible, shareable, visualizable and understandable for users across the globe through its TrueOcean platform.</p>
<p>Using Earth-2 APIs, north.io is developing AI weather forecasts for intelligent operational planning, system management and risk assessment for its AUVs. The combination of high-precision weather modeling and the use of autonomous systems drastically reduces human safety risks in rough, offshore environments.</p>
<p><i>Learn more about the latest AI, </i><a href="https://www.nvidia.com/gtc/sessions/hpc/" target="_blank" rel="noopener"><i>high performance computing</i></a><i> and </i><a href="https://www.nvidia.com/gtc/sessions/sustainable-computing/" target="_blank" rel="noopener"><i>sustainable computing</i></a><i> advancements for climate research at GTC, running through Thursday, March 21.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/earth-2-startups-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/earth-2-startups-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Climate Pioneers: 3 Startups Harnessing NVIDIA’s AI and Earth-2 Platforms]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Celebrates Americas Partners Driving AI-Powered Transformation</title>
		<link>https://blogs.nvidia.com/blog/nvidia-partner-network-npn-awards-2024/</link>
		
		<dc:creator><![CDATA[Craig Weinstein]]></dc:creator>
		<pubDate>Tue, 19 Mar 2024 15:00:03 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70621</guid>

					<description><![CDATA[NVIDIA recognized 14 partners in the Americas for their achievements in transforming businesses with AI, this week at GTC. The winners of the NVIDIA Partner Network Americas Partner of the Year awards have helped customers across industries advance their operations with the software, systems and services needed to integrate AI into their businesses. NPN awards		<a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-partner-network-npn-awards-2024/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>NVIDIA recognized 14 partners in the Americas for their achievements in transforming businesses with AI, this week at <a href="https://www.nvidia.com/gtc/">GTC</a>.</p>
<p>The winners of the <a href="https://www.nvidia.com/en-us/about-nvidia/partners/">NVIDIA Partner Network</a> Americas Partner of the Year awards have helped customers across industries advance their operations with the software, systems and services needed to integrate AI into their businesses.</p>
<p>NPN awards categories span a multitude of competencies and industries, including service delivery, data center networking, public sector, healthcare and higher education.</p>
<p>Three new categories were created this year. One recognizes a partner driving AI-powered success in the financial services industry; one celebrates a partner exhibiting overall AI excellence; and another honors a partner’s dedication to advancing NVIDIA’s full-stack portfolio across a multitude of industries.</p>
<p>All awards reflect the spirit of the NPN ecosystem in driving business success through accelerated full-stack computing and software.</p>
<p>“NVIDIA’s work driving innovation in generative AI has helped partners empower their customers with cutting-edge technology — as well reduced costs and fostered growth opportunities while solving intricate business challenges,” said Rob Enderle, president and principal analyst at the Enderle Group. “The recipients of the 2024 NPN awards embody a diverse array of AI expertise, offering rich knowledge to help customers deploy transformative solutions across industries.”</p>
<p>The 2024 NPN award winners for the Americas are:</p>
<ul>
<li><b>AI Excellence Partner of the Year </b>— <a href="https://lambdalabs.com/blog/lambda-selected-as-2024-nvidia-partner-network-ai-excellence-partner-of-the-year">Lambda</a> received this award for its dedication to providing end-to-end AI solutions featuring NVIDIA accelerated computing and <a href="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.nvidia.com%2Fen-us%2Fdata-center%2Fproducts%2Fai-enterprise%2F&amp;data=05%7C02%7Cpfox%40nvidia.com%7Ccbecb31fb679424fadac08dc396b3015%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638448379745806343%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=u%2BO8WhrVvhtQkP%2BY9RtsErHoavYXnxjUhSeV7yzwYew%3D&amp;reserved=0">NVIDIA AI Enterprise</a> across <a href="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.nvidia.com%2Fen-us%2Fdata-center%2Fdgx-platform%2F&amp;data=05%7C02%7Cpfox%40nvidia.com%7Ccbecb31fb679424fadac08dc396b3015%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638448379745822830%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=FhLA50UmnmAe758yM1opSLX3wk4ltUUWdZRNXyOu8hg%3D&amp;reserved=0">NVIDIA DGX</a> and <a href="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Flambdalabs.com%2F&amp;data=05%7C02%7Cpfox%40nvidia.com%7Ccbecb31fb679424fadac08dc396b3015%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638448379745836001%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=2whFijjHbYNxNXKKBgK%2FzW5ED0XeQIJl5XPDYkqpFzI%3D&amp;reserved=0">Lambda Cloud</a>.</li>
<li><b>Enterprise Partner of the Year </b>— <a href="https://www.wwt.com/press-release/world-wide-technology-named-ai-enterprise-partner-of-the-year">World Wide Technology</a> received this newly introduced award for its leadership, dedication and expertise in advancing the adoption of AI with NVIDIA’s portfolio of purpose-built systems, data center networking, software and accelerated computing solutions across machine learning, digital twins, <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> and visualization.</li>
<li><b>Canadian Partner of the Year </b>— <a href="https://convergetp.com/2024/03/19/converge-technology-solutions-awarded-2024-nvidia-networking-partner-of-the-year-and-canadian-partner-of-the-year/">Converge Technology Solutions</a> is recognized for its dedication and expertise in NVIDIA DGX systems and for its Canadian customer support services, leveraging training courses from NVIDIA, to further industry knowledge of the NVIDIA software stack.</li>
<li><b>Financial Services Partner of the Year</b> — <a href="https://www.cdw.com/content/cdw/en/newsroom/articles/awards/2024/03/19/cdw-named-nvidia-partner-network-financial-services-partner-of-the-year.html">CDW</a> received this newly introduced award for its ecosystem partnerships, strategic investments and targeted domain expertise serving financial customers seeking HPC solutions and customer experience solutions such as chatbots and agentless routing.</li>
<li><b>Global Consulting Partner of the Year </b>— <a href="https://www2.deloitte.com/us/en/pages/about-deloitte/articles/press-releases/deloitte-named-nvidia-partner-network-global-consulting-partner-of-the-year-for-the-fourth-consecutive-year.html">Deloitte</a> is recognized for the fourth consecutive time for its embrace of generative AI and for leveraging the capabilities of <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a>.</li>
<li><b>Healthcare Partner of the Year </b>— <a href="https://www.markiiisys.com/blog/mark-iii-recognized-as-2024-nvidia-partner-network-americas-healthcare-partner-of-the-">Mark III </a>is recognized for the second consecutive year for its utilization for the NVIDIA healthcare portfolio, which supports biopharma research, academic medical centers, research institutions, healthcare systems and life sciences organizations with NVIDIA infrastructure, software and cloud technologies.</li>
<li><b>Higher Education Partner of the Year </b>— <a href="https://www.cambridgecomputer.com/partner-of-the-year-2024/">Cambridge Computer</a> is recognized for the fourth consecutive year for its customer service and technical expertise, bringing NVIDIA AI solutions to the life sciences, education and research sectors.</li>
<li><b>Networking Partner of the Year </b>— Converge Technology Solutions is recognized for its expertise in <a href="https://www.nvidia.com/en-us/networking/">NVIDIA high-performance networking</a> solutions to support state-of-the-art accelerated computing deployments.</li>
<li><b>Public Sector Partner of the Year </b>— <a href="https://sterling.com/sterling-named-nvidia-partner-network-public-sector-partner-of-the-year">Sterling</a> is recognized for its investment and achievements in developing a robust AI practice. This includes assembling a team of dedicated AI software engineers focused on the full-stack NVIDIA platform, establishing Sterling Labs — an AI briefing center near Washington, D.C. — and collaborating with NVIDIA to launch ARC, a 5G/6G platform targeted for next-gen wireless networks.</li>
<li><b>Rising Star Partner of the Year </b>— <a href="https://www.icc-usa.com/icc-named-nvidia-partner-of-the-year-at-GTC-2024">International Computer Concepts</a> is recognized for its growth in developing AI and machine learning solutions for cloud service providers and financial services customers to power machine learning training, real-time inference and other AI workloads.</li>
<li><b>Service Delivery Partner of the Year </b>— <a href="https://quantiphi.com/press-release/quantiphi-awarded-nvidia-partner-network-ai-service-delivery-partner-of-the-year-for-third-consecutive-time/">Quantiphi</a> is recognized for the third consecutive year for its commitment to driving adoption of NVIDIA software and hardware in the enterprise. Its AI Service Delivery team has demonstrated expertise in using LLMs, information retrieval, imaging and data analytics to solve complex business problems in the telecom, life sciences, retail and energy industries for its global customers.</li>
<li><b>Distribution Partner of the Year </b>— <a href="https://news.tdsynnex.com/?p=3883">TD SYNNEX</a> is recognized for demonstrating its commitment to building its AI business on the NVIDIA AI platform, with year-over-year growth that underscores its operational excellence in distribution.</li>
<li><b>Software Partner of the Year </b>— <a href="https://investor.insight.com/news-releases/news-release-details/2024/Insight-Named-NVIDIAs-2024-Americas-Software-Partner-of-the-Year/default.aspx">Insight</a> is recognized for its leadership in NVIDIA AI Enterprise deployments, establishing cutting-edge innovation labs and certifications that cultivate expertise while seamlessly embedding generative AI into its operations.</li>
<li><b>Solution Integration Partner of the Year </b>— <a href="https://www.exxactcorp.com/News-Events/2024-NVIDIA-Partner-Network-Solution-Integration-Partner-of-the-Year">EXXACT</a> is recognized for its commitment and expertise in providing end-to-end NVIDIA AI and high performance computing solutions, including NVIDIA software and data center products across multiple industries.</li>
</ul>
<p>Learn how to <a href="https://www.nvidia.com/en-us/about-nvidia/partners/become-a-partner/">join NPN</a>, or find your local NPN partner.<br />
<b></b></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2022/01/NVIDIA-Endeavor-building-logo-1.jpg"
			type="image/jpeg"
			width="1300"
			height="868"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2022/01/NVIDIA-Endeavor-building-logo-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Celebrates Americas Partners Driving AI-Powered Transformation]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA, Huang Win Top Honors in Innovation, Engineering</title>
		<link>https://blogs.nvidia.com/blog/fast-company-nae-honors/</link>
		
		<dc:creator><![CDATA[Rick Merritt]]></dc:creator>
		<pubDate>Tue, 19 Mar 2024 13:45:55 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[CUDA]]></category>
		<category><![CDATA[Digital Twin]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[New GPU Uses]]></category>
		<category><![CDATA[Omniverse]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70494</guid>

					<description><![CDATA[NVIDIA today was named the world’s most innovative company by Fast Company magazine. The accolade comes on the heels of company founder and CEO Jensen Huang being inducted into the U.S. National Academy of Engineering. A team of several dozen journalists at Fast Company — a business media brand launched in 1995 by two Harvard		<a class="read-more" href="https://blogs.nvidia.com/blog/fast-company-nae-honors/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>NVIDIA today was named the world’s most innovative company by <i>Fast Company</i> magazine.</p>
<p>The accolade comes on the heels of company founder and CEO Jensen Huang being inducted into the U.S. National Academy of Engineering.</p>
<p>A team of several dozen journalists at <i>Fast Company</i> — a business media brand launched in 1995 by two <i>Harvard Business Review</i> editors — ranked NVIDIA the leader in its <a href="https://www.fastcompany.com/most-innovative-companies/list">2024 list</a> of the world’s 50 most innovative companies.</p>
<h2><b>“Putting AI to Work”</b></h2>
<p>“Nvidia isn’t just in the business of providing ever-more-powerful computing hardware and letting everybody else figure out what to do with it,” <i>Fast Company</i> wrote in <a href="https://www.fastcompany.com/91033514/nvidia-most-innovative-companies-2024">an article</a> detailing its selection.</p>
<p>“Across an array of industries, the company’s technologies, platforms, and partnerships are doing much of the heavy lifting of putting AI to work,” citing advances in automotive, drug discovery, gaming and retail announced in one recent week.</p>
<p>The article noted the central role of the <a href="https://developer.nvidia.com/about-cuda">CUDA</a> compute platform. It also shared an eye-popping experience using <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> to interact with a digital twin of a Nissan Z sport coupe.</p>
<h2><b>In a League With Giants</b></h2>
<p>“Even for AI’s titans, building on what Nvidia has created — the more ambitiously, the better — is often how progress happens,” the article concluded.</p>
<p>Last year, OpenAI led the list for ChatGPT, the <a href="https://www.nvidia.com/en-us/glossary/large-language-models">large language model</a> that started a groundswell in <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a>. In 2021, Moderna and Pfizer-BioNTech topped the ranking for rapidly developing a Covid vaccine.</p>
<p><i>Fast Company</i> bases its ranking on four criteria: innovation, impact, timeliness and relevance. Launched in 2008, the annual list recognizes organizations that have introduced groundbreaking products, fostered positive social impact and reshaped industries.</p>
<p>NVIDIA invented the GPU in 1999, redefining computer graphics and igniting the era of modern AI. NVIDIA is now driving the platform shift to <a href="https://blogs.nvidia.com/blog/what-is-accelerated-computing/">accelerated computing</a> and generative AI, transforming the world’s largest industries.</p>
<h2><b>Fueling an AI Revolution</b></h2>
<p>Last month, Huang was elected to the National Academy of Engineering (<a href="https://www.nae.edu/">NAE</a>) for contributions in “high-powered graphics processing units, fueling the artificial intelligence revolution.”</p>
<p>Academy membership honors those who have made outstanding contributions such as pioneering new fields of technology. Founded in 1964, the NAE provides a trusted source of engineering advice for creating a healthier, more secure and sustainable world.</p>
<p>“Jensen Huang’s induction into the National Academy of Engineering is a testament to his enduring contributions to our industry and world,” said Satya Nadella, chairman and CEO of Microsoft.</p>
<p>“His visionary leadership has forever transformed computing, from the broad adoption of advanced 3D graphics to today’s GPUs — and, more importantly, has driven foundational innovations across every sector, from gaming and productivity, to digital biology and healthcare. All of us at Microsoft congratulate Jensen on this distinction, and we are honored to partner with him and the entire NVIDIA team on defining this new era of AI,” he added.</p>
<p>“Jensen’s election is incredibly well deserved,” said John Hennessy, president emeritus of Stanford University and an NAE member since 1992.</p>
<p>“His election recognizes both his transformative technical contributions, as well as his incredible leadership of NVIDIA for almost 30 years. I have seen many NAE nominations over the past 30 years, Jensen’s was one of the best!”</p>
<p>Morris Chang, founder of Taiwan Semiconductor Manufacturing Co. and an NAE member since 2002, added his congratulations.</p>
<p>“Jensen is one of the most visionary engineers and charismatic business leaders I have had the pleasure to work with in the last three decades,” he said.</p>
<p>Huang is also a recipient of the Semiconductor Industry Association’s highest honor, the Robert N. Noyce Award, as well as honorary doctorate degrees from Taiwan’s National Chiao Tung University, National Taiwan University and Oregon State University.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/FC-NAE-logos.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/FC-NAE-logos-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA, Huang Win Top Honors in Innovation, Engineering]]></media:title>
			<media:description type="html">Fast Company, NAE logos</media:description>
			</media:content>
			</item>
		<item>
		<title>Generation Sensation: New Generative AI and RTX Tools Boost Content Creation</title>
		<link>https://blogs.nvidia.com/blog/studio-gtc-ai-studio-driver/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 19 Mar 2024 13:00:20 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio Driver]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70408</guid>

					<description><![CDATA[Creators are getting a generative AI boost with tools announced at NVIDIA GTC, a global AI conference bringing together the brightest minds in AI content creation and accelerated computing. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/" target="_blank" rel="noopener"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/" target="_blank" rel="noopener"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. We’re also deep diving on new </i><a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/" target="_blank" rel="noopener"><i>GeForce RTX 40 Series GPU</i></a><i> features, technologies and resources, and how they dramatically accelerate content creation.</i></p>
<p>Creators are getting a generative AI boost with tools announced at <a href="https://www.nvidia.com/gtc/" target="_blank" rel="noopener">NVIDIA GTC</a>, a global AI conference bringing together the brightest minds in AI content creation and accelerated computing.</p>
<p>Adobe Substance 3D Stager and Sampler via Adobe Firefly, the OBS 30.1 YouTube HDR Beta and <a href="https://www.nvidia.com/en-us/omniverse/apps/audio2face/" target="_blank" rel="noopener">NVIDIA Omniverse Audio2Face</a> for iClone 8 will also receive sizable upgrades.</p>
<p>DLSS 3.5 with Ray Reconstruction is coming soon to the <a href="https://www.nvidia.com/en-us/geforce/rtx-remix/" target="_blank" rel="noopener">NVIDIA RTX Remix Open Beta</a>, enabling modders to upgrade their projects with the power of AI. Sample this leap in high graphical fidelity with the new <a href="https://www.nvidia.com/en-us/geforce/campaigns/play-portal-with-rtx/" target="_blank" rel="noopener"><i>Portal With RTX</i></a> update available on <a href="https://store.steampowered.com/app/2012840/Portal_with_RTX/" target="_blank" rel="noopener">Steam</a> with DLSS Ray Reconstruction, which provides enhanced ray-traced imagery. <a href="https://www.nvidia.com/en-us/geforce/news/portal-with-rtx-dlss-3-5-ray-reconstruction-update" target="_blank" rel="noopener">Learn more</a> about the DLSS 3.5 update to <i>Portal With RTX</i>.</p>
<p>The March NVIDIA Studio Driver, optimizing the latest creative app updates, is available for download today.</p>
<h2><b>A March of Creative App Upgrades</b></h2>
<p>The Adobe Substance 3D Stager beta announced a new Generative Background feature — powered by Adobe Firefly — to create backdrops for rendered images. Stager’s Match Image tool uses machine learning to accurately place 3D models within the generated background, optimizing lighting and perspective for greater flexibility and realism.</p>
<div style="width: 1280px;" class="wp-video"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video class="wp-video-shortcode" id="video-70408-1" width="1280" height="1920" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/nvidia-studio-itns-wk101-1280w-gen-ai-bg.mp4?_=1" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/03/nvidia-studio-itns-wk101-1280w-gen-ai-bg.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/03/nvidia-studio-itns-wk101-1280w-gen-ai-bg.mp4</a></video></div>
<p>&nbsp;</p>
<p>Meanwhile, Substance 3D Sampler’s announced Text to Texture beta — also powered by Adobe Firefly — gives artists a new way to source texture imagery using only a description. All Text to Texture images are square and tileable with proper perspective, ready for material-creation workflows.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-70408-2" width="1280" height="1080" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/nvidia-studio-itns-wk101-1280w-wood-sampler.mp4?_=2" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/03/nvidia-studio-itns-wk101-1280w-wood-sampler.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/03/nvidia-studio-itns-wk101-1280w-wood-sampler.mp4</a></video></div>
<p>&nbsp;</p>
<p>Learn more about both apps in the GTC session “<a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=maheut#/session/1695393531751001EoQy" target="_blank" rel="noopener">Elevating 3D Concepts: GenAI-Infused Design</a>.” Search the <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG#/" target="_blank" rel="noopener">GTC session catalog</a> and check out the “Content Creation / Rendering / Ray Tracing” and “Generative AI” topics for additional creator-focused sessions.</p>
<p>The recently launched OBS 30.1 beta will enable content creators to use Real-Time Messaging Protocol — an Adobe open-source protocol designed to stream audio and video by maintaining low-latency connections — to stream high-dynamic range, high-efficiency video coding content to YouTube. Download OBS Beta 30.1 on the <a href="https://obsproject.com/forum/threads/obs-studio-30-1-beta.172987/" target="_blank" rel="noopener">OBS website</a> to get started.</p>
<p><iframe loading="lazy" title="***please delete***" width="500" height="281" src="https://www.youtube.com/embed/_kiMqnbTjgg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>NVIDIA Omniverse Audio2Face for iClone 8 uses AI to produce expressive facial animations solely from audio input. In addition to generating natural lip-sync animations for multilingual dialogue, the latest standalone release supports multilingual lip-sync and singing animations, as well as full-spectrum editing with slider controls and a keyframe editor.</p>
<p>For more information on how RTX is powering premium AI capabilities and performance, check out the new <a href="https://blogs.nvidia.com/blog/ai-decoded-rtx-pc" target="_blank" rel="noopener">AI Decoded</a> blog series and <a href="https://www.nvidia.com/en-us/ai-on-rtx/?modal=subscribe-ai" target="_blank" rel="noopener">sign up</a> to receive updates weekly.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/" target="_blank" rel="noopener"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio" target="_blank" rel="noopener"><i>X</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/" target="_blank" rel="noopener"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw" target="_blank" rel="noopener"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon" target="_blank" rel="noopener"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/03/nvidia-studio-itns-wk101-1280w-gen-ai-bg.mp4" length="1899762" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/03/nvidia-studio-itns-wk101-1280w-wood-sampler.mp4" length="1837458" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/nv-blog-header-preview-1280x680-1-gen-ai-gtc-2024.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/nv-blog-header-preview-1280x680-1-gen-ai-gtc-2024-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Generation Sensation: New Generative AI and RTX Tools Boost Content Creation]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>GTC Wrap-Up: ‘We Created a Processor for the Generative AI Era,’ NVIDIA CEO Says</title>
		<link>https://blogs.nvidia.com/blog/2024-gtc-keynote/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Mon, 18 Mar 2024 22:43:09 +0000</pubDate>
				<category><![CDATA[Accelerated Analytics]]></category>
		<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Driving]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Networking]]></category>
		<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[Virtual Reality]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70538</guid>

					<description><![CDATA[Generative AI promises to revolutionize every industry it touches — all that’s been needed is the technology to meet the challenge. NVIDIA founder and CEO Jensen Huang on Monday introduced that technology — the company’s new Blackwell computing platform — as he outlined the major advances that increased computing power can deliver for everything from		<a class="read-more" href="https://blogs.nvidia.com/blog/2024-gtc-keynote/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Generative AI promises to revolutionize every industry it touches — all that’s been needed is the technology to meet the challenge.</p>
<p>NVIDIA founder and CEO Jensen Huang on Monday introduced that technology — the company’s new Blackwell computing platform — as he outlined the major advances that increased computing power can deliver for everything from software to services, robotics to medical technology and more.</p>
<p>“Accelerated computing has reached the tipping point — general purpose computing has run out of steam,” Huang told more than 12,000 GTC attendees gathered in-person — and many tens of thousands more online — for his keynote address at Silicon Valley’s cavernous SAP Center arena.</p>
<p>“We need another way of doing computing — so that we can continue to scale so that we can continue to drive down the cost of computing, so that we can continue to consume more and more computing while being sustainable. Accelerated computing is a dramatic speedup over general-purpose computing, in every single industry.”</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-70552" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/MC1_4926-scaled.jpg" alt="" width="2048" height="1365" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/MC1_4926-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MC1_4926-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MC1_4926-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MC1_4926-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MC1_4926-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MC1_4926-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MC1_4926-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MC1_4926-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MC1_4926-1280x853.jpg 1280w" sizes="(max-width: 2048px) 100vw, 2048px" /></p>
<p>Huang spoke in front of massive images on a 40-foot tall, 8K screen the size of a tennis court to a crowd packed with CEOs and developers, AI enthusiasts and entrepreneurs, who walked together 20 minutes to the arena from the San Jose Convention Center on a dazzling spring day.</p>
<p>Delivering a massive upgrade to the world’s AI infrastructure, Huang introduced the NVIDIA Blackwell platform to unleash real-time generative AI on trillion-parameter large language models.</p>
<p>Huang presented NVIDIA NIM — a reference to NVIDIA inference microservices — a new way of packaging and delivering software that connects developers with hundreds of millions of GPUs to deploy custom AI of all kinds.</p>
<p>And bringing AI into the physical world, Huang introduced Omniverse Cloud APIs to deliver advanced simulation capabilities.</p>
<p><iframe loading="lazy" title="YouTube video player" src="https://www.youtube.com/embed/Y2F8yisiS6E?si=b9Y8b7x-sTGY4n-J" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>Huang punctuated these major announcements with powerful demos, partnerships with some of the world’s largest enterprises and more than a score of announcements detailing his vision.</p>
<p><a href="https://www.nvidia.com/gtc/">GTC</a> — which in 15 years has grown from the confines of a local hotel ballroom to the world’s most important AI conference — is returning to a physical event for the first time in five years.</p>
<p>This year’s has over 900 sessions — including a panel discussion on transformers moderated by Huang with the eight pioneers who first developed the technology, more than 300 exhibits and 20-plus technical workshops.</p>
<p>It’s an event that’s at the intersection of AI and just about everything. In a stunning opening act to the keynote, Refik Anadol, the world&#8217;s leading AI artist, showed a massive real-time AI data sculpture with wave-like swirls in greens, blues, yellows and reds, crashing, twisting and unraveling across the screen.</p>
<p>As he kicked off his talk, Huang explained that the rise of multi-modal AI — able to process diverse data types handled by different models — gives AI greater adaptability and power. By increasing their parameters, these models can handle more complex analyses.</p>
<p>But this also means a significant rise in the need for computing power. And as these collaborative, multi-modal systems become more intricate — with as many as a trillion parameters — the demand for advanced computing infrastructure intensifies.</p>
<p>“We need even larger models,” Huang said. “We’re going to train it with multimodality data, not just text on the internet, we’re going to train it on texts and images, graphs and charts, and just as we learned watching TV, there’s going to be a whole bunch of watching video.”</p>
<h2>The Next Generation of Accelerated Computing</h2>
<p>In short, Huang said “we need bigger GPUs.” The Blackwell platform is built to meet this challenge. Huang pulled a Blackwell chip out of his pocket and held it up side-by-side with a Hopper chip, which it dwarfed.</p>
<p>Named for David Harold Blackwell — a University of California, Berkeley mathematician specializing in game theory and statistics, and the first Black scholar inducted into the National Academy of Sciences — the new architecture succeeds the NVIDIA Hopper architecture, launched two years ago.</p>
<p>Blackwell delivers 2.5x its predecessor’s performance in FP8 for training, per chip, and 5x with FP4 for inference. It features a fifth-generation NVLink interconnect that’s twice as fast as Hopper and scales up to 576 GPUs.</p>
<p>And the <a href="https://www.nvidia.com/en-us/data-center/gb200-nvl72/">NVIDIA GB200 Grace Blackwell Superchip</a> connects two Blackwell <a href="https://www.nvidia.com/en-us/data-center/b200/">NVIDIA B200 Tensor Core GPUs</a> to the NVIDIA Grace CPU over a 900GB/s ultra-low-power NVLink chip-to-chip interconnect.</p>
<p>Huang held up a board with the system. “This computer is the first of its kind where this much computing fits into this small of a space,” Huang said. “Since this is memory coherent, they feel like it’s one big happy family working on one application together.”</p>
<p>For the highest AI performance, GB200-powered systems can be connected with the NVIDIA Quantum-X800 InfiniBand and Spectrum-X800 Ethernet platforms, also <a href="https://nvidianews.nvidia.com/news/networking-switches-gpu-computing-ai">announced today</a>, which deliver advanced networking at speeds up to 800Gb/s.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-70577" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/VIVY0652-1-scaled.jpg" alt="" width="2048" height="1365" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/VIVY0652-1-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/VIVY0652-1-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/VIVY0652-1-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/VIVY0652-1-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/VIVY0652-1-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/VIVY0652-1-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/03/VIVY0652-1-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/03/VIVY0652-1-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/03/VIVY0652-1-1280x853.jpg 1280w" sizes="(max-width: 2048px) 100vw, 2048px" /></p>
<p>“The amount of energy we save, the amount of networking bandwidth we save, the amount of wasted time we save, will be tremendous,” Huang said. “The future is generative &#8230; which is why this is a brand new industry. The way we compute is fundamentally different. We created a processor for the generative AI era.”</p>
<p>To scale up Blackwell, NVIDIA built a new chip called NVLink Switch. Each can connect four NVLink interconnects at 1.8 terabytes per second and eliminate traffic by doing in-network reduction.</p>
<p>NVIDIA Switch and GB200 are key components of what Huang described as “one giant GPU,” the <a href="https://developer.nvidia.com/blog/nvidia-gb200-nvl72-delivers-trillion-parameter-llm-training-and-real-time-inference/">NVIDIA GB200 NVL72</a>, a multi-node, liquid-cooled, rack-scale system that harnesses Blackwell to offer supercharged compute for trillion-parameter models, with 720 petaflops of AI training performance and 1.4 exaflops of AI inference performance in a single rack.</p>
<p>“There are only a couple, maybe three exaflop machines on the planet as we speak,” Huang said of the machine, which packs 600,000 parts and weighs 3,000 pounds. “And so this is an exaflop AI system in one single rack. Well let’s take a look at the back of it.”</p>
<p>Going even bigger, NVIDIA today also announced its next-generation AI supercomputer — the <a href="https://www.nvidia.com/en-us/data-center/dgx-superpod-gb200/">NVIDIA DGX SuperPOD powered by NVIDIA GB200 Grace Blackwell Superchips</a> — for processing trillion-parameter models with constant uptime for superscale generative AI training and inference workloads.</p>
<p>Featuring a new, highly efficient, liquid-cooled rack-scale architecture, the new DGX SuperPOD is built with NVIDIA DG GB200 systems and provides 11.5 exaflops of AI supercomputing at FP4 precision and 240 terabytes of fast memory — scaling to more with additional racks.</p>
<p>“In the future, data centers are going to be thought of &#8230; as AI factories,” Huang said. “Their goal in life is to generate revenues, in this case, intelligence.”</p>
<p>The industry has already embraced Blackwell.</p>
<p>The <a href="https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing">press release announcing Blackwell</a> includes endorsements from Alphabet and Google CEO Sundar Pichai, Amazon CEO Andy Jassy, Dell CEO Michael Dell, Google DeepMind CEO Demis Hassabis, Meta CEO Mark Zuckerberg, Microsoft CEO Satya Nadella, OpenAI CEO Sam Altman, Oracle Chairman Larry Ellison, and Tesla and xAI CEO Elon Musk.</p>
<p>Blackwell is being adopted by every major global cloud services provider,  pioneering AI companies, system and server vendors, and regional cloud service providers and telcos all around the world.</p>
<p>“The whole industry is gearing up for Blackwell,” which Huang said would be the most successful launch in the company’s history.</p>
<h2>A New Way to Create Software</h2>
<p>Generative AI changes the way applications are written, Huang said.</p>
<p>Rather than writing software, he explained, companies will assemble AI models, give them missions, give examples of work products, review plans and intermediate results.</p>
<p>These packages — NVIDIA NIMs — are built from NVIDIA’s accelerated computing libraries and generative AI models, Huang explained.</p>
<p>“How do we build software in the future? It is unlikely that you’ll write it from scratch or write a whole bunch of Python code or anything like that,” Huang said. “It is very likely that you assemble a team of AIs.”</p>
<p>The microservices support industry-standard APIs so they are easy to connect, work across NVIDIA’s large CUDA installed base, are re-optimized for new GPUs, and are constantly scanned for security vulnerabilities and exposures.</p>
<p>Huang said customers can use NIM microservices off the shelf, or NVIDIA can help build proprietary AI and copilots, teaching a model specialized skills only a specific company would know to create invaluable new services.</p>
<p>“The enterprise IT industry is sitting on a goldmine,” Huang said. “They have all these amazing tools (and data) that have been created over the years. If they could take that goldmine and turn it into copilots, these copilots can help us do things.”</p>
<p>Major tech players are already putting it to work. Huang detailed how NVIDIA is already helping Cohesity, NetApp, SAP, ServiceNow and Snowflake build copilots and virtual assistants. And industries are stepping in, as well.</p>
<p>In telecom, Huang announced the NVIDIA 6G Research Cloud, a generative AI and Omniverse-powered platform to advance the next communications era. It’s built with NVIDIA’s Sionna neural radio framework, NVIDIA Aerial CUDA-accelerated radio access network and the NVIDIA Aerial Omniverse Digital Twin for 6G.</p>
<p>In semiconductor design and manufacturing, Huang announced that, in collaboration with TSMC and Synopsys, NVIDIA is bringing its breakthrough computational lithography platform, cuLitho, to production. This platform will accelerate the most compute-intensive workload in semiconductor manufacturing by 40-60x.</p>
<p>Huang also announced the NVIDIA Earth Climate Digital Twin. The cloud platform — available now — enables interactive, high-resolution simulation to accelerate climate and weather prediction.</p>
<p>The greatest impact of AI will be in healthcare, Huang said, explaining that NVIDIA is already in imaging systems, in gene sequencing instruments and working with leading surgical robotics companies.</p>
<p>NVIDIA is launching a new type of biology software. NVIDIA today launched more than <a href="https://nvidianews.nvidia.com/news/generative-ai-microservices-for-developers">two dozen new microservices</a> that allow healthcare enterprises worldwide to take advantage of the latest advances in generative AI from anywhere and on any cloud. They offer advanced imaging, natural language and speech recognition, and digital biology generation, prediction and simulation.</p>
<h2>Omniverse Brings AI to the Physical World</h2>
<p>The next wave of AI will be AI learning about the physical world, Huang said.</p>
<p>“We need a simulation engine that represents the world digitally for the robot so that the robot has a gym to go learn how to be a robot,” he said. “We call that virtual world Omniverse.”</p>
<p>That’s why NVIDIA today announced that <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse Cloud</a> will be available as APIs, extending the reach of the world’s leading platform for creating industrial digital twin applications and workflows across the entire ecosystem of software makers.</p>
<p>The five new Omniverse Cloud application programming interfaces enable developers to easily integrate core Omniverse technologies directly into existing design and automation software applications for digital twins, or their simulation workflows for testing and validating autonomous machines like robots or self-driving vehicles.</p>
<p>To show how this works, Huang shared a demo of a robotic warehouse — using multi-camera perception and tracking — watching over workers and orchestrating robotic forklifts, which are driving autonomously with the full robotic stack running.</p>
<p>Huang also announced that NVIDIA is bringing Omniverse to Apple Vision Pro, with the new Omniverse Cloud APIs letting developers stream interactive industrial digital twins into the VR headsets.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-70574" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/MJC_2441-2-scaled.jpg" alt="" width="2048" height="1365" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/MJC_2441-2-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MJC_2441-2-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MJC_2441-2-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MJC_2441-2-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MJC_2441-2-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MJC_2441-2-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MJC_2441-2-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MJC_2441-2-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MJC_2441-2-1280x853.jpg 1280w" sizes="(max-width: 2048px) 100vw, 2048px" /></p>
<p>Some of the world’s largest industrial software makers are embracing Omniverse Cloud APIs, including Ansys, Cadence, Dassault Systèmes for its 3DEXCITE brand, Hexagon, Microsoft, Rockwell Automation, Siemens and Trimble.</p>
<h2>Robotics</h2>
<p>Everything that moves will be robotic, Huang said. The automotive industry will be a big part of that. NVIDIA computers are already in cars, trucks, delivery bots and robotaxis.</p>
<p>Huang announced that BYD, the world’s largest autonomous vehicle company, has selected NVIDIA’s next-generation computer for its AV, building its next-generation EV fleets on DRIVE Thor.</p>
<p>To help robots better see their environment, Huang also announced the Isaac Perceptor software development kit with state-of-the-art multi-camera visual odometry, 3D reconstruction and occupancy map, and depth perception.</p>
<p>And to help make manipulators, or robotic arms, more adaptable, NVIDIA is announcing Isaac Manipulator — a state-of-the-art robotic arm perception, path planning and kinematic control library.</p>
<p>Finally, Huang announced Project GR00T, a general-purpose foundation model for humanoid robots, designed to further the company’s work driving breakthroughs in robotics and embodied AI.</p>
<p>Supporting that effort, Huang unveiled a new computer, Jetson Thor, for humanoid robots based on the NVIDIA Thor system-on-a-chip and significant upgrades to the NVIDIA Isaac robotics platform.</p>
<p>In his closing minutes, Huang brought on stage a pair of diminutive NVIDIA-powered robots from Disney Research.</p>
<p>“The soul of NVIDIA — the intersection of computer graphics, physics, artificial intelligence,” he said. “It all came to bear at this moment.”</p>
<p><iframe loading="lazy" title="YouTube video player" src="https://www.youtube.com/embed/Y2F8yisiS6E?si=b9Y8b7x-sTGY4n-J" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/VIVY0672-1-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1365"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/VIVY0672-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[GTC Wrap-Up: ‘We Created a Processor for the Generative AI Era,’ NVIDIA CEO Says]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>All Aboard: NVIDIA Scores 23 World Records for Route Optimization</title>
		<link>https://blogs.nvidia.com/blog/cuopt-route-optimization-metropolis-omniverse/</link>
		
		<dc:creator><![CDATA[Moon Chung]]></dc:creator>
		<pubDate>Mon, 18 Mar 2024 22:10:56 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[NVIDIA Jetson]]></category>
		<category><![CDATA[Omniverse]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70263</guid>

					<description><![CDATA[With nearly two dozen world records to its name, NVIDIA cuOpt now holds the top spot for 100% of the largest routing benchmarks in the last three years. And this means the route optimization engine allows industries to hop on board for all kinds of cost-saving efficiencies. Kawasaki Heavy Industries and SyncTwin are among the		<a class="read-more" href="https://blogs.nvidia.com/blog/cuopt-route-optimization-metropolis-omniverse/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>With nearly two dozen world records to its name, <a href="https://www.nvidia.com/en-us/ai-data-science/products/cuopt/">NVIDIA cuOpt</a> now holds the top spot for 100% of the largest routing benchmarks in the last three years. And this means the route optimization engine allows industries to hop on board for all kinds of cost-saving efficiencies.</p>
<p><a href="https://global.kawasaki.com/">Kawasaki Heavy Industries</a> and SyncTwin are among the companies that are riding cuOpt for logistics improvements.</p>
<p>Today at GTC 2024, NVIDIA founder and CEO Jensen Huang announced that cuOpt is moving into general availability.</p>
<p>“With cuOpt, NVIDIA is reinventing logistics management and operations research. It is NVIDIA’s pre-quantum computer, driving transformational operational efficiencies for deliveries, service calls, warehouses and factories, and supply chains,” he said.</p>
<p>The NVIDIA cuOpt microservice, part of the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> software platform, makes accelerated optimization for real-time dynamic rerouting, factory optimization and robotic simulations available to any organization.</p>
<p>Companies can embed cuOpt into the advanced 3D tools, applications and USD-based workflows they develop with <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, a software platform for developing and deploying advanced 3D applications and pipelines based on OpenUSD.</p>
<p>Implemented together, cuOpt, Omniverse and <a href="https://developer.nvidia.com/metropolis-for-factories">NVIDIA Metropolis for Factories</a> can help optimize and create safe environments in logistics-heavy facilities that rely on complex automation, precise material flow and human-robot interaction, such as automotive factories, semiconductor fabs and warehouses.</p>
<p>cuOpt has been continuously tested against the best-known solutions on the most studied benchmarks for route optimization, with results up to 100x faster than CPU-based implementations. With 15 records from the Gehring &amp; Homberger vehicle routing benchmark and eight from the Li &amp; Lim pickup and delivery benchmark, cuOpt has demonstrated the world’s best accuracy with the fastest times.</p>
<p>AI promises to deliver logistics efficiencies spanning from transportation networks to manufacturing and much more.</p>
<h2><b>Delivering Cost-Savings for Inspections With cuOpt</b></h2>
<p><a href="https://global.kawasaki.com/">Kawasaki Heavy Industries</a> is a manufacturing company that&#8217;s been building large machinery for more than a hundred years. The Japanese company partnered with Slalom and <a href="https://www.nvidia.com/en-us/case-studies/reinventing-maintenance-operations-with-ai/">used cuOpt to create routing efficiencies</a> for the development of its AI-driven <a href="https://global.kawasaki.com/">Kawasaki Track Maintenance Platform</a>.</p>
<p>Railroad track maintenance is getting an <a href="https://blogs.nvidia.com/blog/autonomous-trains-deep-learning-dgx-drive/">AI makeover worldwide</a>. Traditionally, track inspections and maintenance are time-consuming and difficult to manage to keep trains running on time. But track maintenance is critical for safety and transportation service. Railway companies are automating track inspections with AI and machine learning paired with digital cameras, lasers and gyrometric sensors.</p>
<p><a href="https://global.kawasaki.com/">Kawasaki</a> is harnessing the edge computing of <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">NVIDIA Jetson AGX Orin</a> to develop track inspections on its Track Maintenance Platform for running onboard trains. The platform enables customers to improve vision models with the data collected on tracks for advances in the inspection capability of the edge-based AI system.</p>
<p>The platform provides maintenance teams data on track conditions that allows them to prioritize repairs, creating increased safety and reliability of operations.</p>
<p>According to <a href="https://global.kawasaki.com/">Kawasaki</a>, it’s estimated that such an AI-driven system can save $218 million a year for seven companies from automating their track inspections.</p>
<h2><b>Creating Manufacturing Efficiencies With cuOpt and Omniverse</b></h2>
<p>A worldwide leader in automotive seating manufacturing has adopted SyncTwin’s digital twin capability, which is driven by Omniverse and cuOpt, to improve its operations with AI.</p>
<p>The global automotive seating manufacturer has a vast network of loading docks for the delivery of raw materials, and forklifts for unloading and transporting them to storage and handling areas to ensure a steady supply to production lines. SyncTwin’s connection to cuOpt delivers routing efficiencies that optimize all of these moving parts — from vehicles to robotic pallet jacks.</p>
<p>As the SyncTwin solution was developed on top of Omniverse and USD, manufacturers can ensure that their various factory planning tools can contribute to the creation of a rich <a href="https://blogs.nvidia.com/blog/what-is-a-digital-twin/">digital twin</a> environment. Plus, they eliminate tedious manual data collection and gain new insights from their previously disconnected data.</p>
<p><a href="https://www.nvidia.com/gtc/session-catalog/?search=%22cuopt%22&amp;tab.allsessions=1700692987788001F1cG#/"><em>Attend GTC</em></a><em> to explore how cuOpt is achieving world-record accuracy and performance to solve complex problems. Learn more about cuOpt world records in our tech blog. <a href="https://www.nvidia.com/en-us/omniverse/">Learn more</a></em><em> about</em> Omniverse.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/gtc24-cuopt-corp-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/gtc24-cuopt-corp-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[All Aboard: NVIDIA Scores 23 World Records for Route Optimization]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>All Eyes on AI: Automotive Tech on Full Display at GTC 2024</title>
		<link>https://blogs.nvidia.com/blog/automotive-tech-gtc-2024/</link>
		
		<dc:creator><![CDATA[Danny Shapiro]]></dc:creator>
		<pubDate>Mon, 18 Mar 2024 22:06:31 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70515</guid>

					<description><![CDATA[All eyes across the auto industry are on GTC — the global AI conference running in San Jose, Calif., and online through Thursday, March 21 — as the world&#8217;s top automakers and tech leaders converge to showcase the latest models, demo new technologies and dive into the remarkable innovations reshaping the sector. Attendees will experience		<a class="read-more" href="https://blogs.nvidia.com/blog/automotive-tech-gtc-2024/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>All eyes across the auto industry are on <a href="https://www.nvidia.com/gtc/">GTC</a> — the global AI conference running in San Jose, Calif., and online through Thursday, March 21 — as the world&#8217;s top automakers and tech leaders converge to showcase the latest models, demo new technologies and dive into the remarkable innovations reshaping the sector.</p>
<p>Attendees will experience how generative AI and software-defined computing are advancing the automotive landscape and transforming the behind-the-wheel experience to become safer, smarter and more enjoyable.</p>
<h2><b>Automakers Adopting NVIDIA DRIVE Thor</b></h2>
<p>NVIDIA founder and CEO Jensen Huang kicked off GTC with a keynote address in which he revealed that NVIDIA DRIVE Thor, which combines advanced driver assistance technology and in-vehicle infotainment, now features the newly announced NVIDIA Blackwell GPU architecture for transformer and generative AI workloads.</p>
<p>Following the keynote, top EV makers shared how they will integrate <a href="https://nvidianews.nvidia.com/news/nvidia-drive-powers-next-generation-transportation">DRIVE Thor</a> into their vehicles. <b>BYD</b>, the world’s largest electric vehicle maker, is expanding its ongoing collaboration with NVIDIA and building its next-generation EV fleets on DRIVE Thor. <b>Hyper</b>, a premium luxury brand owned by GAC AION, is announcing it has selected DRIVE Thor for its new models, which will begin production in 2025. <b>XPENG </b>will use DRIVE Thor as the AI brain of its next-generation EV fleets. These EV makers join <b>Li Auto</b> and<b> ZEEKR</b>, which previously announced they’re building their future vehicle roadmaps on DRIVE Thor.</p>
<p>Additionally, trucking, robotaxis and goods delivery vehicle makers are announcing support for DRIVE Thor. <b>Nuro</b> is choosing DRIVE Thor to power the Nuro Driver. <b>Plus</b> is announcing that future generations of its level 4 solution, SuperDrive, will run on DRIVE Thor. <b>Waabi</b> is  leveraging DRIVE Thor to deliver the first generative AI-powered autonomous trucking solution to market. <b>WeRide</b>, in cooperation with tier 1 partner Lenovo Vehicle Computing, is creating level 4 autonomous driving solutions for commercial applications built on DRIVE Thor.</p>
<p>And, <b>DeepRoute.ai</b> is unveiling its new smart driving architecture powered by NVIDIA DRIVE Thor, scheduled to launch next year.</p>
<h2><b>Next-Generation Tech on the Show Floor</b></h2>
<p>The GTC exhibit hall is buzzing with excitement as companies showcase the newest vehicle models and offer technology demonstrations.</p>
<p>Attendees have the opportunity to see firsthand the latest NVIDIA-powered vehicles on display,  including <b>Lucid Air</b>, <b>Mercedes-Benz Concept CLA Class</b>, <b>Nuro R3</b>, <b>Polestar 3</b>,<b> Volvo EX90</b>, <b>WeRide Robobus</b>, and an <b>Aurora</b> truck. The Lucid Air is available for test drives during the week.</p>
<p>A wide array of companies are showcasing innovative automotive technology at GTC, including <b>Foretellix</b>, <b>Luminar</b> and <b>MediaTek</b>, which is launching its <a href="https://blogs.nvidia.com/blog/mediatek-intelligent-cabin-solutions/">Dimensity Auto Cockpit</a> chipsets at the show. The new solutions harness NVIDIA’s graphics and AI technologies to help deliver state-of-the-art in-vehicle user experiences, added safety and security capabilities.</p>
<h2><b>Also Announced at GTC: Omniverse Cloud APIs, Generative AI</b><b><br />
</b></h2>
<ul>
<li><a href="https://nvidianews.nvidia.com/news/omniverse-cloud-apis-industrial-digital-twin">Omniverse Cloud APIs</a>, announced today at NVIDIA GTC, are poised to accelerate the path to autonomy by enabling high-fidelity sensor simulation for AV development and validation. Developers and software vendors such as <b>CARLA</b>, <b>MathWorks</b>, <b>MITRE</b>, <b>Foretellix</b> and <b>Voxel51</b> underscore the broad appeal of these APIs in autonomous vehicles.</li>
<li><a href="https://blogs.nvidia.com/blog/generative-ai-in-vehicle-experiences/">Generative AI developers</a> including <b>Cerence</b>, <b>Geely</b>, <b>Li Auto,</b> <b>NIO,</b> <b>SoundHound</b>, <b>Tata Consulting Services</b> and <b>Wayve</b> announced plans to transform the in-vehicle experience by using NVIDIA’s cloud-to-edge technology to help develop intelligent AI assistants, driver and passenger monitoring, scene understanding and more.</li>
</ul>
<h2><b>AI and Automotive Sessions Available Live and on Demand</b><b><br />
</b></h2>
<p>Throughout the week<b>, </b>the world’s foremost experts on automotive technology will lead a broad array of sessions and panels at GTC, including:</p>
<ul>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62464&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/">How LLMs and Generative AI Will Enhance the Way We Experience Self-Driving Cars<br />
</a><i>Tuesday, March 19, 9 a.m. PT</i></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=s62621&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/">Accelerating the New Era of Autonomous Vehicles With Generative AI<br />
</a><i>Tuesday, March 19, 10 a.m. PT</i></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62380&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/">Generative AI and Industrial Digitalization in the Automotive Industry<br />
</a><i>Tuesday, March 19, 2 p.m. PT</i></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62804&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/">Accelerating Automotive Workflows With Large Language Models<br />
</a><i>Tuesday, March 19, 3 p.m. PT</i></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=SE63001&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/">Accelerating the Shift to AI-Defined Vehicles<b><br />
</b></a><i>Thursday, March 21, 8 a.m. PT</i></li>
</ul>
<p>On <a href="https://www.nvidia.com/gtc/sessions/drive-developer-day/">DRIVE Developer Day</a>, taking place Thursday, March 21, NVIDIA’s engineering experts will highlight the latest DRIVE features and developments through a series of deep-dive sessions on how to build safe and robust self-driving systems.</p>
<p>See the full schedule of <a href="https://images.nvidia.com/nvimages/gtc/pdf/GTC24_March_Automotive_Brochure.pdf">automotive programming at GTC</a> and be sure to tune in.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/auto-gtc.jpeg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/auto-gtc-842x450.jpeg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[All Eyes on AI: Automotive Tech on Full Display at GTC 2024]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Generative AI Developers Harness NVIDIA Technologies to Transform In-Vehicle Experiences</title>
		<link>https://blogs.nvidia.com/blog/generative-ai-in-vehicle-experiences/</link>
		
		<dc:creator><![CDATA[Norm Marks]]></dc:creator>
		<pubDate>Mon, 18 Mar 2024 22:05:45 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70475</guid>

					<description><![CDATA[Cars of the future will be more than just modes of transportation; they’ll be intelligent companions, seamlessly blending technology and comfort to enhance driving experiences, and built for safety, inside and out. NVIDIA GTC, running this week at the San Jose Convention Center, will spotlight the groundbreaking work NVIDIA and its partners are doing to		<a class="read-more" href="https://blogs.nvidia.com/blog/generative-ai-in-vehicle-experiences/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Cars of the future will be more than just modes of transportation; they’ll be intelligent companions, seamlessly blending technology and comfort to enhance driving experiences, and built for safety, inside and out.</p>
<p><a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>, running this week at the San Jose Convention Center, will spotlight the groundbreaking work NVIDIA and its partners are doing to bring the transformative power of <a href="https://www.nvidia.com/en-us/glossary/generative-ai/#:~:text=Generative%20AI%20enables%20users%20to,or%20other%20types%20of%20data.">generative AI</a>, <a href="https://www.nvidia.com/en-us/glossary/large-language-models/">large language models</a> and visual language models to the mobility sector.</p>
<p>At its booth, NVIDIA will showcase how it’s building automotive assistants to enhance driver safety, security and comfort through enhanced perception, understanding and generative capabilities powered by deep learning and transformer models.</p>
<h2><b>Talking the Talk</b></h2>
<p><a href="https://www.nvidia.com/en-us/deep-learning-ai/solutions/large-language-models/">LLMs</a>, a form of generative AI, largely represent a class of deep-learning architectures known as <a href="https://blogs.nvidia.com/blog/what-is-a-transformer-model/">transformer models</a>, which are neural networks adept at learning context and meaning.</p>
<p>Vision language models are another derivative of generative AI, that offer image processing and language understanding capabilities. Unlike traditional or multimodal LLMs that primarily process and generate text-based data, VLMs can analyze and generate text via images or videos.</p>
<p>And <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">retrieval-augmented generations</a> allows manufacturers to access knowledge from a specific database or the web to assist drivers.</p>
<p>These technologies together enable <a href="https://developer.nvidia.com/ace">NVIDIA Avatar Cloud Engine</a>, or ACE, and multimodal language models to work together with the <a href="https://developer.nvidia.com/drive">NVIDIA DRIVE</a> platform to let automotive manufacturers develop their own intelligent in-car assistants.</p>
<p>For example, an Avatar configurator can allow designers to build unique, brand-inspired personas for their cars, complete with customized voices and emotional attributes. These AI-animated avatars can engage in natural dialogue, providing real-time assistance, recommendations and personalized interactions.</p>
<p>Furthermore, AI-enhanced surround visualization enhances vehicle safety using 360-degree camera reconstruction, while the intelligent assistant sources external information, such as local driving laws, to inform decision-making.</p>
<p>Personalization is paramount, with AI assistants learning driver and passenger habits and adapting its behavior to suit occupants’ needs.</p>
<h2><b>Generative AI for Automotive in Full Force at GTC </b></h2>
<p>Several NVIDIA partners at GTC are also showcasing their latest generative AI developments using NVIDIA’s edge-to-cloud technology:</p>
<ul>
<li><b>Cerence’s</b> CaLLM is an automotive-specific LLM that serves as the foundation for the company’s next-gen in-car computing platform, running on NVIDIA DRIVE. The platform, unveiled late last year, is the future of in-car interaction, with an automotive- and mobility-specific assistant that provides an integrated in-cabin experience. Cerence is collaborating with NVIDIA engineering teams for deeper integration of CaLLM with the <a href="https://www.nvidia.com/en-us/ai-data-science/foundation-models/">NVIDIA AI Foundation Models</a>. Through joint efforts, Cerence is harnessing <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a> as the development platform, applying guardrails for enhanced performance, and leveraging <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> to optimize inference. NVIDIA and Cerence will continue to partner and pioneer this solution together with several automotive OEMs this year.</li>
<li><b>Wavye</b> is helping usher in the new era of Embodied AI for autonomy, their next-generation AV2.0 approach is characterized by a large Embodied AI foundation model that learns to drive self-supervised using AI end-to-end —from sensing, as an input, to outputting driving actions. The British startup has already unveiled its GAIA-1, a generative world model for AV development running on NVIDIA; alongside LINGO-1, a closed-loop driving commentator that uses natural language to enhance the learning and explainability of AI driving models.</li>
<li><b>Li Auto</b> unveiled its multimodal cognitive model, Mind GPT, in June. Built on <a href="https://developer.nvidia.com/tensorrt">NVIDIA TensorRT-LLM</a>, an open-source library, it serves as the basis for the electric vehicle maker’s AI assistant, Lixiang Tongxue, for scene understanding, generation, knowledge retention and reasoning capabilities. Li Auto is currently developing DriveVLM to enhance autonomous driving capabilities, enabling the system to understand complex scenarios, particularly those that are challenging for traditional AV pipelines, such as unstructured roads, rare and unusual objects, and unexpected traffic events. This advanced model is trained on the NVIDIA GPUs and utilizes TensorRT-LLM and <a href="https://developer.nvidia.com/triton-inference-server">NVIDIA Triton Inference Server</a> for data generation in the data center. With inference optimized by NVIDIA DRIVE and TensorRT-LLM, DriveVLMs perform efficiently on embedded systems.</li>
<li><b>NIO</b> launched its NOMI GPT, which offers a number of functional experiences, including NOMI Encyclopedia Q&amp;A, Cabin Atmosphere Master and Vehicle Assistant. With the capabilities enabled by LLMs and an efficient computing platform powered by NVIDIA AI stacks, NOMI GPT is capable of basic speech recognition and command execution functions and can use deep learning to understand and process more complex sentences and instructions inside the car.</li>
<li><b>Geely</b> is working with NVIDIA to provide intelligent cabin experiences, along with accelerated edge-to-cloud deployment. Specifically, Geely is applying generative AI and LLM technology to provide smarter, personalized and safer driving experiences, using natural language processing, dialogue systems and predictive analytics for intelligent navigation and voice assistants. When deploying LLMs into production, Geely uses NVIDIA TensorRT-LLM to achieve highly efficient inference. For more complex tasks or scenarios requiring massive data support, Geely plans to deploy large-scale models in the cloud.</li>
<li><b>Waabi</b> is building AI for self-driving and will use the generative AI capabilities afforded by NVIDIA DRIVE Thor for its breakthrough autonomous trucking solutions, bringing safe and reliable autonomy to the trucking industry.</li>
<li><b>Lenovo</b> is unveiling a new AI acceleration engine, dubbed UltraBoost, which will run on NVIDIA DRIVE, and features an AI model engine and AI compiler tool chains to facilitate the deployment of LLMs within vehicles.</li>
<li><b>SoundHound AI</b> is using NVIDIA to run its in-vehicle voice interface — which combines both real-time and generative AI capabilities — even when a vehicle has no cloud connectivity. This solution also offers drivers access to SoundHound’s Vehicle Intelligence product, which instantly delivers settings, troubleshooting and other information directly from the car manual and other data sources via natural speech, as opposed to through a physical document.</li>
<li><b>Tata Consultancy Services</b> (part of the TATA Group), through its AI-based technology and engineering innovation, has built its automotive GenAI suite powered by NVIDIA GPUs and software frameworks. It accelerates the design, development, and validation of software-defined vehicles, leveraging the various LLMs and VLMs for in-vehicle and cloud-based systems.</li>
<li><b>MediaTek</b> is announcing four automotive systems-on-a-chip within its Dimensity Auto Cockpit portfolio, offering powerful AI-based in-cabin experiences for the next generation of intelligent vehicles that span from premium to entry level. To support deep learning capabilities, the Dimensity Auto Cockpit chipsets integrate NVIDIA’s next-gen GPU-accelerated AI computing and <a href="https://www.nvidia.com/en-us/design-visualization/technologies/rtx/">NVIDIA RTX</a>-powered graphics to run LLMs in the car, allowing vehicles to support chatbots, rich content delivery to multiple displays, driver alertness detection and other AI-based safety and entertainment applications.</li>
</ul>
<p>Check out the many <a href="https://images.nvidia.com/nvimages/gtc/pdf/GTC24_March_Automotive_Brochure.pdf">automotive talks</a> on generative AI and LLMs throughout the week of GTC.</p>
<p><a href="https://www.nvidia.com/gtc/?ncid=GTC-NVHWQQGN">Register today</a> to attend GTC in person, or tune in virtually, to explore how generative AI is making transportation safer, smarter and more enjoyable.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/gen-ai-vehicle.png"
			type="image/png"
			width="1600"
			height="851"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/gen-ai-vehicle-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Generative AI Developers Harness NVIDIA Technologies to Transform In-Vehicle Experiences]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Unveils Digital Blueprint for Building Next-Gen Data Centers</title>
		<link>https://blogs.nvidia.com/blog/omniverse-next-gen-data-center/</link>
		
		<dc:creator><![CDATA[Dion Harris]]></dc:creator>
		<pubDate>Mon, 18 Mar 2024 22:05:17 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Digital Twin]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Universal Scene Description]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70362</guid>

					<description><![CDATA[Designing, simulating and bringing up modern data centers is incredibly complex, involving multiple considerations like performance, energy efficiency and scalability. It also requires bringing together a team of highly skilled engineers across compute and network design, computer-aided design (CAD) modeling, and mechanical, electrical and thermal design. NVIDIA builds the world’s most advanced AI supercomputers and		<a class="read-more" href="https://blogs.nvidia.com/blog/omniverse-next-gen-data-center/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Designing, simulating and bringing up modern data centers is incredibly complex, involving multiple considerations like performance, energy efficiency and scalability.</p>
<p>It also requires bringing together a team of highly skilled engineers across compute and network design, computer-aided design (CAD) modeling, and mechanical, electrical and thermal design.</p>
<p>NVIDIA builds the world’s most advanced AI supercomputers and at GTC unveiled its latest — a large cluster based on the NVIDIA GB200 NVL72 liquid-cooled system. It consists of two racks, each containing 18 <a href="https://www.nvidia.com/en-us/data-center/grace-cpu/">NVIDIA Grace CPUs</a> and 36 <a href="https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing">NVIDIA Blackwell GPUs</a>, connected by fourth-generation <a href="https://www.nvidia.com/en-us/data-center/nvlink/">NVIDIA NVLink</a> switches.</p>
<p>On the show floor, NVIDIA demoed this fully operational data center as a <a href="https://blogs.nvidia.com/blog/what-is-a-digital-twin/">digital twin</a> in <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, a platform for connecting and building generative AI-enabled 3D pipelines, tools, applications and services.</p>
<p>To bring up new data centers as fast as possible, NVIDIA first built its digital twin with software tools connected by Omniverse. Engineers unified and visualized multiple CAD datasets in full physical accuracy and photorealism in <a href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description</a> (OpenUSD) using the <a href="https://www.cadence.com/en_US/home.html" target="_blank" rel="noopener">Cadence</a> Reality digital twin platform, powered by NVIDIA Omniverse APIs.</p>
<p><iframe loading="lazy" title="Accelerating Data Center Design With Digital Twins" width="500" height="281" src="https://www.youtube.com/embed/h68kXLIRilM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Design, Simulate and Optimize With Enhanced Efficiency and Accuracy</b></h2>
<p>The new GB200 cluster is replacing an existing cluster in one of NVIDIA’s legacy data centers. To start the digital build-out, technology company <a href="https://kinetic-vision.com/" target="_blank" rel="noopener">Kinetic Vision</a> scanned the facility using the <a href="https://www.navvis.com/vlx" target="_blank" rel="noopener">NavVis VLX wearable lidar scanner</a> to produce highly accurate point cloud data and panorama photos.</p>
<p>Then, <a href="https://www.prevu3d.com/solutions/realitymesh-omniverse/" target="_blank" rel="noopener">Prevu3D</a> software was used to remove the existing clusters and convert the point cloud to a 3D mesh. This provided a physically accurate 3D model of the facility, in which the new digital data center could be simulated.</p>
<p>Engineers combined and visualized multiple CAD datasets with enhanced precision and realism by using the Cadence Reality platform. The platform’s integration with Omniverse provided a powerful computing platform that enabled teams to develop OpenUSD-based 3D tools, workflows and applications.</p>
<p><a href="https://nvidianews.nvidia.com/news/omniverse-cloud-apis-industrial-digital-twin">Omniverse Cloud APIs</a> also added interoperability with more tools, including PATCH MANAGER and NVIDIA Air. With PATCH MANAGER, the team designed the physical layout of their cluster and networking infrastructure, ensuring that cabling lengths were accurate and routing was properly configured.</p>
<p>The team used Cadence’s Reality Digital Twin solvers, accelerated by <a href="https://developer.nvidia.com/modulus">NVIDIA Modulus</a> APIs and NVIDIA Grace Hopper, to simulate airflows, as well as the performance of the new liquid-cooling systems from partners like Vertiv and Schneider Electric. The integrated cooling systems in the GB200 trays were simulated and optimized using solutions from Ansys, which brought simulation data into the digital twin.</p>
<p>The demo showed how digital twins can allow users to fully test, optimize and validate data center designs before ever producing a physical system. By visualizing the performance of the data center in the digital twin, teams can better optimize their designs and plan for what-if scenarios.</p>
<p>Users can also enhance data center and cluster designs by balancing disparate sets of boundary conditions, such as cabling lengths, power, cooling and space, in an integrated manner — enabling engineers and design teams to bring clusters online much faster and with more efficiency and optimization than before.</p>
<p>Learn more about <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> and <a href="https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing">NVIDIA Blackwell</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/gtc-ov-corp-blog-announcement-cadence-1280x680-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/gtc-ov-corp-blog-announcement-cadence-1280x680-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Unveils Digital Blueprint for Building Next-Gen Data Centers]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>New NVIDIA Storage Partner Validation Program Streamlines Enterprise AI Deployments</title>
		<link>https://blogs.nvidia.com/blog/ovx-storage-partner-validation-program/</link>
		
		<dc:creator><![CDATA[Jason Schroedl]]></dc:creator>
		<pubDate>Mon, 18 Mar 2024 22:00:48 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70358</guid>

					<description><![CDATA[A sharp increase in generative AI deployments is driving business innovation for enterprises across industries. But it’s also posing significant challenges for their IT teams, as slowdowns from long and complex infrastructure deployment cycles prevent them from quickly spinning up AI workloads using their own data. To help overcome these barriers, NVIDIA has introduced a		<a class="read-more" href="https://blogs.nvidia.com/blog/ovx-storage-partner-validation-program/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>A sharp increase in generative AI deployments is driving business innovation for enterprises across industries. But it’s also posing significant challenges for their IT teams, as slowdowns from long and complex infrastructure deployment cycles prevent them from quickly spinning up AI workloads using their own data.</p>
<p>To help overcome these barriers, NVIDIA has introduced a storage partner validation program for <a href="https://www.nvidia.com/en-us/omniverse/platform/ovx/">NVIDIA OVX computing systems</a>. The high-performance storage systems leading the way in completing the NVIDIA OVX storage validation are <a href="https://www.ddn.com/blog/ddn-expands-support-for-nvidia-technology-to-enable-ai-application-acceleration-for-data-center-infrastructure/">DDN</a>, Dell PowerScale, <a href="https://www.netapp.com/blog/the-ai-revolution-netapp-aipod-with-nvidia-ovx/">NetApp</a>, <a href="https://www.purestorage.com/company/newsroom/press-releases/pure-and-nvidia-accelerate-enterprise-ai-adoption-to-meet-growing-demands.html">Pure Storage</a> and <a href="https://www.weka.io/blog/ai-ml/accelerating-ai-workloads-wekas-role-in-storage-partner-validation-for-nvidia-ovx-solutions/">WEKA</a>.</p>
<p>NVIDIA OVX servers combine high-performance, GPU-accelerated compute with high-speed storage access and low-latency networking to address a range of complex AI and graphics-intensive workloads. Chatbots, summarization and search tools, for example, require large amounts of data, and high-performance storage is critical to maximize system throughput.</p>
<p>To help enterprises pair the right storage with NVIDIA-Certified OVX servers, the new program provides a standardized process for partners to validate their storage appliances. They can use the same framework and testing that’s needed to validate storage for the <a href="https://www.nvidia.com/en-sg/data-center/dgx-basepod/">NVIDIA DGX BasePOD</a> reference architecture.</p>
<p>To achieve validation, partners must complete a suite of NVIDIA tests measuring storage performance and input/out scaling across multiple parameters that represent the demanding requirements of various enterprise AI workloads. This includes combinations of different I/O sizes, varying numbers of threads, buffered I/O vs. direct I/O, random reads, re-reads and more.</p>
<p>Each test is run multiple times to verify the results and gather the required data, which is then audited by NVIDIA engineering teams to determine whether the storage system has passed.</p>
<p>The program offers prescriptive guidance to ensure optimal storage performance and scalability for enterprise AI workloads with NVIDIA OVX systems. But the overall design remains flexible, so customers can tailor their system and storage choices to fit their existing data center environments and bring accelerated computing to wherever their data resides.</p>
<p>Generative AI use cases have fundamentally different requirements than traditional enterprise applications, so IT teams must carefully consider their compute, networking, storage and software choices to ensure high performance and scalability.</p>
<p><a href="https://www.nvidia.com/en-us/data-center/products/certified-systems/">NVIDIA-Certified Systems</a> are tested and validated to provide enterprise-grade performance, manageability, security and scalability for AI workloads. Their flexible reference architectures help deliver faster, more efficient and more cost-effective deployments than independently building from the ground up.</p>
<p>Powered by<a href="https://www.nvidia.com/en-us/data-center/l40s/"> NVIDIA L40S GPUs</a>, OVX servers include<a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/"> NVIDIA AI Enterprise</a> software with <a href="https://www.nvidia.com/en-us/networking/quantum2/">NVIDIA Quantum-2 InfiniBand</a> or<a href="https://www.nvidia.com/en-us/networking/spectrumx/"> NVIDIA Spectrum-X</a> Ethernet networking, as well as<a href="https://www.nvidia.com/en-us/networking/products/data-processing-unit/"> NVIDIA BlueField-3 DPUs</a>. They’re optimized for generative AI workloads, including training for smaller LLMs (for example, Llama 2 7B or 70B), fine-tuning existing models and inference with high throughput and low latency.</p>
<p><a href="https://docs.nvidia.com/certification-programs/nvidia-certified-systems/index.html#nvidia-certified-systems-ovx-list">NVIDIA-Certified OVX servers</a> are now available and shipping from global system vendors, including GIGABYTE, Hewlett Packard Enterprise and <a href="https://news.lenovo.com/pressroom/press-releases/lenovo-unveils-hybrid-ai-solutions-delivering-power-of-generative-ai-to-enterprises-with-nvidia">Lenovo</a>. Comprehensive, enterprise-grade support for these servers is provided by each system builder, in collaboration with NVIDIA.</p>
<h2><b>Availability </b></h2>
<p>Validated storage solutions for NVIDIA-Certified OVX servers are now available, and reference architectures will be published over the coming weeks by each of the storage and system vendors. Learn more about <a href="https://www.nvidia.com/en-us/data-center/products/ovx/">NVIDIA OVX Systems</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/ovx-keynote-blog-header.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/ovx-keynote-blog-header-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[New NVIDIA Storage Partner Validation Program Streamlines Enterprise AI Deployments]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>From Atoms to Supercomputers: NVIDIA, Partners Scale Quantum Computing</title>
		<link>https://blogs.nvidia.com/blog/cuda-q-ecosystem/</link>
		
		<dc:creator><![CDATA[Elica Kyoseva]]></dc:creator>
		<pubDate>Mon, 18 Mar 2024 22:00:47 +0000</pubDate>
				<category><![CDATA[Supercomputing]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Customer Stories]]></category>
		<category><![CDATA[Financial Services]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[New GPU Uses]]></category>
		<category><![CDATA[Science]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70242</guid>

					<description><![CDATA[The latest advances in quantum computing include investigating molecules, deploying giant supercomputers and building the quantum workforce with a new academic program. Researchers in Canada and the U.S. used a large language model to simplify quantum simulations that help scientists explore molecules. “This new quantum algorithm opens the avenue to a new way of combining		<a class="read-more" href="https://blogs.nvidia.com/blog/cuda-q-ecosystem/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The latest advances in quantum computing include investigating molecules, deploying giant supercomputers and building the quantum workforce with a new academic program.</p>
<p>Researchers in Canada and the U.S. used a large language model to simplify quantum simulations that help scientists explore molecules.</p>
<p>“This new quantum algorithm opens the avenue to a new way of combining quantum algorithms with machine learning,” said Alan Aspuru-Guzik, a professor of chemistry and computer science at the University of Toronto, who led the team.</p>
<p>The effort used <a href="https://developer.nvidia.com/cuda-q">CUDA-Q</a>, a hybrid programming model for GPUs, CPUs and the <a href="https://blogs.nvidia.com/blog/what-is-a-qpu/">QPUs</a> quantum systems use. The team ran its research on <a href="https://blogs.nvidia.com/blog/eos/">Eos</a>, NVIDIA’s H100 GPU supercomputer.</p>
<p>Software from the effort will be made available for researchers in fields like healthcare and chemistry. Aspuru-Guzik will detail the work in <a href="https://www.nvidia.com/gtc/session-catalog/?search=quantum&amp;tab.allsessions=1700692987788001F1cG&amp;search=quantum#/session/1696280074506001Ts8y">a talk</a> at GTC.</p>
<h2><b>Quantum Scales for Fraud Detection</b></h2>
<p>At HSBC, one of the world’s largest banks, researchers designed a quantum machine learning application that can detect fraud in digital payments.</p>
<p>The bank’s quantum machine learning algorithm simulated a whopping 165 qubits on NVIDIA GPUs. Research papers typically don’t extend beyond 40 of these fundamental calculating units quantum systems use.</p>
<p>HSBC used machine learning techniques implemented with CUDA-Q and<a href="https://docs.nvidia.com/cuda/cuquantum/latest/cutensornet/index.html"> cuTensorNet</a> software on NVIDIA GPUs to overcome challenges simulating quantum circuits at scale. Mekena Metcalf, a quantum computing research scientist at HSBC (pictured above), will present her work in a<a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=quantum#/session/1693079968998001x10J"> session at GTC</a>.</p>
<h2><b>Raising a Quantum Generation</b></h2>
<p>In education, NVIDIA is working with nearly two dozen universities to prepare the next generation of computer scientists for the quantum era. The collaboration will design curricula and teaching materials around CUDA-Q.</p>
<p>&#8220;Bridging the divide between traditional computers and quantum systems is essential to the future of computing,&#8221; said Theresa Mayer, vice president for research at Carnegie Mellon University. &#8220;NVIDIA is partnering with institutions of higher education, Carnegie Mellon included, to help students and researchers navigate and excel in this emerging hybrid environment.&#8221;</p>
<p>To help working developers get hands-on with the latest tools, NVIDIA co-sponsored QHack, a quantum hackathon in February. The winning project, developed by Gopal Dahale of Qkrishi — a quantum company in Gurgaon, India — used CUDA-Q to develop an algorithm to simulate a material critical in designing better batteries.</p>
<h2><b>A Trio of New Systems</b></h2>
<p>Two new systems being deployed further expand the ecosystem for hybrid quantum-classical computing.</p>
<p>The largest of the two, <a href="https://nvidianews.nvidia.com/news/nvidia-powers-japans-abci-q-supercomputer-for-quantum-research">ABCI-Q</a> at Japan’s National Institute of Advanced Industrial Science and Technology, will be one of the largest supercomputers dedicated to research in quantum computing. It will use CUDA-Q on <a href="https://www.nvidia.com/en-us/data-center/technologies/hopper-architecture/">NVIDIA H100 GPUs</a> to advance the nation’s efforts in the field.</p>
<p>In Denmark, the Novo Nordisk Foundation will lead on the deployment of an <a href="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.nvidia.com%2Fen-us%2Fdata-center%2Fdgx-superpod%2F&amp;data=05%7C02%7Cgrainville%40nvidia.com%7C5a3284deff074ef3643c08dc479a76a0%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638463976012098204%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=CFCvpXPiz8u7ATwwhmqr6AUjmlyyd2iJgC7iZH3A6cU%3D&amp;reserved=0">NVIDIA DGX SuperPOD</a>, a significant part of which will be dedicated to research in quantum computing in alignment with the country’s national plan to advance the technology.</p>
<p>The new systems join Australia’s Pawsey Supercomputing Research Centre, which <a href="https://nvidianews.nvidia.com/news/nvidia-accelerates-quantum-computing-exploration-at-australias-pawsey-supercomputing-centre">announced</a> in February it will run CUDA-Q on <a href="https://www.nvidia.com/en-us/data-center/grace-hopper-superchip/">NVIDIA Grace Hopper Superchips</a> at its National Supercomputing and Quantum Computing Innovation Hub.</p>
<h2><b>Partners Drive CUDA-Q Forward</b></h2>
<p>In other news, Israeli startup Classiq released at GTC a new integration with CUDA-Q. Classiq’s quantum circuit synthesis lets high-level functional models automatically generate optimized quantum programs, so researchers can get the most out of today’s quantum hardware and expand the scale of their work on future algorithms.</p>
<p>Software and service provider QC Ware is <a href="https://www.prnewswire.com/news-releases/accelerating-the-development-of-new-molecules---promethium-to-empower-ml-models-for-drug-discovery-using-nvidia-quantum-cloud-302090961.html">integrating its Promethium quantum chemistry package</a> with the just-announced <a href="https://nvidianews.nvidia.com/news/nvidia-launches-cloud-quantum-computer-simulation-microservices">NVIDIA Quantum Cloud</a>.</p>
<p>ORCA Computing, a quantum systems developer headquartered in London, released <a href="https://orcacomputing.com/orca-computing-unveils-first-demonstration-of-a-hybrid-algorithm-utilizing-the-orca-pt-1-photonic-quantum-processor-and-nvidia-cuda-quantum/">results</a> running quantum machine learning on its photonics processor with CUDA-Q. In addition, ORCA was selected to build and supply a quantum computing testbed for the UK’s National Quantum Computing Centre which will include an NVIDIA GPU cluster using CUDA-Q.</p>
<p>Nvidia and Infleqtion, a quantum technology leader, partnered to bring cutting-edge quantum-enabled solutions to <a href="https://www.infleqtion.com/quantum-software-updates/quantum-cybersecurity-gets-a-boost-infleqtion-at-dcm3">Europe’s largest cyber-defense exercise</a> with NVIDIA-enabled Superstaq software.</p>
<p>A cloud-based platform for quantum computing, <a href="https://qbraid.com/blog/unleashing-the-power-of-nvidia-cuda-quantum-with-qbraid">qBraid</a>, is integrating CUDA-Q into its developer environment. And California-based BlueQubit described in a <a href="https://www.bluequbit.io/bluequbit-nvidia-managed-platform">blog</a> how NVIDIA’s quantum technology, used in its research and GPU service, provides the fastest and largest quantum emulations possible on GPUs.</p>
<h2><b>Get the Big Picture at GTC</b></h2>
<p>To learn more, watch a session about <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=quantum#/session/1694875146306001JiaF">how NVIDIA is advancing quantum computing</a> and attend an <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=quantum#/session/1695925756553001O1NU">expert panel</a> on the topic, both at <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>, a global AI conference, running March 18-21 at the San Jose Convention Center.</p>
<p>And get the full view from NVIDIA founder and CEO Jensen Huang in his <a href="https://www.nvidia.com/gtc/keynote/">GTC keynote</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/HSBC-quantum-researcher.jpg"
			type="image/jpeg"
			width="1647"
			height="878"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/HSBC-quantum-researcher-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[From Atoms to Supercomputers: NVIDIA, Partners Scale Quantum Computing]]></media:title>
			<media:description type="html">Picture of HSBC quantum resear4ch scientist, Mekena Metcalf</media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Maxine Developer Platform to Transform $10 Billion Video Conferencing Industry</title>
		<link>https://blogs.nvidia.com/blog/maxine-developer-video-conferencing/</link>
		
		<dc:creator><![CDATA[Trisha Tripathi]]></dc:creator>
		<pubDate>Mon, 18 Mar 2024 22:00:45 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[Video Streaming]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70331</guid>

					<description><![CDATA[Video conferencing has allowed many to be productive from anywhere. Now NVIDIA is boosting the productivity of the developers of video conferencing, call center and streaming applications within the $10 billion industry by allowing them to easily integrate AI into their workflows. The new release of the Maxine AI Developer Platform transforms the creation of		<a class="read-more" href="https://blogs.nvidia.com/blog/maxine-developer-video-conferencing/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Video conferencing has allowed many to be productive from anywhere.</p>
<p>Now NVIDIA is boosting the productivity of the developers of video conferencing, call center and streaming applications within the $10 billion industry by allowing them to easily integrate AI into their workflows.</p>
<p>The new release of the Maxine AI Developer Platform transforms the creation of state-of-the-art, real-time video conferencing applications with features enabling enhanced user flexibility, engagement and efficiency.</p>
<p>Available through the <a href="https://docs.nvidia.com/ai-enterprise/index.html">NVIDIA AI Enterprise</a> software platform, Maxine allows developers to tap into the latest AI-driven features — such as enhanced video and audio quality and augmented reality effects — to turn users’ everyday video calls into engaging, collaborative experiences.</p>
<h2><b>Expanding Video Conferencing With New Maxine Features </b></h2>
<p>The Maxine AI Developer Platform enables developers to easily access and integrate real-time, AI-enhanced features that increase the quality of engagement for video conferencing users.</p>
<p>Features like noise reduction, video denoising and upscaling, and studio voice improve the quality of audio and video streams. With advanced capabilities like eye-gaze correction, live portrait and future features such as video relighting and cloud microservice Maxine 3D, developers can enhance video conferencing engagement and personal connection.</p>
<p>The platform extends the utility of the state-of-the-art AI models for audio, video and augmented reality effects with multiple ways for developers to deliver Maxine features with offerings of software development kits, microservices, and even application programming interface (API) endpoints delivered from NVIDIA’s cloud infrastructure.</p>
<p>Maxine production feature updates available now include:<b></b></p>
<ul>
<li><b>Eye Contact</b>: The improved eye contact model provides gaze redirection with natural eye movements for deeper meeting participant engagement.</li>
<li><b>Voice Font</b>: This new model matches the speaker’s voice to a target voice while keeping linguistic information and prosody (rhythm and tone) unchanged.</li>
<li><b>Background Noise Reduction (BNR) 2.0</b>: This model updates noise reduction for human listening and for language encoding with a specific effort to decrease encoding word error rates.</li>
</ul>
<p>New features available for early access this spring include:</p>
<ul>
<li><b>Speech Live Portrait</b>: This model allows a user to drive their portrait with direct speech or any audio source, allowing users to always look their best during a conference call.</li>
<li><b>Studio Voice</b>: This model enables ordinary headset, laptop and desktop microphones to deliver the sound of a high-end studio mic, allowing users to always sound their best during a conference call.</li>
</ul>
<p>The <a href="https://developer.nvidia.com/maxine-microservice-early-access">Maxine early access program</a> shares preproduction and prerelease builds of upcoming features in order to get feedback from developers on the utility and refinement of Maxine models. In this release we are asking developers for feedback on features early in the development pipeline including:</p>
<ul>
<li><b>Maxine 3D</b>: Previously shown as a <a href="https://youtu.be/sZefJHL8X_4?si=wR_7-B4gt70mfh9D">research demonstration</a> at SIGGRAPH 2023, this cloud microservice offers a new level of engagement for video conferencing with real-time NeRF technology lifting 2D video to 3D.</li>
<li><b>Video Relighting</b>: This new model uses a high-dynamic-range image to light the user, enabling seamless matching of user lighting with various background images.</li>
<li><b>API Endpoints</b>: API Endpoints offer developers the flexibility of accessing Maxine features through NVIDIA cloud infrastructure, making Maxine integration even easier.</li>
</ul>
<h2><b>Jugo and Arsenal Football Club Score Major Goals </b></h2>
<p>Sporting events are the ultimate human experience, uniting teams and fans beyond borders and language barriers. Jugo, using Maxine’s AI Green Screen feature, offers a digital platform for virtual events that enables companies to create immersive experiences with Unreal Engine that bring fans together from all over the world without the use of a full production studio.</p>
<p>Arsenal FC, a powerhouse franchise in England’s Premier League, is collaborating with Jugo to revolutionize the way the soccer club engages with its 600 million global fan base. The collaboration offers new virtual sports entertainment experiences to boost engagement for global supporters. Jugo brings the power of real, human interaction into Arsenal events, creating realistic virtual connections between supporters and the club’s sports heroes.</p>
<p>“The Jugo Experience platform is transforming the market for brands in their pursuit of global awareness and engagement,” said Richard Stirk, CEO of Jugo Experience. “Arsenal F.C. is the perfect example of a global brand extension. The flexibility in creating an immersive brand experience is a key to Jugo’s offering and the Maxine AI Developer Platform is a basic building block of this flexibility.”</p>
<h2><b>Setting a New Standard of AI-Enhanced Video Conferencing </b></h2>
<p>Among the first customers to tap into the newest set of features within the early access program to create a professional audio-visual studio from commodity cameras and microphones are <a href="http://gemelo.ai">Gemelo</a>, <a href="https://www.pexip.com/">Pexip</a>, <a href="http://www.thespectacleapp.com/">Spectacle</a> and <a href="https://videorequest.io/">VideoRequest</a>.</p>
<p>“Gemelo has been involved in testing prerelease builds of Maxine models for a number of years now, and we value the chance to give early input on Maxine features as they’re developed,” said Paul Jaski, CEO of Gemelo. “The latest feature, Speech Live Portrait, will provide our customers with greater flexibility in creating customized video messaging, opening the doors to a new era of personalization.”</p>
<p>“Pexip welcomes the chance to test development versions of Maxine features and help guide the final product models,” said Ian Mortimer, chief technology officer at Pexip. “In testing the newest version of Maxine BNR, we are seeing significant improvements in intelligibility and speech quality and plan to continue refining our testing parameters to help optimize for accuracy in AI translation pipelines.”</p>
<p>“The NVIDIA Maxine Eye Contact API significantly simplified our path to providing engaging video processing capabilities to the users of our Spectacle app, eliminating the need to worry about infrastructure and resource-intensive integrations,” said Benjamin Portman, president of Spectacle. “With it, we were able to create a proof of concept within a matter of days, speeding up our production application deployment timeline.”</p>
<p>“Our early testing of Maxine Studio Voice enabled an impressive look into what is now possible with AI-enhanced production and video testimonials,” said Joe Tyler, chief technology officer at VideoRequest. “The new Maxine BNR and Eye Contact features will help elevate the quality of our customer’s videos by overcoming their challenging recording environments.”</p>
<h2><b>Availability </b></h2>
<p>Learn more about <a href="https://developer.nvidia.com/maxine">NVIDIA Maxine</a>, which is available now on <a href="https://docs.nvidia.com/ai-enterprise/index.html">NVIDIA AI Enterprise</a>.</p>
<p><i>See </i><a href="https://www.nvidia.com/en-us/about-nvidia/legal-info/"><b><i>notice</i></b></a><i> regarding software product information.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/MAxine_Jugo_1280x680.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/MAxine_Jugo_1280x680-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Maxine Developer Platform to Transform $10 Billion Video Conferencing Industry]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
	</channel>
</rss>
