<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Wed, 04 Oct 2023 22:50:37 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.3.1</generator>
	<item>
		<title>A Mine-Blowing Breakthrough: Open-Ended AI Agent Voyager Autonomously Plays ‘Minecraft’</title>
		<link>https://blogs.nvidia.com/blog/2023/10/04/ai-jim-fan/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Wed, 04 Oct 2023 21:04:52 +0000</pubDate>
				<category><![CDATA[The AI Podcast]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67324</guid>

					<description><![CDATA[For NVIDIA Senior AI Scientist Jim Fan, the video game Minecraft served as the “perfect primordial soup” for his research on open-ended AI agents. In the latest AI Podcast episode, host Noah Kravitz spoke with Fan on using large language models to create AI agents — specifically to create Voyager, an AI bot built with <a class="read-more" href="https://blogs.nvidia.com/blog/2023/10/04/ai-jim-fan/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>For NVIDIA Senior AI Scientist Jim Fan, the video game <i>Minecraft</i> served as the “perfect primordial soup” for his research on open-ended AI agents.</p>
<p>In the latest <a href="https://blogs.nvidia.com/ai-podcast/">AI Podcast</a> episode, host Noah Kravitz spoke with Fan on using <a href="https://blogs.nvidia.com/blog/2023/01/26/what-are-large-language-models-used-for/">large language models</a> to create AI agents — specifically to create Voyager, an AI bot built with Chat GPT-4 that can autonomously play <i>Minecraft</i>.</p>
<p>AI agents are models that “can proactively take actions and then perceive the world, see the consequences of its actions, and then improve itself,” Fan said. Many current AI agents are programmed to achieve specific objectives, such as beating a game as quickly as possible or answering a question. They can work autonomously toward a particular output but lack a broader decision-making agency.</p>
<p>Fan wondered if it was possible to have a “truly open-ended agent that can be prompted by arbitrary natural language to do open-ended, even creative things.”</p>
<p>But he needed a flexible playground in which to test that possibility.</p>
<p>“And that’s why we found <i>Minecraft </i>to be almost a perfect primordial soup for open-ended agents to emerge, because it sets up the environment so well,” he said. <i>Minecraft </i>at its core, after all, doesn’t set a specific key objective for players other than to survive and freely explore the open world.</p>
<p>That became the springboard for Fan’s project, MineDojo, which eventually led to the creation of the AI bot Voyager.</p>
<p>“Voyager leverages the power of Chat GPT-4 to write code in Javascript to execute in the game,” Fan explained. “GPT-4 then looks at the output, and if there’s an error from JavaScript or some feedback from the environment, GPT-4 does a self-reflection and tries to debug the code.”</p>
<p>The bot learns from its mistakes and stores the correctly implemented programs in a skill library for future use, allowing for “lifelong learning.”</p>
<p>In-game, Voyager can autonomously explore for hours, adapting its decisions based on its environment and developing skills to combat monsters and find food when needed.</p>
<p>“We see all these behaviors come from the Voyager setup, the skill library and also the coding mechanism,” Fan explained. “We did not preprogram any of these behaviors.”</p>
<p>He then spoke more generally about the rise and trajectory of LLMs. He foresees strong applications in software, gaming and robotics and increasingly pressing conversations surrounding AI safety.</p>
<p>Fan encourages those looking to get involved and work with LLMs to “just do something,” whether that means using <a href="https://www.nvidia.com/en-us/training/">online resources</a> or experimenting with beginner-friendly, CPU-based AI models.</p>
<p><iframe src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1627125918%3Fsecret_token%3Ds-PgUquX2ckQi&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="NVIDIA’s Jim Fan delves into large language models and their industry impact - Ep. 204" href="https://soundcloud.com/theaipodcast/ai-jim-fan/s-PgUquX2ckQi" target="_blank" rel="noopener">NVIDIA’s Jim Fan delves into large language models and their industry impact &#8211; Ep. 204</a></div>
<h2>You Might Also Like</h2>
<p><a href="https://soundcloud.com/theaipodcast/jules-anh-tuan-nguyen-explains-how-ai-lets-amputee-control-prosthetic-hand-video-games-ep-149">Jules Anh Tuan Nguyen Explains How AI Lets Amputee Control Prosthetic Hand, Video Games<br />
</a>A postdoctoral researcher at the University of Minnesota discusses his efforts to allow amputees to control their prosthetic limb — right down to the finger motions — with their minds.</p>
<p><a href="https://soundcloud.com/theaipodcast/ai-overjet">Overjet’s Ai Wardah Inam on Bringing AI to Dentistry<br />
</a>Overjet, a member of <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a>, is moving fast to bring AI to dentists’ offices. Dr. Wardah Inam, CEO of the company, discusses using AI to improve patient care.</p>
<p><a href="https://soundcloud.com/theaipodcast/ai-luis-voloch">Immunai CTO and Co-Founder Luis Voloch on Using Deep Learning to Develop New Drugs<br />
</a>Luis Voloch talks about tackling the challenges of the immune system with a machine learning and data science mindset.</p>
<h2>Subscribe to the AI Podcast: Now Available on Amazon Music</h2>
<p><a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">The AI Podcast is now available through Amazon Music</a>.</p>
<p>In addition, get the <a href="https://blogs.nvidia.com/ai-podcast/">AI Podcast</a> through <a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439">iTunes</a>, <a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjI2NDAzNDEzMy9zb3VuZHMucnNz">Google Podcasts</a>, <a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm">Google Play</a>, <a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us">Castbox</a>, DoggCatcher, <a href="https://overcast.fm/itunes1186480811/the-ai-podcast">Overcast</a>, <a href="https://player.fm/series/the-ai-podcast">PlayerFM</a>, Pocket Casts, <a href="http://www.podbay.fm/show/1186480811">Podbay</a>, <a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast">PodBean</a>, PodCruncher, PodKicker, <a href="https://soundcloud.com/theaipodcast">Soundcloud</a>, <a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L">Spotify</a>, <a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr">Stitcher</a> and <a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/">TuneIn</a>.</p>
<p>Make the AI Podcast better. Have a few minutes to spare? Fill out <a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short">this listener survey</a>.</p>
<p>&nbsp;</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast.jpg"
			type="image/jpeg"
			width="1400"
			height="931"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[A Mine-Blowing Breakthrough: Open-Ended AI Agent Voyager Autonomously Plays ‘Minecraft’]]></media:title>
			<media:description type="html">NVIDIA AI Podcast</media:description>
			</media:content>
			</item>
		<item>
		<title>How AI Helps Fight Wildfires in California</title>
		<link>https://blogs.nvidia.com/blog/2023/10/04/ai-wildfires-california/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Wed, 04 Oct 2023 15:00:55 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Climate]]></category>
		<category><![CDATA[GPU]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67306</guid>

					<description><![CDATA[California has a new weapon against the wildfires that have devastated the state: AI. A freshly launched system powered by AI trained on NVIDIA GPUs promises to provide timely alerts to first responders across the Golden State every time a blaze ignites. The ALERTCalifornia initiative, a collaboration between California’s wildfire fighting agency CAL FIRE and <a class="read-more" href="https://blogs.nvidia.com/blog/2023/10/04/ai-wildfires-california/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>California has a new weapon against the wildfires that have devastated the state: AI.</p>
<p>A freshly launched system powered by AI trained on NVIDIA GPUs promises to provide timely alerts to first responders across the Golden State every time a blaze ignites.</p>
<p>The ALERTCalifornia initiative, a collaboration between California’s wildfire fighting agency CAL FIRE and the University of California, San Diego, uses advanced AI developed by DigitalPath.</p>
<p>Harnessing the raw power of NVIDIA GPUs and aided by a network of thousands of cameras dotting the Californian landscape, DigitalPath has refined a <a href="https://blogs.nvidia.com/blog/2018/09/05/whats-the-difference-between-a-cnn-and-an-rnn/" target="_blank" rel="noopener">convolutional neural network</a> to spot signs of fire in real time.</p>
<h2><strong>A Mission That’s Close to Home</strong></h2>
<p><a href="https://www.digitalpath.net/" target="_blank" rel="noopener">DigitalPath</a> CEO Jim Higgins said it’s a mission that means a lot to the 100-strong technology partner, which is nestled in the Sierra Nevada foothills in Chico, Calif., a short drive from the town of Paradise, where the state’s deadliest wildfire killed 85 people in 2018.</p>
<p>“It’s one of the main reasons we’re doing this,” Higgins said of the wildfire, the deadliest and most destructive in the history of the most populous U.S. state. “We don’t want people to lose their lives.”</p>
<p>The ALERTCalifornia initiative is based at UC San Diego’s Jacobs School of Engineering, the Qualcomm Institute and the Scripps Institution of Oceanography.</p>
<p>The program manages a network of thousands of monitoring cameras and sensor arrays and collects data that provides actionable, real-time information to inform public safety.</p>
<p>The AI program started in June and was initially deployed in six of Cal Fire’s command centers. This month it expanded to all of CAL FIRE’s 21 command centers.</p>
<figure id="attachment_67307" aria-describedby="caption-attachment-67307" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire1.png"><img decoding="async" fetchpriority="high" class="wp-image-67307 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire1-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire1-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire1-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire1-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire1-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire1-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire1-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire1-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire1-1280x720.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire1.png 1920w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67307" class="wp-caption-text">ALERTCalifornia, powered by DigitalPath, can detect fires from cameras positioned across the golden state.</figcaption></figure>
<p>DigitalPath began by building out a management platform for a network of cameras used to confirm California wildfires after a 911 call.</p>
<p>The company quickly realized there would be no way to have people examine images from the thousands of cameras relaying images to the system every ten to fifteen seconds.</p>
<p>So Ethan Higgins, the company’s system architect, turned to AI.</p>
<p>The team began by training a convolutional neural network on a cloud-based system running an NVIDIA A100 Tensor Core GPU and later transitioned to a system running on eight A100 GPUs.</p>
<p>The AI model is crucial to examining a system that sees almost 8 million images a day streaming in from over 1,000 first-party cameras, primarily in California, and thousands more from third-party sources nationwide, he said.</p>
<h2><strong>Impact of Wildfires</strong></h2>
<figure id="attachment_67311" aria-describedby="caption-attachment-67311" style="width: 299px" class="wp-caption alignleft"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire2.png"><img decoding="async" class="wp-image-67311 " src="https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire2-348x500.png" alt="" width="299" height="430" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire2-348x500.png 348w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire2-278x400.png 278w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire2-768x1105.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire2-1068x1536.png 1068w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire2-313x450.png 313w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire2-149x215.png 149w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire2-70x100.png 70w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire2.png 1167w" sizes="(max-width: 299px) 100vw, 299px" /></a><figcaption id="caption-attachment-67311" class="wp-caption-text">All anomalies being tracked throughout California as of Sept. 20, 2023. Image Credit: DigitalPath</figcaption></figure>
<p>It’s arriving just in time.</p>
<p>Wildfires have ravaged California over the past decade, burning millions of acres of land, destroying thousands of homes and businesses and claiming hundreds of lives.</p>
<p><a href="https://www.fire.ca.gov/our-impact/statistics" target="_blank" rel="noopener">According to CAL FIRE</a>, in 2020 alone, the state experienced five of its six largest and seven of its 20 most destructive wildfires.</p>
<p>And the <a href="https://calmatters.org/california-wildfire-map-tracker/" target="_blank" rel="noopener">total dollar damage of wildfires in California from 2019 to 2021 was estimated at over $25 billion</a>.</p>
<p>The new system promises to give first responders a crucial tool to prevent such conflagrations.</p>
<p>In fact, during a recent interview with DigitalPath, the system detected two separate fires in Northern California as they ignited.</p>
<p>Every day, the system detects between 50 and 300 events, offering invaluable real-time information to local first responders.</p>
<h2><strong>Beyond Detection: Enhancing Capabilities</strong></h2>
<figure id="attachment_67314" aria-describedby="caption-attachment-67314" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire3.png"><img decoding="async" loading="lazy" class="wp-image-67314 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire3-672x481.png" alt="" width="672" height="481" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire3-672x481.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire3-400x286.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire3-768x549.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire3-629x450.png 629w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire3-301x215.png 301w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire3-140x100.png 140w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire3-1280x916.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/10/29fire3.png 1462w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67314" class="wp-caption-text">Example of multiple cameras detecting a single anomaly. Image Credit: DigitalPath.</figcaption></figure>
<p>But AI is just part of the story.</p>
<p>The system is also a case study in how innovative companies can use AI to amplify their unique capabilities.</p>
<p>One of DigitalPath’s breakthroughs is its system’s ability to identify the same fire captured from diverse camera angles. DigitalPath’s system efficiently filters imagery down to a human-digestible level. The system filters 8 million daily images down to just 100 alerts, or 1.25 thousandths of one percent of total images captured.</p>
<p>“The system was designed from the start with human processing in mind,” Higgins said, ensuring that authorities receive a single, consolidated notification for every incident.</p>
<p>“We’ve got to catch every fire we can,” he adds.</p>
<h2><strong>Expanding Horizons</strong></h2>
<p>DigitalPath eventually hopes to expand its detection technology to help California detect more kinds of natural disasters.</p>
<p>And having proven its worth in California, DigitalPath is now in talks with state and county officials and university research teams across the fire-prone Western United States under its ALERTWest subsidiary.</p>
<p>Their goal: to help partners replicate the success of UC San Diego and ALERTCalifornia, potentially shielding countless lives and homes from the wrath of wildfires.</p>
<p><i>Featured image credit: </i><a href="https://www.flickr.com/photos/slworking/29034137667" target="_blank" rel="noopener"><i>SLworking2, via Flickr</i></a><i>, Creative Commons license, some rights reserved. </i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/29firemain1080.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/29firemain1080-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[How AI Helps Fight Wildfires in California]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Meet the Maker: Robotics Student Rolls Out Autonomous Wheelchair With NVIDIA Jetson</title>
		<link>https://blogs.nvidia.com/blog/2023/10/03/kabilan-kb-autonomous-wheelchair/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Tue, 03 Oct 2023 15:00:04 +0000</pubDate>
				<category><![CDATA[Autonomous Machines]]></category>
		<category><![CDATA[Inner Geek]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Computer Vision]]></category>
		<category><![CDATA[Education]]></category>
		<category><![CDATA[Embedded Computing]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[Synthetic Data Generation]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67273</guid>

					<description><![CDATA[With the help of AI, robots, tractors and baby strollers — even skate parks — are becoming autonomous. One developer, Kabilan KB, is bringing autonomous-navigation capabilities to wheelchairs, which could help improve mobility for people with disabilities. The undergraduate from the Karunya Institute of Technology and Sciences in Coimbatore, India, is powering his autonomous wheelchair <a class="read-more" href="https://blogs.nvidia.com/blog/2023/10/03/kabilan-kb-autonomous-wheelchair/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>With the help of AI, robots, <a href="https://blogs.nvidia.com/blog/2022/12/01/mondavi-monarch-smart-electric-jetson-tractor/" target="_blank" rel="noopener">tractors</a> and <a href="https://blogs.nvidia.com/blog/2023/01/18/ella-stroller-jetson/" target="_blank" rel="noopener">baby strollers</a> — even <a href="https://blogs.nvidia.com/blog/2023/06/12/kirk-kaiser-jetson-self-driving-skate-park/" target="_blank" rel="noopener">skate parks</a> — are becoming autonomous. One developer, Kabilan KB, is bringing autonomous-navigation capabilities to wheelchairs, which could help improve mobility for people with disabilities.</p>
<p><img decoding="async" loading="lazy" class="wp-image-67283 alignright" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/image1-300x400.png" alt="" width="233" height="311" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/image1-300x400.png 300w, https://blogs.nvidia.com/wp-content/uploads/2023/10/image1-375x500.png 375w, https://blogs.nvidia.com/wp-content/uploads/2023/10/image1-768x1023.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/image1-1153x1536.png 1153w, https://blogs.nvidia.com/wp-content/uploads/2023/10/image1-338x450.png 338w, https://blogs.nvidia.com/wp-content/uploads/2023/10/image1-161x215.png 161w, https://blogs.nvidia.com/wp-content/uploads/2023/10/image1-75x100.png 75w, https://blogs.nvidia.com/wp-content/uploads/2023/10/image1-1280x1706.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/10/image1.png 1500w" sizes="(max-width: 233px) 100vw, 233px" /></p>
<p>The undergraduate from the Karunya Institute of Technology and Sciences in Coimbatore, India, is powering his autonomous wheelchair project using the <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/" target="_blank" rel="noopener">NVIDIA Jetson</a> platform for edge AI and robotics.</p>
<p>The autonomous motorized wheelchair is connected to depth and lidar sensors — along with USB cameras — which allow it to perceive the environment and plan an obstacle-free path toward a user’s desired destination.</p>
<p>“A person using the motorized wheelchair could provide the location they need to move to, which would already be programmed in the autonomous navigation system or path-planned with assigned numerical values,” KB said. “For example, they could press ‘one’ for the kitchen or ‘two’ for the bedroom, and the autonomous wheelchair will take them there.”</p>
<p>An <a href="https://developer.nvidia.com/embedded/jetson-nano-developer-kit" target="_blank" rel="noopener">NVIDIA Jetson Nano Developer Kit</a> processes data from the cameras and sensors in real time. It then uses deep learning-based computer vision models to detect obstacles in the environment.</p>
<p><img decoding="async" loading="lazy" class="aligncenter wp-image-67274 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/10/diagram-image-672x422.png" alt="" width="672" height="422" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/10/diagram-image-672x422.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/10/diagram-image-400x251.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/10/diagram-image-768x482.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/10/diagram-image-1536x964.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/10/diagram-image.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/10/diagram-image-717x450.png 717w, https://blogs.nvidia.com/wp-content/uploads/2023/10/diagram-image-342x215.png 342w, https://blogs.nvidia.com/wp-content/uploads/2023/10/diagram-image-159x100.png 159w, https://blogs.nvidia.com/wp-content/uploads/2023/10/diagram-image-1280x804.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></p>
<p>The developer kit acts as the brain of the autonomous system — generating a 2D map of its surroundings to plan a collision-free path to the destination — and sends updated signals to the motorized wheelchair to help ensure safe navigation along the way.</p>
<h2><strong>About the Maker</strong></h2>
<p>KB, who has a background in mechanical engineering, became fascinated with AI and robotics during the pandemic, when he spent his free time searching up educational YouTube videos on the topics.</p>
<p>He’s now working toward a bachelor’s degree in robotics and automation at the Karunya Institute of Technology and Sciences and aspires to one day launch a robotics startup.</p>
<p>KB, a self-described supporter of self-education, has also received several certifications from the <a href="https://www.nvidia.com/en-us/training/" target="_blank" rel="noopener">NVIDIA Deep Learning Institute</a>, including “Building Video AI Applications at the Edge on Jetson Nano” and “Develop, Customize and Publish in Omniverse With Extensions.”</p>
<p>Once he learned the basics of robotics, he began experimenting with simulation in <a href="https://www.nvidia.com/en-us/omniverse/" target="_blank" rel="noopener">NVIDIA Omniverse</a>, a platform for building and operating 3D tools and applications based on the <a href="https://www.nvidia.com/en-us/omniverse/usd/" target="_blank" rel="noopener">OpenUSD</a> framework.</p>
<p>“Using Omniverse for simulation, I don’t need to invest heavily in prototyping models for my robots, because I can use <a href="https://blogs.nvidia.com/blog/2021/06/08/what-is-synthetic-data/" target="_blank" rel="noopener">synthetic data</a> generation instead,” he said. “It’s the software of the future.”</p>
<h2><strong>His Inspiration</strong></h2>
<p>With this latest NVIDIA Jetson project, KB aimed to create a device that could be helpful for his cousin, who has a mobility disorder, and other people with disabilities who might not be able to control a manual or motorized wheelchair.</p>
<p>“Sometimes, people don’t have the money to buy an electric wheelchair,” KB said. “In India, only upper- and middle-class people can afford them, so I decided to use the most basic type of motorized wheelchair available and connect it to the Jetson to make it autonomous.”</p>
<p>The personal project was funded by the Program in Global Surgery and Social Change, which is jointly positioned under the Boston Children’s Hospital and Harvard Medical School.</p>
<h2><b>His Jetson Project</b></h2>
<p>After purchasing the basic motorized wheelchair, KB connected its motor hub with the NVIDIA Jetson Nano and lidar and depth cameras.</p>
<p>He trained the AI algorithms for the autonomous wheelchair using YOLO object detection on the Jetson Nano, as well as the Robot Operating System, or ROS, a popular software for building robotics applications.</p>
<p>The wheelchair can tap these algorithms to perceive and map its environment and plan a collision-free path.</p>
<p>“The NVIDIA Jetson Nano’s real-time processing speed prevents delays or lags for the user,” said KB, who’s been working on the project’s prototype since June. The developer dives into the technical components of the autonomous wheelchair on <a href="https://medium.com/@kabilankb2003/autonomous-wheelchair-using-nvidia-jetson-nano-84268525763c" target="_blank" rel="noopener">his blog</a>. <a href="https://www.youtube.com/watch?v=cqt5zgTIMlE" target="_blank" rel="noopener">A demo</a> of the autonomous wheelchair has also been featured on the Karunya Innovation and Design Studio YouTube channel.</p>
<p>Looking forward, he envisions his project could be expanded to allow users to control a wheelchair using brain signals from electroencephalograms, or EEGs, that are connected to machine learning algorithms.</p>
<p>“I want to make a product that would let a person with a full mobility disorder control their wheelchair by simply thinking, ‘I want to go there,’” KB said.</p>
<p><i>Learn more about the </i><a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/" target="_blank" rel="noopener"><i>NVIDIA Jetson platform</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/autonomouswheelchair.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/autonomouswheelchair-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Meet the Maker: Robotics Student Rolls Out Autonomous Wheelchair With NVIDIA Jetson]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>CG Geek Makes VFX Look Easy This Week ‘In the NVIDIA Studio’</title>
		<link>https://blogs.nvidia.com/blog/2023/10/03/cg-geek-blender/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 03 Oct 2023 13:00:33 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67223</guid>

					<description><![CDATA[Releasing a 3D tutorial dubbed The Easiest VFX Tutorial Ever takes supreme confidence and the skills to back it up. Steve Lund a.k.a. CG Geek — the featured artist of this week’s In the NVIDIA Studio installment — has both in spades.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. We’re also deep-diving on new </i><a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/"><i>GeForce RTX 40 Series GPU</i></a><i> features, technologies and resources and how they dramatically accelerate content creation.</i></p>
<p>Releasing a 3D tutorial dubbed <i>The Easiest VFX Tutorial Ever</i> takes supreme confidence and the skills to back it up.</p>
<p>Steve Lund a.k.a. CG Geek — the featured artist of this week’s <i>In the NVIDIA Studio</i> installment — has both in spades. It’s no surprise that over 1 million people have subscribed to his YouTube channel, which features tutorials on animation and visual effects (VFX) as well as select tech reviews.</p>
<p><iframe loading="lazy" title="the Easiest VFX Tutorial Ever." width="500" height="281" src="https://www.youtube.com/embed/cNbVl6LCEFI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>CG Geek has been a content creator for over 13 years, starting with videos on stop-motion animation before moving on to 3D software. Films and movies are his primary sources of inspiration. He grew up creating short films with his family — experimenting with and implementing video effects and 3D characters — which became a critical foundation for his current work.</p>
<p>Artists can strengthen their creative arsenal with the new <a href="https://www.microsoft.com/en-us/d/surface-laptop-studio-2/8rqr54krf1dz">Microsoft Surface Laptop Studio 2</a>, available for pickup today. It’s powered by <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4060-4060ti/">GeForce RTX 4060</a>, GeForce RTX 4050 or <a href="https://www.nvidia.com/en-us/design-visualization/rtx-professional-laptops/?ncid=ref-pr-584767#">NVIDIA RTX 2000 Ada Generation</a> Laptop GPUs with 13th Gen Intel Core processors, up to 64GB of RAM and a 2TB SSD. It features a bright, vibrant 14.4-inch PixelSense Flow touchscreen, a 120Hz refresh rate, and Dolby Vision IQ and HDR to deliver sharper colors.</p>
<figure id="attachment_67227" aria-describedby="caption-attachment-67227" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-1.png"><img decoding="async" loading="lazy" class="size-large wp-image-67227" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-1-672x340.png" alt="" width="672" height="340" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-1-672x340.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-1-400x202.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-1-768x388.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-1-842x426.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-1-406x205.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-1-188x95.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-1.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67227" class="wp-caption-text">The versatile Microsoft Surface Laptop Studio 2.</figcaption></figure>
<h2><b>The Easiest VFX Tutorial Ever</b></h2>
<p>CG Geek also happens to be a geek for Blender, free for 3D enthusiasts, who regularly create impressive, individualistic art.</p>
<p>“I love the amazing Blender 3D community,” he said. “Whenever you need inspiration or creative feedback, they’re the most helpful, kind and talented collective of ever-growing artists.”</p>
<p>CG Geek wanted to make a tutorial that could prove that virtually anyone could get started in VFX with relative ease, from anywhere, at any time.</p>
<figure id="attachment_67230" aria-describedby="caption-attachment-67230" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-outdoor-wideshot4-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67230" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-outdoor-wideshot4-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-outdoor-wideshot4-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-outdoor-wideshot4-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-outdoor-wideshot4-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-outdoor-wideshot4-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-outdoor-wideshot4-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-outdoor-wideshot4-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-outdoor-wideshot4-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67230" class="wp-caption-text">Work on VFX from anywhere — even the outdoors.</figcaption></figure>
<p>The first step, he instructs, is to capture video footage. To keep things simple, CG Geek recommends mounting a camera or mobile device to a tripod. Note that the camera lens determines the focal length and sensor size — critical details to input in Blender later in the process.</p>
<figure id="attachment_67233" aria-describedby="caption-attachment-67233" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube1-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67233" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube1-1280w-672x370.png" alt="" width="672" height="370" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube1-1280w-672x370.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube1-1280w-400x220.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube1-1280w-768x423.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube1-1280w-817x450.png 817w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube1-1280w-390x215.png 390w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube1-1280w-182x100.png 182w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube1-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67233" class="wp-caption-text">Keep track of the camera’s focal length and sensor size.</figcaption></figure>
<p>Keep a close eye on the video footage lighting for shadows and light intensity — it helps to snap a straight-down photo of the environment the 3D element will populate, namely for light bounces, to help create more realistic shadows.</p>
<figure id="attachment_67236" aria-describedby="caption-attachment-67236" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube2-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67236" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube2-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube2-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube2-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube2-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube2-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube2-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube2-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube2-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67236" class="wp-caption-text">Seasoned visual effects artists can capture and scan the entire 3D area.</figcaption></figure>
<p>Next, secure a 3D model. Create one with guidance from an <a href="https://www.nvidia.com/en-us/studio/blog/">NVIDIA Studio blog</a> or watch detailed tutorials on the <a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw">Studio YouTube channel</a>. Alternatively, look online for a 3D model equipped with basic physically based rendering materials, as well as a roughness and normal map.</p>
<figure id="attachment_67239" aria-describedby="caption-attachment-67239" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube3-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67239" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube3-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube3-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube3-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube3-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube3-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube3-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube3-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube3-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67239" class="wp-caption-text">Sketchfab is an excellent resource for acquiring 3D models.</figcaption></figure>
<p>Next, combine the video footage and 3D materials. Open Blender, import the video footage and line up the 3D grid floor to the surface where the model will be presented. The 3D grid doubles as a shadow catcher that will grab the shadows being cast from the 3D elements. With an added texture, lighting will bounce back against the object, resulting in heightened realism.</p>
<figure id="attachment_67242" aria-describedby="caption-attachment-67242" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube4-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67242" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube4-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube4-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube4-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube4-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube4-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube4-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube4-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube4-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67242" class="wp-caption-text">The 3D grid floor will determine where the 3D model will be placed.</figcaption></figure>
<p>Then, light the 3D model to match the video footage. Most commonly, this is achieved by acquiring a high-dynamic range image (HDRI), a panorama with lighting data. CG Geek recommends Poly Haven for free, high-quality HDRIs. The key is picking one that resembles the lighting, color, shadow and intensity of the video footage.</p>
<figure id="attachment_67245" aria-describedby="caption-attachment-67245" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube5-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67245" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube5-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube5-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube5-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube5-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube5-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube5-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube5-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube5-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67245" class="wp-caption-text">Poly Haven has HDRIs for use in VFX work.</figcaption></figure>
<p>Use the HDRI lighting to align the sun’s rotation with the shadows of the footage, adding further realism.</p>
<figure id="attachment_67248" aria-describedby="caption-attachment-67248" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube6-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67248" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube6-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube6-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube6-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube6-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube6-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube6-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube6-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube6-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67248" class="wp-caption-text">Lighting adjustments in Blender.</figcaption></figure>
<p>From there, import camera information into Blender and render out passes for the 3D model over a transparent background in Cycles. Create as many render layers as possible for added post-render editing flexibility, especially in compositing. Shadowcatcher, glossy passes, Z depth and ambient occlusion layers are recommended for advanced users.</p>
<figure id="attachment_67251" aria-describedby="caption-attachment-67251" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube7-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67251" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube7-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube7-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube7-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube7-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube7-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube7-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube7-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube7-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67251" class="wp-caption-text">Speedy renders in Blender on NVIDIA Studio hardware.</figcaption></figure>
<p>These layers can then be combined in popular creative apps like Adobe Premiere Pro, After Effects, Blackmagic Design’s DaVinci Resolve or any of the over 100 NVIDIA RTX GPU-accelerated apps. This workflow, in particular, will be completed in Blender’s custom compositor.</p>
<figure id="attachment_67254" aria-describedby="caption-attachment-67254" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube8-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67254" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube8-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube8-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube8-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube8-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube8-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube8-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube8-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-youtube8-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67254" class="wp-caption-text">Speedy renders in Blender.</figcaption></figure>
<p>Add shadows to the live footage with a multiple overlay. Then, carry over the 3D elements render layer to adjust the intensity of the shadows, helping them mesh better with the video capture. Individual layers can be edited to match the desired tone.</p>
<p>CG Geek made use of Blender Cycles’ RTX-accelerated OptiX ray tracing in the viewport. “Rendering in Cycles with multiple render layers and passes, along with the NVIDIA OptiX Denoiser, made animations and early tests a breeze,” he said.</p>
<div class="simplePullQuote right"><p>“All my rendering changes can be visualized in real time thanks to the power of NVIDIA Studio before ever even hitting that button.” &#8211; CG Geek </p>
</div>
<p>Finally, perform simple masking on areas where the 3D model passes in front of or behind objects. CG Geek’s <a href="https://www.youtube.com/watch?v=lA6AuZYbLyQ">one-minute YouTube tutorial</a> can help guide this process. DaVinci Resolve or Premiere Pro’s AI-powered magic mask features can further speed the process by automatically masking background elements, saving the effort of painstakingly editing videos frame by frame.</p>
<p>These AI features are all accelerated by the GeForce RTX 4070 GPU equipped in CG Geek’s ASUS Zenbook 14 NVIDIA Studio laptop.</p>
<figure id="attachment_67257" aria-describedby="caption-attachment-67257" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-wip-renderlayers-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67257" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-wip-renderlayers-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-wip-renderlayers-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-wip-renderlayers-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-wip-renderlayers-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-wip-renderlayers-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-wip-renderlayers-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-wip-renderlayers-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-cg-geek-wk77-wip-renderlayers-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67257" class="wp-caption-text">An entire workflow in a single shot.</figcaption></figure>
<div class="simplePullQuote right"><p>“NVIDIA Studio laptops powered by RTX GPUs are great for portability and speed in a compact form factor.” &#8211; CG Geek</p>
</div>
<p>For CG Geek, getting reps in, making mistakes and strengthening weaknesses are the keys to evolving as an artist. “Don’t get hung up on the details!” he stressed. “Give yourself a deadline and then get started on another project.”</p>
<p>For more on the basics of 3D VFX and CGI with Blender, accelerated by the <a href="https://www.nvidia.com/en-us/studio/">NVIDIA Studio</a> platform and RTX GPUs, watch his featured five-minute <a href="https://www.youtube.com/watch?v=cNbVl6LCEFI">tutorial</a>.</p>
<figure id="attachment_67263" aria-describedby="caption-attachment-67263" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-itns-cg-geek-wk77-featured-setup-1280w.png"><img decoding="async" loading="lazy" class="wp-image-67263 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-itns-cg-geek-wk77-featured-setup-1280w-672x228.png" alt="" width="672" height="228" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-itns-cg-geek-wk77-featured-setup-1280w-672x228.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-itns-cg-geek-wk77-featured-setup-1280w-400x136.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-itns-cg-geek-wk77-featured-setup-1280w-768x261.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-itns-cg-geek-wk77-featured-setup-1280w-842x286.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-itns-cg-geek-wk77-featured-setup-1280w-406x138.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-itns-cg-geek-wk77-featured-setup-1280w-188x64.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/studio-itns-cg-geek-wk77-featured-setup-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67263" class="wp-caption-text">Content creator CG Geek.</figcaption></figure>
<p>Check out CG Geek on <a href="https://www.youtube.com/@CGGeek/featured">YouTube</a>.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>Twitter</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/nv-blog-header-preview-1280x680-3.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/nv-blog-header-preview-1280x680-3-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[CG Geek Makes VFX Look Easy This Week ‘In the NVIDIA Studio’]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Heeding Huang’s Law: Video Shows How Engineers Keep the Speedups Coming</title>
		<link>https://blogs.nvidia.com/blog/2023/09/29/huangs-law-dally-hot-chips/</link>
		
		<dc:creator><![CDATA[Rick Merritt]]></dc:creator>
		<pubDate>Fri, 29 Sep 2023 15:00:00 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[NVIDIA Life]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[NVIDIA Ampere Architecture]]></category>
		<category><![CDATA[NVIDIA Hopper Architecture]]></category>
		<category><![CDATA[NVIDIA Research]]></category>
		<category><![CDATA[NVLink]]></category>
		<category><![CDATA[Parallel Computing]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67172</guid>

					<description><![CDATA[In a talk, now available online, NVIDIA Chief Scientist Bill Dally describes a tectonic shift in how computer performance gets delivered in a post-Moore’s law era. Each new processor requires ingenuity and effort inventing and validating fresh ingredients, he said in a recent keynote address at Hot Chips, an annual gathering of chip and systems <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/29/huangs-law-dally-hot-chips/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>In a talk, now available <a href="https://youtu.be/rsxCZAE8QNA">online</a>, NVIDIA Chief Scientist Bill Dally describes a tectonic shift in how computer performance gets delivered in a post-Moore’s law era.</p>
<p>Each new processor requires ingenuity and effort inventing and validating fresh ingredients, he said in a recent keynote address at Hot Chips, an annual gathering of chip and systems engineers. That’s radically different from a generation ago, when engineers essentially relied on the physics of ever smaller, faster chips.</p>
<p>The team of more than 300 that Dally leads at NVIDIA Research helped deliver a whopping 1,000x improvement in single GPU performance on AI inference over the past decade (see chart below).</p>
<p>It’s an astounding increase that <a href="https://spectrum.ieee.org/move-over-moores-law-make-way-for-huangs-law">IEEE Spectrum</a> was the first to dub “Huang’s Law” after NVIDIA founder and CEO Jensen Huang. The label was later popularized by <a href="https://www.wsj.com/articles/huangs-law-is-the-new-moores-law-and-explains-why-nvidia-wants-arm-11600488001">a column</a> in the Wall Street Journal.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/1000x-GPU-Gains-in-10-Years.jpg"><img decoding="async" loading="lazy" class="aligncenter size-large wp-image-67174" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/1000x-GPU-Gains-in-10-Years-672x372.jpg" alt="1000x leap in GPU performance in a decade" width="672" height="372" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/1000x-GPU-Gains-in-10-Years-672x372.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/1000x-GPU-Gains-in-10-Years-400x221.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/1000x-GPU-Gains-in-10-Years-768x425.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/1000x-GPU-Gains-in-10-Years-1536x850.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/1000x-GPU-Gains-in-10-Years-813x450.jpg 813w, https://blogs.nvidia.com/wp-content/uploads/2023/09/1000x-GPU-Gains-in-10-Years-388x215.jpg 388w, https://blogs.nvidia.com/wp-content/uploads/2023/09/1000x-GPU-Gains-in-10-Years-181x100.jpg 181w, https://blogs.nvidia.com/wp-content/uploads/2023/09/1000x-GPU-Gains-in-10-Years-1280x709.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/1000x-GPU-Gains-in-10-Years.jpg 2014w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<p>The advance was a response to the equally phenomenal rise of <a href="https://blogs.nvidia.com/blog/2023/01/26/what-are-large-language-models-used-for/">large language models</a> used for <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/">generative AI</a> that are growing by an order of magnitude every year.</p>
<p>“That’s been setting the pace for us in the hardware industry because we feel we have to provide for this demand,” Dally said.</p>
<p>In his talk, Dally detailed the elements that drove the 1,000x gain.</p>
<p>The largest of all, a sixteen-fold gain, came from finding simpler ways to represent the numbers computers use to make their calculations.</p>
<h2><b>The New Math</b></h2>
<p>The latest <a href="https://www.nvidia.com/en-us/data-center/technologies/hopper-architecture/">NVIDIA Hopper architecture</a> with its <a href="https://blogs.nvidia.com/blog/2022/03/22/h100-transformer-engine/">Transformer Engine</a> uses a dynamic mix of eight- and 16-bit floating point and integer math. It’s tailored to the needs of today’s generative AI models. Dally detailed both the performance gains and the energy savings the new math delivers.</p>
<p>Separately, his team helped achieve a 12.5x leap by crafting advanced instructions that tell the GPU how to organize its work. These complex commands help execute more work with less energy.</p>
<p>As a result, computers can be “as efficient as dedicated accelerators, but retain all the programmability of GPUs,” he said.</p>
<p>In addition, the <a href="https://www.nvidia.com/en-us/data-center/ampere-architecture/">NVIDIA Ampere architecture</a> added <a href="https://blogs.nvidia.com/blog/2020/05/14/sparsity-ai-inference/">structural sparsity</a>, an innovative way to simplify the weights in AI models without compromising the model’s accuracy. The technique brought another 2x performance increase and promises future advances, too, he said.</p>
<p>Dally described how <a href="https://www.nvidia.com/en-us/data-center/nvlink/">NVLink</a> interconnects between GPUs in a system and <a href="https://www.nvidia.com/en-us/networking/">NVIDIA networking</a> among systems compound the 1,000x gains in single GPU performance.</p>
<h2><b>No Free Lunch  </b></h2>
<p>Though NVIDIA migrated GPUs from 28nm to 5nm semiconductor nodes over the decade, that technology only accounted for 2.5x of the total gains, Dally noted.</p>
<p>That’s a huge change from computer design a generation ago under Moore’s law, an observation that performance should double every two years as chips become ever smaller and faster.</p>
<p>Those gains were described in part by Denard scaling, essentially a physics formula defined in <a href="https://ieeexplore.ieee.org/document/1050511">a 1974 paper</a> co-authored by IBM scientist Robert Denard. Unfortunately, the physics of shrinking hit natural limits such as the amount of heat the ever smaller and faster devices could tolerate.</p>
<h2><b>An Upbeat Outlook</b></h2>
<p>Dally expressed confidence that Huang’s law will continue despite diminishing gains from Moore’s law.</p>
<p>For example, he outlined several opportunities for future advances in further simplifying how numbers are represented, creating more sparsity in AI models and designing better memory and communications circuits.</p>
<p>Because each new chip and system generation demands new innovations, “it’s a fun time to be a computer engineer,” he said.</p>
<p>Dally believes the new dynamic in computer design is giving NVIDIA’s engineers the three opportunities they desire most: to be part of a winning team, to work with smart people and to work on designs that have impact.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/HotChips-2023-2292-Dally-KV-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1091"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/HotChips-2023-2292-Dally-KV-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Heeding Huang’s Law: Video Shows How Engineers Keep the Speedups Coming]]></media:title>
			<media:description type="html">Bill Dally speaking at Hot Chjps 2023</media:description>
			</media:content>
			</item>
		<item>
		<title>Kicking Games Up a Notch: Startup Sports Vision AI to Broadcast Athletics Across the Globe</title>
		<link>https://blogs.nvidia.com/blog/2023/09/28/pixellot-vision-ai-sports-broadcasting/</link>
		
		<dc:creator><![CDATA[Angie Lee]]></dc:creator>
		<pubDate>Thu, 28 Sep 2023 15:00:07 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Customer Stories]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[Jetson]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Metropolis]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67151</guid>

					<description><![CDATA[Pixellot is scoring with vision AI — making it easier for organizations to deliver real-time sports broadcasting and analytics to viewers across the globe. A member of the NVIDIA Metropolis vision AI partner ecosystem, the company based near Tel Aviv offers an AI-powered platform that automates the capturing, streaming and analysis of sporting events. It’s <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/28/pixellot-vision-ai-sports-broadcasting/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Pixellot is scoring with vision AI — making it easier for organizations to deliver real-time sports broadcasting and analytics to viewers across the globe.</p>
<p>A member of the <a href="https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/" target="_blank" rel="noopener">NVIDIA Metropolis</a> vision AI partner ecosystem, the company based near Tel Aviv offers an AI-powered platform that automates the capturing, streaming and analysis of sporting events.</p>
<p>It’s changing the game for fans, coaches and players of nearly 20 different sports — not just basketball and soccer but also rugby and handball — as it broadcasts events and provides analytics from more than 30,000 venues across 70+ countries. In the U.S., Pixellot powers the broadcasting of over a million games every year through its partnership with the NFHS Network, a leader in streaming live and on-demand high school sports.</p>
<p>Through its broadcasting partners like the NFHS Network, MLB and others, Pixellot provides professional analytics, post-match breakdowns and highlights based on jersey numbers with shot charts and heat maps — which can be especially useful for coaches and players of school and pro sports alike as they study their moves to up their game. It also enables interactive experiences for users, who can manipulate viewframes and cut their own highlights for a game.</p>
<p>Recently, <a href="https://supersportschools.com/" target="_blank" rel="noopener">SuperSport Schools</a>, a company based in Cape Town, South Africa, deployed the Pixellot platform to power an app that broadcasts student athletics across the nation, where more than 1,500 high schools are active in sports.</p>
<p>“Our goal is to democratize the coverage of sports with the help of AI and automation,” said Yossi Tarablus, who leads marketing at Pixellot, a member of the <a href="https://www.nvidia.com/en-us/startups/" target="_blank" rel="noopener">NVIDIA Inception</a> program for cutting-edge startups. “Using the <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/" target="_blank" rel="noopener">NVIDIA Jetson</a> platform for edge AI, Pixellot brings powerful technology for sports broadcasting and analytics to some of the world’s most remote areas.”</p>
<p><iframe loading="lazy" title="Introducing Show S3 | The best automated sports camera ever made" width="500" height="281" src="https://www.youtube.com/embed/OWiU1-isCcw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>How Pixellot Works</b></h2>
<p>During peak sports seasons, about 200,000 games a month are broadcasted across the globe using the Pixellot platform, according to Tarablus.</p>
<p>Lightweight Pixellot cameras powered by NVIDIA Jetson capture high-quality video of games, matches and even practices — and livestream them in high definition to users through an app in real time with an overlaid scoreboard, live stats, commentary and more.</p>
<p><img decoding="async" loading="lazy" class="aligncenter wp-image-67187 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/pixellot-featured-667x500.jpg" alt="" width="667" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/pixellot-featured-667x500.jpg 667w, https://blogs.nvidia.com/wp-content/uploads/2023/09/pixellot-featured-400x300.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/pixellot-featured-768x576.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/pixellot-featured-600x450.jpg 600w, https://blogs.nvidia.com/wp-content/uploads/2023/09/pixellot-featured-287x215.jpg 287w, https://blogs.nvidia.com/wp-content/uploads/2023/09/pixellot-featured-133x100.jpg 133w, https://blogs.nvidia.com/wp-content/uploads/2023/09/pixellot-featured.jpg 1024w" sizes="(max-width: 667px) 100vw, 667px" /></p>
<p>The platform creates an automatic viewframe that simulates a camera operator, optimizes videos and corrects scene lighting using <a href="https://www.nvidia.com/en-us/geforce/rtx/" target="_blank" rel="noopener">NVIDIA RTX</a> ray-tracing technology.</p>
<p>In addition, the platform helps organizations and companies monetize sports while making them more accessible to viewers, as it enables over-the-top, or OTT, streaming — direct streaming over the internet without the need for a traditional cable or satellite TV provider.</p>
<p>In all of its camera setups, the Metropolis member runs the <a href="https://developer.nvidia.com/deepstream-sdk" target="_blank" rel="noopener">NVIDIA DeepStream</a> software development kit for AI-powered video streaming analytics. And the company relies on the <a href="https://developer.nvidia.com/tensorrt" target="_blank" rel="noopener">NVIDIA TensorRT SDK</a> for high-performance deep learning inference.</p>
<p>“NVIDIA Jetson made it possible for Pixellot to create the most accurate and affordable AI-powered camera solution for broadcasting live sporting events,” said Gal Oz, chief technology officer and cofounder of Pixellot. “The versatility of Jetson modules in terms of camera pipeline, encoders and AI capabilities enabled Pixellot to develop multiple products based on the same hardware and software platform.”</p>
<h2><b>Broadcasting South African School Sports</b></h2>
<p>High-quality, real-time broadcasts of athletics are difficult to produce without access to a slew of graphics and data.</p>
<p>As the <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/" target="_blank" rel="noopener">NVIDIA Jetson Orin NX</a> module enables AI-powered video processing and GPU-accelerated computing right at the edge — on the field or at courtside — Pixellot lets organizations broadcast sports from anywhere.</p>
<p>“It’s amazing how many people have told us stories about a moment they were empowered to share with their children thanks to SuperSport Schools and Pixellot, because they couldn’t be there physically but were present through live or on-demand video,” said Kelvin Watt, managing director of Capitalize Media and SuperSport Schools, on the Pixellot deployment in South Africa.</p>
<p>The SuperSport Schools app, which is free and recently reached 600,000 subscribers, was the first to broadcast a junior nationals track race in the country.</p>
<p>At the event last year, a student named Viwe Jingqi broke 50-plus-year national records for both the 100- and 200-meter races for South African girls under 18 years old. People all over the world could easily witness these historic victories through the SuperSport Schools app, powered by Pixellot.</p>
<p><iframe loading="lazy" title="Changing the game for THOUSANDS of African athletes &#x1f30d;&#x26bd;&#x1f3c0;" width="500" height="281" src="https://www.youtube.com/embed/1rGbHWLIReQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Building a Smart Sports City in China</b></h2>
<p>In China, tech giant Baidu and the Chengdu Sports Authority are using Pixellot technology in an initiative to develop a smart sports city, with an initial focus on broadcasting community soccer.</p>
<p>Chengdu, the capital of southwestern China’s Sichuan province, is a sports-oriented city and was the host of this year’s <a href="https://olympics.com/en/sport-events/2023-fisu-world-university-games-chengdu" target="_blank" rel="noopener">World University Games</a>, an event sanctioned by the International University Sports Federation.</p>
<p>“Pixellot’s AI-driven sports production solutions are a perfect fit for our strategic vision of delivering innovative technology solutions to communities,” said Liu Chuan, solution director of the intelligent cloud sports industry at <a href="https://www.sportsvideo.org/2023/03/13/pixellot-inks-new-partnership-with-chinas-baidu-to-transform-local-sports-through-ai/" target="_blank" rel="noopener">Baidu</a>.</p>
<p>“Broadcasting community soccer with vision AI is part of the Chengdu initiative’s efforts to emphasize the health benefits of engaging in sports recreationally,” said Tarablus. “It moves the spotlight from pro or Olympic sports to the importance of athletics for all.”</p>
<p><i>Learn more about the </i><a href="https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/" target="_blank" rel="noopener"><i>NVIDIA Metropolis</i></a><i> application framework, developer tools and partner ecosystem.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/pixellot-featured-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/pixellot-featured-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Kicking Games Up a Notch: Startup Sports Vision AI to Broadcast Athletics Across the Globe]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>V for Victory: ‘Cyberpunk 2077: Phantom Liberty’ Comes to GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/2023/09/28/geforce-now-thursday-sep-28/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 28 Sep 2023 13:00:45 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67195</guid>

					<description><![CDATA[The wait is over. GeForce NOW Ultimate members can experience Cyberpunk 2077: Phantom Liberty on GOG.com at full GeForce RTX 4080 quality, with support for NVIDIA DLSS 3.5 technology. It’s part of an action-packed GFN Thursday, with 26 more games joining the cloud gaming platform’s library, including Quake II from id Software. A New Look <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/28/geforce-now-thursday-sep-28/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The wait is over. GeForce NOW <a href="https://www.nvidia.com/en-us/geforce-now/memberships/">Ultimate</a> members can experience <i>Cyberpunk 2077:</i> <i>Phantom Liberty</i> on GOG.com at full <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4080/">GeForce RTX 4080</a> quality, with support for <a href="https://www.nvidia.com/en-us/geforce/news/nvidia-dlss-3-5-ray-reconstruction/">NVIDIA DLSS 3.5</a> technology.</p>
<p>It’s part of an action-packed GFN Thursday, with 26 more games joining the cloud gaming platform’s library, including <i>Quake II</i> from id Software.</p>
<h2><b>A New Look for Night City</b></h2>
<figure id="attachment_67205" aria-describedby="caption-attachment-67205" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Cyberpunk_2077_Phantom_Liberty-scaled.jpg"><img decoding="async" loading="lazy" class="size-large wp-image-67205" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Cyberpunk_2077_Phantom_Liberty-672x378.jpg" alt="Cyberpunk 2077: Phantom Liberty on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Cyberpunk_2077_Phantom_Liberty-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Cyberpunk_2077_Phantom_Liberty-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Cyberpunk_2077_Phantom_Liberty-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Cyberpunk_2077_Phantom_Liberty-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Cyberpunk_2077_Phantom_Liberty-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Cyberpunk_2077_Phantom_Liberty-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Cyberpunk_2077_Phantom_Liberty-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Cyberpunk_2077_Phantom_Liberty-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Cyberpunk_2077_Phantom_Liberty-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67205" class="wp-caption-text">Experience NVIDIA DLSS 3.5 in <em>Cyberpunk 2077’s</em> spy-thriller expansion.</figcaption></figure>
<p>Take on a thrilling challenge with <i>Phantom Liberty</i>, an all-new adventure for <i>Cyberpunk 2077</i>. When the orbital shuttle of the President of the New United States of America is shot down over the deadliest district of Night City, there’s only one person who can save her. Become V, a cyberpunk for hire, and dive into a tangled web of espionage and political intrigue, unraveling a story that connects the highest echelons of power with the brutal world of black-market mercenaries.</p>
<p>Ultimate members can return to the neon lights of Night City and experience the benefits of NVIDIA DLSS 3.5 and its new Ray Reconstruction technology. These updates enhance the quality of full ray tracing in <i>Cyberpunk 2077</i>’s Ray Tracing: Overdrive Mode, as part of the game’s 2.0 update available for the base game for free and included with the <i>Phantom Liberty</i> expansion. Upgrade to a GeForce NOW Ultimate membership today to see Night City at its best.</p>
<h2><b>Prepare for War</b></h2>
<figure id="attachment_67202" aria-describedby="caption-attachment-67202" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Quake_II.jpg"><img decoding="async" loading="lazy" class="size-large wp-image-67202" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Quake_II-672x336.jpg" alt="Quake II on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Quake_II-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Quake_II-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Quake_II-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Quake_II-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Quake_II-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Quake_II-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Quake_II-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Quake_II-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Quake_II.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67202" class="wp-caption-text">id Software’s classic first-person shooter is better than ever, streaming from the cloud.</figcaption></figure>
<p>Experience the authentic, enhanced and complete version of id Software’s critically acclaimed first-person shooter, <i>Quake II</i>, now streaming from the cloud.</p>
<p>Humankind is at war with the Strogg, a hostile alien race that’s attacked Earth. In response, humanity launched a strike on the Strogg homeworld — which failed. Outnumbered and outgunned, battle through fortified military installations to shut down the enemy’s war machine. Only then will the fate of humanity be decided.</p>
<p><i>Quake II</i> includes a new, enhanced version of id Software’s classic, along with both original mission packs: “The Reckoning” and “Ground Zero.” Plus, battle through 28 campaign levels in MachineGames’ all-new “Call of the Machine” expansion and play through the exclusive levels from <i>Quake II 64</i> for the first time on PC. Blast the Stroggs or friends in classic multiplayer modes at up to 4K and 120 frames per second or with ultrawide resolutions for GeForce NOW Ultimate members.</p>
<h2><b>Nice Shootin,’ Tex</b></h2>
<figure id="attachment_67199" aria-describedby="caption-attachment-67199" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Ultimate_KovaaKs_Challenge_Leaderboard.jpg"><img decoding="async" loading="lazy" class="size-large wp-image-67199" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Ultimate_KovaaKs_Challenge_Leaderboard-672x354.jpg" alt="GeForce NOW Kovaaks Ultimate Challenge" width="672" height="354" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Ultimate_KovaaKs_Challenge_Leaderboard-672x354.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Ultimate_KovaaKs_Challenge_Leaderboard-400x211.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Ultimate_KovaaKs_Challenge_Leaderboard-768x404.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Ultimate_KovaaKs_Challenge_Leaderboard-842x443.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Ultimate_KovaaKs_Challenge_Leaderboard-406x215.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Ultimate_KovaaKs_Challenge_Leaderboard-188x100.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Ultimate_KovaaKs_Challenge_Leaderboard.jpg 1126w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67199" class="wp-caption-text">Ultimate leads the way.</figcaption></figure>
<p>The <a href="https://blogs.nvidia.com/blog/2023/08/10/geforce-now-thursday-aug-10/">GeForce NOW Ultimate KovaaK’s challenge</a> is complete, and the results are in: Ultimate power means more ultimate wins. Members worked to sharpen their skills and win amazing prizes during the challenge while experiencing the power of Ultimate for themselves. With up to 240 fps streaming at ultra-low latency, gamers are playing up to their ultimate potential, just by upgrading to an Ultimate membership.</p>
<p>The proof is in the data. Check out some powerful stats showing what Ultimate members accomplished:</p>
<ul>
<li>Nearly <b>15,000</b> people took on the challenge, playing over <b>120,000 sessions</b>.</li>
<li>Members saw a <b>2x boost</b> in scores when playing on Ultimate over a Free membership.</li>
<li>All of the leaderboard’s <b>top 25 slots</b> were filled with those playing on Ultimate.</li>
</ul>
<p>But don’t just take our word for it. Here’s what it felt like for TinooQ, who placed third overall in the challenge:</p>
<blockquote><p><i>“As a long-time KovaaK’s user, transitioning to this platform was seamless, as the precision and responsiveness was nothing short of extraordinary. </i></p>
<p><i>“The minimal latency and the consistent 240 fps made me think that many people could rely solely on the GeForce NOW Ultimate plan and a monitor, that’s all. I found it perfect for top gaming, saving a lot of money and the PC hardware headaches I suffered when building mine.” — TinooQ</i></p></blockquote>
<p>And check out what the press had to say about the Ultimate membership tier:</p>
<blockquote><p>“GeForce NOW KovaaK&#8217;s Challenge Proves Gaming At Glorious 240 FPS Matters” – <a href="https://hothardware.com/news/geforce-now-kovaaks-challenge-240-fps-matters">Hot Hardware</a></p>
<p>“Hot dang does GeForce Now Ultimate ever deliver.” – <a href="https://www.tomsguide.com/opinion/i-just-played-cyberpunk-2077-at-60-fps-on-a-dollar120-laptop-heres-how">Tom’s Guide</a></p>
<p>“NVIDIA GeForce NOW has held the crown for cloud gaming performance for a while now, and it’s just getting better.” – <a href="https://9to5google.com/2023/08/10/geforce-now-ultimate-rtx-4080-upgrade/">9to5Google</a></p>
<p>“Unsurprisingly, NVIDIA says 98% of the users who tried Kovaak’s Challenge on the GeForce NOW Ultimate tier have seen improvements in their test results over the free tier.” – <a href="https://wccftech.com/geforce-now-adds-gord-shadow-gambit-texas-chainsaw-massacre-wayfinder-and-more-this-week/">Wccftech</a></p>
<p>“Nvidia has taken a different approach to cloud gaming: Instead of boosting their library and settling for 1080p 60fps, Nvidia’s GeForce Now service prioritizes performance, implementing faster graphics cards for players to use.” – <a href="https://www.slashgear.com/1363048/geforce-now-4080-servers-ultimate/">SlashGear</a></p>
<p>“One of the distinguishing factors of GeForce Now is its superior image quality and lack of noticeable input delay. ” –<a href="https://gameishard.gg/news/geforce-now-game-streaming-is-like-magic-and-it-puts-xboxs-cloud-effort-to-shame/39297/"> Game Is Hard</a></p>
<p>“NVIDIA’s GeForce NOW is widely considered one of the best cloud gaming platforms in terms of latency, visual fidelity, and overall experience.” — <a href="https://www.tweaktown.com/news/93300/starfield-is-available-to-stream-in-4k-via-nvidia-geforce-now-supporting-steam-and-game-pass/index.html">TweakTown</a></p></blockquote>
<p>Everyone’s a winner when they play on Ultimate. Upgrade today for the best performance in the cloud, even when streaming popular shooters like <i>Counter Strike, Destiny 2, Tom Clancy’s Rainbow Six Siege </i>and more, where every frame counts.</p>
<p>Even better, Ultimate members get a free copy of <i>KovaaK</i>’<i>s</i> – the world’s best aim trainer. Don’t miss this chance to claim the reward, starting today, only for Ultimate members. Be on the lookout for an email starting today, available only for a limited time.</p>
<h2><b>Challenge Accepted</b></h2>
<figure id="attachment_67196" aria-describedby="caption-attachment-67196" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Infinity_Strash_DRAGON_QUEST_The_Adventures_Of_Dai.jpg"><img decoding="async" loading="lazy" class="size-large wp-image-67196" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Infinity_Strash_DRAGON_QUEST_The_Adventures_Of_Dai-672x336.jpg" alt="Infinity Strash DRAGON QUEST The Adventure of Dai on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Infinity_Strash_DRAGON_QUEST_The_Adventures_Of_Dai-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Infinity_Strash_DRAGON_QUEST_The_Adventures_Of_Dai-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Infinity_Strash_DRAGON_QUEST_The_Adventures_Of_Dai-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Infinity_Strash_DRAGON_QUEST_The_Adventures_Of_Dai-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Infinity_Strash_DRAGON_QUEST_The_Adventures_Of_Dai-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Infinity_Strash_DRAGON_QUEST_The_Adventures_Of_Dai-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Infinity_Strash_DRAGON_QUEST_The_Adventures_Of_Dai-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Infinity_Strash_DRAGON_QUEST_The_Adventures_Of_Dai-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Infinity_Strash_DRAGON_QUEST_The_Adventures_Of_Dai.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67196" class="wp-caption-text">Be a hero. Be Dai.</figcaption></figure>
<p>Square Enix’s <i>Infinity Strash: DRAGON QUEST The Adventure of Dai</i> leads 26 new titles in the GeForce NOW library this week. In this action role-playing game based on the popular anime and manga series of the same name, Dai and his friends must fight the Dark Lord Hadlar and his evil army of monsters. Fulfill Dai’s dream of becoming a hero in this game, which features fast-paced, dynamic combat, stunning anime-style graphics and a rich storyline.</p>
<p>Here’s the full list of what’s joining this week:</p>
<ul>
<li><i>These Doomed Isles</i> (New release on <a href="https://store.steampowered.com/app/1840710?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Sept. 25)</li>
<li><i>Paleo Pines </i>(New release on <a href="https://store.steampowered.com/app/1202200?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Sept. 26)</li>
<li><i>Infinity Strash: DRAGON QUEST The Adventure of Dai </i>(New release on <a href="https://store.steampowered.com/app/1895810?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Sept. 28)</li>
<li><i>Pizza Possum </i>(New release on <a href="https://store.steampowered.com/app/1951230?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Sept. 28)</li>
<li><i>Wildmender </i>(New release on <a href="https://store.steampowered.com/app/1599330?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Sept. 28)</li>
<li><i>Overpass 2 </i>(New release on <a href="https://store.steampowered.com/app/1830630?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Sept. 28)</li>
<li><i>Soulstice </i>(New release on <a href="https://www.epicgames.com/store/p/soulstice?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, Free on Sept. 28)</li>
<li><i>Amnesia: Rebirth </i>(<a href="https://www.xbox.com/games/store/amnesia-rebirth/9PMM21KVRD72?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>BlazBlue: Cross Tag Battle </i>(<a href="https://www.xbox.com/games/store/blazblue-cross-tag-battle-special-edition/9NFWDRBZXDL9?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Bramble: The Mountain King </i>(<a href="https://www.xbox.com/games/store/bramble-the-mountain-king/9NHDFTCL691C?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Broforce (</i><a href="https://store.steampowered.com/app/274190?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a><i>)</i></li>
<li><i>Don Duality (</i><a href="https://store.steampowered.com/app/2247570?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a><i>)</i></li>
<li><i>Doom Eternal </i>(<a href="https://www.xbox.com/games/store/Doom-eternal-standard-edition-pc/9PK09BL31FK1?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Dordogne </i>(<a href="https://www.xbox.com/games/store/dordogne/9pbc65kxpv5v?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Dust Fleet </i>(<a href="https://store.steampowered.com/app/406160?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Eastern Exorcist </i>(<a href="https://www.xbox.com/games/store/eastern-exorcist/9NQCJ132C6KW?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Figment 2: Creed Valley </i>(<a href="https://www.xbox.com/games/store/figment-2-creed-valley/9NZWW8K1KX6S?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>I Am Fish </i>(<a href="https://www.xbox.com/games/store/i-am-fish/9mxgj8jzl0lk?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>)</li>
<li><i>Necesse </i>(<a href="https://store.steampowered.com/app/1169040?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>A Plague Tale: Innocence </i>(<a href="https://www.xbox.com/games/store/a-plague-tale-innocence-windows-10/9ND0CG3LM22K?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>)</li>
<li><i>Quake II </i>(<a href="https://store.steampowered.com/app/2320?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.epicgames.com/store/p/quake-ii?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a> and <a href="https://www.xbox.com/games/store/quake-ii/9P7L9H478GGV?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Road 96 </i>(<a href="https://www.xbox.com/games/store/road-96/9NVBKDF85W8T?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>)</li>
<li><i>Spacelines from the Far Out </i>(<a href="https://www.xbox.com/games/store/spacelines-from-the-far-out/9N23WV1HGLTQ?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>)</li>
<li><i>Totally Reliable Delivery Service </i>(<a href="https://www.xbox.com/games/store/totally-reliable-delivery-service/9NZG72SH3H4W?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Warhammer 40,000: Battlesector </i>(<a href="https://www.xbox.com/games/store/warhammer-40000-battlesector/9PFLW6WZVJC7?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Yooka-Laylee and the Impossible Lair </i>(<a href="https://www.xbox.com/games/store/yooka-laylee-and-the-impossible-lair/9NB1LCQDPPM1?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">Twitter</a> or in the comments below.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/gfn-thursday-9-28-nv-blog-1280x680-no-cta.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/gfn-thursday-9-28-nv-blog-1280x680-no-cta-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[V for Victory: ‘Cyberpunk 2077: Phantom Liberty’ Comes to GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>DENZA Unwraps Smart Driving Options for N7 Model Lineup, Powered by NVIDIA DRIVE Orin</title>
		<link>https://blogs.nvidia.com/blog/2023/09/27/denza-smart-driving-n7-model-nvidia-drive-orin/</link>
		
		<dc:creator><![CDATA[Calisa Cole]]></dc:creator>
		<pubDate>Wed, 27 Sep 2023 16:41:47 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Driving]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<category><![CDATA[Omniverse]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67180</guid>

					<description><![CDATA[DENZA, the luxury electric-vehicle brand and joint venture between BYD and Mercedes-Benz, is debuting new intelligent driving features for its entire N7 model lineup, powered by the NVIDIA DRIVE Orin system-on-a-chip (SoC). The N7 series was introduced earlier this year as a family of spacious five-seater SUVs for commuters looking to sport a deluxe EV <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/27/denza-smart-driving-n7-model-nvidia-drive-orin/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>DENZA, the luxury electric-vehicle brand and joint venture between BYD and Mercedes-Benz, is debuting new intelligent driving features for its entire N7 model lineup, powered by the <a href="https://www.nvidia.com/en-us/self-driving-cars/hardware/" target="_blank" rel="noopener">NVIDIA DRIVE Orin</a> system-on-a-chip (SoC).</p>
<p>The N7 series was introduced earlier this year as a family of spacious five-seater SUVs for commuters looking to sport a deluxe EV with advanced driving functionality.</p>
<p>All N7 models can be equipped with the NVIDIA DRIVE Orin SoC for high-performance compute to simultaneously run in-vehicle applications and deep neural networks for automated driving.</p>
<p>NVIDIA DRIVE Orin serves as the brain behind DENZA’s proprietary Commuter Smart Driving system, which offers an array of smart features, including:</p>
<ul>
<li>Navigate on autopilot for high-speed, all-scenario assisted driving.</li>
<li>Intelligent speed-limit control and emergency lane-keeping aid, for safer commutes on urban roads and highways.</li>
<li>Enhanced automatic emergency braking and front cross-traffic alert for increased safety at intersections and on narrow streets.</li>
<li>Automated parking assist, which scouts for parking spots, identifying horizontal, vertical and diagonal spaces to ease the challenge of parking in crowded areas.</li>
</ul>
<h2><strong>Next-Gen Car Configuration</strong></h2>
<p>In addition to adopting accelerated computing in the car, DENZA is one of the flagship automotive trailblazers using the <a href="https://www.nvidia.com/en-us/omniverse/cloud/" target="_blank" rel="noopener">NVIDIA Omniverse Cloud</a> platform to build and deploy next-generation car configurators to deliver greater personalization options for the consumer’s vehicle-purchasing experience.</p>
<p><i>Learn more about the </i><a href="https://blogs.nvidia.com/blog/2023/08/08/denza-wpp-car-configurators-nvidia-omniverse-cloud/" target="_blank" rel="noopener"><i>DENZA N7 3D configurator</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/denzfinal2.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/denzfinal2-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[DENZA Unwraps Smart Driving Options for N7 Model Lineup, Powered by NVIDIA DRIVE Orin]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>The Fastest Path: Healthcare Startup Uses AI to Analyze Cancer Cells in the Operating Room</title>
		<link>https://blogs.nvidia.com/blog/2023/09/27/healthcare-ai-startup-analyzes-cancer-cells-in-the-operating-room/</link>
		
		<dc:creator><![CDATA[Renee Yao]]></dc:creator>
		<pubDate>Wed, 27 Sep 2023 13:00:40 +0000</pubDate>
				<category><![CDATA[Autonomous Machines]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Embedded Computing]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[Jetson]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67110</guid>

					<description><![CDATA[Medical-device company Invenio Imaging is developing technology that enables surgeons to evaluate tissue biopsies in the operating room, immediately after samples are collected — providing in just three minutes AI-accelerated insights that would otherwise take weeks to obtain from a pathology lab. In a surgical biopsy, a medical professional removes samples of cells or tissue <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/27/healthcare-ai-startup-analyzes-cancer-cells-in-the-operating-room/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Medical-device company Invenio Imaging is developing technology that enables surgeons to evaluate tissue biopsies in the operating room, immediately after samples are collected — providing in just three minutes AI-accelerated insights that would otherwise take weeks to obtain from a pathology lab.</p>
<p>In a surgical biopsy, a medical professional removes samples of cells or tissue that pathologists analyze for diseases such as cancer. By delivering these capabilities through a compact, AI-powered imaging system within the treatment room, Invenio aims to support rapid clinical decision-making.</p>
<p>“This technology will help surgeons make intraoperative decisions when performing a biopsy or surgery,” said Chris Freudiger, chief technology officer of Silicon Valley-based Invenio. “They’ll be able to rapidly evaluate whether the tissue sample contains cancerous cells, decide whether they need to take another tissue sample and, with the AI models Invenio is developing, potentially make a molecular diagnosis for personalized medical treatment within minutes.”</p>
<p>Quicker diagnosis enables quicker treatment. It’s especially critical for aggressive types of cancer that could grow or spread significantly in the weeks it takes for biopsy results to return from a dedicated pathology lab.</p>
<p>Invenio is a member of <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a>, a program that provides cutting-edge startups with technological support and AI platform guidance. The company accelerates AI training and inference using NVIDIA GPUs and software libraries.</p>
<h2><b>Laser Focus on Cancer Care</b></h2>
<figure id="attachment_67119" aria-describedby="caption-attachment-67119" style="width: 279px" class="wp-caption alignright"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/image001.png"><img decoding="async" loading="lazy" class="wp-image-67119 size-medium" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image001-279x400.png" alt="" width="279" height="400" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image001-279x400.png 279w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image001-349x500.png 349w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image001-314x450.png 314w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image001-150x215.png 150w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image001-70x100.png 70w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image001.png 693w" sizes="(max-width: 279px) 100vw, 279px" /></a><figcaption id="caption-attachment-67119" class="wp-caption-text">The NIO Laser Imaging System accelerates the imaging of fresh tissue biopsies.</figcaption></figure>
<p>Invenio’s NIO Laser Imaging System is a digital pathology tool that accelerates the imaging of fresh tissue biopsies. It’s been used in thousands of procedures in the U.S. and Europe. In 2021, it received the CE Mark of regulatory approval in Europe.</p>
<p>The company plans to adopt the <a href="https://www.nvidia.com/en-us/lp/embedded-computing/robotics-edge-ai-tech-brief/">NVIDIA Jetson Orin series of edge AI modules</a> for its next-generation imaging system, which will feature near real-time AI inference accelerated by the <a href="https://developer.nvidia.com/tensorrt#:~:text=TensorRT%20provides%20INT8%20using%20quantization,detection%2C%20and%20natural%20language%20processing.">NVIDIA TensorRT SDK</a>.</p>
<p>“We’re building a layer of AI models on top of our imaging capabilities to provide physicians with not just the diagnostic image but also an analysis of what they’re seeing,” Freudiger said. “With the AI performance provided by NVIDIA Jetson at the edge, they’ll be able to quickly determine what kinds of cancer cells are present in a biopsy image.”</p>
<p>Invenio uses a cluster of <a href="https://www.nvidia.com/en-us/design-visualization/rtx-a6000/">NVIDIA RTX A6000 GPUs</a> to train neural networks with tens of millions of parameters on pathologist-annotated images. The models were developed using the <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow">TensorFlow deep learning framework</a> and trained on images acquired with NIO imaging systems.</p>
<p>“The most powerful capability for us is the expanded VRAM on the RTX A6000 GPUs, which allows us to load large batches of images and capture the variability of features,” Freudiger said. “It makes a big difference for AI training.”</p>
<h2><b>On the Path to Clinical Deployment</b></h2>
<p>One of Invenio’s AI products, NIO Glioma Reveal, is approved for clinical use in Europe and available for research use in the U.S. to help identify areas of cancerous cells in brain tissue.</p>
<p>A team of Invenio’s collaborators from the University of Michigan, New York University, University of California San Francisco, the Medical University of Vienna and University Hospital of Cologne recently developed a <a href="https://deepglioma.mlins.org/" target="_blank" rel="noopener">deep learning model</a> that can find biomarkers of cancerous tumors with <a href="https://www.nature.com/articles/s41591-023-02252-4" target="_blank" rel="noopener">93% accuracy</a> in 90 seconds.</p>
<p>With this ability to analyze different molecular subtypes of cancer within a tissue sample, doctors can predict how well a patient will respond to chemotherapy — or determine whether a tumor has been successfully removed during surgery.</p>
<p>Beyond its work on brain tissue analysis, Invenio this year announced a clinical research <a href="https://www.prnewswire.com/news-releases/invenio-imaging-announces-clinical-research-collaboration-agreement-301712598.html" target="_blank" rel="noopener">collaboration with Johnson &amp; Johnson’s Lung Cancer Initiative</a> to develop and validate an AI solution that can help evaluate lung biopsies. The AI model will help doctors rapidly determine whether collected tissue samples contain cancer.</p>
<p>Lung cancer is the world’s <a href="https://www.who.int/news-room/fact-sheets/detail/cancer" target="_blank" rel="noopener">deadliest form of cancer</a>, and in the U.S. alone, lung nodules are found in <a href="https://pubmed.ncbi.nlm.nih.gov/35040882/#:~:text=Importance%3A%20Pulmonary%20nodules%20are%20identified,CT)%20images%20of%20the%20chest.">over 1.5 million</a> patients each year. Once approved for clinical use, Invenio’s NIO Lung Cancer Reveal tool aims to shorten the time needed to analyze tissue biopsies for these patients.</p>
<p>As part of this initiative, Invenio will run a clinical study before submitting the NVIDIA Jetson-powered AI solution for FDA approval.</p>
<p><a href="https://www.nvidia.com/en-us/industries/healthcare-life-sciences/healthcare-news-sign-up/"><i>Subscribe to NVIDIA healthcare news</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/Ambra_1_blogsize.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/Ambra_1_blogsize-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[The Fastest Path: Healthcare Startup Uses AI to Analyze Cancer Cells in the Operating Room]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Works With NTT DOCOMO to Launch World’s First GPU-Accelerated 5G Network</title>
		<link>https://blogs.nvidia.com/blog/2023/09/26/ntt-docomo-gpu-accelerated-5g-network/</link>
		
		<dc:creator><![CDATA[Soma Velayutham]]></dc:creator>
		<pubDate>Wed, 27 Sep 2023 00:00:03 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[5G]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[NVIDIA BlueField]]></category>
		<category><![CDATA[Telecommunications]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67153</guid>

					<description><![CDATA[As generative AI sweeps across corporate boardrooms around the world, global telecommunications companies are exploring how to cost-effectively deliver many of these new AI applications to the edge over 5G and upcoming 6G networks. Telcos plan to deploy over 17 million 5G microcells and towers worldwide by 2025. Building, managing and optimizing this new infrastructure <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/26/ntt-docomo-gpu-accelerated-5g-network/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>As generative AI sweeps across corporate boardrooms around the world, global telecommunications companies are exploring how to cost-effectively deliver many of these new AI applications to the edge over 5G and upcoming 6G networks.</p>
<p>Telcos plan to deploy over 17 million 5G microcells and towers worldwide by 2025. Building, managing and optimizing this new infrastructure while maintaining quality-of-service delivery and maximizing the customer experience is the industry’s next big challenge.</p>
<p>Today, <a href="https://www.docomo.ne.jp/english/info/media_center/pr/2023/0927_00.html" target="_blank" rel="noopener">NTT DOCOMO announced</a> it is deploying a <a href="https://developer.nvidia.com/blog/enabling-the-worlds-first-gpu-accelerated-5g-open-ran-for-ntt-docomo-with-nvidia-aerial/">GPU-accelerated wireless solution</a> in its network in Japan. This makes it the first-ever telco in the world to deploy a GPU-accelerated commercial 5G network.</p>
<p>DOCOMO’s move aims to address the multibillion-dollar problem of driving improvements in performance, total cost of ownership and energy efficiency while unlocking the flexibility, scalability and supply chain diversity promise of <a href="https://www.o-ran.org/" target="_blank" rel="noopener">Open RAN</a>.</p>
<p>The 5G Open RAN solution uses a high-performance 5G virtual radio access network (vRAN) from Fujitsu built on the <a href="https://developer.nvidia.com/aerial-sdk" target="_blank" rel="noopener">NVIDIA Aerial vRAN stack</a> and <a href="https://www.nvidia.com/en-us/data-center/products/converged-accelerator/" target="_blank" rel="noopener">NVIDIA Converged Accelerators</a>. This combination enables telcos to create a fully software- and cloud-defined network that can dynamically allocate resources using industry-standard equipment.</p>
<p>“Open RAN offers the opportunity to build next-generation 5G networks with unprecedented flexibility and scalability thanks to multivendor connections,” said Sadayuki Abeta, global head of Open RAN solutions at NTT DOCOMO. “We look forward to continuing working with NVIDIA on infrastructure solutions that meet those needs.”</p>
<p>The 5G Open RAN solution is the first 5G vRAN for telco commercial deployment using the NVIDIA Aerial platform, with a hardened, carrier-grade vRAN stack. The platform brings together the NVIDIA Aerial vRAN stack for 5G, AI frameworks, accelerated compute infrastructure and long-term software support and maintenance.</p>
<h2><strong>Cost and Energy-Efficiency Benefits of GPU Acceleration</strong></h2>
<p>Working with offerings from Fujitsu and Wind River, the new 5G solution uses the NVIDIA Aerial platform to lower costs and reduce power consumption. Compared to its existing 5G network deployments, DOCOMO says the solution reduces total costs by up to 30%, network design utilization by up to 50%, and power consumption at base stations by up to 50%.</p>
<p>“Delivering a 5G Open RAN network that meets stringent performance requirements of operators is a significant accomplishment,” said Masaki Taniguchi, senior vice president and head of the Mobile System Business Unit at Fujitsu Limited. “Using our Fujitsu vCU/vDU, in combination with NVIDIA Aerial platform, will help network operators to efficiently build high-performance 5G networks for consumers and businesses alike.”</p>
<p>NVIDIA’s contribution to the DOCOMO rollout is part of a growing portfolio of 5G solutions that are driving transformation in the telecommunications industry. Anchored on NVIDIA Aerial vRAN stack and NVIDIA Converged Accelerators — combined with <a href="https://www.nvidia.com/en-us/networking/products/data-processing-unit/" target="_blank" rel="noopener">NVIDIA BlueField data processing units (DPUs)</a> and a suite of AI frameworks — NVIDIA provides a high-performance, software-defined, cloud-native, AI-enabled 5G for on-premises and telco operators’ RAN.</p>
<p>Fujitsu, NVIDIA and Wind River have been working under the OREX (5G Open RAN service brand), which was launched by DOCOMO in February 2021, to develop the Open RAN 5G vRAN. OREX has been deployed in Japan based on Fujitsu’s virtualized DU (vDU) and virtualized CU (vCU) and leverages commercial off-the-shelf servers, the Wind River cloud platform, Fujitsu’s 5G vRAN software and the NVIDIA Aerial vRAN stack and NVIDIA Converged Accelerators.</p>
<p>“Wind River is delighted to work with NTT DOCOMO, Fujitsu and NVIDIA towards a vision of improved efficiency of RAN deployments and operations,” said Paul Miller, chief technology officer at Wind River. “Wind River Studio provides a cloud-native, distributed cloud, automation, and analytics solution based on open source, so that operators can deploy and manage their 5G edge networks globally at high scale with faster innovation. This solution is proven in highly scaled production deployments today.”</p>
<h2><strong>OREX: Building Out From Japan and Beyond</strong></h2>
<p>DOCOMO and its partners in OREX are promoting a multivendor, Open RAN-compliant 5G vRAN to the global operator community. The commercial deployment in Japan is a first step in the vision of OREX, where members can commercially validate their solutions and then promote them to other operators globally.</p>
<p>NVIDIA is working with DOCOMO and other partners to support operators around the world to deploy high-performance, energy-efficient, software-defined, commercial 5G vRAN.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/docomo2.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/docomo2-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Works With NTT DOCOMO to Launch World’s First GPU-Accelerated 5G Network]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Founder and CEO Jensen Huang Returns to Denny’s Where NVIDIA Launched a Trillion-Dollar Vision</title>
		<link>https://blogs.nvidia.com/blog/2023/09/26/nvidia-dennys-trillion/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Tue, 26 Sep 2023 20:37:19 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67152</guid>

					<description><![CDATA[Talk about a Grand Slam. Denny’s CEO Kelli Valade was joined Tuesday by NVIDIA CEO Jensen Huang to unveil a plaque at the Silicon Valley Denny’s where NVIDIA’s founders hatched their idea for a chip that would enable realistic 3D graphics on personal computers. “This is a place where we fuel ideas. Your story is <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/26/nvidia-dennys-trillion/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Talk about a Grand Slam.</p>
<p>Denny’s CEO Kelli Valade was joined Tuesday by NVIDIA CEO Jensen Huang to unveil a plaque at the Silicon Valley Denny’s where NVIDIA’s founders hatched their idea for a chip that would enable realistic 3D graphics on personal computers.</p>
<p>“This is a place where we fuel ideas. Your story is so inspiring it will continue to inspire people at Denny’s,” Valade said, as she presented the plaque to Huang.</p>
<p>“Denny’s has taught me so many lessons,” Huang said.</p>
<p>Both CEOs got their start working in diners. Valade got her first job as a waitress at a diner when she was 16. Huang got his first job at Denny’s in Portland when he was 15.</p>
<p>“I was a dishwasher, I was a busboy, I waited tables,” Huang said. “No one can carry more coffee cups than I can.”</p>
<p>To fuel even more great ideas, Valade announced the Denny’s Trillion-Dollar Incubator Contest — offering $25,000 in seed money for the next $1 trillion idea.</p>
<p><img decoding="async" loading="lazy" class="alignleft wp-image-67166 size-medium" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-278x400.jpg" alt="https://apimages.photoshelter.com/galleries/C0000IW9ydIWWwzE/2023-09-30-Denny-s-Trillion-Dollar-Incubator" width="278" height="400" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-278x400.jpg 278w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-347x500.jpg 347w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-768x1106.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-1067x1536.jpg 1067w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-scaled.jpg 1422w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-312x450.jpg 312w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-149x215.jpg 149w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-69x100.jpg 69w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-1280x1843.jpg 1280w" sizes="(max-width: 278px) 100vw, 278px" />The contest is open to anyone with a creative and innovative idea that could impact the world. The only catch? The idea must originate — like NVIDIA — in a Denny’s booth.</p>
<p>NVIDIA, the leading accelerated computing and AI company, got its start at the 24-hour diner chain known for favorites such as its signature Grand Slam breakfast combo.</p>
<p>In 1993, three friends — Huang, Chris Malachowsky and Curtis Priem — met at Denny’s to discuss creating a chip that would enable realistic 3D graphics on personal computers.</p>
<p>The Denny’s just off a busy thoroughfare in the heart of Silicon Valley was the perfect place to start a business, said Huang, who lived nearby at the time with his wife and kids.</p>
<p>“It had all the coffee you could drink and no one could chase you out,” Huang told Valade.</p>
<p>Tuesday’s event took place in a corner of the bustling restaurant — one of the most popular Denny’s locations in Northern California — as families, retirees and workers coming off the night shift piled in for plates piled high with eggs and pancakes, sausage and bacon.</p>
<p>Huang was among them, starting the day with a meeting where he and his table polished off a Lumberjack Slam, Moons Over My Hammy and a Super Bird sandwich — washed down with plenty of coffee.  <b><br />
</b><br />
Huang, whose family immigrated to the United States from Taiwan when he was a child, told Valade he had his first hamburger at Denny’s and his first milkshake.</p>
<p>“We make the best pancakes here,” Huang said.</p>
<p>“I love how you still say ‘we,’” Valade said.</p>
<p>“Made fresh every day,” Huang added with a grin.</p>
<p>Valade and Huang said Denny’s can be a great launching pad, not just for great ideas, but for great careers.</p>
<p>“Start your first job in the restaurant business,” Huang said. “It teaches you humility, it teaches you hard work, it teaches you hospitality.”</p>
<p>Valade agreed wholeheartedly. After talking shop with Huang, she checked in with diners like Alfred, who was tucking into a stack of pancakes amid the morning rush.</p>
<p>For people across Silicon Valley, it’s the place to be. “I come here every day,” the retired roofer said.</p>
<p><b>Full contest details for the Denny’s Trillion Dollar Incubator Contest can be found at </b><a href="http://www.dennys.com/trilliondollarincubator"><b>www.dennys.com/trilliondollarincubator</b></a><b>. Contestants can submit their ideas online or at a Denny’s restaurant by Nov. 21 at 8:59 a.m. The winner will be announced early next year.</b></p>
<p>&nbsp;</p>
<p><em>Image credit: Don Feria/AP Images for Denny&#8217;s</em></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/Valade-Huang-Dennys-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1365"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/Valade-Huang-Dennys-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Founder and CEO Jensen Huang Returns to Denny’s Where NVIDIA Launched a Trillion-Dollar Vision]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI Power Players: GeForce and NVIDIA RTX GPUs Supercharge Creativity, Gaming, Development, Productivity and More</title>
		<link>https://blogs.nvidia.com/blog/2023/09/26/itns-rtx-ai-windows/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 26 Sep 2023 13:00:49 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67123</guid>

					<description><![CDATA[From gaming to creating to everyday productivity, NVIDIA RTX graphics cards feature specialized Tensor Cores that deliver cutting-edge performance and transformative capabilities for AI. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. We’re also deep-diving on new </i><a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/"><i>GeForce RTX 40 Series GPU</i></a> <i>features, technologies and resources and how they dramatically accelerate content creation.</i></p>
<p>Improving gaming, creating and everyday productivity, NVIDIA RTX graphics cards feature specialized Tensor Cores that deliver cutting-edge performance and transformative capabilities for AI.</p>
<p>An arsenal of 100 million AI-ready, RTX-powered Windows 11 PCs and workstations are primed to excel in AI workflows and help launch a new wave of training models and apps.</p>
<p>This week <i>In the NVIDIA Studio</i>, learn more about these AI power-players and read about Victor de Martrin, a self-taught 3D artist who shares the creative process behind his viral video <i>Ascension</i>, which features an assist from AI and uses a new visual effect process involving point clouds.</p>
<p><iframe loading="lazy" title="3D TRANSITION with Point Clouds" width="500" height="281" src="https://www.youtube.com/embed/S_zKwzaVsP4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>AI on the Prize</b></h2>
<p>AI can elevate both work and play.</p>
<p>Content creators with <a href="https://www.nvidia.com/en-us/studio/laptops-desktops/">NVIDIA Studio hardware</a> can access over 100 AI-enabled and RTX-accelerated creative apps, including the Adobe Creative Cloud suite, Blender, Blackmagic Design’s DaVinci Resolve, OBS Studio and more.</p>
<p>This includes the NVIDIA Studio suite of AI tools and exclusive next-generation technology such as NVIDIA DLSS 3.5, featuring <a href="https://www.nvidia.com/en-us/geforce/news/dlss-3-5-available-september-21/">Ray Reconstruction</a> and <a href="https://developer.nvidia.com/rtx/ray-tracing/optix">OptiX</a>. AI image generation on a GeForce RTX 4090-powered PC can be completed at lightning speed — the same task would take 8x longer with an Apple M2 Ultra.</p>
<p>3D modelers can benefit immensely from AI, with dramatic improvements in real-time viewport rendering and upscaling with DLSS in NVIDIA Omniverse, Adobe Substance, Adobe Painter, Blender, D5 Render, Unreal Engine and more.</p>
<figure id="attachment_67139" aria-describedby="caption-attachment-67139" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1.png"><img decoding="async" loading="lazy" class="size-large wp-image-67139" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1-672x383.png" alt="" width="672" height="383" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1-672x383.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1-400x228.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1-768x437.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1-790x450.png 790w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1-378x215.png 378w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1-176x100.png 176w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67139" class="wp-caption-text">D5 Render full ray-tracing preview with Ray Reconstruction.</figcaption></figure>
<p>Gamers are primed for AI boosts with <a href="https://www.nvidia.com/en-us/geforce/news/dlss-3-5-available-september-21/">DLSS</a> in over 300 games, including <i>Alan Wake 2</i>, coming soon, and <i>Cyberpunk 2077: Phantom Liberty</i>, available for download today.</p>
<p><iframe loading="lazy" title="Cyberpunk 2077: Phantom Liberty | NVIDIA DLSS 3.5 &amp; Full Ray Tracing Technology Overview" width="500" height="281" src="https://www.youtube.com/embed/DbuKZgZpDP8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Modders can breathe new life into classic games with <a href="https://www.nvidia.com/en-us/geforce/rtx-remix/">NVIDIA RTX Remix’s</a> revolutionary AI upscaling and texture enhancements. Game studios deploying the NVIDIA Avatar Cloud Engine (ACE) can build intelligent game characters, interactive avatars and digital humans in apps at scale — saving time and money.</p>
<p><iframe loading="lazy" title="NVIDIA ACE for Games Sparks Life Into Virtual Characters With Generative AI" width="500" height="281" src="https://www.youtube.com/embed/5R8xZb6J3r0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Everyday tasks also get a boost. AI can draft emails, summarize content and upscale video to stunning 4K on YouTube and Netflix with RTX Video Super Resolution. Frequent video chat users can harness the power of <a href="https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/">NVIDIA Broadcast</a> for AI-enhanced voice and video features. And livestreamers can take advantage of AI-powered features like virtual backgrounds, noise removal and eye contact, which moves the eyes of the speaker to simulate eye contact with the camera.</p>
<p>NVIDIA hardware powers AI natively and in the cloud — including for the world’s leading cloud AIs like ChatGPT, Midjourney, Microsoft 365 Copilot, Adobe Firefly and more.</p>
<p>Get <a href="https://www.nvidia.com/en-us/ai-on-rtx/">further with AI — faster on RTX</a> — and <a href="https://blogs.nvidia.com/blog/2023/09/21/ai-on-local-rtx-windows-pc/">learn more</a> to get started.</p>
<h2><b>AI on Windows</b></h2>
<p>NVIDIA AI, the world’s leading AI development platform, is supported by <a href="https://blogs.nvidia.com/blog/2023/05/28/computex-generative-ai-rtx/#:~:text=NVIDIA%20Brings%20New%20Generative%20AI,is%20set%20to%20improve%20efficiency.">100 million AI-ready RTX-powered Windows 11 PCs and workstations</a>.</p>
<p>State-of-the-art technologies behind the Windows platform and NVIDIA’s AI hardware and software enable GPU-accelerated workflows for training and deploying AI models, exclusive tools, containers, software development kits and new open-source models optimized for RTX.</p>
<figure id="attachment_67136" aria-describedby="caption-attachment-67136" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1.png"><img decoding="async" loading="lazy" class="wp-image-67136 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1-672x382.png" alt="" width="672" height="382" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1-672x382.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1-400x227.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1-768x436.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1-792x450.png 792w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1-379x215.png 379w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1-176x100.png 176w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67136" class="wp-caption-text">100 million RTX-powered Windows 11 PCs and workstations are already AI-ready.</figcaption></figure>
<p>With these integrations, Windows and NVIDIA are <a href="https://blogs.nvidia.com/blog/2023/09/21/ai-on-local-rtx-windows-pc/">making it easier</a> for developers to create the next generation of AI-powered Windows apps.</p>
<h2><b>AI on Viral Content</b></h2>
<p>3D content creator Martrin saw content creation as a means to gain financial, creative and geographical freedom — as well as a sense of gratification that he wasn’t getting in his day job in advertising.</p>
<p>“To gain recognition as an artist nowadays, unless you have connections, you’ve got to grind it out on social media,” admitted Martrin. As he began to showcase artwork to wider audiences, Martrin unexpectedly enjoyed the process of creating art aimed at garnering social media attention.</p>
<p>Best known for his viral video series<i> Satisfying Marble Music — </i>in which he replicates melodies by simulating a marble bouncing on xylophone notes — Martrin also takes a keen interest in the latest trends and advancements in the world of 3D to consistently meet his clients’ evolving demands.</p>
<p>In his recent project <i>Ascension</i>, he experimented with a point-cloud modeling technique for the first time, aiming to create a transition between reality and 3D.<i> </i></p>
<p>Martrin used several 3D apps to refine video footage and animate himself in 3D. The initial stages involved modeling and animating a portrait of himself, which he used Daz Studio and Blender to accomplish. His PC, equipped with two NVIDIA GeForce RTX 4090 GPUs, easily handled this task.</p>
<figure id="attachment_67133" aria-describedby="caption-attachment-67133" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1.png"><img decoding="async" loading="lazy" class="size-large wp-image-67133" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1-672x355.png" alt="" width="672" height="355" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1-672x355.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1-400x212.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1-768x406.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1-842x445.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1-406x215.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67133" class="wp-caption-text">Animations come to life in Blender.</figcaption></figure>
<p>He then used the GPU-accelerated Marvelous Designer cloth simulation engine to craft and animate his clothing.</p>
<figure id="attachment_67130" aria-describedby="caption-attachment-67130" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/image5.png"><img decoding="async" loading="lazy" class="size-large wp-image-67130" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image5-672x365.png" alt="" width="672" height="365" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image5-672x365.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image5-400x217.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image5-768x417.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image5-829x450.png 829w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image5-396x215.png 396w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image5-184x100.png 184w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image5.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67130" class="wp-caption-text">Realistic clothes generated in Marvelous Designer.</figcaption></figure>
<p>Martrin stressed the importance of GPU acceleration in his creative workflow. “When did I use it? The countless times I checked my live viewer and during the creation of every render,” said Martrin.</p>
<p>From there, Martrin tested point-cloud modeling techniques. He first 3D-scanned his room. Then, instead of using the room as conventional 3D mesh, he deployed it as a set of data points in space to create a unique visual style.</p>
<figure id="attachment_67127" aria-describedby="caption-attachment-67127" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1.png"><img decoding="async" loading="lazy" class="size-large wp-image-67127" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1-672x362.png" alt="" width="672" height="362" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1-672x362.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1-400x216.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1-768x414.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1-835x450.png 835w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1-399x215.png 399w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1-186x100.png 186w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67127" class="wp-caption-text">Background elements added in Cinema 4D.</figcaption></figure>
<p>He then used Cinema 4D and OctaneRender with RTX-accelerated ray tracing to render the animation.</p>
<p>Martrin completed the project by applying a GPU-accelerated composition and special effects in Adobe After Effects, achieving faster rendering with <a href="https://developer.nvidia.com/cuda-toolkit">NVIDIA CUDA</a> technology.</p>
<p>“No matter how tough it is at the start, keep grinding and challenging — odds are, success will eventually follow,” said Martrin.</p>
<figure id="attachment_67124" aria-describedby="caption-attachment-67124" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1.png"><img decoding="async" loading="lazy" class="size-large wp-image-67124" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1-672x247.png" alt="" width="672" height="247" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1-672x247.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1-400x147.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1-768x283.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1-842x310.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1-406x149.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1-188x69.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67124" class="wp-caption-text">3D content creator Victor de Martrin.</figcaption></figure>
<p>Check out Martrin’s viral content on <a href="https://www.tiktok.com/@victordemartrin/video/7218928551737691398">TikTok</a>.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>Twitter</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/image1-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/image1-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI Power Players: GeForce and NVIDIA RTX GPUs Supercharge Creativity, Gaming, Development, Productivity and More]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Six Steps Toward AI Security</title>
		<link>https://blogs.nvidia.com/blog/2023/09/25/ai-security-steps/</link>
		
		<dc:creator><![CDATA[David Reber Jr.]]></dc:creator>
		<pubDate>Mon, 25 Sep 2023 15:00:22 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Explainer]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cybersecurity]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[NGC]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67098</guid>

					<description><![CDATA[In the wake of ChatGPT, every company is trying to figure out its AI strategy, work that quickly raises the question: What about security? Some may feel overwhelmed at the prospect of securing new technology. The good news is policies and practices in place today provide excellent starting points. Indeed, the way forward lies in <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/25/ai-security-steps/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>In the wake of ChatGPT, every company is trying to figure out its AI strategy, work that quickly raises the question: What about security?</p>
<p>Some may feel overwhelmed at the prospect of securing new technology. The good news is policies and practices in place today provide excellent starting points.</p>
<p>Indeed, the way forward lies in extending the existing foundations of enterprise and cloud security. It’s a journey that can be summarized in six steps:</p>
<ul>
<li style="font-weight: 400;" aria-level="1">Expand analysis of the threats</li>
<li style="font-weight: 400;" aria-level="1">Broaden response mechanisms</li>
<li style="font-weight: 400;" aria-level="1">Secure the data supply chain</li>
<li style="font-weight: 400;" aria-level="1">Use AI to scale efforts</li>
<li style="font-weight: 400;" aria-level="1">Be transparent</li>
<li style="font-weight: 400;" aria-level="1">Create continuous improvements</li>
</ul>
<figure id="attachment_67103" aria-describedby="caption-attachment-67103" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-scaled.jpg"><img decoding="async" loading="lazy" class="size-large wp-image-67103" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-672x408.jpg" alt="Chart on scaling AI security" width="672" height="408" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-672x408.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-400x243.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-768x467.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-1536x933.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-741x450.jpg 741w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-354x215.jpg 354w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-165x100.jpg 165w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-1280x778.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67103" class="wp-caption-text">AI security builds on protections enterprises already rely on.</figcaption></figure>
<h2><b>Take in the Expanded Horizon</b></h2>
<p>The first step is to get familiar with the new landscape.</p>
<p>Security now needs to cover the AI development lifecycle. This includes new attack surfaces like training data, models and the people and processes using them.</p>
<p>Extrapolate from the known types of threats to identify and anticipate emerging ones. For instance, an attacker might try to alter the behavior of an AI model by accessing data while it’s training the model on a cloud service.</p>
<p>The security researchers and red teams who probed for vulnerabilities in the past will be great resources again. They’ll need access to AI systems and data to identify and act on new threats as well as help building solid working relationships with data science staff.</p>
<h2><b>Broaden Defenses</b></h2>
<p>Once a picture of the threats is clear, define ways to defend against them.</p>
<p>Monitor AI model performance closely. Assume it will drift, opening new attack surfaces, just as it can be assumed that traditional security defenses will be breached.</p>
<p>Also build on the PSIRT (product security incident response team) practices that should already be in place.</p>
<p>For example, NVIDIA released <a href="https://www.nvidia.com/en-us/security/psirt-policies/">product security policies</a> that encompass its AI portfolio. Several organizations — including the <a href="https://llmtop10.com/">Open Worldwide Application Security Project</a> — have released AI-tailored implementations of key security elements such as the common vulnerability enumeration method used to identify traditional IT threats.</p>
<p>Adapt and apply to AI models and workflows traditional defenses like:</p>
<ul>
<li style="font-weight: 400;" aria-level="1">Keeping network control and data planes separate</li>
<li style="font-weight: 400;" aria-level="1">Removing any unsafe or personal identifying data</li>
<li style="font-weight: 400;" aria-level="1">Using <a href="https://blogs.nvidia.com/blog/2022/06/07/what-is-zero-trust">zero-trust security</a> and authentication</li>
<li style="font-weight: 400;" aria-level="1">Defining appropriate event logs, alerts and tests</li>
<li style="font-weight: 400;" aria-level="1">Setting flow controls where appropriate</li>
</ul>
<h2><b>Extend Existing Safeguards</b></h2>
<p>Protect the datasets used to train AI models. They’re valuable and vulnerable.</p>
<p>Once again, enterprises can leverage existing practices. Create secure data supply chains, similar to those created to secure channels for software. It’s important to establish access control for training data, just like other internal data is secured.</p>
<p>Some gaps may need to be filled. Today, security specialists know how to use hash files of applications to ensure no one has altered their code. That process may be challenging to scale for petabyte-sized datasets used for AI training.</p>
<p>The good news is researchers see the need, and they’re working on tools to address it.</p>
<h2><b>Scale Security With AI</b></h2>
<p>AI is not only a new attack area to defend, it’s also a new and powerful security tool.</p>
<p>Machine learning models can detect subtle changes no human can see in mountains of network traffic. That makes AI an ideal technology to prevent many of the most widely used attacks, like identity theft, phishing, malware and ransomware.</p>
<p><a href="https://developer.nvidia.com/morpheus-cybersecurity">NVIDIA Morpheus</a>, a cybersecurity framework, can build AI applications that create, read and update digital fingerprints that scan for many kinds of threats. In addition, generative AI and Morpheus can enable <a href="https://developer.nvidia.com/blog/nvidia-morpheus-helps-defend-against-spear-phishing-with-generative-ai/">new ways to detect spear phishing attempts</a>.</p>
<figure id="attachment_67112" aria-describedby="caption-attachment-67112" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-scaled.jpg"><img decoding="async" loading="lazy" class="wp-image-67112 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-672x356.jpg" alt="Chart of AI security use cases" width="672" height="356" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-672x356.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-400x212.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-768x406.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-1536x813.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-842x446.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-406x215.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-188x100.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-1280x677.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67112" class="wp-caption-text">Machine learning is a powerful tool that spans many use cases in security.</figcaption></figure>
<h2><b>Security Loves Clarity</b></h2>
<p>Transparency is a key component of any security strategy. Let customers know about any new AI security policies and practices that have been put in place.</p>
<p>For example, NVIDIA publishes details about the AI models in <a href="https://www.nvidia.com/en-us/gpu-cloud/">NGC</a>, its hub for accelerated software. Called <a href="https://developer.nvidia.com/blog/enhancing-ai-transparency-and-ethical-considerations-with-model-card/">model cards</a>, they act like truth-in-lending statements, describing AIs, the data they were trained on and any constraints for their use.</p>
<p>NVIDIA uses an expanded set of fields in its model cards, so users are clear about the history and limits of a neural network before putting it into production. That helps advance security, establish trust and ensure models are robust.</p>
<h2><b>Define Journeys, Not Destinations</b></h2>
<p>These six steps are just the start of a journey. Processes and policies like these need to evolve.</p>
<p>The emerging practice of <a href="https://blogs.nvidia.com/blog/2023/03/01/what-is-confidential-computing/">confidential computing</a>, for instance, is extending security across cloud services where AI models are often trained and run in production.</p>
<p>The industry is already beginning to see basic versions of code scanners for AI models. They’re a sign of what’s to come. Teams need to keep an eye on the horizon for best practices and tools as they arrive.</p>
<p>Along the way, the community needs to share what it learns. An excellent example of that occurred at the recent <a href="https://blogs.nvidia.com/blog/2023/08/10/nvidia-generative-red-team-challenge/">Generative Red Team Challenge</a>.</p>
<p>In the end, it’s about creating a collective defense. We’re all making this journey to AI security together, one step at a time.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/Six-levels-pixabay-1280.jpg"
			type="image/jpeg"
			width="1280"
			height="677"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/Six-levels-pixabay-1280-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Six Steps Toward AI Security]]></media:title>
			<media:description type="html">Pix of six lines in the sky representing six steps</media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Studio Lineup Adds RTX-Powered Microsoft Surface Laptop Studio 2</title>
		<link>https://blogs.nvidia.com/blog/2023/09/21/surface-studio-chaos-dlss-resolve-tensor-rt/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Thu, 21 Sep 2023 15:00:42 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio Driver]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67040</guid>

					<description><![CDATA[The NVIDIA Studio laptop lineup is expanding with the new Microsoft Surface Laptop Studio 2, powered by GeForce RTX 4060, GeForce RTX 4050 or NVIDIA RTX 2000 Ada Generation Laptop GPUs, providing powerful performance and versatility for creators.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows.</i></p>
<p>The <a href="https://www.nvidia.com/en-us/studio/laptops-desktops/">NVIDIA Studio laptop</a> lineup is expanding with the new Microsoft Surface Laptop Studio 2, powered by <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4060-4060ti/">GeForce RTX 4060</a>, GeForce RTX 4050 or <a href="https://www.nvidia.com/en-us/design-visualization/rtx-professional-laptops/?ncid=ref-pr-584767#">NVIDIA RTX 2000 Ada Generation</a> Laptop GPUs, providing powerful performance and versatility for creators.</p>
<figure id="attachment_67047" aria-describedby="caption-attachment-67047" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67047" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w-672x473.png" alt="" width="672" height="473" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w-672x473.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w-400x281.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w-768x540.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w-640x450.png 640w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w-306x215.png 306w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w-142x100.png 142w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67047" class="wp-caption-text">The Microsoft Surface Laptop Studio 2.</figcaption></figure>
<p>Backed by the NVIDIA Studio platform, the Surface Laptop Studio 2, announced today, offers maximum stability with preinstalled Studio Drivers, plus exclusive tools to accelerate professional and creative workflows.</p>
<p>NVIDIA today also launched DLSS 3.5, adding Ray Reconstruction to the suite of AI-powered DLSS technologies. The latest feature puts a powerful new AI neural network at the fingertips of creators on RTX PCs, producing higher-quality, lifelike ray-traced images in real time before generating a full render.</p>
<p>Chaos Vantage is the first creative application to integrate Ray Reconstruction. For gamers, Ray Reconstruction is now available in <i>Cyberpunk 2077</i> and is slated for the <i>Phantom Liberty </i>expansion on Sept. 26.</p>
<p>Blackmagic Design has adopted <a href="https://developer.nvidia.com/tensorrt">NVIDIA TensorRT</a> acceleration in update 18.6 for its popular DaVinci Resolve software for video editing, color correction, visual effects, motion graphics and audio post-production. By integrating TensorRT, the software now runs AI tools like Magic Mask, Speed Warp and Super Scale over 50% faster than before. With this acceleration, AI runs up to 2.3x faster on GeForce RTX and NVIDIA RTX GPUs compared to Macs.</p>
<p>The September Studio Driver is now available for download — providing support for the Surface Laptop Studio 2, new app releases and more.</p>
<figure id="attachment_67050" aria-describedby="caption-attachment-67050" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67050" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67050" class="wp-caption-text">NVIDIA and GeForce RTX GPUs get NVIDIA Studio Drivers free of charge.</figcaption></figure>
<p>This week’s <i>In the NVIDIA Studio</i> installment features Studio Spotlight artist Gavin O’Donnell, who created a Wild West-inspired piece using a workflow streamlined with AI and RTX acceleration in Blender and Unreal Engine running on a <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3090-3090ti/">GeForce RTX 3090 GPU</a>.</p>
<h2><b>Create Without Compromise</b></h2>
<p>The Surface Laptop Studio 2, when configured with NVIDIA laptop GPUs, delivers up to 2x the graphics performance compared to the previous generation, and is NVIDIA Studio validated.</p>
<figure id="attachment_67053" aria-describedby="caption-attachment-67053" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67053" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-672x340.png" alt="" width="672" height="340" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-672x340.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-400x202.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-768x388.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-842x426.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-406x205.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-188x95.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67053" class="wp-caption-text">The versatile Microsoft Surface Laptop Studio 2.</figcaption></figure>
<p>In addition to NVIDIA graphics, the Surface Laptop Studio 2 comes with 13th Gen Intel Core processors, up to 64GB of RAM and a 2TB SSD. It features a bright, vibrant 14.4-inch PixelSense Flow touchscreen, with true-to-life color and up to 120Hz refresh rate, and now comes with Dolby Vision IQ and HDR to deliver sharper colors.</p>
<p>The system’s unique design adapts to fit any workflow. It instantly transitions from a pro-grade laptop to a perfectly angled display for entertainment to a portable creative canvas for drawing and sketching with the Surface Slim Pen 2.</p>
<p>NVIDIA Studio systems deliver upgraded performance thanks to dedicated ray tracing, AI and video encoding hardware. They also provide AI app acceleration, advanced rendering and Ray Reconstruction with NVIDIA DLSS, plus exclusive software like <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, <a href="https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/">NVIDIA Broadcast</a>, <a href="https://www.nvidia.com/en-us/studio/canvas/">NVIDIA Canvas</a> and RTX Video Super Resolution — helping creators go from concept to completion faster.</p>
<p>The Surface Laptop Studio 2 will be available beginning October 3.</p>
<h2><b>An AI for RTX</b></h2>
<p>NVIDIA GeForce and RTX GPUs feature powerful local accelerators that are critical for AI performance, supercharging creativity by unlocking AI capabilities on Windows 11 PCs — including the Surface Laptop Studio 2.​</p>
<figure id="attachment_67056" aria-describedby="caption-attachment-67056" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67056" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w-672x340.png" alt="" width="672" height="340" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w-672x340.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w-400x202.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w-768x388.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w-842x426.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w-406x205.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w-188x95.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67056" class="wp-caption-text">AI-powered Ray Resstruction.</figcaption></figure>
<p>With the launch of <a href="https://www.nvidia.com/en-us/geforce/news/dlss-3-5-available-september-21">DLSS 3.5 with Ray Reconstruction</a>, an NVIDIA supercomputer-trained AI network replaces hand-tuned denoisers to generate higher-quality pixels between sampled rays.</p>
<p>Ray Reconstruction improves the real-time editing experience by sharpening images and reducing noise — even while panning around a scene. The benefits of Ray Reconstruction shine in the viewport, as rendering during camera movement is notoriously difficult.</p>
<figure id="attachment_67059" aria-describedby="caption-attachment-67059" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67059" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w-672x367.png" alt="" width="672" height="367" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w-672x367.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w-400x218.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w-768x419.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w-824x450.png 824w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w-394x215.png 394w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w-183x100.png 183w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67059" class="wp-caption-text">Chaos Vantage DLSS 3.5 with Ray Reconstruction technology.</figcaption></figure>
<p>By adding DLSS 3.5 support, Chaos Vantage will enable creators to explore large scenes in a fully ray-traced environment at high frame rates with improved image quality. Ray Reconstruction joins other AI-accelerated features in Vantage, including the <a href="https://developer.nvidia.com/optix-denoiser">NVIDIA OptiX denoiser</a> and Super Resolution.</p>
<p>DLSS 3.5 and AI-powered Ray Reconstruction today join performance-multiplying AI Frame Generation in <i>Cyberpunk 2077</i> with the new 2.0 update. On Sept. 26, <i>Cyberpunk 2077: Phantom Liberty</i> will launch with full ray tracing and DLSS 3.5.</p>
<p><iframe loading="lazy" title="Cyberpunk 2077: Phantom Liberty | NVIDIA DLSS 3.5 &amp; Full Ray Tracing Technology Overview" width="500" height="281" src="https://www.youtube.com/embed/DbuKZgZpDP8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>NVIDIA TensorRT — the high-performance inference optimizer that delivers low latency and high throughput for deep learning inference applications and features — has been added to DaVinci Resolve in version 18.6.</p>
<figure id="attachment_67094" aria-describedby="caption-attachment-67094" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2.png"><img decoding="async" loading="lazy" class="size-large wp-image-67094" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2-672x168.png" alt="" width="672" height="168" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2-672x168.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2-400x100.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2-768x192.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2-842x210.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2-406x101.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2-188x47.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2.png 1281w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67094" class="wp-caption-text">Performance testing conducted by NVIDIA in August 2023. NVIDIA Driver 536.75. Windows 11. Measures time to apply various AI effects in DaVinci Resolve 18.6: Magic Mask, Speed Warp, Super Res, Depth Map.</figcaption></figure>
<p>The added acceleration dramatically increases performance. AI effects now run on a <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4090/">GeForce RTX 4090 GPU</a> up to 2.3x faster than on M2 Ultra, and 5.4x faster than on 7900 XTX.</p>
<p>Stay tuned for updates in the weeks ahead for more AI on RTX, including DLSS 3.5 support coming to Omniverse this October.</p>
<h2><b>Welcome to the Wild, Wild West</b></h2>
<p>Gavin O’Donnell — an Ireland-based senior environment concept artist at Disruptive Games — is no stranger to interactive entertainment.</p>
<p>He also does freelance work on the side including promo art, environment design and matte painting for an impressive client list, including Disney, Giant Animation, ImagineFX, Netflix and more.</p>
<p><iframe loading="lazy" title="The Wild, Wild West - Community Digital Art Showcase | NVIDIA Studio Standouts" width="500" height="281" src="https://www.youtube.com/embed/Dyu-lkHgdIk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>O’Donnell’s series of Western-themed artwork — the<i> Wild West Project </i>— was directly inspired by the critically acclaimed classic open adventure game <i>Red Dead Redemption 2</i>.</p>
<figure id="attachment_67062" aria-describedby="caption-attachment-67062" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67062" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w-672x286.png" alt="" width="672" height="286" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w-672x286.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w-400x170.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w-768x327.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w-842x359.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w-406x173.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w-188x80.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67062" class="wp-caption-text">Prospector, lawman or vigilante?</figcaption></figure>
<p>“I really enjoyed how immersive the storyline and the world in general was, so I wanted to create a scene that might exist in that fictional world,” said O’Donnell. Furthermore, it presented him an opportunity to practice new workflows within 3D apps Blender and Unreal Engine.</p>
<figure id="attachment_67066" aria-describedby="caption-attachment-67066" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67066" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w-672x319.png" alt="" width="672" height="319" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w-672x319.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w-400x190.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w-768x365.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w-842x400.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w-406x193.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w-188x89.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67066" class="wp-caption-text">‘Wild West Project’ brings the American Frontier to life.</figcaption></figure>
<p>Workflows combining NVIDIA technologies including RTX GPU acceleration at the intersection of AI were of especially great interest — accelerated by his <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3090-3090ti/">GeForce RTX 3090 laptop GPU</a>.</p>
<p>In Blender — O&#8217;Donnell sampled AI-powered Blender Cycles RTX-accelerated OptiX ray tracing in the viewport for interactive, photoreal rendering for modeling and animation.</p>
<figure id="attachment_67069" aria-describedby="caption-attachment-67069" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_.png"><img decoding="async" loading="lazy" class="size-large wp-image-67069" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_-672x289.png" alt="" width="672" height="289" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_-672x289.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_-400x172.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_-768x331.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_-842x362.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_-406x175.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_-188x81.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67069" class="wp-caption-text">On a beautiful journey.</figcaption></figure>
<p>Meanwhile — in Unreal Engine — O’Donnell sampled <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">NVIDIA DLSS</a> to increase the interactivity of the viewport by using AI to upscale frames rendered at lower resolution while still retaining high-fidelity detail. On top of RTX-accelerated rendering for high-fidelity visualization of 3D designs, virtual production and game development, the artist could simply create better, more detailed artwork, faster and easier.</p>
<p>O’Donnell credits his success to a constant state of creative evaluation — ensuring everything from his content creation techniques, methods of gaining inspiration, and technological knowledge — enabling the highest quality artwork possible — all while maintaining resource and efficiency gains.</p>
<p>As such, O&#8217;Donnell recently upgraded to an NVIDIA Studio laptop equipped with a GeForce RTX 4090 GPU with spectacular results. His rendering speeds in Blender, already very fast, sped up 73%, a massive time savings for the artist.</p>
<figure id="attachment_67072" aria-describedby="caption-attachment-67072" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67072" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w-672x193.png" alt="" width="672" height="193" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w-672x193.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w-400x115.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w-768x221.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w-842x242.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w-406x117.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w-188x54.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67072" class="wp-caption-text">Senior environment concept artist Gavin O’Donnell.</figcaption></figure>
<p>Check out O’Donnell’s portfolio on <a href="https://www.artstation.com/gavinodonnell">ArtStation</a>.</p>
<p>And finally, don’t forget to enter the #StartToFinish community challenge! Show us a photo or video of how one of your art projects started — and then one of the final result — using the hashtag #StartToFinish and tagging @NVIDIAStudio for a chance to be featured! Submissions considered through Sept. 30.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>Twitter</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/nv-blog-header-preview-1280x680-2.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/nv-blog-header-preview-1280x680-2-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Studio Lineup Adds RTX-Powered Microsoft Surface Laptop Studio 2]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Run AI on Your PC? GeForce Users Are Ahead of the Curve</title>
		<link>https://blogs.nvidia.com/blog/2023/09/21/ai-on-local-rtx-windows-pc/</link>
		
		<dc:creator><![CDATA[Jesse Clayton]]></dc:creator>
		<pubDate>Thu, 21 Sep 2023 15:00:33 +0000</pubDate>
				<category><![CDATA[Explainer]]></category>
		<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67078</guid>

					<description><![CDATA[Gone are the days when AI was the domain of sprawling data centers or elite researchers. For GeForce RTX users, AI is now running on your PC. It’s personal, enhancing every keystroke, every frame and every moment. Gamers are already enjoying the benefits of AI in over 300 RTX games. Meanwhile, content creators have access <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/21/ai-on-local-rtx-windows-pc/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Gone are the days when AI was the domain of sprawling data centers or elite researchers.</p>
<p>For <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/">GeForce RTX</a> users, AI is now running on your PC. It’s personal, enhancing every keystroke, every frame and every moment.</p>
<p>Gamers are already enjoying the benefits of AI in <a href="https://www.nvidia.com/en-us/geforce/rtx/">over 300 RTX games</a>. Meanwhile, content creators have access to <a href="https://www.nvidia.com/en-us/studio/software/">over 100 RTX creative and design apps</a>, with AI enhancing everything from video and photo editing to asset generation.</p>
<p>And for GeForce enthusiasts, it’s just the beginning. <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/">RTX</a> is the platform for today and the accelerator that will power the AI of tomorrow.</p>
<h2><b>How Did AI and Gaming Converge?</b></h2>
<p>NVIDIA pioneered the integration of AI and gaming with <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">DLSS</a>, a technique that uses AI to generate pixels in video games automatically and which has increased frame rates by up to 4x.</p>
<p>And with the recent introduction of DLSS 3.5, NVIDIA has enhanced the visual quality in some of the world’s top titles, setting a new standard for visually richer and more immersive gameplay.</p>
<p>But NVIDIA’s AI integration doesn’t stop there. Tools like <a href="https://www.nvidia.com/en-us/geforce/rtx-remix/">RTX Remix</a> empower game modders to remaster classic content using high-quality textures and materials generated by AI.</p>
<p>With <a href="https://nvidianews.nvidia.com/news/nvidia-ace-for-games-sparks-life-into-virtual-characters-with-generative-ai">NVIDIA ACE for Games</a>, AI-powered avatars come to life on the PC, marking a new era of immersive gaming.</p>
<h2><b>How Are RTX and AI Powering Creators?</b></h2>
<p>Creators use AI to imagine new concepts, automate tedious tasks and create stunning works of art. They rely on RTX because it accelerates top creator applications, including the world’s most popular photo editing, video editing, broadcast and 3D apps.</p>
<p>With over 100 RTX apps now AI-enabled, creators can get more done and deliver incredible results.</p>
<p>The performance metrics are staggering.</p>
<p>RTX GPUs boost AI image generation speeds in tools like Stable Diffusion by 4.5x compared to competing processors. Meanwhile, in 3D rendering, Blender experiences a speed increase of 5.4x.</p>
<p>Video editing in DaVinci Resolve powered by AI doubles its speed, and Adobe Photoshop’s photo editing tasks become 3x as swift.</p>
<p>NVIDIA RTX AI tech demonstrates a staggering 10x faster speeds in distinct workflows when juxtaposed against its competitors.</p>
<p>NVIDIA provides various <a href="https://www.nvidia.com/en-us/studio/resources/">AI tools, apps and software development kits</a> designed specifically for creators. This includes exclusive offerings like <a href="https://www.nvidia.com/en-us/omniverse/creators/">NVIDIA Omniverse</a>, <a href="https://developer.nvidia.com/optix-denoiser">OptiX Denoiser</a>, <a href="https://www.nvidia.com/en-us/studio/canvas/">NVIDIA Canvas</a>, <a href="https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/">NVIDIA Broadcast</a> and <a href="https://developer.nvidia.com/rtx/dlss/get-started">NVIDIA DLSS</a>.</p>
<h2><b>How Is AI Changing Our Digital Experience Beyond Chatbots?</b></h2>
<p>Beyond gaming and content creation, RTX GPUs bring AI to all types of users.</p>
<p>Add Microsoft to the equation and <a href="https://blogs.nvidia.com/blog/2023/05/28/computex-generative-ai-rtx/#:~:text=NVIDIA%20Brings%20New%20Generative%20AI,is%20set%20to%20improve%20efficiency.">100 million RTX-powered Windows 11 PCs and workstations</a> are already AI-ready.</p>
<p><img decoding="async" loading="lazy" class="aligncenter wp-image-67083 size-full" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-microsoft-annoucement-nv-blog-header-preview-1280x680-1.jpg" alt="" width="1280" height="680" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-microsoft-annoucement-nv-blog-header-preview-1280x680-1.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-microsoft-annoucement-nv-blog-header-preview-1280x680-1-400x213.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-microsoft-annoucement-nv-blog-header-preview-1280x680-1-672x357.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-microsoft-annoucement-nv-blog-header-preview-1280x680-1-768x408.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-microsoft-annoucement-nv-blog-header-preview-1280x680-1-842x447.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-microsoft-annoucement-nv-blog-header-preview-1280x680-1-406x215.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-microsoft-annoucement-nv-blog-header-preview-1280x680-1-188x100.jpg 188w" sizes="(max-width: 1280px) 100vw, 1280px" /></p>
<p>The complementary technologies behind the Windows platform and NVIDIA’s dynamic AI hardware and software stack are the driving forces that power hundreds of Windows apps and games.</p>
<ul>
<li style="font-weight: 400"><b>Gamers</b>: RTX-accelerated AI has been adopted in more than 300 games, increasing frame rates and enhancing visual fidelity.</li>
<li style="font-weight: 400"><b>Creators</b>: More than 100 AI-enabled creative applications benefit from RTX acceleration — including the top apps for image generation, video editing, photo editing and 3D. AI helps artists work faster, automate tedious tasks and  expand the boundaries of creative expression.</li>
<li style="font-weight: 400"><b>Video Streamers</b>: <a href="https://blogs.nvidia.com/blog/2023/02/28/rtx-video-super-resolution/">RTX Video Super Resolution</a> uses AI to increase the resolution and improve the quality of streamed video, elevating the home video experience.</li>
<li style="font-weight: 400"><b>Office Workers and Students</b>: Teleconferencing and remote learning get an RTX boost with NVIDIA Broadcast. AI improves video and audio quality and adds unique effects to make virtual interactions smoother and collaboration more efficient.</li>
<li style="font-weight: 400"><b>Developers</b>: Thanks to NVIDIA’s world-leading AI development platform and technology developed by Microsoft and NVIDIA called <a href="https://developer.nvidia.com/cuda/wsl">CUDA on Windows Subsystem for Linux</a>, developers can now do early AI development and training from the comfort of Windows, and easily migrate to servers for large training runs.</li>
</ul>
<h2><b>What Are the Emerging AI Applications for RTX PCs?</b></h2>
<p><a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/">Generative AI</a> enables users to quickly generate new content based on a variety of inputs — text, images, sounds, animation, 3D models or other types of data — bringing easy-to-use AI to more PCs.</p>
<p><a href="https://blogs.nvidia.com/blog/2023/01/26/what-are-large-language-models-used-for/">Large language models (LLMs)</a> are at the heart of many of these use cases.</p>
<p><img decoding="async" loading="lazy" class="aligncenter wp-image-67086 size-full" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/llm-explainer.jpg" alt="" width="1280" height="680" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/llm-explainer.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/llm-explainer-400x213.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/llm-explainer-672x357.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/llm-explainer-768x408.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/llm-explainer-842x447.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/llm-explainer-406x215.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/llm-explainer-188x100.jpg 188w" sizes="(max-width: 1280px) 100vw, 1280px" /></p>
<p>Perhaps the best known is ChatGPT, a chatbot that runs in the cloud and one of the fastest growing applications in history.</p>
<p>Many of these LLMs now run directly on PC, enabling new end-user applications like automatically drafting documents and emails, summarizing web content, extracting insights from spreadsheet data, planning travel, and powering general-purpose AI assistants.</p>
<p>LLMs are some of the most demanding PC workloads, requiring a powerful AI accelerator — like an RTX GPU.</p>
<h2><b>What Powers the AI Revolution on Our Desktops (and Beyond)?</b></h2>
<p>What’s fueling the PC AI revolution?</p>
<p>Three pillars: lightning-fast graphics processing from GPUs, AI capabilities integral to GeForce and the omnipresent cloud.</p>
<p>Gamers already know all about the parallel processing power of GPUs. But what role did the GPU play in enabling AI in the cloud?</p>
<p>NVIDIA GPUs have transformed cloud services. These advanced systems power everything from voice recognition to autonomous factory operations.</p>
<p>In 2016, NVIDIA hand-delivered to OpenAI the <a href="https://nvidianews.nvidia.com/news/nvidia-launches-world-s-first-deep-learning-supercomputer">first NVIDIA DGX AI supercomputer</a> — the engine behind the LLM breakthrough powering ChatGPT.</p>
<p><a href="https://www.nvidia.com/en-us/data-center/dgx-platform/">NVIDIA DGX supercomputers</a>, packed with GPUs and used initially as an AI research instrument, are now running 24/7 at businesses worldwide to refine data and process AI. Half of all Fortune 100 companies have installed DGX AI supercomputers.</p>
<p>The cloud, in turn, provides more than just vast quantities of training data for advanced AI models running on these machines.</p>
<h2><b>Why Choose Desktop AI?</b></h2>
<p>But why run AI on your desktop when the cloud seems limitless?</p>
<p>GPU-equipped desktops — where the AI revolution began — are still where the action is.</p>
<ul>
<li style="font-weight: 400"><b>Availability</b>: Whether a gamer or a researcher, everyone needs tools — from games to sophisticated AI models used by wildlife researchers in the field — that can function even when offline.</li>
<li style="font-weight: 400"><b>Speed</b>: Some applications need instantaneous results. Cloud latency doesn’t always cut it.</li>
<li style="font-weight: 400"><b>Data size</b>: Uploading and downloading large datasets from the cloud can be inefficient and cumbersome.</li>
<li style="font-weight: 400"><b>Privacy</b>: Whether you’re a Fortune 500 company or just editing family photos and videos, we all have data we want to keep close to home.</li>
</ul>
<p>RTX GPUs are based on the same architecture that fuels <a href="https://www.nvidia.com/en-us/data-center/gpu-cloud-computing/">NVIDIA’s cloud performance</a>. They blend the benefits of running AI locally with access to tools and the performance only NVIDIA can deliver.</p>
<p>NPUs, often called inference accelerators, are now finding their way into modern CPUs, highlighting the growing understanding of AI’s critical role in every application.</p>
<p>While NPUs are designed to offload light AI tasks, NVIDIA’s GPUs stand unparalleled for demanding AI models with raw performance ranging from a 20x-100x increase.</p>
<h2><b>What’s Next for AI in Our Everyday Lives?</b></h2>
<p>AI isn’t just a trend — it will impact many aspects of our daily lives.</p>
<p>AI functionality will expand as research advances and user expectations will evolve. Keeping up will require GPUs — and a rich software stack built on top of them — that are up to the challenge.</p>
<p>NVIDIA is at the forefront of this transformative era, offering end-to-end optimized development solutions.</p>
<p>NVIDIA provides developers with tools to add more AI features to PCs, enhancing value for users, all powered by RTX.</p>
<p>From gaming innovations with RTX Remix to the <a href="https://developer.nvidia.com/nemo">NVIDIA NeMo</a> LLM language model for assisting coders, the AI landscape on the PC is rich and expanding.</p>
<p>Whether it’s stunning new gaming content, AI avatars, incredible tools for creators or the next generation of digital assistants, the promise of AI-powered experiences will continuously redefine the standard of personal computing.</p>
<p><i>Learn more about </i><a href="https://www.geforce.com"><i>GeForce’s AI capabilities</i></a><i>.</i><b><br />
</b></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/gpu-explainer-nv-blog-header-preview-1280x680-r2.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/gpu-explainer-nv-blog-header-preview-1280x680-r2-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Run AI on Your PC? GeForce Users Are Ahead of the Curve]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Into the Omniverse: Blender 4.0 Alpha Release Sets Stage for New Era of OpenUSD Artistry</title>
		<link>https://blogs.nvidia.com/blog/2023/09/21/omniverse-blender-release-openusd/</link>
		
		<dc:creator><![CDATA[Dane Johnston]]></dc:creator>
		<pubDate>Thu, 21 Sep 2023 13:00:34 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[Into the Omniverse]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Universal Scene Description]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67011</guid>

					<description><![CDATA[For seasoned 3D artists and budding digital creation enthusiasts alike, an alpha version of the popular 3D software Blender is elevating creative journeys. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of </i><a href="https://www.nvidia.com/en-us/omniverse/news/" target="_blank" rel="noopener"><i>Into the Omniverse</i></a><i>, a series focused on how artists, developers and enterprises can transform their workflows using the latest advances in </i><a href="https://www.nvidia.com/en-us/omniverse/usd/" target="_blank" rel="noopener"><i>OpenUSD</i></a><i> and </i><a href="https://www.nvidia.com/en-us/omniverse/usd/" target="_blank" rel="noopener"><i>NVIDIA Omniverse</i></a><i>.</i></p>
<p>For seasoned 3D artists and budding digital creation enthusiasts alike, an <a href="https://wiki.blender.org/wiki/Reference/Release_Notes/4.0" target="_blank" rel="noopener">alpha</a> version of the popular 3D software Blender is elevating creative journeys.</p>
<p>With the update’s features for intricate shader network creation and enhanced asset-export capabilities, the development community using Blender and the <a href="https://www.nvidia.com/en-us/omniverse/usd/" target="_blank" rel="noopener">Universal Scene Description</a> framework, aka OpenUSD, is helping to evolve the 3D landscape.</p>
<p>NVIDIA engineers play a key role in enhancing the OpenUSD capabilities of Blender which also brings enhancements for use with <a href="https://www.nvidia.com/en-us/omniverse/" target="_blank" rel="noopener">NVIDIA Omniverse</a>, a development platform for connecting and building OpenUSD-based tools and applications.</p>
<h2><b>A Universal Upgrade for Blender Workflows</b></h2>
<p>With Blender 4.0 Alpha, 3D creators across industries and enterprises can access optimized OpenUSD workflows for various use cases.</p>
<p>For example, <a href="https://blogs.nvidia.com/blog/2023/09/19/industrial-designer-blender-openusd-ai/" target="_blank" rel="noopener">Emily Boehmer</a>, a design intern at BMW Group’s Technology Office in Munich, is using the combined power of Omniverse, Blender and Adobe Substance 3D Painter to create realistic, OpenUSD-based assets to train computer vision AI models.</p>
<p>Boehmer worked with her team to create assets for use with <a href="https://sordi.ai/" target="_blank" rel="noopener">SORDI.ai</a>, an AI dataset published by BMW Group that contains over 800,000 photorealistic images.</p>
<p style="text-align: center"><img decoding="async" loading="lazy" class=" wp-image-67013 aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/ezgif.com-video-to-gif-36.gif" alt="" width="623" height="351" /><i>A clip of an industrial crate virtually “aging.”</i></p>
<p>USD helped optimize Boehmer’s workflow. “It’s great to see USD support for both Blender and Substance 3D Painter,” she said. “When I create 3D assets using USD, I can be confident that they’ll look and behave as I expect them to in the scenes that they’ll be placed in because I can add physical properties to them.”</p>
<p>Australian animator <a href="https://blogs.nvidia.com/blog/2022/07/15/marko-matosevic-omniverse-animator/" target="_blank" rel="noopener">Marko Matosevic</a> is also harnessing the combined power of Blender, Omniverse and USD in his 3D workflows.</p>
<p>Matosevic began creating tutorials for his YouTube channel, <a href="https://www.youtube.com/c/Markom3D/featured" target="_blank" rel="noopener">Markom3D</a>, to help artists of all levels. He now shares his vast 3D knowledge with over 77,000 subscribers.</p>
<p>Most recently, Matosevic <a href="https://youtu.be/e90afeuxRC8" target="_blank" rel="noopener">created a 3D spaceship in Blender</a> that he later enhanced in Omniverse through <a href="https://docs.omniverse.nvidia.com/create-xr/latest/index.html" target="_blank" rel="noopener">virtual reality</a>.</p>
<p><iframe loading="lazy" title="Inside My 3D Spaceship: Blender Design Enhanced in Omniverse VR" width="500" height="281" src="https://www.youtube.com/embed/dsH-TM8Xmpk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Individual creators aren’t the only ones seeing success with Blender and USD. Multimedia entertainment studio <a href="https://developer.nvidia.com/blog/creating-immersive-events-with-openusd-and-digital-twins" target="_blank" rel="noopener">Moment Factory</a> creates OpenUSD-based <a href="https://www.nvidia.com/en-us/omniverse/solutions/digital-twins/" target="_blank" rel="noopener">digital twins</a> to simulate their immersive events — including live performances, multimedia shows and interactive installations — in Omniverse with USD before deploying them in the real world.</p>
<p style="text-align: center"><img decoding="async" loading="lazy" class="wp-image-67016 aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-scaled.jpg" alt="" width="651" height="446" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-400x274.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-672x461.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-768x526.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-1536x1053.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-657x450.jpg 657w, https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-314x215.jpg 314w, https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-146x100.jpg 146w, https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-1280x877.jpg 1280w" sizes="(max-width: 651px) 100vw, 651px" /><i></i><i>Moment Factory&#8217;s interactive installation at InfoComm 2023.</i></p>
<p>Team members can work in the digital twin at the same time, including designers using Blender to create and render eye-catching beauty shots to share their creative vision with customers.</p>
<p>See how Moment Factory uses Omniverse, Blender and USD to bring their immersive events to life in <a href="https://www.youtube.com/live/ikpP7bQ6kXA?si=t5s5QLLsA2aAk6z-" target="_blank" rel="noopener">their recent livestream</a>.</p>
<p>These 3D workflow enhancements are available to all. Blender users and <a href="https://resources.nvidia.com/en-us-omniverse-usd/ov-openusd-allstars" target="_blank" rel="noopener">USD creators</a>, including Boehmer, showcased their unique 3D pipeline on this recent Omniverse community livestream:</p>
<p><iframe loading="lazy" title="Explore the Power of OpenUSD and Blender Across 3D Use Cases | Omniverse Live" width="500" height="281" src="https://www.youtube.com/embed/tjiQZixHlkA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>New Features Deliver Elevated 3D Experience</b></h2>
<p>The latest USD improvements in Blender are the result of collaboration among many contributors, including AMD, Apple, Unity and NVIDIA, enabled by the Blender Foundation.</p>
<p>For example, hair object support — which improves USD import and export capabilities for digital hair — was added by a Unity software engineer. And a new Python IO callback system — which lets technical artists use Python to access USD application programming interfaces — was developed by a software engineer at NVIDIA, with support from others at Apple and AMD.</p>
<p>NVIDIA engineers are continuing to work on other USD contributions to include in future Blender updates.</p>
<p>Coming soon, the <a href="https://docs.omniverse.nvidia.com/connect/latest/blender/release-notes.html" target="_blank" rel="noopener">Blender 4.0 Alpha 201.0 Omniverse Connector</a> will offer new features for USD and Omniverse users, including:</p>
<ul>
<li style="font-weight: 400"><b>Universal Material Mapper 2 add-on:</b> This allows for more complex shader networks, or the blending of multiple textures and materials, to be round-tripped between Omniverse apps and Blender through USD.</li>
<li style="font-weight: 400"><b>Improved UsdPreviewSurface support and USDZ import/export capabilities</b>: This enables creators to export 3D assets for viewing in AR and VR applications.</li>
<li style="font-weight: 400"><b>Generic attribute support:</b> This allows geometry artists to generate vertex colors — red, green or blue values — or other per-vertex (3D point) values and import/export them between Blender and other 3D applications.</li>
</ul>
<p>Learn more about the Blender updates by watching this tutorial:</p>
<p><iframe loading="lazy" title="NVIDIA Omniverse |" width="500" height="281" src="https://www.youtube.com/embed/Y5o9f2dt6pI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Get Plugged Into the Omniverse </b></h2>
<p>Learn from industry experts on how OpenUSD is enabling custom 3D pipelines, easing 3D tool development and delivering interoperability between 3D applications in sessions from SIGGRAPH 2023, now available <a href="https://www.youtube.com/playlist?list=PL3jK4xNnlCVevpoiQ8YR-kYz5h0_9GTD9" target="_blank" rel="noopener">on demand</a>.</p>
<p>Anyone can build their own <a href="https://developer.nvidia.com/omniverse" target="_blank" rel="noopener">Omniverse extension or Connector</a> to enhance their 3D workflows and tools. Explore the Omniverse ecosystem’s <a href="https://www.nvidia.com/en-us/omniverse/ecosystem/" target="_blank" rel="noopener">growing catalog</a> of connections, extensions, foundation applications and third-party tools.</p>
<p>Share your Blender and Omniverse work as part of the latest community challenge, #StartToFinish. Use the hashtag to submit a screenshot of a project featuring both its beginning and ending stages for a chance to be featured on the @NVIDIAStudio and @NVIDIAOmniverse social channels.</p>
<p>To learn more about how OpenUSD can improve 3D workflows, check out a <a href="https://www.youtube.com/playlist?list=PL3jK4xNnlCVcUP08kj6eOzvCA82U_JKiy" target="_blank" rel="noopener">new video series </a>about the framework. For more resources on OpenUSD, explore the Alliance for OpenUSD <a href="https://forum.aousd.org/" target="_blank" rel="noopener">forum</a> or visit the <a href="https://aousd.org/" target="_blank" rel="noopener">AOUSD website</a>.</p>
<p><i>Get started with NVIDIA Omniverse by downloading the standard license for </i><a href="https://www.nvidia.com/en-us/omniverse/download/" target="_blank" rel="noopener"><i>free</i></a><i> or learn how </i><a href="https://www.nvidia.com/en-us/omniverse/enterprise/" target="_blank" rel="noopener"><i>Omniverse Enterprise</i><i> can connect your team</i></a><i>. </i></p>
<p><i>Developers can check out these </i><a href="https://developer.nvidia.com/omniverse/get-started/" target="_blank" rel="noopener"><i>Omniverse resources</i></a><i> to begin building on the platform. </i></p>
<p><i>Stay up to date on the platform by subscribing to the </i><a href="https://nvda.ws/3u5KPv1"><i>newsletter</i></a><i> and following NVIDIA Omniverse on </i><a href="https://www.instagram.com/nvidiaomniverse/" target="_blank" rel="noopener"><i>Instagram</i></a><i>, </i><a href="https://www.linkedin.com/showcase/nvidia-omniverse" target="_blank" rel="noopener"><i>LinkedIn</i></a><i>, </i><a href="https://medium.com/@nvidiaomniverse" target="_blank" rel="noopener"><i>Medium</i></a><i>, </i><a href="https://www.threads.net/@nvidiaomniverse" target="_blank" rel="noopener"><i>Threads</i></a><i> and </i><a href="https://twitter.com/nvidiaomniverse" target="_blank" rel="noopener"><i>Twitter</i></a><i>.</i></p>
<p><i>For more, check out our </i><a href="https://forums.developer.nvidia.com/c/omniverse/300" target="_blank" rel="noopener"><i>forums</i></a><i>, </i><a href="https://discord.com/invite/XWQNJDNuaC" target="_blank" rel="noopener"><i>Discord server</i></a><i>, </i><a href="https://www.twitch.tv/nvidiaomniverse" target="_blank" rel="noopener"><i>Twitch</i></a><i> and </i><a href="https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA" target="_blank" rel="noopener"><i>YouTube</i></a><i> channels.</i></p>
<p><i>Featured image courtesy of Alex Trevino.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/ov-corp-blog-sept-ito-1280x680-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/ov-corp-blog-sept-ito-1280x680-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Into the Omniverse: Blender 4.0 Alpha Release Sets Stage for New Era of OpenUSD Artistry]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA CEO Jensen Huang to Headline AI Summit in Tel Aviv</title>
		<link>https://blogs.nvidia.com/blog/2023/09/21/ai-summit/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Thu, 21 Sep 2023 13:00:27 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Events]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67032</guid>

					<description><![CDATA[NVIDIA founder and CEO Jensen Huang will highlight the newest in generative AI and cloud computing at the NVIDIA AI Summit in Tel Aviv from Oct. 15-16. The two-day summit is set to attract more than 2,500 developers, researchers and decision-makers from across one of the world’s most vibrant technology hubs. With over 6,000 startups, <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/21/ai-summit/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>NVIDIA founder and CEO Jensen Huang will highlight the newest in generative AI and cloud computing at the <a href="https://www.nvidia.com/en-il/ai-summit-israel/">NVIDIA AI Summit in Tel Aviv</a> from Oct. 15-16.</p>
<p>The two-day summit is set to attract more than 2,500 developers, researchers and decision-makers from across one of the world’s most vibrant technology hubs.</p>
<p>With over 6,000 startups, Israel consistently ranks among the world’s top countries for VC investments per capita. The 2023 Global Startup Ecosystem report places Tel Aviv among the top 5 cities globally for startups.</p>
<p>The summit features more than 60 live sessions led by experts from NVIDIA and the region’s tech leaders, who will dive deep into topics like accelerated computing, robotics, cybersecurity and climate science.</p>
<p>Attendees will be able to network and gain insights from some of NVIDIA’s foremost experts, including Kimberly Powell, vice president and general manager of healthcare; Deepu Talla, vice president and general manager of embedded and edge computing; Gilad Shainer, senior vice president of networking and HPC; and Gal Chechik, senior director and head of the Israel AI Research Center.</p>
<p>Key events and features of the summit include:</p>
<ul>
<li><b>Livestream</b>: The keynote by Huang will take place Monday, Oct. 16, at 10 a.m. Israel time (11 p.m. Pacific) and will be available for livestreaming, with on-demand access to follow.</li>
<li><b>Ecosystem exhibition</b>: An exhibition space at the Summit will showcase NVIDIA’s tech demos, paired with contributions from partners and emerging startups from the <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception program</a>.</li>
<li><b>Deep dive into AI</b>: The first day is dedicated to intensive learning sessions hosted by the <a href="https://www.nvidia.com/en-us/training/">NVIDIA Deep Learning Institute</a>. Workshops encompass topics like “Fundamentals of Deep Learning” and “Building AI-Based Cybersecurity Pipelines,” among a range of other topics. Edge AI &amp; Robotics Developer Day activities will explore innovations in AI and the <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">NVIDIA Jetson Orin platform</a>.</li>
<li><b>Multitrack sessions</b>: The second day will include multiple tracks, covering areas such as generative AI and LLMs, AI in healthcare, networking and developer tools and <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>.</li>
</ul>
<p>Learn more at <a href="https://www.nvidia.com/en-il/ai-summit-israel/">https://www.nvidia.com/en-il/ai-summit-israel/</a>.</p>
<p><em>Featured image credit: Gady Munz via the <a href="http://www.pikiwiki.org.il/?action=gallery&amp;img_id=51036">PikiWiki &#8211; Israel free image collection project</a></em></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2019/03/tel-aviv.jpg"
			type="image/jpeg"
			width="1080"
			height="689"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2019/03/tel-aviv-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA CEO Jensen Huang to Headline AI Summit in Tel Aviv]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Cash In: ‘PAYDAY 3’ Streams on GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/2023/09/21/geforce-now-thursday-sep-21/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 21 Sep 2023 13:00:19 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=66999</guid>

					<description><![CDATA[Time to get the gang back together — PAYDAY 3 streams on GeForce NOW this week. It’s one of 11 titles joining the cloud this week, including Party Animals. The Perfect Heist PAYDAY 3 is the highly anticipated sequel to one of the world’s most popular co-op shooters. Step out of retirement and back into <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/21/geforce-now-thursday-sep-21/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Time to get the gang back together — <i>PAYDAY 3</i> streams on <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> this week.</p>
<p>It’s one of 11 titles joining the cloud this week, including <i>Party Animals</i>.</p>
<h2><b>The Perfect Heist</b></h2>
<figure id="attachment_67007" aria-describedby="caption-attachment-67007" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" loading="lazy" class="size-large wp-image-67007" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-672x378.png" alt="PAYDAY 3 on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-1280x720.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-67007" class="wp-caption-text"><em>Not pictured: the crew member in a fuzzy bunny mask. He stayed home.</em></figcaption></figure>
<p><i>PAYDAY 3</i> is the highly anticipated sequel to one of the world’s most popular co-op shooters. Step out of retirement and back into the life of crime in the shoes of the Payday Gang — who bring the envy of their peers and the nightmare of law enforcement wherever they go. Set several years after the end of the crew’s reign of terror over Washington, D.C., the game reassembles the group to deal with the threat that’s roused them out of early retirement.</p>
<p>Upgrade to a GeForce NOW <a href="https://www.nvidia.com/en-us/geforce-now/memberships/">Ultimate</a> membership to pull off every heist at the highest quality. Ultimate members can stream on GeForce RTX 4080 rigs with support for up to 4K at 120 frames per second gameplay on PCs and Macs, providing a gaming experience so seamless that it would be a crime to stream on anything less.</p>
<h2><b>Game On</b></h2>
<figure id="attachment_67003" aria-describedby="caption-attachment-67003" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" loading="lazy" class="size-large wp-image-67003" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-672x336.jpg" alt="Party Animals on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-67003" class="wp-caption-text"><em>Paw it out with friends on nearly any device.</em></figcaption></figure>
<p>There’s always more action every GFN Thursday. Here’s the full list of this week’s GeForce NOW library additions:<i></i></p>
<ul>
<li><i>HumanitZ </i>(New release on <a href="https://store.steampowered.com/app/1766060?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Sept. 18)</li>
<li><i>Party Animals</i> (New release on <a href="https://store.steampowered.com/app/1260320?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Sept. 20)</li>
<li><i>PAYDAY 3 </i>(New release on <a href="https://store.steampowered.com/app/1272080?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.epicgames.com/store/p/payday-3?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, <a href="https://www.xbox.com/games/store/payday-3/9npzvdch73sx?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> PC Game Pass, Sept. 21)</li>
<li><i>Warhaven </i>(New release on <a href="https://store.steampowered.com/app/2107670?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>911 Operator</i> (<a href="https://www.epicgames.com/store/p/911-operator-585edd?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Ad Infinitum</i> (<a href="https://store.steampowered.com/app/1234430?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Chained Echoes</i> (<a href="https://www.xbox.com/games/store/chained-echoes/9N1WWRPJ12FK?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Deceit 2</i> (<a href="https://store.steampowered.com/app/2064870?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>The Legend of Tianding</i> (<a href="https://www.xbox.com/games/store/the-legend-of-tianding/9NCBTKXHFF8K?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Mechwarrior 5: Mercenaries</i> (<a href="https://www.xbox.com/games/store/mechwarrior-5-mercenaries/9PB86W3JK8Z5?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Sprawl </i>(<a href="https://store.steampowered.com/app/1549690?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<p><span>Starting today, the </span><i><span>Cyberpunk 2077 </span></i><span>2.0 patch will also be supported, adding </span><a href="https://www.nvidia.com/en-us/geforce/news/dlss-3-5-available-september-21/"><span>DLSS 3.5</span></a><span> technology and other new features.</span></p>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">Twitter</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Form a team of video game characters to perform a heist, who are you recruiting? <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f4b0.png" alt="💰" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1704525826446823629?ref_src=twsrc%5Etfw">September 20, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/gfn-thursday-9-21-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/gfn-thursday-9-21-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Cash In: ‘PAYDAY 3’ Streams on GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
	</channel>
</rss>
