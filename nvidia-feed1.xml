<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Sun, 05 May 2024 21:28:16 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.5.2</generator>
	<item>
		<title>NVIDIA AI Microservices for Drug Discovery, Digital Health Now Integrated With AWS</title>
		<link>https://blogs.nvidia.com/blog/nim-ai-microservices-for-healthcare-integrate-with-aws/</link>
		
		<dc:creator><![CDATA[Lyndi Wu]]></dc:creator>
		<pubDate>Thu, 02 May 2024 13:30:03 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Genomics]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[NVIDIA Clara]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71408</guid>

					<description><![CDATA[Harnessing optimized AI models for healthcare is easier than ever as NVIDIA NIM, a collection of cloud-native microservices, integrates with Amazon Web Services. NIM, part of the NVIDIA AI Enterprise software platform available on AWS Marketplace, enables developers to access a growing library of AI models through industry-standard application programming interfaces, or APIs. The library		<a class="read-more" href="https://blogs.nvidia.com/blog/nim-ai-microservices-for-healthcare-integrate-with-aws/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Harnessing optimized AI models for healthcare is easier than ever as <a href="https://www.nvidia.com/en-us/ai/">NVIDIA NIM</a>, a collection of cloud-native microservices, integrates with Amazon Web Services.</p>
<p><a href="http://ai.nvidia.com/">NIM</a>, part of the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> software platform available on <a href="https://aws.amazon.com/marketplace/pp/prodview-ozgjkov6vq3l6" target="_blank" rel="noopener">AWS Marketplace</a>, enables developers to access a growing library of AI models through industry-standard application programming interfaces, or APIs. The library includes <a href="https://blogs.nvidia.com/blog/what-are-foundation-models/">foundation models</a> for drug discovery, medical imaging and genomics, backed by enterprise-grade security and support.</p>
<p>NIM is now available via Amazon SageMaker ‚Äî a fully managed service to prepare data and build, train and deploy machine learning models ‚Äî and AWS ParallelCluster, an open-source tool to deploy and manage high performance computing clusters on AWS. NIMs can also be orchestrated using AWS HealthOmics, a purpose-built service for biological data analysis.</p>
<p>Easy access to NIM will enable the thousands of healthcare and life sciences companies already using AWS to deploy <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> more quickly, without the complexities of model development and packaging for production. It‚Äôll also help developers build workflows that combine AI models across different modalities, such as amino acid sequences, MRI images and plain-text patient health records.</p>
<p>Presented today at the <a href="https://pages.awscloud.com/NAMER-event-T3-AWS-Life-Science-Symposium-2024-reg-event.html" target="_blank" rel="noopener">AWS Life Sciences Leader Symposium</a> in Boston, this initiative extends the availability of <a href="https://www.nvidia.com/en-us/clara/">NVIDIA Clara</a> accelerated healthcare software and services on AWS ‚Äî which include fast and easy-to-deploy NIMs from <a href="https://www.nvidia.com/en-us/clara/bionemo/">NVIDIA BioNeMo</a> for drug discovery, <a href="https://www.nvidia.com/en-us/clara/monai/">NVIDIA MONAI</a> for medical imaging workflows and <a href="https://www.nvidia.com/en-us/clara/genomics/">NVIDIA Parabricks</a> for accelerated genomics.</p>
<h2><b>Pharma and Biotech Companies Adopt NVIDIA AI on AWS</b></h2>
<p><a href="https://www.nvidia.com/en-us/clara/bionemo/">BioNeMo</a> is a generative AI platform of foundation models, training frameworks, domain-specific data loaders and optimized training recipes‚Äã that support the training and fine-tuning of biology and chemistry models on proprietary data.‚Äã It‚Äôs used by more than 100 organizations globally.</p>
<p><a href="https://blogs.nvidia.com/blog/genomics-ai-amgen-superpod/">Amgen</a>, one of the world‚Äôs leading biotechnology companies, has used the BioNeMo framework to train generative models for protein design, and is exploring the potential use of BioNeMo with AWS.</p>
<p><i>‚Äã</i>BioNeMo models for protein structure prediction, generative chemistry and molecular docking prediction are available as NIM microservices, <a href="https://blogs.nvidia.com/blog/what-is-a-pretrained-ai-model/">pretrained</a> and optimized to run on any NVIDIA GPU or cluster of GPUs. These models can be combined to support a holistic, AI-accelerated drug discovery workflow.</p>
<p>Biotechnology company A-Alpha Bio harnesses synthetic biology and AI to measure, predict and engineer protein-to-protein interactions. When its researchers moved from a generic version of the ESM-2 protein language model to <a href="https://docs.nvidia.com/bionemo-framework/latest/models/esm2-nv.html">a version optimized by NVIDIA</a> running on <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100 Tensor Core GPUs</a> on AWS, they immediately saw a speedup of more than 10x. This lets the team sample a much more extensive field of protein candidates than they would have otherwise.</p>
<p>For organizations that want to augment these models with their own experimental data, NIM enables developers to <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">enhance a model with retrieval-augmented generation, or RAG</a> ‚Äî known as a lab-in-the-loop design.</p>
<h2><b>Parabricks Enables Accelerated Genomics Pipelines</b></h2>
<p>NVIDIA NIM includes genomics models from NVIDIA Parabricks, which are also <a href="https://aws.amazon.com/blogs/industries/easily-run-nvidia-parabricks-ready2run-workflows-on-amazon-omics/" target="_blank" rel="noopener">available on AWS HealthOmics</a> as Ready2Run workflows that enable customers to deploy pre-built pipelines.</p>
<p>Life sciences company Agilent used Parabricks genomics analysis tools running on NVIDIA GPU-powered <a href="https://aws.amazon.com/ec2/pricing/" target="_blank" rel="noopener">Amazon Elastic Compute Cloud (EC2) instances</a> to significantly improve processing speeds for variant calling workflows on the company‚Äôs cloud-native <a href="https://www.agilent.com/en/product/next-generation-sequencing/clinical-informatics-platform/alissa-reporter-1947792" target="_blank" rel="noopener">Alissa Reporter</a> software. Integrating Parabricks with Alissa secondary analysis pipelines enables researchers to access rapid data analysis in a secure cloud environment.‚Äã</p>
<h2><b>Conversational AI Technology Supports Digital Health</b></h2>
<p>In addition to models that can decode proteins and genomic sequences, NIM microservices offer optimized <a href="https://www.nvidia.com/en-us/glossary/large-language-models/">large language models</a> for conversational AI and visual generative AI models for avatars and digital humans.</p>
<p>AI-powered digital assistants can enhance healthcare by answering patient questions and supporting clinicians with logistics. Trained on healthcare organization-specific data using RAG, they could connect to relevant internal data sources to synthesize research, surface insights and improve productivity.</p>
<p>Generative AI startup <a href="https://www.globenewswire.com/news-release/2024/03/18/2848236/0/en/Hippocratic-AI-Announces-Collaboration-with-NVIDIA-to-Develop-Super-Low-Latency-Empathy-Inference-for-One-of-the-World-s-First-Generative-AI-Powered-Healthcare-Agents.html" target="_blank" rel="noopener">Hippocratic AI</a> is in the final stages of testing AI-powered healthcare agents that focus on a wide range of tasks including wellness coaching, preoperative outreach and post-discharge follow-up.</p>
<p>The company, which uses NVIDIA GPUs through AWS, is adopting NVIDIA NIM and <a href="https://developer.nvidia.com/ace">NVIDIA ACE</a> microservices to power a generative AI agent for digital health.</p>
<p><iframe title="Always Available, Real-Time Generative AI Healthcare Agents" width="500" height="281" src="https://www.youtube.com/embed/yg0m8eR7k24?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>The team used <a href="https://www.nvidia.com/en-us/ai-data-science/audio2face/">NVIDIA Audio2Face</a> facial animation technology, <a href="https://www.nvidia.com/en-us/ai-data-science/products/riva/">NVIDIA Riva</a> automatic speech recognition and text-to-speech capabilities, and more to power a healthcare assistant avatar‚Äôs conversation.</p>
<p>Experiment with <a href="https://build.nvidia.com/explore/healthcare">NVIDIA NIMs for healthcare</a> and get started with <a href="https://aws.amazon.com/nvidia/hcls/" target="_blank" rel="noopener">NVIDIA Clara on AWS</a>.</p>
<p><a href="https://www.nvidia.com/en-us/industries/healthcare-life-sciences/healthcare-news-sign-up/"><i>Subscribe to NVIDIA healthcare news</i></a><i>. </i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/image-17.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/image-17-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA AI Microservices for Drug Discovery, Digital Health Now Integrated With AWS]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>GeForce NOW Delivers 24 A-May-zing Games This Month</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-may-games-list/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 02 May 2024 13:00:24 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71370</guid>

					<description><![CDATA[GeForce NOW brings 24 new games for members this month. Ninja Theory‚Äôs highly anticipated Senua‚Äôs Saga: Hellblade II will be coming to the cloud soon ‚Äî get ready by streaming the first in the series, Hellblade: Senua‚Äôs Sacrifice, part of the seven new games joining the GeForce NOW library this week. Plus, game across more		<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-may-games-list/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> brings 24 new games for members this month.</p>
<p>Ninja Theory‚Äôs highly anticipated <i>Senua‚Äôs Saga: Hellblade II</i> will be coming to the cloud soon ‚Äî get ready by streaming the first in the series, <i>Hellblade: Senua‚Äôs Sacrifice, </i>part of the seven new games joining the <a href="http://play.geforcenow.com">GeForce NOW library</a> this week.</p>
<p>Plus, game across more devices than ever as GeForce NOW adds improved support on Steam Deck this GFN Thursday.</p>
<h2><b>Journey into Viking Hell</b></h2>
<figure id="attachment_71374" aria-describedby="caption-attachment-71374" style="width: 672px" class="wp-caption aligncenter"><img fetchpriority="high" decoding="async" class="wp-image-71374 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-672x378.png" alt="Hellblade 1 on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1-1280x720.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/05/HB1-Screenshot-1.png 1920w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71374" class="wp-caption-text"><em>No sacrificing frame rates, streaming from the cloud.</em></figcaption></figure>
<p>Experience exceptional storytelling in Ninja Theory‚Äôs award-winning game <i>Hellblade: Senua‚Äôs Sacrifice</i>, available to stream from the cloud this week.</p>
<p>Set in a dark fantasy world inspired by Norse mythology and Celtic culture, the game follows the journey of Senua, a Pict warrior. Her quest is to reach Helheim, the realm of the dead,to rescue her deceased lover‚Äôs soul from the goddess Hela.</p>
<p>Solve intricate puzzles with observation, engage in melee combat and get pulled deep into Senua‚Äôs mind as she grapples with inner demons. Journey through the hauntingly beautiful landscapes of Helheim with ray tracing and high-dynamic range using an <a href="http://geforcenow.com">Ultimate or Priority membership</a> for the most immersive and stunning visual fidelity.</p>
<h2><b>Decked Out</b></h2>
<p>Thanks to GeForce NOW, nearly any device can perform like a GeForce-powered PC gaming rig. Members who want to stream their favorite PC games to Valve‚Äôs <a href="https://store.steampowered.com/steamdeck">Steam Deck</a> now have an easier way to get started.</p>
<p>Members can use a new beta <a href="https://www.nvidia.com/en-us/geforce-now/download/">installation method</a> to automatically configure GeForce NOW‚Äôs browser in Steam Deck‚Äôs Gaming Mode. The installation script automatically installs Google Chrome to the device, then adds all the settings needed to help members log into GeForce NOW and stream their favorite games.</p>
<p>The <a href="https://www.nvidia.com/en-us/geforce-now/release-highlights/">latest GeForce NOW update</a>, released last week, also allows members to navigate GeForce NOW on a browser using a gamepad, including on the Steam Deck. That means it‚Äôs even easier to find and play supported titles with <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">NVIDIA DLSS</a> technology or real-time ray tracing, regardless of the handheld‚Äôs system specs.</p>
<p>Plus, members can easily play non-Steam games on the Steam Deck thanks to the cloud. This includes games from Battle.net, Epic Games Store, Ubisoft Connect, GOG.com and Xbox, as well as supported PC Game Pass titles. No more worrying about downloads or backend configurations. And with more than 1,900 games supported, there‚Äôs always something new to stream.</p>
<p>Steam Deck is just one of many popular handheld PC devices with support for GeForce NOW. Others include <a href="https://www.asus.com/us/site/gaming/rog/gaming-handheld/rog-ally.html">ASUS ROG Ally</a>, <a href="https://www.logitechg.com/en-us/products/cloud-gaming.html">Logitech G Cloud</a>, <a href="https://www.lenovo.com/us/en/p/handheld/legion-go/len106g0001">Lenovo Legion Go</a>, <a href="https://www.msi.com/Handheld/Claw-A1MX">MSI Claw</a> and <a href="https://www.razer.com/mobile-handhelds/razer-edge">Razer Edge</a>. <a href="https://www.nvidia.com/en-us/geforce-now/download">Get started</a> now. Learn more about how to <a href="https://nvidia.custhelp.com/app/answers/detail/a_id/5337">configure GeForce NOW on Steam Deck</a>.</p>
<h2><b>May New Games Be With You</b></h2>
<figure id="attachment_71377" aria-describedby="caption-attachment-71377" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" class="size-large wp-image-71377" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-672x336.jpg" alt="Foundry on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-foundry-tw-li-2048x1024-1.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71377" class="wp-caption-text"><em>If you build it, they will come.</em></figcaption></figure>
<p>Get complete creative freedom in Paradox Interactive‚Äôs <i>FOUNDRY</i>, an exciting first-person factory-building sandbox game set in an infinite voxel world for expansive, ever-changing landscapes. Build a factory optimized to perfection or an artistic masterpiece, harvest resources, automate ever-growing production lines and manage complex systems to achieve mechanical mastery in <i>FOUNDRY</i>.</p>
<p>Check out the list of new games this week:</p>
<ul>
<li><i>Hellblade: Senua&#8217;s Sacrifice </i>(<a href="https://store.steampowered.com/app/414340?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.xbox.com/games/store/hellblade-senuas-sacrifice/9NCLP4LV5K7Z?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Stormgate Closed Beta </i>(New release on <a href="https://store.steampowered.com/app/2012510?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 30,<a href="https://playstormgate.com/beta"> sign up</a> for access)</li>
<li><i>Gray Zone Warfare </i>(New release on <a href="https://store.steampowered.com/app/2479810?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 30)</li>
<li><i>MotoGP24 </i>(New release on <a href="https://store.steampowered.com/app/2581700?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 2)</li>
<li><i>FOUNDRY </i>(New release on <a href="https://store.steampowered.com/app/983870?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 2)</li>
<li><i>INDIKA </i>(New release on <a href="https://store.steampowered.com/app/1373960?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 2)</li>
<li><i>Orcs Must Die! 3 </i>(New release on <a href="https://www.epicgames.com/store/p/combo-a7e03a?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, May 2)</li>
</ul>
<p>And members can look for the following throughout the rest of the month:</p>
<ul>
<li><i>Little Kitty, Big City </i>(New release on <a href="https://store.steampowered.com/app/1177980?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.xbox.com/games/store/little-kitty-big-city/9nf5s7mlm8xt?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass, May 9)</li>
<li><i>Ships at Sea </i>(New release on <a href="https://store.steampowered.com/app/1266540?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 9)</li>
<li><i>The Rogue Prince of Persia¬† </i>(New release on <a href="https://store.steampowered.com/app/2717880?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 14)</li>
<li><i>Men of War II </i>(New release on <a href="https://store.steampowered.com/app/1128860?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 15)</li>
<li><i>Die by the Blade </i>(New release on <a href="https://store.steampowered.com/app/1154670?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 16)</li>
<li><i>Norland </i>(New release on <a href="https://store.steampowered.com/app/1857090?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 16)</li>
<li><i>Gestalt: Steam &amp; Cinder </i>(New release on <a href="https://store.steampowered.com/app/1231990?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 21)</li>
<li><i>Synergy </i>(New release on <a href="https://store.steampowered.com/app/1989070?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 21)</li>
<li><i>SunnySide </i>(New release on <a href="https://store.steampowered.com/app/1746930?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 21)</li>
<li><i>Crown Wars: The Black Prince </i>(New release on <a href="https://store.steampowered.com/app/1658920?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 23)</li>
<li><i>Capes </i>(New release on <a href="https://store.steampowered.com/app/2081080?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 29)</li>
<li><i>Colony Survival </i>(<a href="https://store.steampowered.com/app/366090?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Exo One </i>(<a href="https://store.steampowered.com/app/773370?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Farmer‚Äôs Life </i>(<a href="https://store.steampowered.com/app/1137750?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Honkai: Star Rail </i>(<a href="https://www.epicgames.com/store/p/honkai-star-rail?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Phantom Brigade </i>(<a href="https://store.steampowered.com/app/553540?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Supermarket Simulator </i>(<a href="https://store.steampowered.com/app/2670630?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<h2><b>April Showers Brought More Titles</b></h2>
<p>In addition to the 19 games announced last month, 20 more joined the <a href="http://play.geforcenow.com">GeForce NOW library</a>:</p>
<ul>
<li><i>Gigantic: Rampage Edition </i>(New release on <a href="https://store.steampowered.com/app/1924490?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 9)</li>
<li><i>Inkbound 1.0</i> (New release, on <a href="https://store.steampowered.com/app/1062810/Inkbound/">Steam</a>, April 9)</li>
<li><i>Broken Roads </i>(New release on <a href="https://store.steampowered.com/app/1403440?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 10)</li>
<li><i>Infection Free Zone </i>(New release on <a href="https://store.steampowered.com/app/1465460?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 11)</li>
<li><i>Shadow of the Tomb Raider: Definitive Edition </i>(New release on <a href="https://www.xbox.com/games/store/shadow-of-the-tomb-raider-definitive-edition/BNQQ3WVBNZCQ?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass, April 11)</li>
<li><i>Ghostrunner </i>(<a href="https://www.epicgames.com/store/p/ghostrunner?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, free April 11-18)</li>
<li><i>Kill It With Fire 2 </i>(New release on <a href="https://store.steampowered.com/app/2357000?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 16)</li>
<li><i>The Crew Motorfest </i>(New release on <a href="https://store.steampowered.com/app/2698940?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 18)</li>
<li><i>No Rest for the Wicked </i>(New release on <a href="https://store.steampowered.com/app/1371980?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 18)</li>
<li><i>Bellwright </i>(New release on <a href="https://store.steampowered.com/app/1812450?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 23)</li>
<li><i>Age of Water </i>(New release on <a href="https://store.steampowered.com/app/2695490?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 25)</li>
<li><i>Diablo II: Resurrected </i>(<a href="https://shop.battle.net/product/diablo-ii?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
<li><i>Diablo III </i>(<a href="https://shop.battle.net/product/diablo-iii?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
<li><i>Fallout 4 </i>(<a href="https://store.steampowered.com/app/377160?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Fallout 76 </i>(<a href="https://store.steampowered.com/app/1151340?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.xbox.com/games/store/fallout-76-pc/9nkgnmnk3k3z?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>StarCraft Remastered </i>(<a href="https://shop.battle.net/product/starcraft-remastered?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
<li><i>StarCraft II </i>(<a href="https://shop.battle.net/product/starcraft-ii?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
<li><i>Stargate: Timekeepers </i>(<a href="https://store.steampowered.com/app/1523650?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Terra Invicta</i> (<a href="https://www.xbox.com/games/store/terra-invicta-game-preview/9pb0glgxqz83?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Tomb Raider I-III Remastered </i>(<a href="https://store.steampowered.com/app/2478970?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<p>Riot Games has rolled out the <i>League of Legends</i> 14.9 update globally, which adds the Vanguard security software to the game. Since Vanguard doesn‚Äôt support virtual machines like GeForce NOW, the game is under maintenance and no longer playable on the cloud gaming platform for the foreseeable future. Work is underway to find a solution for GeForce NOW members.</p>
<p><i>Lightyear Frontier </i>(Xbox) didn‚Äôt make it in April due to technical issues. Stay tuned to GFN Thursday for updates.</p>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">what are you gaming goals for next month? <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f914.png" alt="ü§î" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f329.png" alt="üå©" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1785700708882251889?ref_src=twsrc%5Etfw">May 1, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-thursday-5-2-nv-blog-1280x680-no-cta.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-thursday-5-2-nv-blog-1280x680-no-cta-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[GeForce NOW Delivers 24 A-May-zing Games This Month]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Explainable AI: Insights from Arthur‚Äôs Adam Wenchel</title>
		<link>https://blogs.nvidia.com/blog/arthur-podcast/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Wed, 01 May 2024 19:28:59 +0000</pubDate>
				<category><![CDATA[The AI Podcast]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71392</guid>

					<description><![CDATA[Arthur.ai enhances the performance of AI systems across various metrics like accuracy, explainability and fairness. In this episode of the NVIDIA AI Podcast, recorded live at GTC 2024, host Noah Kravitz sits down with Adam Wenchel, cofounder and CEO of Arthur, to discuss the challenges and opportunities of deploying generative AI. Their conversation spans a		<a class="read-more" href="https://blogs.nvidia.com/blog/arthur-podcast/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Arthur.ai enhances the performance of AI systems across various metrics like accuracy, explainability and fairness. In this episode of the <a href="https://blogs.nvidia.com/ai-podcast/">NVIDIA AI Podcast</a>, recorded live at GTC 2024, host Noah Kravitz sits down with Adam Wenchel, cofounder and CEO of Arthur, to discuss the challenges and opportunities of deploying generative AI. Their conversation spans a range of topics, including AI bias, the observability of AI systems and the practical implications of AI in business. For more on Arthur, visit<a href="http://arthur.ai/"> arthur.ai</a>.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1811598663%3Fsecret_token%3Ds-cC3zby3JQS4&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> ¬∑ <a style="color: #cccccc; text-decoration: none;" title="Explainable AI: Insights from Arthur AI's Adam Wenchel ‚Äì Ep. 221" href="https://soundcloud.com/theaipodcast/arthur-ai-adam-wenchel/s-cC3zby3JQS4" target="_blank" rel="noopener">Explainable AI: Insights from Arthur AI&#8217;s Adam Wenchel ‚Äì Ep. 221</a></div>
<h2>Time Stamps:</h2>
<ul>
<li style="font-weight: 400;" aria-level="1"><strong>00:11:</strong> Introduction and background on Adam Wenchel and Arthur.ai.</li>
<li style="font-weight: 400;" aria-level="1"><strong>01:31:</strong> Discussion on the mission and services of Arthur.</li>
<li style="font-weight: 400;" aria-level="1"><strong>02:31:</strong> Real-world use cases of LLMs and generative AI in enterprises.</li>
<li style="font-weight: 400;" aria-level="1"><strong>06:22:</strong> Challenges in deploying AI systems internally within companies.</li>
<li style="font-weight: 400;" aria-level="1"><strong>08:23:</strong> The process of adapting AI models for specific business needs.</li>
<li style="font-weight: 400;" aria-level="1"><strong>09:26:</strong> Exploring AI observability and the importance of real-time monitoring.</li>
<li style="font-weight: 400;" aria-level="1"><strong>11:36:</strong> Addressing bias in AI systems and its implications.</li>
<li style="font-weight: 400;" aria-level="1"><strong>15:21:</strong> Wenchel‚Äôs journey from cybersecurity to AI and founding Arthur.</li>
<li style="font-weight: 400;" aria-level="1"><strong>20:38:</strong> Cybersecurity concerns with generative AI and large language models.</li>
<li style="font-weight: 400;" aria-level="1"><strong>21:37:</strong> Future of work and AI‚Äôs role in enhancing job performance.</li>
<li style="font-weight: 400;" aria-level="1"><strong>24:27:</strong> Future directions for Arthur and ongoing projects.</li>
</ul>
<h2>You Might Also Like‚Ä¶</h2>
<p><a href="https://soundcloud.com/theaipodcast/ai-daniel-castro-itif">ITIF‚Äôs Daniel Castro on Energy-Efficient AI and Climate Change ‚Äì Ep. 215</a></p>
<p>AI-driven change is in the air, as are concerns about the technology‚Äôs environmental impact. In this episode of NVIDIA‚Äôs AI Podcast, Daniel Castro, vice president of the Information Technology and Innovation Foundation and director of its Center for Data Innovation, speaks with host Noah Kravitz about the motivation behind his AI energy use report, which addresses misconceptions about the technology‚Äôs energy consumption.</p>
<p><a href="https://soundcloud.com/theaipodcast/ai-wildfire">DigitalPath‚Äôs Ethan Higgins on Using AI to Fight Wildfires ‚Äì Ep. 211</a></p>
<p>DigitalPath is igniting change in the golden state ‚Äî using computer vision, generative adversarial networks and a network of thousands of cameras to detect signs of fire in real-time. In the latest episode of NVIDIA‚Äôs AI Podcast, host Noah Kravtiz spoke with DigitalPath system architect Ethan Higgins about the company‚Äôs role in the ALERTCalifornia initiative, a collaboration between California‚Äôs wildfire fighting agency CAL FIRE and the University of California, San Diego.</p>
<p><a href="https://soundcloud.com/theaipodcast/anima-anandkumar">Anima Anandkumar on Using Generative AI to Tackle Global Challenges ‚Äì Ep. 203</a></p>
<p>Generative AI-based models can not only learn and understand natural languages ‚Äî they can learn the very language of nature itself, presenting new possibilities for scientific research. On the latest episode of NVIDIA‚Äôs AI Podcast, host Noah Kravitz spoke with Anandkumar on generative AI‚Äôs potential to make splashes in the scientific community.</p>
<p><a href="https://soundcloud.com/theaipodcast/ai-alex-fielding">How Alex Fielding and Privateer Space Are Taking on Space Debris ‚Äì Ep. 196</a></p>
<p>In this episode of the NVIDIA AI Podcast, host Noah Kravitz dives into an illuminating conversation with Alex Fielding, co-founder and CEO of Privateer Space. Privateer Space, Fielding‚Äôs latest venture, aims to address one of the most daunting challenges facing our world today: space debris.</p>
<h2>Subscribe to the AI Podcast</h2>
<p>Get the<a href="https://blogs.nvidia.com/ai-podcast/"> AI Podcast</a> through<a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439"> iTunes</a>,<a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjI2NDAzNDEzMy9zb3VuZHMucnNz"> Google Podcasts</a>,<a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm"> Google Play</a>, <a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">Amazon Music, </a><a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us">Castbox</a>, DoggCatcher,<a href="https://overcast.fm/itunes1186480811/the-ai-podcast"> Overcast</a>,<a href="https://player.fm/series/the-ai-podcast"> PlayerFM</a>, Pocket Casts,<a href="http://www.podbay.fm/show/1186480811"> Podbay</a>,<a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast"> PodBean</a>, PodCruncher, PodKicker,<a href="https://soundcloud.com/theaipodcast"> Soundcloud</a>,<a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L"> Spotify</a>,<a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr"> Stitcher</a> and<a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/"> TuneIn</a>.</p>
<p>Make the AI Podcast better: Have a few minutes to spare? Fill out<a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short"> this listener survey</a>.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2021/08/ai-podcast-2600x1472_-1-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1159"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2021/08/ai-podcast-2600x1472_-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Explainable AI: Insights from Arthur‚Äôs Adam Wenchel]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI Takes a Bow: Interactive GLaDOS Robot Among 9 Winners in Hackster.io Challenge</title>
		<link>https://blogs.nvidia.com/blog/glados-robot-hackster/</link>
		
		<dc:creator><![CDATA[Scott Martin]]></dc:creator>
		<pubDate>Wed, 01 May 2024 15:33:24 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Conversational AI]]></category>
		<category><![CDATA[NVIDIA Jetson]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71365</guid>

					<description><![CDATA[YouTube robotics influencer Dave Niewinski has developed robots for everything from driveable La-Z-Boy chairs to an AI-guided cornhole tosser and horse-drawn chariot racing. His recent Interactive Animatronic GLaDOS project was among nine winners in the Hackster AI Innovation Challenge. About 100 contestants vied for prizes from NVIDIA and Sparkfun by creating open-source projects to advance		<a class="read-more" href="https://blogs.nvidia.com/blog/glados-robot-hackster/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>YouTube robotics influencer Dave Niewinski has developed robots for everything from driveable La-Z-Boy chairs to an AI-guided cornhole tosser and horse-drawn chariot racing.</p>
<p>His recent <a href="https://www.hackster.io/davesarmoury/interactive-animatronic-glados-8b4238">Interactive Animatronic GLaDOS</a> project was among nine winners in the <a href="https://www.hackster.io/contests/SparkFun-NVIDIA-AI-Innovation-Challenge">Hackster AI Innovation Challenge</a>. About 100 contestants vied for prizes from NVIDIA and Sparkfun by creating open-source projects to advance the use of AI in edge computing, robotics and IoT.</p>
<p>Niewinski won first place in the generative AI applications category for his innovative robot based on the GLaDOS guide from game series <i>Portal</i>, the first-person puzzle platform from video game developer Valve.</p>
<p>Other top winners included contestants Andrei Ciobanu and Allen Tao, who took first prize in the generative AI models for the edge and AI at the edge applications categories, respectively. Ciobanu used generative AI to help virtually try on clothes, while Tao developed a ROS-based robot to map the inside of a home to help find things.</p>
<h2><b>Harnessing LLMs for Robots</b></h2>
<p>Niewinski builds custom applications for robotics at his <a href="https://www.armourylabs.com/">Armoury Labs</a> business in Waterloo, Ontario, Canada, where he uses the NVIDIA Jetson platform for edge AI and robotics, creating open-source tutorials and <a href="https://www.youtube.com/@DavesArmoury/videos">YouTube videos</a> following his experiences.</p>
<p>He built his interactive GLaDOS robot to create a personal assistant for himself in the lab. It handles queries using Transformer-based speech recognition, text-to-speech, and large language models (LLMs) running onboard an <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">NVIDIA Jetson AGX Orin</a>, which interfaces with a robot arm and camera for interactions.</p>
<p>GLaDOS can track his whereabouts in the lab, move in different directions to face him and respond quickly to queries.</p>
<p>‚ÄúI like doing things with robots that people will look at and say it‚Äôs not what they had immediately expected,‚Äù he said.</p>
<p><iframe loading="lazy" title="Bringing GLaDOS to life with Robotics and AI" width="500" height="281" src="https://www.youtube.com/embed/yNcKTZsHyfA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>He wanted the assistant to sound like the original GLaDOS from <i>Portal</i> and respond quickly. Fortunately, the gaming company Valve has put all of the voice lines from <i>Portal </i>and <i>Portal 2</i> on its website, allowing Niewinski to download the audio to help train a model.</p>
<p>‚ÄúUsing Jetson, your average question-and-answer stuff runs pretty quick for speech,‚Äù he said.</p>
<p>Niewinski used NVIDIA‚Äôs open-source <a href="https://github.com/NVIDIA/NeMo">NeMo</a> toolkit to fine-tune a voice for GLaDOS, training a spectrogram generator network called <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/tts_en_fastpitch">FastPitch</a> and <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/tts_hifigan">HiFiGAN</a> vocoder network to refine the audio quality.</p>
<p>Both networks are deployed on Orin with <a href="https://www.nvidia.com/en-us/ai-data-science/products/riva/">NVIDIA Riva</a> to enable speech recognition and synthesis that‚Äôs been optimized to run at many times the real-time rate of speech, so that it can run alongside the LLM while maintaining a smooth, interactive delivery.</p>
<p>For generating realistic responses from GLaDOS, Niewinski uses a locally hosted LLM called OpenChat that he runs in Docker from <a href="https://github.com/dusty-nv/jetson-containers">jetson-containers</a>, saying that it was a drop-in replacement for OpenAI‚Äôs API. All of this AI is running on the <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">Jetson</a> module, using the latest open-source ML software stack built with CUDA and <a href="https://developer.nvidia.com/embedded/jetpack">JetPack</a>.</p>
<p>To enable GLaDOS to move, Niewinski developed the interactions for a Unitree Z1 robotic arm. It has a stereo camera and models for seeing and tracking a human speaking and a 3D-printed GLaDOS head and body shell around the arm.</p>
<h2><b>Trying on Generative AI for Fashion Fit</b></h2>
<p>Winner Ciobanu, based in Romania, aimed to improve the virtual clothing try-on experience with the help of generative AI, taking a top prize for his <a href="https://www.hackster.io/andrei-ciobanu2/edgestyle-fashion-preview-at-the-edge-b6d845">EdgeStyle: Fashion Preview at the Edge</a>.</p>
<p>He used AI models such as YOLOv5, SAM and OpenPose to extract and refine data from images and videos. Then he used Stable Diffusion to generate the images, which he said was key to achieving accurate virtual try-ons.</p>
<p>This system taught the model how clothes fit different poses on people, which he said enhanced the realism of the try-ons.</p>
<p>‚ÄúIt‚Äôs quite handy as it allows users to see how clothes would look on them without actually trying them on,‚Äù said Ciobanu.</p>
<p><iframe loading="lazy" title="EdgeStyle Demo" width="500" height="281" src="https://www.youtube.com/embed/kR_o9eEUHK4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>The NVIDIA JetPack SDK provided all the tools needed to run AI models smoothly on the Jetson Orin, he said.</p>
<p>‚ÄúIt‚Äôs super-helpful to have a stable set of tools, especially when you‚Äôre dealing with AI tech that keeps changing,‚Äù said Ciobanu. ‚ÄúIt really cut down on the time and hassle for us developers, letting us focus more on the cool stuff we‚Äôre building instead of getting stuck on tech issues.‚Äù</p>
<h2>¬†<b>Finding Lost Items With Robot Assistance</b></h2>
<p>Winner Tao, based in Ontario, Canada, created a robot to lessen the burden of searching for things lost around the house. His <a href="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.hackster.io%2Fceyeber%2Fan-eye-for-an-item-9162a7&amp;data=05%7C02%7Cscmartin%40nvidia.com%7C0e398a0434c949e581b508dc65b1f664%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638497062235862516%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=FiIs8uLHjF8szFOvOs5F1vHFD3ax0fKBEnLyL3kS9aQ%3D&amp;reserved=0">An Eye for an Item</a> project took top honors at the Hackster challenge.</p>
<p>‚ÄúFinding lost objects is a chore, and recent developments in zero-shot object detection and LLMs make it feasible for a computer to detect arbitrary objects for us based on textual or pictorial descriptions, presenting an opportunity for automation,‚Äù said Tao.</p>
<p><iframe loading="lazy" title="Teleop Drive Test" width="500" height="281" src="https://www.youtube.com/embed/dx87BFX5nA8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Tao said he needed robot computing capabilities to catalog objects in any unstructured environment ‚Äî whether a living room or large warehouse. And he needed it to also perform real-time calculations for localization to help with navigation, as well as running inference on larger object detection models.</p>
<p>‚ÄúJetson Orin was a perfect fit, supporting all functionality from text and image queries into <a href="https://www.jetson-ai-lab.com/tutorial_nanodb.html">NanoDB</a>, to real-time odometry feedback, including leveraging <a href="https://developer.nvidia.com/isaac/ros">Isaac ROS</a>‚Äô hardware-accelerated AprilTag detections for drift correction,‚Äù he said.</p>
<p>Other <a href="https://www.hackster.io/contests/SparkFun-NVIDIA-AI-Innovation-Challenge">winners</a> of the AI Innovation Challenge include:</p>
<ul>
<li style="font-weight: 400;" aria-level="1">George Profenza, Escalator people tracker, 2nd place, Generative AI Applications category</li>
<li style="font-weight: 400;" aria-level="1">Dimiter Kendri, Cooking meals with a local AI assistant using Jetson AGX Orin, 3rd place, Generative AI Applications category</li>
<li style="font-weight: 400;" aria-level="1">Vy Phan, ClearWaters Underwater Image Enhancement with Generative AI, 2nd place, Generative AI Models category</li>
<li style="font-weight: 400;" aria-level="1">Huy Mai, Realtime Language Segment Anything on Jetson Orin, 2nd place, Generative AI Models category</li>
<li style="font-weight: 400;" aria-level="1">Fakhrur Razi, Autonomous Intelligent Robotic Shopping Cart, 2nd place, AI at the Edge Open category</li>
<li style="font-weight: 400;" aria-level="1">Team Kinetika, Counting for Inspection and Quality Control with TensorRT, 3rd place, AI at the Edge Open category</li>
</ul>
<p><i>Learn more about </i><a href="https://developer.nvidia.com/embedded-computing"><i>NVIDIA Jetson Orin</i></a><i> for robotics and edge AI applications. Get started creating your own projects at the </i><a href="https://www.jetson-ai-lab.com/"><i>Jetson AI Lab</i></a><i>.¬†¬†</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/Hackster_Edge_AI_Challenge_Winners-Blog.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/Hackster_Edge_AI_Challenge_Winners-Blog-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI Takes a Bow: Interactive GLaDOS Robot Among 9 Winners in Hackster.io Challenge]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Say It Again: ChatRTX Adds New AI Models, Features in Latest Update</title>
		<link>https://blogs.nvidia.com/blog/ai-decoded-chatrtx-update/</link>
		
		<dc:creator><![CDATA[Jesse Clayton]]></dc:creator>
		<pubDate>Wed, 01 May 2024 13:00:57 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[AI Decoded]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Conversational AI]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[Gaming]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71359</guid>

					<description><![CDATA[Chatbots powered by large-language AI models have transformed computing, and NVIDIA ChatRTX lets users interact with their local data, accelerated by NVIDIA RTX-powered Windows PCs and workstations. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><i>Editor‚Äôs note: This post is part of the </i><a href="https://blogs.nvidia.com/blog/tag/ai-decoded/" target="_blank" rel="noopener"><i>AI Decoded series</i></a><i>, which demystifies AI by making the technology more accessible, and which showcases new hardware, software, tools and accelerations for RTX PC users.</i></p>
<p>Chatbots powered by large-language AI models have transformed computing, and <a href="https://www.nvidia.com/en-us/ai-on-rtx/chatrtx/" target="_blank" rel="noopener">NVIDIA ChatRTX</a> lets users interact with their local data, accelerated by <a href="https://www.nvidia.com/en-us/design-visualization/technologies/rtx/" target="_blank" rel="noopener">NVIDIA RTX</a>-powered Windows PCs and workstations. A <a href="https://www.nvidia.com/en-us/ai-on-rtx/chatrtx/" target="_blank" rel="noopener">new update</a>, first demoed at <a href="https://blogs.nvidia.com/blog/ai-decoded-gtc-chatrtx-workbench-nim/" target="_blank" rel="noopener">GTC</a> in March, expands the power of this RTX-accelerated chatbot app with additional features and support for new models.</p>
<p>The NVIDIA RTX Remix beta update brings NVIDIA DLSS 3.5 with <a href="https://blogs.nvidia.com/blog/ai-decoded-ray-reconstruction" target="_blank" rel="noopener">Ray Reconstruction</a> to the modding platform for even more impressive real-time ray tracing.</p>
<h2><b>Say It Out Loud</b></h2>
<p><iframe loading="lazy" title="ChatRTX Update: New Models &amp; Features | Voice &amp; Image Data Support" width="500" height="281" src="https://www.youtube.com/embed/zMROAxJQ7rk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>ChatRTX uses <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/" target="_blank" rel="noopener">retrieval-augmented generation</a>, NVIDIA TensorRT-LLM software and NVIDIA RTX acceleration to bring chatbot capabilities to RTX-powered Windows PCs and workstations. Backed by its powerful large language models (LLMs), users can query their notes and documents with ChatRTX, which can quickly generate relevant responses, while running locally on the user‚Äôs device.</p>
<p>The latest version adds support for additional LLMs, including Gemma, the latest open, local LLM trained by Google. Gemma was developed from the same research and technology used to create the company‚Äôs Gemini models and is built for responsible AI development. ChatRTX also now supports ChatGLM3, an open, bilingual (English and Chinese) LLM based on the general language model framework.</p>
<p>Users can also interact with image data thanks to support for Contrastive Language-Image Pre-training from OpenAI. CLIP is a neural network that, through training and refinement, learns visual concepts from natural language supervision ‚Äî that is, the model recognizes what it‚Äôs ‚Äúseeing‚Äù in image collections. With CLIP support in ChatRTX, users can interact with photos and images on their local devices through words, terms and phrases, without the need for complex metadata labeling.</p>
<p>The new ChatRTX release also lets people chat with their data using their voice. Thanks to support for Whisper, an automatic speech recognition system that uses AI to process spoken language, users can send voice queries to the application and ChatRTX will provide text responses.</p>
<p><a href="https://www.nvidia.com/en-us/ai-on-rtx/chatrtx/" target="_blank" rel="noopener">Download</a> ChatRTX today.</p>
<h2><b>Mix It Up</b></h2>
<p>With RTX Remix, modders can transform classic PC games into RTX remasters using AI-accelerated tools on the <a href="https://www.nvidia.com/en-us/omniverse/" target="_blank" rel="noopener">NVIDIA Omniverse</a> platform.</p>
<p>Now, they can use <a href="https://www.nvidia.com/en-us/geforce/news/nvidia-dlss-3-5-ray-reconstruction/" target="_blank" rel="noopener">DLSS 3.5 with Ray Reconstruction</a> in their projects with just a few clicks, thanks to an update to RTX Remix available this week. Its advanced, AI-powered neural renderer improves the fidelity, responsiveness and quality of ray-traced effects, giving <a href="https://www.nvidia.com/en-us/geforce/rtx/" target="_blank" rel="noopener">NVIDIA GeForce RTX</a> gamers an even better experience.</p>
<p><iframe loading="lazy" title="Portal with RTX | DLSS 3.5 with Ray Reconstruction Comparison - Fence Scene" width="500" height="281" src="https://www.youtube.com/embed/kXNzDQTSFF8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>AI powers other elements of the Remix workflow, too. Modders can use generative AI texture tools to analyze low-resolution textures from classic games, generate physically accurate materials ‚Äî including normal and roughness maps ‚Äî and upscale the resolution by up to 4x. Tools like this also save modders time, quickly handling a task that could otherwise become tedious.</p>
<p>Learn more about the new <a href="https://www.nvidia.com/en-us/geforce/news/rtx-remix-dlss-3-5-ray-reconstruction" target="_blank" rel="noopener">RTX Remix beta update</a> on the <a href="https://www.nvidia.com/en-us/geforce/">GeForce page</a>.</p>
<p><i>Generative AI is transforming gaming, videoconferencing and interactive experiences of all kinds. Make sense of what‚Äôs new and what‚Äôs next by subscribing to the </i><a href="https://www.nvidia.com/en-us/ai-on-rtx/?modal=subscribe-ai" target="_blank" rel="noopener"><i>AI Decoded newsletter</i></a><i>.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/ai-chat-rtx-nv-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/ai-chat-rtx-nv-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Say It Again: ChatRTX Adds New AI Models, Features in Latest Update]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>SEA.AI Navigates the Future With AI at the Helm</title>
		<link>https://blogs.nvidia.com/blog/sea-ai/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Mon, 29 Apr 2024 13:00:00 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Metropolis]]></category>
		<category><![CDATA[NVIDIA Jetson]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71247</guid>

					<description><![CDATA[Talk about commitment. When startup SEA.AI, an NVIDIA Metropolis partner, set out to create a system that would use AI to scan the seas to enhance maritime safety, entrepreneur Raphael Biancale wasn‚Äôt afraid to take the plunge. He donned a lifejacket and jumped into the ocean. It‚Äôs a move that demonstrates Biancale‚Äôs commitment and pioneering		<a class="read-more" href="https://blogs.nvidia.com/blog/sea-ai/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Talk about commitment. When startup SEA.AI, an NVIDIA Metropolis partner, set out to create a system that would use AI to scan the seas to enhance maritime safety, entrepreneur Raphael Biancale wasn‚Äôt afraid to take the plunge. He donned a lifejacket and jumped into the ocean.</p>
<p>It‚Äôs a move that demonstrates Biancale‚Äôs commitment and pioneering approach. The startup, founded in 2018 and based in Linz, Austria, with subsidiaries in France, Portugal and the US, had to build its first-of-its-kind training data from scratch in order to train an AI to help oceangoers of all kinds scan the seas.</p>
<p>And to do that, the company needed photos of what a person in the water looked like. That‚Äôs when Biancale, now the company‚Äôs head of research, walked the plank.</p>
<p>The company has come a long way since then, with a full product line powered by NVIDIA AI technology that lets commercial and recreational sailors detect objects on the seas, whether potential hazards or people needing rescue.</p>
<p>It‚Äôs an effort inspired by Biancale‚Äôs experience on a night sail. The lack of visibility and situational awareness illuminated the pressing need for advanced safety technologies in the maritime world that AI is bringing to the automotive industry.</p>
<p>AI, of course, is finding its way into all things aquatic. Startup <a href="https://blogs.nvidia.com/blog/saildrone-autonomous-oceanic-monitoring-jetson-deepstream/">Saildrone‚Äôs autonomous sailing vessels</a> can help conduct data-gathering for science, fisheries, weather forecasting, ocean mapping and maritime security. Other researchers are using AI to <a href="https://blogs.nvidia.com/blog/project-ceti/">interpret whale songs</a> and even protect beachgoers from <a href="https://blogs.nvidia.com/blog/rip/">dangerous rip currents</a>.</p>
<p><img loading="lazy" decoding="async" class="aligncenter wp-image-71251 size-full" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/SEA-ABOVE.jpg" alt="" width="624" height="433" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/SEA-ABOVE.jpg 624w, https://blogs.nvidia.com/wp-content/uploads/2024/04/SEA-ABOVE-400x278.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/SEA-ABOVE-310x215.jpg 310w, https://blogs.nvidia.com/wp-content/uploads/2024/04/SEA-ABOVE-144x100.jpg 144w" sizes="(max-width: 624px) 100vw, 624px" /></p>
<p>SEA.AI, however, promises to make the seas safer for everyone who steps aboard a boat. First introduced for ocean racing sailboats, SEA.AI‚Äôs system has quickly evolved into an AI-powered situational awareness system that can be deployed on everything from recreational sail and powerboats to commercial shipping vessels.</p>
<p>SEA.AI directly addresses one of the most significant risks for all these vessels: collisions. Thanks to SEA.AI, commercial and recreational oceangoers worldwide can travel with more confidence.</p>
<h2>How SEA.AI Works</h2>
<p>At the heart of SEA.AI‚Äôs approach is a proprietary database of over 9 million annotated marine objects which is growing constantly.</p>
<p>When combined with high-tech optical sensors and the latest AI technology from NVIDIA, SEA.AI‚Äôs systems can recognize and classify objects in real-time, significantly improving maritime safety.</p>
<p>SEA.AI technology can detect a person in water up to 700 meters ‚Äî almost half a mile ‚Äî away, a dinghy up to 3,000 meters, and motorboats up to 7,500 meters.</p>
<p>This capability ensures maritime operators can identify hazards before they pose a threat. It complements older marine safety systems that rely on radar and satellite signals.</p>
<p>SEA.AI solutions integrate with central marine display units from industry-leading manufacturers like Raymarine, B&amp;G, Garmin and Furuno as well as Android and iOS-based mobile devices. This provides broad applicability across the maritime sector, from recreational vessels to commercial and government ships.</p>
<p>The <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/">NVIDIA Jetson</a> edge AI platform is integral to SEA.AI‚Äôs success. The platform for robotics and embedded computing applications enables SEA.AI products to achieve unparalleled processing power and efficiency, setting a new standard in maritime safety by quickly detecting, analyzing and alerting operators to objects.</p>
<p><img loading="lazy" decoding="async" class="aligncenter wp-image-71255 size-full" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/SEAAI-GEAR.png" alt="" width="624" height="284" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/SEAAI-GEAR.png 624w, https://blogs.nvidia.com/wp-content/uploads/2024/04/SEAAI-GEAR-400x182.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/SEAAI-GEAR-406x185.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/04/SEAAI-GEAR-188x86.png 188w" sizes="(max-width: 624px) 100vw, 624px" /></p>
<h2>AI Integration and Real-Time Object Detection</h2>
<p>SEA.AI uses NVIDIA‚Äôs AI and machine vision technology to offer real-time object detection and classification, providing maritime operators with immediate identification of potential hazards.</p>
<p>SEA.AI is bringing its approach to oceangoers of all kinds with three product lines.</p>
<p>One, SEA.AI Sentry, provides 360-degree situational awareness for commercial vessels and motor yachts with features like collision avoidance, object tracking and perimeter surveillance.</p>
<p>Another, SEA.AI Offshore,¬† provides bluewater sailors with high-tech safety and convenience with simplified installation across several editions that can suit different detection and technical needs.</p>
<p>The third, SEA.AI Competition, offers reliable object detection for ocean racing and performance yacht sailors. Its ultra-lightweight design ensures maximum performance when navigating at high speeds.</p>
<p>With a growing team of more than 60 and a distribution network spanning over 40 countries, SEA.AI is charting a course to help ensure every journey on the waves is safer.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/SEAAI-SAIL.jpg"
			type="image/jpeg"
			width="624"
			height="351"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/SEAAI-SAIL.jpg"
			width="624"
			height="351"
			/>
			<media:title type="html"><![CDATA[SEA.AI Navigates the Future With AI at the Helm]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI Drives Future of Transportation at Asia‚Äôs Largest Automotive Show</title>
		<link>https://blogs.nvidia.com/blog/nvidia-partners-auto-china/</link>
		
		<dc:creator><![CDATA[Danny Shapiro]]></dc:creator>
		<pubDate>Fri, 26 Apr 2024 01:30:38 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Isaac]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<category><![CDATA[Omniverse]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71295</guid>

					<description><![CDATA[The latest trends and technologies in the automotive industry are in the spotlight at the Beijing International Automotive Exhibition, aka Auto China, which opens to the public on Saturday, April 27. An array of NVIDIA auto partners is embracing this year‚Äôs theme, ‚ÄúNew Era, New Cars,‚Äù by making announcements and showcasing their latest offerings powered		<a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-partners-auto-china/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>The latest trends and technologies in the automotive industry are in the spotlight at the Beijing International Automotive Exhibition, aka Auto China, which opens to the public on Saturday, April 27.</p>
<p>An array of NVIDIA auto partners is embracing this year‚Äôs theme, ‚ÄúNew Era, New Cars,‚Äù by making announcements and showcasing their latest offerings powered by <a href="https://developer.nvidia.com/drive">NVIDIA DRIVE</a>, the platform for AI-defined vehicles.</p>
<h2><b>NVIDIA Auto Partners Announce New Vehicles and Technologie</b><b>s</b></h2>
<figure id="attachment_71339" aria-describedby="caption-attachment-71339" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/04/jiyue_car_kv_social_1280_680.png"><img loading="lazy" decoding="async" class="wp-image-71339 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/jiyue_car_kv_social_1280_680-672x357.png" alt="" width="672" height="357" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/jiyue_car_kv_social_1280_680-672x357.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/04/jiyue_car_kv_social_1280_680-400x213.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/jiyue_car_kv_social_1280_680-768x408.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/jiyue_car_kv_social_1280_680-842x447.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/04/jiyue_car_kv_social_1280_680-406x215.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/04/jiyue_car_kv_social_1280_680-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/04/jiyue_car_kv_social_1280_680.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71339" class="wp-caption-text">Image courtesy of JIYUE.</figcaption></figure>
<p>Electric vehicle (EV) makers <b>Chery</b> (booth E107) and <b>JIYUE </b>(booth W206), a joint venture between Baidu and Geely (booth W204), announced they have adopted the next-generation <a href="https://www.nvidia.com/en-us/self-driving-cars/in-vehicle-computing/" target="_blank" rel="noopener">NVIDIA DRIVE Thor</a> centralized car computer.</p>
<p>DRIVE Thor <a href="https://nvidianews.nvidia.com/news/nvidia-drive-powers-next-generation-transportation" target="_blank" rel="noopener">will integrate</a> the new <a href="https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/" target="_blank" rel="noopener">NVIDIA Blackwell</a> GPU architecture, designed for <a href="https://blogs.nvidia.com/blog/what-is-a-transformer-model/" target="_blank" rel="noopener">transformer</a>, <a href="https://www.nvidia.com/en-us/glossary/large-language-models/" target="_blank" rel="noopener">large language model</a> and <a href="https://www.nvidia.com/en-us/glossary/generative-ai/" target="_blank" rel="noopener">generative AI</a> workloads.</p>
<p>In addition, a number of automakers are building next-gen vehicles on NVIDIA DRIVE Orin, including:</p>
<p><b>smart</b>, a joint venture between Mercedes-Benz and Geely, previewed its largest and most spacious model to date, an electric SUV called #5. It will be built on its Pilot Assist 3.0 intelligent driving-assistance platform, powered by <a href="https://www.nvidia.com/en-us/self-driving-cars/in-vehicle-computing/" target="_blank" rel="noopener">NVIDIA DRIVE Orin</a>, which supports point-to-point automatic urban navigation. smart #5 will be available for purchase in the second half of this year. smart will be at booth E408.</p>
<figure id="attachment_71441" aria-describedby="caption-attachment-71441" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/04/NIO-booth-scaled.jpg"><img loading="lazy" decoding="async" class="wp-image-71441 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/NIO-booth-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/NIO-booth-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/04/NIO-booth-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/NIO-booth-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/NIO-booth-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/04/NIO-booth-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/04/NIO-booth-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/04/NIO-booth-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/04/NIO-booth-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/04/NIO-booth-1280x853.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71441" class="wp-caption-text">NIO&#8217;s booth at Auto China.</figcaption></figure>
<p><b></b><b>NIO</b>, a pioneer in the premium smart EV market, unveiled its updated ET7 sedan, featuring upgraded cabin intelligence and smart-driving capabilities. NIO also showcased its 2024 ET5 and ES7. All 2024 models are equipped with four NVIDIA DRIVE Orin systems-on-a-chip (SoCs). Intelligent-driving capabilities in urban areas will fully launch soon. NIO will be at booth E207.</p>
<figure id="attachment_71348" aria-describedby="caption-attachment-71348" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/04/GWM_kv_social_1280_680.png"><img loading="lazy" decoding="async" class="wp-image-71348 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/GWM_kv_social_1280_680-672x357.png" alt="" width="672" height="357" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/GWM_kv_social_1280_680-672x357.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/04/GWM_kv_social_1280_680-400x213.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/GWM_kv_social_1280_680-768x408.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/GWM_kv_social_1280_680-842x447.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/04/GWM_kv_social_1280_680-406x215.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/04/GWM_kv_social_1280_680-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/04/GWM_kv_social_1280_680.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71348" class="wp-caption-text">Image courtesy of GWM.</figcaption></figure>
<p><b>GWM </b>revealed the WEY Blue Mountain (Lanshan) Intelligent Driving Edition, its luxury, high-end SUV. This upgraded vehicle is built on GWM‚Äôs Coffee Pilot Ultra intelligent-driving system, powered by NVIDIA DRIVE Orin, and can support features such as urban navigate-on-autopilot (NOA) and cross-floor memory parking. GWM will be at booth E303.</p>
<p><b>XPENG</b>, a designer and manufacturer of intelligent EVs, announced that it is streamlining the design workflow of its flagship XPENG X9 using the <a href="https://www.nvidia.com/en-us/omniverse/" target="_blank" rel="noopener">NVIDIA Omniverse</a> platform. In March, XPENG announced it will adopt NVIDIA DRIVE Thor for its next-generation EV fleets. XPENG will be at booth W402.</p>
<h2><b>Innovation on Display</b></h2>
<p>On the exhibition floor, NVIDIA partners are showcasing their NVIDIA DRIVE-powered vehicles:</p>
<figure id="attachment_71351" aria-describedby="caption-attachment-71351" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/04/BYD_kv_social_1280_680.png"><img loading="lazy" decoding="async" class="wp-image-71351 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/BYD_kv_social_1280_680-672x357.png" alt="" width="672" height="357" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/BYD_kv_social_1280_680-672x357.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/04/BYD_kv_social_1280_680-400x213.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/BYD_kv_social_1280_680-768x408.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/BYD_kv_social_1280_680-842x447.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/04/BYD_kv_social_1280_680-406x215.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/04/BYD_kv_social_1280_680-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/04/BYD_kv_social_1280_680.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71351" class="wp-caption-text">Image courtesy of BYD.</figcaption></figure>
<p><b>BYD</b>, <b>DENZA</b> and <b>YANGWANG</b> are featuring their latest vehicles built on NVIDIA DRIVE Orin. The largest EV maker in the world, BYD is building both its Ocean and Dynasty series on NVIDIA DRIVE Orin. In addition, BYDE, a subsidiary of BYD, will tap into the <a href="https://developer.nvidia.com/isaac" target="_blank" rel="noopener">NVIDIA Isaac</a> and NVIDIA Omniverse platforms to develop tools and applications for virtual factory planning and retail configurators. BYD will be at booth W106, DENZA at W408 and YANGWANG at W105.</p>
<p><b>DeepRoute.ai </b>is showcasing its new intelligent driving-platform, DeepRoute IO, and highlighting its end-to-end model. Powered by NVIDIA DRIVE Orin, the first mass-produced car built on DeepRoute IO will focus on assisted driving and parking. DeepRoute.ai will be at booth W4-W07.</p>
<p><b>Hyper</b>, a luxury brand owned by GAC AION, is displaying its latest Hyper GT and Hyper HT models, powered by NVIDIA DRIVE Orin. These vehicles feature advanced <a href="https://blogs.nvidia.com/blog/whats-difference-level-2-level-5-autonomy/" target="_blank" rel="noopener">level 2+</a> driving capabilities in high-speed environments. Hyper recently announced it selected DRIVE Thor for its next-generation EVs with level 4 driving capabilities. Hyper will be at booth W310.</p>
<p><b>IM Motors </b>is exhibiting the recently launched L6 Super Intelligent Vehicle. The entire lineup of the IM L6 is equipped with NVIDIA DRIVE Orin to power intelligent driving abilities, including urban NOA features. IM Motors will be at booth W205.</p>
<p><b>Li Auto </b>is showcasing its recently released L6 model, as well as L7, L8, L9 and MEGA. Models equipped with Li Auto‚Äôs AD Max system are powered by dual NVIDIA DRIVE Orin SoCs, which help bring ever-upgrading intelligent functionality to Li Auto‚Äôs NOA feature. Li Auto will be at booth E405.</p>
<figure id="attachment_71345" aria-describedby="caption-attachment-71345" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/04/lotus_emeya_kv_social_1280_680.png"><img loading="lazy" decoding="async" class="wp-image-71345 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/lotus_emeya_kv_social_1280_680-672x357.png" alt="" width="672" height="357" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/lotus_emeya_kv_social_1280_680-672x357.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/04/lotus_emeya_kv_social_1280_680-400x213.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/lotus_emeya_kv_social_1280_680-768x408.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/lotus_emeya_kv_social_1280_680-842x447.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/04/lotus_emeya_kv_social_1280_680-406x215.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/04/lotus_emeya_kv_social_1280_680-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/04/lotus_emeya_kv_social_1280_680.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71345" class="wp-caption-text">Image courtesy of Lotus.</figcaption></figure>
<p><b>Lotus</b> is featuring a full range of vehicles, including the Emeya electric hyper-GT powered by NVIDIA DRIVE Orin. Lotus will be at booth E403.</p>
<p><b>Mercedes-Benz </b>is exhibiting its Concept CLA Class, the first car to be developed on the all-new Mercedes-Benz Modular Architecture. The Concept CLA Class fully runs on MB.OS, which handles infotainment, automated driving, comfort and charging. Mercedes-Benz will be at booth E404.</p>
<p><b>Momenta </b>is rolling out a new NVIDIA DRIVE Orin solution to accelerate commercialization of urban NOA capabilities at scale.</p>
<figure id="attachment_71445" aria-describedby="caption-attachment-71445" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/04/Polestar-scaled.jpg"><img loading="lazy" decoding="async" class="wp-image-71445 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/Polestar-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/Polestar-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Polestar-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Polestar-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Polestar-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Polestar-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Polestar-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Polestar-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Polestar-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Polestar-1280x853.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71445" class="wp-caption-text">The Polestar 3.</figcaption></figure>
<p><b>Polestar </b>is featuring the Polestar 3, the Swedish car manufacturer‚Äôs battery electric mid-size luxury crossover SUV powered by DRIVE Orin. Polestar will be at booth E205.</p>
<p><b>SAIC R Motors </b>is showcasing the Rising Auto R7 and F7 powered by NVIDIA DRIVE Orin at booth W406.</p>
<figure id="attachment_71448" aria-describedby="caption-attachment-71448" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/04/Volvo-EX90-scaled.jpeg"><img loading="lazy" decoding="async" class="wp-image-71448 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/Volvo-EX90-672x448.jpeg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/Volvo-EX90-672x448.jpeg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Volvo-EX90-400x267.jpeg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Volvo-EX90-768x512.jpeg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Volvo-EX90-1536x1024.jpeg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Volvo-EX90-scaled.jpeg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Volvo-EX90-675x450.jpeg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Volvo-EX90-323x215.jpeg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Volvo-EX90-150x100.jpeg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Volvo-EX90-1280x853.jpeg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71448" class="wp-caption-text">The Volvo EX90.</figcaption></figure>
<p><span><strong>Volvo</strong> is displaying the NVIDIA DRIVE Orin-powered Volvo EX90 during the press exhibition.</span></p>
<figure id="attachment_71437" aria-describedby="caption-attachment-71437" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/Chery-ET-and-ES-at-WeRide-booth-scaled.jpg"><img loading="lazy" decoding="async" class="wp-image-71437 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Chery-ET-and-ES-at-WeRide-booth-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/Chery-ET-and-ES-at-WeRide-booth-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Chery-ET-and-ES-at-WeRide-booth-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Chery-ET-and-ES-at-WeRide-booth-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Chery-ET-and-ES-at-WeRide-booth-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Chery-ET-and-ES-at-WeRide-booth-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Chery-ET-and-ES-at-WeRide-booth-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Chery-ET-and-ES-at-WeRide-booth-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Chery-ET-and-ES-at-WeRide-booth-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Chery-ET-and-ES-at-WeRide-booth-1280x853.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71437" class="wp-caption-text">The Chery ET and ES at the WeRide booth.</figcaption></figure>
<p><b>WeRide</b> is exhibiting Chery‚Äôs Exeed Sterra ET SUV and ES sedan, both powered by NVIDIA DRIVE Orin. The vehicles demonstrate progress made by Bosch and WeRide on level 2 to level 3 autonomous-driving technology. WeRide will be at booth E1-W04.</p>
<p><b>Xiaomi </b>is displaying its NVIDIA DRIVE Orin-powered SU7 and ‚ÄúHuman x Car x Home‚Äù smart ecosystem, designed to seamlessly connect people, cars and homes, at booth W203.</p>
<p><b>ZEEKR</b> unveiled its SEA-M architecture and is showcasing the ZEEKR 007 powered by NVIDIA DRIVE Orin at booth E101.</p>
<p>Auto China runs through Saturday, May 4, at the China International Exhibition Center in Beijing.</p>
<p><em>Learn more about the <a href="https://developer.nvidia.com/drive" target="_blank" rel="noopener">industry-leading designs and technologies</a> NVIDIA is developing with its automotive partners.</em></p>
<p><em>Featured image courtesy of JIYUE.</em></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/jiyue_announcement_1280_680.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/jiyue_announcement_1280_680-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI Drives Future of Transportation at Asia‚Äôs Largest Automotive Show]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Blast From the Past: Stream ‚ÄòStarCraft‚Äô and ‚ÄòDiablo‚Äô on GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-more-battle-net-games/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 25 Apr 2024 13:00:59 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71301</guid>

					<description><![CDATA[Support for Battle.net on GeForce NOW expands this GFN Thursday, as titles from the iconic StarCraft and Diablo series come to the cloud. StarCraft Remastered, StarCraft II, Diablo II: Resurrected and Diablo III are part of 16 new games joining the GeForce NOW library of more than 1,900 titles. Plus, a new update rolling out		<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-more-battle-net-games/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Support for Battle.net on <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> expands this GFN Thursday, as titles from the iconic <i>StarCraft </i>and <i>Diablo</i> series come to the cloud.</p>
<p><i>StarCraft Remastered, StarCraft II,</i> <i>Diablo II: Resurrected</i> and<i> Diablo III</i> are part of 16 new games joining the GeForce NOW <a href="https://www.nvidia.com/en-us/geforce-now/games/">library</a> of more than 1,900 titles.</p>
<p>Plus, a <a href="https://nvidia.custhelp.com/app/answers/detail/a_id/5225">new update</a> rolling out for members this week brings AV1 streaming to Mac M3 computers. This feature will improve game-streaming quality for members on M3, M3 Pro and M3 Max devices.</p>
<h2><b>Plenty of Space in Hell</b></h2>
<p>Dive into the original Blizzard games that set the stage for real-time strategy and action role-playing games (RPGs). <i>StarCraft Remastered, StarCraft II, Diablo II: Resurrected </i>and<i> Diablo III </i>bring galactic warfare, epic quests and legendary battles to the cloud.</p>
<figure id="attachment_71305" aria-describedby="caption-attachment-71305" style="width: 640px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-full wp-image-71305" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/ss1-l.jpg" alt="StarCraft Remastered on GeForce NOW" width="640" height="480" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/ss1-l.jpg 640w, https://blogs.nvidia.com/wp-content/uploads/2024/04/ss1-l-400x300.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/ss1-l-600x450.jpg 600w, https://blogs.nvidia.com/wp-content/uploads/2024/04/ss1-l-287x215.jpg 287w, https://blogs.nvidia.com/wp-content/uploads/2024/04/ss1-l-133x100.jpg 133w" sizes="(max-width: 640px) 100vw, 640px" /><figcaption id="caption-attachment-71305" class="wp-caption-text"><em>Oh my Zerg.</em></figcaption></figure>
<p>In <i>StarCraft Remastered</i>, command one of three races ‚Äî Terran, Zerg or Protoss ‚Äî as they desperately struggle for survival. Build bases, gather resources and engage in intense battles using unique units and strategies.</p>
<figure id="attachment_71308" aria-describedby="caption-attachment-71308" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71308" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/SC2-10thAnniversary_CampaignAchiev_LegacyOfTheVoid-672x378.jpg" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/SC2-10thAnniversary_CampaignAchiev_LegacyOfTheVoid-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/04/SC2-10thAnniversary_CampaignAchiev_LegacyOfTheVoid-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/SC2-10thAnniversary_CampaignAchiev_LegacyOfTheVoid-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/SC2-10thAnniversary_CampaignAchiev_LegacyOfTheVoid-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/04/SC2-10thAnniversary_CampaignAchiev_LegacyOfTheVoid-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/04/SC2-10thAnniversary_CampaignAchiev_LegacyOfTheVoid-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/04/SC2-10thAnniversary_CampaignAchiev_LegacyOfTheVoid-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/04/SC2-10thAnniversary_CampaignAchiev_LegacyOfTheVoid-1280x720.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/04/SC2-10thAnniversary_CampaignAchiev_LegacyOfTheVoid.jpg 1920w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71308" class="wp-caption-text"><i>Time to Plyon to the cloud.</i></figcaption></figure>
<p>Continue the saga with <i>StarCraft II,</i> with enhanced graphics and extended storytelling. Save the galaxy from emergent threats in full-length Terran, Zerg and Protoss campaigns. Take charge of all multiplayer units solo in Versus Mode, team up with a friend for Co-Op Missions or explore community-created game modes in the Arcade.</p>
<figure id="attachment_71311" aria-describedby="caption-attachment-71311" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71311" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/reaper-of-souls-08-large-672x378.jpg" alt="Diablo III on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/reaper-of-souls-08-large-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/04/reaper-of-souls-08-large-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/reaper-of-souls-08-large-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/04/reaper-of-souls-08-large-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/04/reaper-of-souls-08-large.jpg 704w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71311" class="wp-caption-text"><em>The fires of hell heat up the cloud once again.</em></figcaption></figure>
<p>In <i>Diablo III</i>, become a hero to battle the forces of darkness, uncover ancient secrets and face powerful foes in the action RPG set in the world of Sanctuary. With various character classes, intense combat and a rich loot system, members can experience a gripping single-player experience and cooperative multiplayer adventures.</p>
<figure id="attachment_71314" aria-describedby="caption-attachment-71314" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71314" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/diablo_ii_resurrected-section1-feature1-672x378.jpg" alt="Diablo II on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/diablo_ii_resurrected-section1-feature1-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/04/diablo_ii_resurrected-section1-feature1-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/diablo_ii_resurrected-section1-feature1-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/diablo_ii_resurrected-section1-feature1-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/04/diablo_ii_resurrected-section1-feature1-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/04/diablo_ii_resurrected-section1-feature1-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/04/diablo_ii_resurrected-section1-feature1.jpg 960w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71314" class="wp-caption-text"><em>Remastered goodness.</em></figcaption></figure>
<p>Pursue the mysterious Dark Wanderer and battle the denizens of hell in the remastered action RPG <i>Diablo II: Resurrected</i>. The title‚Äôs classic Diablo gameplay ‚Äî enhanced with stunning 3D visuals for all the environments, characters and monsters ‚Äî enable a nostalgic, high-quality return to hell.</p>
<p>Stream all the action at up to 4K resolution or up to 240 frames per second with an <a href="http://geforcenow.com">Ultimate membership</a>. These top games join the Battle.net games <a href="https://blogs.nvidia.com/blog/geforce-now-thursday-battlenet-march-games-list/">first added</a> to GeForce NOW, including <i>Diablo IV, Overwatch 2, Call of Duty HQ </i>and <i>Hearthstone.</i></p>
<h2><b>Remember the Cloud</b></h2>
<figure id="attachment_71317" aria-describedby="caption-attachment-71317" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71317" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-remnant-2-dlc-the-forgotten-kingdomtw-li-2048x1024-1-672x336.jpg" alt="Remnant II DLC on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-remnant-2-dlc-the-forgotten-kingdomtw-li-2048x1024-1-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-remnant-2-dlc-the-forgotten-kingdomtw-li-2048x1024-1-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-remnant-2-dlc-the-forgotten-kingdomtw-li-2048x1024-1-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-remnant-2-dlc-the-forgotten-kingdomtw-li-2048x1024-1-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-remnant-2-dlc-the-forgotten-kingdomtw-li-2048x1024-1-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-remnant-2-dlc-the-forgotten-kingdomtw-li-2048x1024-1-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-remnant-2-dlc-the-forgotten-kingdomtw-li-2048x1024-1-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-remnant-2-dlc-the-forgotten-kingdomtw-li-2048x1024-1-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-remnant-2-dlc-the-forgotten-kingdomtw-li-2048x1024-1.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71317" class="wp-caption-text"><em>Unrelenting odds are no problem for the cloud.</em></figcaption></figure>
<p>The second downloadable content (DLC) for Ark Games‚Äô <i>Remnant II</i> is available for members to stream. Experience a brand-new storyline, area, weapons, bosses and more in <i>The Forgotten Kingdom</i>.</p>
<p>Piece together the forgotten history of the lost tribe of Yaesha in an attempt to quell the vengeful wrath of Lydusa, an ancient stone spirit. Navigate the lingering traces of torment, treachery and death that haunt the land‚Äôs once-proud ziggurats. Traverse new dungeons, acquire powerful gear ‚Äî including a new Archetype, ‚ÄúThe Invoker‚Äù ‚Äî meet unexpected allies and face new threats to return a semblance of peace to the forgotten kingdom.</p>
<p>GeForce NOW members will be able to stream the DLC without waiting around for downloads. Uncover the secrets of the lost tribe with an Ultimate membership for eight-hour gaming sessions and support for ultrawide resolutions.</p>
<h2><b>New Adventures</b></h2>
<figure id="attachment_71320" aria-describedby="caption-attachment-71320" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71320" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-manor-lords-tw-li-2048x1024-1-672x336.jpg" alt="Manor Lords on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-manor-lords-tw-li-2048x1024-1-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-manor-lords-tw-li-2048x1024-1-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-manor-lords-tw-li-2048x1024-1-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-manor-lords-tw-li-2048x1024-1-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-manor-lords-tw-li-2048x1024-1-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-manor-lords-tw-li-2048x1024-1-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-manor-lords-tw-li-2048x1024-1-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-manor-lords-tw-li-2048x1024-1-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-manor-lords-tw-li-2048x1024-1.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71320" class="wp-caption-text"><em>Grow from a humble hamlet to a hub for the kingdom in ‚ÄúManor Lords.‚Äù</em></figcaption></figure>
<p>Guide a medieval village as it grows into a bustling city in <i>Manor Lords</i>, streaming this week on GeForce NOW. Manage resources and production chains in this historically accurate city builder while expanding the land through large-scale tactical battles.</p>
<p>Check out the full list of new games this week:</p>
<ul>
<li><i>Dead Island 2 </i>(New release on <a href="https://store.steampowered.com/app/934700?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 22)</li>
<li><i>Bellwright </i>(New release on <a href="https://store.steampowered.com/app/1812450?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 23)</li>
<li><i>Phantom Fury </i>(New release on <a href="https://store.steampowered.com/app/1733240?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 23)</li>
<li><i>Oddsparks: An Automation Adventure </i>(New release on <a href="https://store.steampowered.com/app/1817800?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 24)</li>
<li><i>Age of Water </i>(New release on <a href="https://store.steampowered.com/app/2695490?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 25)</li>
<li><i>Manor Lords </i>(New release on <a href="https://store.steampowered.com/app/1363080?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.microsoft.com/p/manor-lords-game-preview/9p5f966564fs?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, April 26, available on PC Game Pass)</li>
<li><i>9-Bit Armies: A Bit Too Far </i>(<a href="https://store.steampowered.com/app/1439750?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Diablo II: Resurrected </i>(<a href="https://shop.battle.net/product/diablo-ii?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
<li><i>Diablo III </i>(<a href="https://shop.battle.net/product/diablo-iii?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
<li><i>Dragon‚Äôs Dogma 2 Character Creator &amp; Storage </i>(<a href="https://store.steampowered.com/app/2674810?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Islands of Insight </i>(<a href="https://store.steampowered.com/app/2071500?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Metaball </i>(<a href="https://store.steampowered.com/app/2215910?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>StarCraft Remastered </i>(<a href="https://shop.battle.net/product/starcraft-remastered?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
<li><i>StarCraft II </i>(<a href="https://shop.battle.net/product/starcraft-ii?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
<li><i>Stargate: Timekeepers </i>(<a href="https://store.steampowered.com/app/1523650?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Tortuga &#8211; A Pirate‚Äôs Tale </i>(<a href="https://store.steampowered.com/app/1604250/Tortuga__A_Pirates_Tale/">Steam</a>)<i></i></li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">The last thing in your hand is your weapon against the final boss, what item is it? <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/2694.png" alt="‚öî" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f329.png" alt="üå©" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1783163993302900757?ref_src=twsrc%5Etfw">April 24, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-thursday-4-25-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-thursday-4-25-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Blast From the Past: Stream ‚ÄòStarCraft‚Äô and ‚ÄòDiablo‚Äô on GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Into the Omniverse: Unlocking the Future of Manufacturing With OpenUSD on Siemens Teamcenter X</title>
		<link>https://blogs.nvidia.com/blog/siemens-unlocks-future-of-manufacturing-with-openusd/</link>
		
		<dc:creator><![CDATA[Madison Huang]]></dc:creator>
		<pubDate>Thu, 25 Apr 2024 13:00:28 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Into the Omniverse]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Universal Scene Description]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71325</guid>

					<description><![CDATA[OpenUSD integration into Siemens technologies powers a new wave of industrial digitalization.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><i>Editor‚Äôs note: This post is part of </i><a href="https://www.nvidia.com/en-us/omniverse/news/"><i>Into the Omniverse</i></a><i>, a series focused on how artists, developers and enterprises can transform their workflows using the latest advances in </i><a href="https://www.nvidia.com/en-us/omniverse/usd/"><i>OpenUSD</i></a><i> and </i><a href="https://www.nvidia.com/en-us/omniverse/usd/"><i>NVIDIA Omniverse</i></a><i>.</i></p>
<p><a href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description</a>, aka OpenUSD, is elevating the manufacturing game. Siemens, a leader in industrial technology, <a href="https://www.nvidia.com/en-us/industries/industrial-sector/siemens/">has embraced OpenUSD</a> as a cornerstone of its digital transformation journey, using it to help bridge the gap between physical and virtual worlds.</p>
<p>Siemens is adding support for <a href="https://blogs.nvidia.com/blog/siemens-immersive-visualization-generative-ai/">OpenUSD in its Siemens Xcelerator</a> platform applications, starting with <a href="https://plm.sw.siemens.com/en-US/teamcenter/teamcenter-x-cloud-plm/"><span>Teamcenter X software</span></a>.</p>
<p>The integration empowers manufacturers to create photorealistic, robust <a href="https://blogs.nvidia.com/blog/what-is-a-digital-twin/">digital twins</a> that mirror real-world counterparts with unprecedented fidelity and efficiency. This allows for optimized resource utilization, minimized waste and enhanced product quality through comprehensive simulation and analysis ‚Äî all of which align with sustainability and quality objectives.</p>
<p>For a company such as Siemens ‚Äî one whose software touches all parts of the manufacturing cycle ‚Äî digitalization can <span>mean helping customers save time and costs</span>, streamline workflows and reduce risk of manufacturing defects.</p>
<p>Ian Fisher, a member of <a href="https://www.sw.siemens.com/en-US/" target="_blank" rel="noopener">Siemens Digital Industries Software</a> team, is no stranger to the impact of embracing digital transformation ‚Äî especially one powered by OpenUSD and <a href="https://www.nvidia.com/en-us/glossary/generative-ai/#:~:text=Generative%20AI%20enables%20users%20to,on%20a%20variety%20of%20inputs.">generative AI</a>.</p>
<p>‚ÄúWe are an industrial company where data is king,‚Äù he said. ‚ÄúOpenUSD comes in from the media side of the world, and we are looking to bring its openness and flexibility into the industrial world.‚Äù</p>
<p>Enterprises of all sizes depend on Siemens‚Äô Teamcenter software, part of the Siemens Xcelerator platform, to develop and deliver products at scale. By connecting <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> ‚Äî a platform of APIs and services based on OpenUSD ‚Äî with Teamcenter X, Siemens‚Äô cloud-based product lifecycle management software, engineering teams can make their physics-based digital twins more photorealistic and immersive, improving accuracy and minimizing waste and errors within workflows.</p>
<p><img loading="lazy" decoding="async" class="size-full wp-image-71329 aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/ss060_comp_v01-ezgif.com-video-to-gif-converter.gif" alt="" width="600" height="360" /></p>
<p>Siemens‚Äô adoption of OpenUSD means that companies like <a href="https://blogs.nvidia.com/blog/siemens-immersive-visualization-generative-ai/">HD Hyundai</a>, a leader in sustainable ship manufacturing, can consolidate and visualize complex engineering projects directly within Teamcenter X. Find out more in the demo:</p>
<p><iframe loading="lazy" title="Siemens Teamcenter X Powered by NVIDIA Omniverse APIs" width="500" height="281" src="https://www.youtube.com/embed/rrb2tPHiLRo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>OpenUSD is touching other parts of Siemens as well. Siemens produces inverters, drive controllers and motors for more than 30,000 customers worldwide. Its lead electronics plant, <a href="https://assets.new.siemens.com/siemens/assets/api/uuid:50b2232d-7c93-4684-99af-2d532a52de9b/4681-SIE-BRO-GWE-Fly-A4-One-Pager-3_original.pdf" target="_blank" rel="noopener">GWE</a>, in Erlangen, Germany, has been developing use cases from AI-enabled computer vision for <a href="https://blogs.nvidia.com/blog/siemens-omniverse-replicator-aws-synthetic-data-generation/">defect detection</a> to training pick-and-place robots.</p>
<p>One of their main challenges has been acquiring data to train the AI models that fuel these use cases. By building custom<a href="https://blogs.nvidia.com/blog/what-is-synthetic-data/"> synthetic data generation</a> pipelines using Omniverse Replicator, powered by OpenUSD, the engineers were able to generate large sets of diverse training data by varying many parameters including color, texture, background, lighting and more ‚Äî allowing them to not only bootstrap but also quickly iterate on their AI models.</p>
<p>Committed to a future of widespread OpenUSD integration, Siemens was one of <a href="https://aousd.org/news/alliance-for-openusd-introduces-new-working-groups-and-liaison/" target="_blank" rel="noopener">eight new general members</a> that joined the <a href="https://aousd.org/" target="_blank" rel="noopener">Alliance for OpenUSD (AOUSD)</a> last month, an organization dedicated to interoperability of 3D content through standardization.</p>
<p>Watch Fisher and other special guests discuss the impact of OpenUSD on industrial digitization workflows in this livestream replay:</p>
<p><iframe loading="lazy" title="Industrial Design With OpenUSD and Generative AI" width="500" height="281" src="https://www.youtube.com/embed/y0RFntPwzvs?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<h2><b>Get Plugged Into the World of OpenUSD</b></h2>
<p>Siemens and OpenUSD took center stage this week at Hannover Messe, the world‚Äôs leading industrial trade fair. Siemens CEO Roland Busch and Rev Lebaredian, vice president of Omniverse and simulation technology at NVIDIA, <a href="https://www.linkedin.com/events/7182007244371165186/about/">shared their vision</a> on the potential of OpenUSD for customers in all industries.</p>
<p>For more on how Siemens is using OpenUSD to build and test complex AI-based automation systems completely virtually, watch the replay of the GTC session, ‚Äú<a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62338/?playlistId=playList-23a9dd33-3687-4ac8-8210-e21a79247079">Virtual Commissioning of AI Vision Systems With OpenUSD</a>.‚Äù All other sessions from GTC‚Äôs <a href="https://www.nvidia.com/en-us/on-demand/playlist/playList-68e1b334-b6b3-4195-b254-f1224f7260ea/">OpenUSD Day</a> are available for viewing on demand.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Watch <a href="https://twitter.com/BuschRo?ref_src=twsrc%5Etfw">@BuschRo</a> and <a href="https://twitter.com/RevLebaredian?ref_src=twsrc%5Etfw">@RevLebaredian</a> discuss how <a href="https://twitter.com/hashtag/digitaltwins?src=hash&amp;ref_src=twsrc%5Etfw">#digitaltwins</a>, powered by <a href="https://twitter.com/hashtag/AI?src=hash&amp;ref_src=twsrc%5Etfw">#AI</a> and <a href="https://twitter.com/hashtag/OpenUSD?src=hash&amp;ref_src=twsrc%5Etfw">#OpenUSD</a>, can drive productivity across all industries at <a href="https://twitter.com/hashtag/HM24?src=hash&amp;ref_src=twsrc%5Etfw">#HM24</a>.</p>
<p>&mdash; NVIDIA Design &amp; Visualization (@NVIDIADesign) <a href="https://twitter.com/NVIDIADesign/status/1782434184474042615?ref_src=twsrc%5Etfw">April 22, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p><i>Get started with NVIDIA Omniverse by downloading the standard license </i><a href="https://www.nvidia.com/en-us/omniverse/download/"><i>free</i></a><i>, access </i><a href="https://developer.nvidia.com/usd"><i>OpenUSD</i></a><i> resources and learn how </i><a href="https://www.nvidia.com/en-us/omniverse/enterprise/"><i>Omniverse Enterprise</i><i> can connect team</i></a><i>s. Follow Omniverse on </i><a href="https://www.instagram.com/nvidiaomniverse/"><i>Instagram</i></a><i>, </i><a href="https://medium.com/@nvidiaomniverse"><i>Medium</i></a><i> and </i><a href="https://twitter.com/nvidiaomniverse"><i>X</i></a><i>. For more, join the </i><a href="https://www.nvidia.com/en-us/omniverse/community/"><i>Omniverse community</i></a><i> on the </i><a href="https://forums.developer.nvidia.com/c/omniverse/300"><i>forums</i></a><i>, </i><a href="https://discord.com/invite/XWQNJDNuaC"><i>Discord server</i></a><i>, </i><a href="https://www.twitch.tv/nvidiaomniverse"><i>Twitch</i></a><i> and </i><a href="https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA"><i>YouTube</i></a><i> channels.¬†</i></p>
<p><i>Featured image courtesy of Siemens, HD Hyundai.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/nv-ov-ito-1280x680_april2024_v2.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/nv-ov-ito-1280x680_april2024_v2-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Into the Omniverse: Unlocking the Future of Manufacturing With OpenUSD on Siemens Teamcenter X]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>How Virtual Factories Are Making Industrial Digitalization a Reality</title>
		<link>https://blogs.nvidia.com/blog/virtual-factories-industrial-digitalization/</link>
		
		<dc:creator><![CDATA[James McKenna]]></dc:creator>
		<pubDate>Wed, 24 Apr 2024 15:00:40 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[Digital Twin]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Retail]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71266</guid>

					<description><![CDATA[To address the shift to electric vehicles, increased semiconductor demand, manufacturing onshoring, and ambitions for greater sustainability, manufacturers are investing in new factory developments and re-engineering their existing facilities. These projects often run over budget and schedule, due to complex and manual planning processes, legacy technology infrastructure, and disconnected tools, data and teams. To address		<a class="read-more" href="https://blogs.nvidia.com/blog/virtual-factories-industrial-digitalization/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>To address the shift to electric vehicles, increased semiconductor demand, manufacturing onshoring, and ambitions for greater sustainability, manufacturers are investing in new factory developments and re-engineering their existing facilities.</p>
<p>These projects often run over budget and schedule, due to complex and manual planning processes, legacy technology infrastructure, and disconnected tools, data and teams.</p>
<p>To address these challenges, manufacturers are embracing digitalization and virtual factories, powered by technologies like <a href="https://blogs.nvidia.com/blog/what-is-a-digital-twin/">digital twins,</a> the <a href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description (OpenUSD)</a><a href="https://blogs.nvidia.com/blog/what-is-a-digital-twin/"> ecosystem</a> and <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a>, that enable new possibilities from planning to operations.</p>
<h2>What Is a Virtual Factory?</h2>
<p>A virtual factory is a physically accurate representation of a real factory. These digital twins of factories allow manufacturers to model, simulate, analyze and optimize their production processes, resources and operations without the need for a physical prototype or pilot plant.</p>
<h2>Benefits of Virtual Factories</h2>
<p>Virtual factories unlock many benefits and possibilities for manufacturers, including:</p>
<ul>
<li><b>Streamlined Communication: </b>Instead of teams relying on in-person meetings and static planning documents for project alignment, virtual factories streamline communication and ensure that critical design and operations decisions are informed by the most current data.</li>
<li><b>Contextualized Planning</b>: During facility design, construction and commissioning, virtual factories allow project stakeholders to visualize designs in the context of the entire facility and production process. Planning and operations teams can compare and verify built structures with the virtual designs in real time and decrease costs by identifying errors and incorporating feedback early in the review process.</li>
<li><b>Optimized Facility Designs: </b>Connecting virtual factories to simulations of processes and discrete events enables teams to optimize facility designs for production and material flow, ergonomic work design, safety and overall utilization.</li>
<li><b>Intelligent and Optimized Operations: </b>Operations teams can integrate their virtual factories with valuable production data from Internet of Things technology at the <a href="https://blogs.nvidia.com/blog/what-is-edge-computing/">edge</a>, and tap AI to drive further optimizations.</li>
</ul>
<h2>Virtual Factories: A Testing Ground for AI and Robotics</h2>
<p>Robotics developers are increasingly using virtual factories to train and test AI and autonomous systems that run in physical factories. For example, virtual factories can enable developers and manufacturing teams to simulate digital workers and <a href="https://blogs.nvidia.com/blog/isaac-amr-nova-orin-autonomous-mobile-robots/">autonomous mobile robots</a> (AMRs), vision AI agents and sensors to create a centralized map of worker activity throughout a facility. By fusing data from simulated camera streams with multi-camera tracking, developers can generate occupancy maps that inform optimal AMR routes.</p>
<p>Developers can also use these physically accurate virtual factories to train and test AI agents capable of managing their robot fleets, to ensure AI-enabled robots can adapt to real-world unpredictability and to identify streamlined configurations for human-robot collaboration.</p>
<p><iframe loading="lazy" title="Fusing Real-Time AI With Digital Twins" width="500" height="281" src="https://www.youtube.com/embed/l5M4sqaRd6w?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<h2>What Are the Foundations of a Virtual Factory</h2>
<p>Building large-scale, physically accurate virtual factories that unlock these transformational possibilities requires bringing together many tools, data formats and technologies to harmonize the representation of real-world aspects in the digital world.</p>
<p>Originally invented by Pixar Animation Studios, <a href="https://www.nvidia.com/en-us/omniverse/usd/">OpenUSD</a> encompasses a collection of tools and capabilities that enable the data interoperability developers and manufacturers require to achieve their digitalization goals.</p>
<p>OpenUSD‚Äôs core superpower is flexible data modeling. 3D input can be accepted from source applications and combined with a variety of data, including from computer-aided design software, live sensors, documentation and maintenance records, through a unified data pipeline. OpenUSD enables developers to share these data types across different simulation tools and AI models, providing insights for all stakeholders. Data can be synced from the factory floor to the digital twin, surfacing real-time insights for factory managers and teams.</p>
<p>By developing virtual factory solutions on OpenUSD, developers can enhance collaboration for factory teams, allowing them to review plans, discuss optimization opportunities and make decisions in real time.</p>
<p>To support and accelerate the development of the OpenUSD ecosystem, Pixar, Adobe, Apple, Autodesk and NVIDIA formed the <a href="https://aousd.org/">Alliance for OpenUSD</a>, which is building open standards for USD in core specification, materials, geometry and more.</p>
<h2>Industrial Use Cases for Virtual Factories</h2>
<p>To unlock the potential of virtual factories, industry leaders including Autodesk, Continental, Pegatron, Rockwell Automation, Siemens and Wistron are developing virtual-factory solutions that interoperate with OpenUSD and <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, a platform of application programming interfaces (APIs) and software development kits that enable developers to build applications for complex 3D and industrial digitalization workflows based on OpenUSD.</p>
<p><a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62639/">FlexSim</a>, an Autodesk company, uses OpenUSD to enable factory teams to analyze, visualize and optimize real-world processes with its simulation modeling for complex systems and operations. The discrete-event simulation software provides an intuitive drag-and-drop interface to create 3D simulation models, account for real-world variability, run ‚Äúwhat-if‚Äù scenarios and perform in-depth analyses.</p>
<p>Developers at <a href="https://www.continental.com/en/" target="_blank" rel="noopener">Continental</a>, a leading German automotive technology company, developed <a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62919/">ContiVerse</a>, a factory planning and manufacturing operations application on OpenUSD and NVIDIA Omniverse. The application helps Continental optimize factory layouts and plan production processes collaboratively, leading to an expected 13% reduction in time to market.<a href="https://www.pegatroncorp.com/">¬†</a></p>
<p>Partnering with IT consulting and digital services provider <a href="https://www.softserveinc.com/en-us">SoftServe</a>, Continental also developed <a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s61799/">Industrial Co-Pilot</a>, which combines AI-driven insights with immersive visualization to deliver real-time guidance and predictive analytics to engineers. This is expected to reduce maintenance effort and downtime by 10%.</p>
<p><a href="https://www.pegatroncorp.com/" target="_blank" rel="noopener">Pegatron</a>, one of the world‚Äôs largest manufacturers of smartphones and consumer electronics, is <a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62553/">developing virtual-factory solutions</a> on OpenUSD to accelerate the development of new factories ‚Äî as well as to minimize change orders, optimize operations and maximize production-line throughput in existing facilities.</p>
<p><a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62623/">Rockwell Automation</a> is integrating NVIDIA Omniverse Cloud APIs and OpenUSD with its <a href="https://www.demo3d.com/">Emulate3D</a> digital twin software to bring manufacturing teams data interoperability, live collaboration and physically based visualization for designing, building and operating industrial-scale digital twins of production systems.</p>
<p><a href="https://www.siemens.com/global/en.html" target="_blank" rel="noopener">Siemens</a>, a leading technology company for automation, digitalization and sustainability and a member of the Alliance for OpenUSD, is adopting Omniverse Cloud APIs within its Siemens Xcelerator Platform, starting with Teamcenter X, the industry-leading cloud-based product lifecycle management software. This will help teams design, build and test next-generation products, manufacturing processes and factories virtually, before they‚Äôre built in the physical world.</p>
<p><a href="https://www.wistron.com/en" target="_blank" rel="noopener">Wistron</a>, a leading global technology service provider and electronics manufacturer, is <a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62600/">digitalizing new and existing factories</a> with OpenUSD. By developing virtual-factory solutions on NVIDIA Omniverse, Wistron enables its factory teams to collaborate remotely to refine layout configurations, optimize surface mount technology and in-circuit testing lines, and transform product-on-dock testing.</p>
<p>With these solutions, Wistron has achieved a 51% boost in worker efficiency and 50% reduction in production process times. Layout optimization and real-time monitoring have decreased defect rates by 40%. And construction time on Wistron‚Äôs new <a href="https://www.nvidia.com/en-us/data-center/dgx-platform/">NVIDIA DGX</a> factory was cut in half, from about five months to just two and a half months.</p>
<p><iframe loading="lazy" title="Meet a Factory Digital Twin From Wistron" width="500" height="281" src="https://www.youtube.com/embed/OAdqXZGUb70?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Learn more about developing advanced, generative AI-enabled virtual factory solutions at the <a href="https://www.nvidia.com/en-us/use-cases/ai-for-virtual-factory-solutions/">Virtual Factory Use Case page</a>. Developers can get started with <a href="https://developer.nvidia.com/blog/developing-virtual-factory-solutions-with-openusd-and-nvidia-omniverse/">a reference architecture</a> that provides an overview of components and capabilities to consider when developing virtual-factory solutions.</p>
<p><i>Get started with NVIDIA Omniverse by downloading the standard license </i><a href="https://www.nvidia.com/en-us/omniverse/download/"><i>free</i></a><i>, access </i><a href="https://developer.nvidia.com/usd"><i>OpenUSD</i></a><i> resources, and learn how </i><a href="https://www.nvidia.com/en-us/omniverse/enterprise/"><i>Omniverse Enterprise</i><i> can connect your team</i></a><i>. Stay up to date on </i><a href="https://www.instagram.com/nvidiaomniverse/"><i>Instagram</i></a><i>, </i><a href="https://medium.com/@nvidiaomniverse"><i>Medium</i></a><i> and </i><a href="https://twitter.com/nvidiaomniverse"><i>X</i></a><i>. For more, join the </i><a href="https://www.nvidia.com/en-us/omniverse/community/"><i>Omniverse community</i></a><i> on the </i><a href="https://forums.developer.nvidia.com/c/omniverse/300"><i>forums</i></a><i>, </i><a href="https://discord.com/invite/XWQNJDNuaC"><i>Discord server</i></a><i>, </i><a href="https://www.twitch.tv/nvidiaomniverse"><i>Twitch</i></a><i> and </i><a href="https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA"><i>YouTube</i></a><i> channels.¬†</i></p>
<p><em>Featured visual courtesy of Siemens.</em></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/vfi-blog.jpg"
			type="image/jpeg"
			width="1920"
			height="1020"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/vfi-blog-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[How Virtual Factories Are Making Industrial Digitalization a Reality]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA to Acquire GPU Orchestration Software Provider Run:ai</title>
		<link>https://blogs.nvidia.com/blog/runai/</link>
		
		<dc:creator><![CDATA[Alexis Bjorlin]]></dc:creator>
		<pubDate>Wed, 24 Apr 2024 13:15:08 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Software]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71285</guid>

					<description><![CDATA[To help customers make more efficient use of their AI computing resources, NVIDIA today announced it has entered into a definitive agreement to acquire Run:ai, a Kubernetes-based workload management and orchestration software provider. Customer AI deployments are becoming increasingly complex, with workloads distributed across cloud, edge and on-premises data center infrastructure. Managing and orchestrating generative		<a class="read-more" href="https://blogs.nvidia.com/blog/runai/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>To help customers make more efficient use of their AI computing resources, NVIDIA today announced it has entered into a definitive agreement to acquire Run:ai, a Kubernetes-based workload management and orchestration software provider.</p>
<p>Customer AI deployments are becoming increasingly complex, with workloads distributed across cloud, edge and on-premises data center infrastructure.</p>
<p>Managing and orchestrating generative AI, recommender systems, search engines and other workloads requires sophisticated scheduling to optimize performance at the system level and on the underlying infrastructure.</p>
<p>Run:ai enables enterprise customers to manage and optimize their compute infrastructure, whether on premises, in the cloud or in hybrid environments.</p>
<p>The company has built an open platform on <a href="https://www.nvidia.com/en-us/glossary/kubernetes/">Kubernetes</a>, the orchestration layer for modern AI and cloud infrastructure. It supports all popular Kubernetes variants and integrates with third-party AI tools and frameworks.</p>
<p>Run:ai customers include some of the world‚Äôs largest enterprises across multiple industries, which use the Run:ai platform to manage data-center-scale GPU clusters.</p>
<p>‚ÄúRun:ai has been a close collaborator with NVIDIA since 2020 and we share a passion for helping our customers make the most of their infrastructure,‚Äù said Omri Geller, Run:ai cofounder and CEO. ‚ÄúWe‚Äôre thrilled to join NVIDIA and look forward to continuing our journey together.‚Äù</p>
<p>The Run:ai platform provides AI developers and their teams:</p>
<ul>
<li style="font-weight: 400;" aria-level="1">A centralized interface to manage shared compute infrastructure, enabling easier and faster access for complex AI workloads.</li>
<li style="font-weight: 400;" aria-level="1">Functionality to add users, curate them under teams, provide access to cluster resources, control over quotas, priorities and pools, and monitor and report on resource use.</li>
<li style="font-weight: 400;" aria-level="1">The ability to pool GPUs and share computing power ‚Äî from <a href="https://www.nvidia.com/en-us/technologies/multi-instance-gpu/#:~:text=Multi%2DInstance%20GPU%20(MIG)%20expands%20the%20performance%20and%20value,%2C%20cache%2C%20and%20compute%20cores.">fractions of GPUs</a> to multiple GPUs or multiple nodes of GPUs running on different clusters ‚Äî for separate tasks.</li>
<li style="font-weight: 400;" aria-level="1">Efficient GPU cluster resource utilization, enabling customers to gain more from their compute investments.</li>
</ul>
<p>NVIDIA will continue to offer Run:ai&#8217;s products under the same business model for the immediate future. And NVIDIA will continue to invest in the Run:ai product roadmap, including enabling on <a href="http://www.nvidia.com/dgx-cloud">NVIDIA DGX Cloud</a>, an AI platform co-engineered with leading clouds for enterprise developers, offering an integrated, full-stack service optimized for generative AI.</p>
<p>NVIDIA HGX, DGX and DGX Cloud customers will gain access to Run:ai&#8217;s capabilities for their AI workloads, particularly for large language model deployments. Run:ai&#8217;s solutions are already integrated with <a href="https://www.nvidia.com/en-us/data-center/dgx-platform/">NVIDIA DGX</a>, <a href="https://www.nvidia.com/en-us/data-center/dgx-superpod/">NVIDIA DGX SuperPOD</a>, <a href="https://www.nvidia.com/en-us/data-center/base-command/">NVIDIA Base Command</a>, <a href="https://www.nvidia.com/en-us/gpu-cloud/">NGC</a> containers, and <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> software, among other products.</p>
<p>NVIDIA‚Äôs accelerated computing platform and Run:ai&#8217;s platform will continue to support a broad ecosystem of third-party solutions, giving customers choice and flexibility.</p>
<p>Together with Run:ai, NVIDIA will enable customers to have a single fabric that accesses GPU solutions anywhere. Customers can expect to benefit from better GPU utilization, improved management of GPU infrastructure and greater flexibility from the open architecture.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/nvidia-ravioli.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/nvidia-ravioli-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA to Acquire GPU Orchestration Software Provider Run:ai]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Forecasting the Future: AI2‚Äôs Christopher Bretherton Discusses Using Machine Learning for Climate Modeling</title>
		<link>https://blogs.nvidia.com/blog/ai2s-christopher-bretherton/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Wed, 24 Apr 2024 13:00:13 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[The AI Podcast]]></category>
		<category><![CDATA[Climate]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71293</guid>

					<description><![CDATA[Can machine learning help predict extreme weather events and climate change? Christopher Bretherton, senior director of climate modeling at the Allen Institute for Artificial Intelligence, or AI2, explores the technology‚Äôs potential to enhance climate modeling with AI Podcast host Noah Kravitz in an episode recorded live at the NVIDIA GTC global AI conference. Bretherton explains		<a class="read-more" href="https://blogs.nvidia.com/blog/ai2s-christopher-bretherton/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Can machine learning help predict extreme weather events and climate change? Christopher Bretherton, senior director of climate modeling at the Allen Institute for Artificial Intelligence, or AI2, explores the technology‚Äôs potential to enhance climate modeling with <a href="https://soundcloud.com/theaipodcast">AI Podcast</a> host Noah Kravitz in an episode recorded live at the <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a> global AI conference. Bretherton explains how machine learning helps overcome the limitations of traditional climate models and underscores the role of localized predictions in empowering communities to prepare for climate-related risks. Through ongoing research and collaboration, Bretherton and his team aim to improve climate modeling and enable society to better mitigate and adapt to the impacts of climate change.</p>
<p>Stay tuned for more episodes recorded live from GTC, and watch the replay of Bretherton‚Äôs <a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62359/">GTC session</a> on using machine learning for climate modeling.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1806553098%3Fsecret_token%3Ds-EFTMFbquHt4&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> ¬∑ <a style="color: #cccccc; text-decoration: none;" title="AI2‚Äôs Christopher Bretherton Discusses Using Machine Learning for Climate Modeling - Ep. XXX" href="https://soundcloud.com/theaipodcast/christopher-bretherton/s-EFTMFbquHt4" target="_blank" rel="noopener">AI2‚Äôs Christopher Bretherton Discusses Using Machine Learning for Climate Modeling &#8211; Ep. XXX</a></div>
<h2><b>Time Stamps</b></h2>
<p>2:03: What is climate modeling and how can it prepare us for climate change?</p>
<p>5:28: How can machine learning help enhance climate modeling?</p>
<p>7:21: What were the limitations of traditional climate models?</p>
<p>10:24: How does a climate model work?</p>
<p>12:11: What information can you get from a climate model?</p>
<p>13:26: What are the current climate models telling us about the future?</p>
<p>15:56: How does machine learning help enable localized climate modeling?</p>
<p>18:39: What, if anything, can individuals or small communities do to prepare for what climate change has in store for us?</p>
<p>25:59: How do you measure the accuracy or performance of an emulator that‚Äôs doing something like climate modeling out into the future?</p>
<h2><b>You Might Also Like‚Ä¶</b></h2>
<p><a href="https://soundcloud.com/theaipodcast/ai-daniel-castro-itif"><b>ITIF‚Äôs Daniel Castro on Energy-Efficient AI and Climate Change &#8211; Ep. 215</b><b><br />
</b><br />
</a>AI-driven change is in the air, as are concerns about the technology‚Äôs environmental impact. In this episode of NVIDIA‚Äôs AI Podcast, Daniel Castro, vice president of the Information Technology and Innovation Foundation and director of its Center for Data Innovation, speaks with host Noah Kravitz about the motivation behind his AI energy use report, which addresses misconceptions about the technology‚Äôs energy consumption.</p>
<p><a href="https://soundcloud.com/theaipodcast/ai-wildfire"><b>DigitalPath‚Äôs Ethan Higgins on Using AI to Fight Wildfires &#8211; Ep. 211</b></a></p>
<p>DigitalPath is igniting change in the golden state ‚Äî using computer vision, generative adversarial networks and a network of thousands of cameras to detect signs of fire in real-time. In the latest episode of NVIDIA‚Äôs AI Podcast, host Noah Kravtiz spoke with DigitalPath system architect Ethan Higgins about the company‚Äôs role in the ALERTCalifornia initiative, a collaboration between California‚Äôs wildfire fighting agency CAL FIRE and the University of California, San Diego.</p>
<p><a href="https://soundcloud.com/theaipodcast/anima-anandkumar"><b>Anima Anandkumar on Using Generative AI to Tackle Global Challenges &#8211; Ep. 203</b></a></p>
<p>Generative AI-based models can not only learn and understand natural languages ‚Äî they can learn the very language of nature itself, presenting new possibilities for scientific research. On the latest episode of NVIDIA‚Äôs AI Podcast, host Noah Kravitz spoke with Anandkumar on generative AI‚Äôs potential to make splashes in the scientific community.</p>
<p><a href="https://soundcloud.com/theaipodcast/ai-alex-fielding"><b>How Alex Fielding and Privateer Space Are Taking on Space Debris &#8211; Ep. 196</b></a></p>
<p>In this episode of the NVIDIA AI Podcast, host Noah Kravitz dives into an illuminating conversation with Alex Fielding, co-founder and CEO of Privateer Space. Privateer Space, Fielding‚Äôs latest venture, aims to address one of the most daunting challenges facing our world today: space debris.</p>
<h2><b>Subscribe to the AI Podcast</b></h2>
<p>Get the<a href="https://blogs.nvidia.com/ai-podcast/"> AI Podcast</a> through<a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439"> iTunes</a>,<a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjI2NDAzNDEzMy9zb3VuZHMucnNz"> Google Podcasts</a>,<a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm"> Google Play</a>, <a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">Amazon Music, </a><a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us">Castbox</a>, DoggCatcher,<a href="https://overcast.fm/itunes1186480811/the-ai-podcast"> Overcast</a>,<a href="https://player.fm/series/the-ai-podcast"> PlayerFM</a>, Pocket Casts,<a href="http://www.podbay.fm/show/1186480811"> Podbay</a>,<a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast"> PodBean</a>, PodCruncher, PodKicker,<a href="https://soundcloud.com/theaipodcast"> Soundcloud</a>,<a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L"> Spotify</a>,<a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr"> Stitcher</a> and<a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/"> TuneIn</a>.</p>
<p>Make the AI Podcast better: Have a few minutes to spare? Fill out<a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short"> this listener survey</a>.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2021/08/ai-podcast-2600x1472_-1-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1159"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2021/08/ai-podcast-2600x1472_-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Forecasting the Future: AI2‚Äôs Christopher Bretherton Discusses Using Machine Learning for Climate Modeling]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Rays Up: Decoding AI-Powered DLSS 3.5 Ray Reconstruction</title>
		<link>https://blogs.nvidia.com/blog/ai-decoded-ray-reconstruction/</link>
		
		<dc:creator><![CDATA[Henry Lin]]></dc:creator>
		<pubDate>Wed, 24 Apr 2024 13:00:12 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[AI Decoded]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71272</guid>

					<description><![CDATA[DLSS 3.5 with Ray Reconstruction creates higher quality ray-traced images for intensive ray-traced games and apps.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><i>Editor‚Äôs note: This post is part of the </i><a href="https://blogs.nvidia.com/blog/tag/ai-decoded/"><i>AI Decoded series</i></a><i>, which demystifies AI by making the technology more accessible, and which showcases new hardware, software, tools and accelerations for RTX PC users.</i></p>
<p>AI continues to raise the bar for PC gaming.</p>
<p><a href="https://www.nvidia.com/en-us/geforce/news/nvidia-dlss-3-5-ray-reconstruction/">DLSS 3.5 with Ray Reconstruction</a> creates higher quality ray-traced images for intensive ray-traced games and apps. This advanced AI-powered neural renderer is a groundbreaking feature that elevates ray-traced image quality for all GeForce RTX GPUs, outclassing traditional hand-tuned denoisers by using an AI network trained by an NVIDIA supercomputer. The result improves lighting effects like reflections, global illumination, and shadows to create a more immersive, realistic gaming experience.</p>
<h2><b>A Ray of Light</b></h2>
<p>Ray tracing is a rendering technique that can realistically simulate the lighting of a scene and its objects by rendering physically accurate reflections, refractions, shadows and indirect lighting. Ray tracing generates computer graphics images by tracing the path of light from the view camera ‚Äî which determines the view into the scene ‚Äî through the 2D viewing plane, out into the 3D scene, and back to the light sources. For instance, if rays strike a mirror, reflections are generated.</p>
<figure id="attachment_71276" aria-describedby="caption-attachment-71276" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/04/ray-tracing-image-1.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-71276" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/ray-tracing-image-1-672x442.jpg" alt="" width="672" height="442" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/ray-tracing-image-1-672x442.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/04/ray-tracing-image-1-400x263.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/ray-tracing-image-1-768x505.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/ray-tracing-image-1-684x450.jpg 684w, https://blogs.nvidia.com/wp-content/uploads/2024/04/ray-tracing-image-1-327x215.jpg 327w, https://blogs.nvidia.com/wp-content/uploads/2024/04/ray-tracing-image-1-152x100.jpg 152w, https://blogs.nvidia.com/wp-content/uploads/2024/04/ray-tracing-image-1.jpg 1063w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71276" class="wp-caption-text">A visualization of how ray tracing works.</figcaption></figure>
<p>It‚Äôs the digital equivalent to real-world objects illuminated by beams of light and the path of the light being followed from the eye of the viewer to the objects that light interacts with. That‚Äôs ray tracing.</p>
<p>Simulating light in this manner ‚Äî shooting rays for every pixel on the screen ‚Äî is computationally intensive, even for offline renderers that calculate scenes over the course of several minutes or hours. Instead, ray samples fire a handful of rays at various points across the scene for a representative sample of the scene‚Äôs lighting, reflectivity and shadowing.</p>
<p>However, there are limitations. The output is a noisy, speckled image with gaps, good enough to ascertain how the scene should look when ray traced. To fill in the missing pixels that weren‚Äôt ray traced, hand-tuned denoisers use two different methods, temporally accumulating pixels across multiple frames, and spatially interpolating them to blend neighboring pixels together. Through this process, the noisy raw output is converted into a ray-traced image.</p>
<p>This adds complexity and cost to the development process, and reduces the frame rate in highly ray-traced games where multiple denoisers operate simultaneously for different lighting effects.</p>
<p>DLSS 3.5 Ray Reconstruction introduces an NVIDIA supercomputer-trained, AI-powered neural network that generates higher-quality pixels in between the sampled rays. It recognizes different ray-traced effects to make smarter decisions about using temporal and spatial data, and retains high frequency information for superior-quality upscaling. And it recognizes lighting patterns from its training data, such as that of global illumination or ambient occlusion, and recreates it in-game.</p>
<p><iframe loading="lazy" title="Portal with RTX | DLSS 3.5 with Ray Reconstruction Comparison - Fan Scene" width="500" height="281" src="https://www.youtube.com/embed/Gg_3-X3d3iY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p><i>Portal with RTX</i> is a great example of Ray Reconstruction in action. With DLSS OFF, the denoiser struggles to reconstruct the dynamic shadowing alongside the moving fan.</p>
<p>With DLSS 3.5 and Ray Reconstruction enabled, the denoiser is trained on AI and recognizes certain patterns associated with shadows and keeps the image stable, accumulating accurate pixels while blending neighboring pixels to generate high-quality reflections.</p>
<h2><b>Deep Learning, Deep Gaming</b></h2>
<p>Ray Reconstruction is just one of the AI graphics breakthroughs that multiply performance in DLSS. Super Resolution, the cornerstone of DLSS, samples multiple lower resolution images and uses motion data and feedback from prior frames to reconstruct native-quality images. The result is high image quality without sacrificing game performance.</p>
<p><iframe loading="lazy" title="NVIDIA DLSS 3 | AI-Powered Performance In Your Favorite Games &amp; Apps" width="500" height="281" src="https://www.youtube.com/embed/GKpURmnNMoA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>DLSS 3 introduced Frame Generation, which boosts performance by using AI to analyze data from surrounding frames to predict what the next generated frame should look like. These generated frames are then inserted in between rendered frames. Combining the DLSS-generated frames with DLSS Super Resolution enables DLSS 3 to reconstruct seven-eighths of the displayed pixels with AI, boosting frame rates by up to 4x compared to without DLSS.</p>
<p>Because DLSS Frame Generation is post-processed (applied after the main render) on the GPU, it can boost frame rates even when the game is bottlenecked by the CPU.</p>
<p><i>Generative AI is transforming gaming, videoconferencing and interactive experiences of all kinds. Make sense of what‚Äôs new and what‚Äôs next by subscribing to the </i><a href="https://www.nvidia.com/en-us/ai-on-rtx/?modal=subscribe-ai"><i>AI Decoded newsletter</i></a><i>.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/dlss-ray-reconstruction-nv-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/dlss-ray-reconstruction-nv-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Rays Up: Decoding AI-Powered DLSS 3.5 Ray Reconstruction]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Small and Mighty: NVIDIA Accelerates Microsoft‚Äôs Open Phi-3 Mini Language Models</title>
		<link>https://blogs.nvidia.com/blog/microsoft-open-phi-3-mini-language-models/</link>
		
		<dc:creator><![CDATA[Ankit Patel]]></dc:creator>
		<pubDate>Tue, 23 Apr 2024 17:08:23 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[TensorRT]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71258</guid>

					<description><![CDATA[NVIDIA announced today its acceleration of Microsoft‚Äôs new Phi-3 Mini open language model with NVIDIA TensorRT-LLM, an open-source library for optimizing large language model inference when running on NVIDIA GPUs from PC to Cloud. Phi-3 Mini packs the capability of 10x larger models and is licensed for both research and broad commercial usage, advancing Phi-2		<a class="read-more" href="https://blogs.nvidia.com/blog/microsoft-open-phi-3-mini-language-models/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>NVIDIA announced today its acceleration of Microsoft‚Äôs new Phi-3 Mini open language model with <a href="https://github.com/NVIDIA/TensorRT-LLM/tree/main">NVIDIA TensorRT-LLM</a>, an open-source library for optimizing large language model inference when running on NVIDIA GPUs from PC to Cloud.</p>
<p>Phi-3 Mini packs the capability of 10x larger models and is licensed for both research and broad commercial usage, advancing Phi-2 from its research-only roots. Workstations with NVIDIA RTX GPUs or PCs with <a href="https://www.nvidia.com/en-us/geforce/buy/">GeForce RTX GPUs</a> have the performance to run the model locally using Windows DirectML with <a href="http://aka.ms/phi3-optimizations">ONNX Runtime</a> or TensorRT-LLM.</p>
<p>The model has 3.8 billion parameters and was trained on 3.3 trillion tokens in only seven days on 512 NVIDIA H100 Tensor Core GPUs.</p>
<p>Phi-3 Mini has two variants, with one supporting 4k tokens and the other supporting 128K tokens and that is the first model in its class for very long contexts. This allows developers to use 128,000 tokens ‚Äî the atomic parts of language that the model processes ‚Äî when asking the model a question, which results in more relevant responses from the model.</p>
<p>Developers can try Phi-3 Mini with the 128K context window at <a href="http://ai.nvidia.com">ai.nvidia.com</a>, where it is packaged as an NVIDIA NIM, a microservice with a standard application programming interface that can be deployed anywhere.</p>
<h2><b>Creating Efficiency for the Edge </b></h2>
<p>Developers working on autonomous robotics and embedded devices can learn to create and deploy generative AI through community-driven tutorials, like on <a href="https://www.jetson-ai-lab.com/">Jetson AI Lab</a>, and deploy Phi-3 on <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/">NVIDIA Jetson</a>.</p>
<p>With only 3.8 billion parameters, the Phi-3 Mini model is compact enough to run efficiently on edge devices. Parameters are like knobs, in memory, that have been precisely tuned during the model training process so that the model can respond with high accuracy to input prompts.</p>
<p>Phi-3 can assist in cost- and resource-constrained use cases, especially for simpler tasks. The model can outperform some larger models on key language benchmarks while delivering results within latency requirements.</p>
<p>TensorRT-LLM will support Phi-3 Mini‚Äôs long context window and uses many optimizations and kernels such as <a href="https://arxiv.org/html/2402.13753v1#S1">LongRoPE</a>, FP8 and inflight batching, which improve inference throughput and latency. The TensorRT-LLM implementations will soon be available in the examples folder on <a href="https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples">GitHub</a>. There, developers can convert to the TensorRT-LLM checkpoint format, which is optimized for inference and can be easily deployed with <a href="https://github.com/triton-inference-server/server">NVIDIA Triton Inference Server</a>.</p>
<h2><b>Developing Open Systems</b></h2>
<p>NVIDIA is an active contributor to the open-source ecosystem and has released over 500 projects under open-source licenses.</p>
<p>Contributing to many external projects such as JAX, Kubernetes, OpenUSD, PyTorch and the Linux kernel, NVIDIA supports a wide variety of open-source foundations and standards bodies as well.</p>
<p>Today‚Äôs news expands on long-standing NVIDIA collaborations with Microsoft, which have paved the way for innovations including accelerating <a href="https://onnxruntime.ai/blogs">DirectML</a>, Azure cloud, generative AI research, and healthcare and life sciences.</p>
<p><a href="https://nvidianews.nvidia.com/news/microsoft-nvidia-generative-ai-enterprises"><i>Learn more</i></a><i> about our recent collaboration. </i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/partner-blog-microsoft-promo-1260x680-1.png"
			type="image/png"
			width="1260"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/partner-blog-microsoft-promo-1260x680-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Small and Mighty: NVIDIA Accelerates Microsoft‚Äôs Open Phi-3 Mini Language Models]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Climate Tech Startups Integrate NVIDIA AI for Sustainability Applications</title>
		<link>https://blogs.nvidia.com/blog/earth-day-2024-climate-tech-ai-startups/</link>
		
		<dc:creator><![CDATA[Tenika Versey Walker]]></dc:creator>
		<pubDate>Mon, 22 Apr 2024 15:00:12 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Agriculture and Food]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Climate]]></category>
		<category><![CDATA[Digital Twin]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Scientific Visualization]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71220</guid>

					<description><![CDATA[Whether they‚Äôre monitoring miniscule insects or delivering insights from satellites in space, NVIDIA-accelerated startups are making every day Earth Day. Sustainable Futures, an initiative within the NVIDIA Inception program for cutting-edge startups, is supporting 750+ companies globally focused on agriculture, carbon capture, clean energy, climate and weather, environmental analysis, green computing, sustainable infrastructure and waste		<a class="read-more" href="https://blogs.nvidia.com/blog/earth-day-2024-climate-tech-ai-startups/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Whether they‚Äôre monitoring miniscule insects or delivering insights from satellites in space, NVIDIA-accelerated startups are making every day Earth Day.</p>
<p>Sustainable Futures, an initiative within the <a href="https://www.nvidia.com/startups/?nvid=nv-int-tblg-295718-vt33">NVIDIA Inception</a> program for cutting-edge startups, is supporting 750+ companies globally focused on agriculture, carbon capture, clean energy, climate and weather, environmental analysis, green computing, sustainable infrastructure and waste management.</p>
<p>This Earth Day, discover how five of these sustainability-focused startups are advancing their work with accelerated computing and the <a href="https://www.nvidia.com/en-us/high-performance-computing/earth-2/">NVIDIA Earth-2</a> platform for climate tech.</p>
<p>Earth-2 features a suite of AI models that help simulate, visualize and deliver actionable insights about weather and climate.</p>
<h2><b>Insect Farming Catches the AI Bug</b></h2>
<figure id="attachment_71240" aria-describedby="caption-attachment-71240" style="width: 400px" class="wp-caption alignright"><img loading="lazy" decoding="async" class="wp-image-71240 size-medium" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/Bug-Mars-2-400x400.png" alt="" width="400" height="400" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/Bug-Mars-2-400x400.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Bug-Mars-2-500x500.png 500w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Bug-Mars-2-150x150.png 150w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Bug-Mars-2-768x768.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Bug-Mars-2-450x450.png 450w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Bug-Mars-2-215x215.png 215w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Bug-Mars-2-100x100.png 100w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Bug-Mars-2.png 1024w" sizes="(max-width: 400px) 100vw, 400px" /><figcaption id="caption-attachment-71240" class="wp-caption-text">Image courtesy of Bug Mars</figcaption></figure>
<p>Amid a changing climate, a key component of environmental resilience is food security: the ability to produce and provide enough food to meet the nutrition needs of all people. Edible insects, such as crickets and black soldier flies, are one solution that could reduce humans‚Äô reliance on resource-intensive livestock farming for protein.</p>
<p><a href="https://bugmars.com/" target="_blank" rel="noopener">Bug Mars</a>, a startup based in Ontario, Canada, supports insect protein production with AI tools that monitor variables including temperature, pests and number of insects ‚Äî and predict issues and recommend actions based on that data. It can help insect farmers increase yield by 30%.</p>
<p>The company uses <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">NVIDIA Jetson Orin Nano</a> modules to accelerate its work, and <a href="https://www.linkedin.com/feed/update/urn:li:activity:7178512288889368577/" target="_blank" rel="noopener">recently announced</a> it‚Äôs using synthetic data and digital twin technology to further advance its AI solutions for insect agriculture.</p>
<h2><b>Seeing the Forest for the Trees</b></h2>
<p>Based in Truckee, Calif.,¬†<a href="https://www.vibrantplanet.net" target="_blank" rel="noopener">Vibrant Planet</a> is modeling trillions of trees and other flammable vegetation such as shrublands and grasslands to help land managers, counties and fire districts across North America build wildfire and climate resilience.</p>
<p>NVIDIA hardware and software has helped Vibrant Planet develop <a href="https://blogs.nvidia.com/blog/what-is-a-transformer-model/">transformer models</a> for forest and ecosystem management and AI-enhanced operational planning.</p>
<figure id="attachment_71231" aria-describedby="caption-attachment-71231" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71231" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/Vibrant-Planet-1-672x311.jpg" alt="Visualization of forest" width="672" height="311" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/Vibrant-Planet-1-672x311.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Vibrant-Planet-1-400x185.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Vibrant-Planet-1-768x356.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Vibrant-Planet-1-1536x712.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Vibrant-Planet-1-842x390.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Vibrant-Planet-1-406x188.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Vibrant-Planet-1-188x87.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Vibrant-Planet-1-1280x593.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Vibrant-Planet-1.jpg 1849w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71231" class="wp-caption-text">Visualization courtesy of Vibrant Planet</figcaption></figure>
<p>The startup collects and analyzes data from lidar sensors, satellites and aircraft to train AI models that can map vegetation with high precision, estimate canopy height and detect characteristics of forest and vegetation areas such as carbon, water, biodiversity and built infrastructure. Customers can use this data to understand fire and drought hazards, and, with these insights, conduct scenario planning to forecast the effects of potential forest thinning, prescribed fire or other actions.</p>
<h2><b>Delivering Tomorrow‚Äôs Forecast</b></h2>
<p><a href="http://tomorrow.io/" target="_blank" rel="noopener">Tomorrow.io</a>, based in Boston, is a leading resilience platform that helps organizations adapt to increasing weather and climate volatility. Powered by next-generation space technology, advanced AI models and proprietary modeling capabilities, the startup enables businesses and governments to proactively mitigate risk, ensure operational resilience and drive critical decision-making.</p>
<figure id="attachment_71234" aria-describedby="caption-attachment-71234" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71234" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/Resilience-Dashboard-672x420.jpg" alt="screen capture of tomorrow.io dashboard" width="672" height="420" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/Resilience-Dashboard-672x420.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Resilience-Dashboard-400x250.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Resilience-Dashboard-720x450.jpg 720w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Resilience-Dashboard-344x215.jpg 344w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Resilience-Dashboard-160x100.jpg 160w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Resilience-Dashboard.jpg 768w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71234" class="wp-caption-text">Image courtesy of Tomorrow.io</figcaption></figure>
<p>The startup is developing weather forecasting AI and is launching its own satellites to collect environmental data to further train its models. It‚Äôs also conducting experiments using Earth-2 AI forecast models to determine the optimal configurations of satellites to improve weather-forecasting conditions.</p>
<p>One of Tomorrow.io‚Äôs projects is an initiative in Kenya with the Bill and Melinda Gates Foundation that provides daily alerts to 6 million farmers with insights around when to water their crops, when to spray pesticides, when to harvest or when to change crops altogether due to changes in the local climate. The team hopes to scale up their user base to 100 million farmers in Africa by 2030.</p>
<h2><b>Winds of Change</b></h2>
<p>Palo Alto, Calif.-based <a href="https://windbornesystems.com" target="_blank" rel="noopener">WindBorne Systems</a> is developing weather-sensing balloons equipped with WeatherMesh, a state-of-the-art AI model for real-time global weather forecasts.</p>
<figure id="attachment_71237" aria-describedby="caption-attachment-71237" style="width: 550px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-71237" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/Windborne-1-653x500.jpg" alt="weather balloon against landscape" width="550" height="421" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/Windborne-1-653x500.jpg 653w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Windborne-1-400x306.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Windborne-1-768x588.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Windborne-1-1536x1176.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Windborne-1-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Windborne-1-588x450.jpg 588w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Windborne-1-281x215.jpg 281w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Windborne-1-131x100.jpg 131w, https://blogs.nvidia.com/wp-content/uploads/2024/04/Windborne-1-1280x980.jpg 1280w" sizes="(max-width: 550px) 100vw, 550px" /><figcaption id="caption-attachment-71237" class="wp-caption-text">Image courtesy of WindBorne Systems</figcaption></figure>
<p>WeatherMesh predicts factors including surface temperature, pressure, winds, precipitation and radiation. The model has <a href="https://windbornesystems.com/blog/most-accurate-global-weather-forecasts-with-new-ai-forecast-offering" target="_blank" rel="noopener">set world records for accuracy</a> and is lightweight enough to run on a gaming laptop, unlike traditional models that run on supercomputers.</p>
<p>WindBorne uses NVIDIA GPUs to develop its AI and is an early-access user of Earth-2. The company‚Äôs weather balloon development is funded in part by the <a href="https://wpo.noaa.gov/windborne-weather-balloon-reaches-new-heights/" target="_blank" rel="noopener">National Oceanic and Atmospheric Administration‚Äôs Weather Program Office</a>.</p>
<h2><b>Taking the Temperature of Global Cities</b></h2>
<p><a href="https://www.fortyguard.com/" target="_blank" rel="noopener">FortyGuard</a>, a startup founded in Abu Dhabi with headquarters in Miami, is developing a system to measure urban heat with AI models that present insights for public health officials, city planners, landscape architects and environmental engineers.</p>
<figure id="attachment_71243" aria-describedby="caption-attachment-71243" style="width: 400px" class="wp-caption alignleft"><img loading="lazy" decoding="async" class="size-medium wp-image-71243" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/FortyGuard-NVIDIA-GTC-Picture-400x300.jpg" alt="" width="400" height="300" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/FortyGuard-NVIDIA-GTC-Picture-400x300.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/FortyGuard-NVIDIA-GTC-Picture-667x500.jpg 667w, https://blogs.nvidia.com/wp-content/uploads/2024/04/FortyGuard-NVIDIA-GTC-Picture-768x576.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/FortyGuard-NVIDIA-GTC-Picture-1536x1152.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/04/FortyGuard-NVIDIA-GTC-Picture-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/04/FortyGuard-NVIDIA-GTC-Picture-600x450.jpg 600w, https://blogs.nvidia.com/wp-content/uploads/2024/04/FortyGuard-NVIDIA-GTC-Picture-287x215.jpg 287w, https://blogs.nvidia.com/wp-content/uploads/2024/04/FortyGuard-NVIDIA-GTC-Picture-133x100.jpg 133w, https://blogs.nvidia.com/wp-content/uploads/2024/04/FortyGuard-NVIDIA-GTC-Picture-1280x960.jpg 1280w" sizes="(max-width: 400px) 100vw, 400px" /><figcaption id="caption-attachment-71243" class="wp-caption-text">FortyGuard presented in the Expo Hall Theater at NVIDIA GTC.</figcaption></figure>
<p>The company ‚Äî an early-access user of the Earth-2 platform ‚Äî aims for its temperature AI models to provide a more granular view into urban heat dynamics, providing data that can help industries and governments shape cooler and more livable cities.</p>
<p>FortyGuard‚Äôs technology, offered via application programming interfaces, could integrate with existing enterprise platforms to enable use cases including temperature-based route navigation, predictive enhanced EV performance and property insights.</p>
<p><i></i><i>To learn more about the Sustainable Futures program, watch the ‚Äú</i><a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-se62606/"><i>AI Nations and Sustainable Futures Day</i></a><i>‚Äù session from </i><a href="https://www.nvidia.com/gtc/"><i>NVIDIA GTC</i></a><i>.¬†</i></p>
<p><i>NVIDIA is a member of the <a href="https://www.state.gov/coalition-for-climate-entrepreneurship-cce/" target="_blank" rel="noopener">U.S. Department of State‚Äôs Coalition for Climate Entrepreneurship</a>, which aims to address the United Nations‚Äô Sustainable Development Goals using emerging technologies. Learn more in the GTC session, ‚Äú</i><a href="https://www.nvidia.com/gtc/session-catalog/?search=tenika&amp;search=tenika%2C+tenika&amp;tab.allsessions=1700692987788001F1cG#/session/1696445353484001C0A2"><i>Global Strategies: Startups, Venture Capital, and Climate Change Solutions</i></a><i>.‚Äù</i></p>
<p><em>Video at top courtesy of Vibrant Planet.</em></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/forest-still_Vibrant-Planet.jpg"
			type="image/jpeg"
			width="1280"
			height="845"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/forest-still_Vibrant-Planet-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Climate Tech Startups Integrate NVIDIA AI for Sustainability Applications]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Wide Open: NVIDIA Accelerates Inference on Meta Llama 3¬†¬†¬†</title>
		<link>https://blogs.nvidia.com/blog/meta-llama3-inference-acceleration/</link>
		
		<dc:creator><![CDATA[Ankit Patel]]></dc:creator>
		<pubDate>Thu, 18 Apr 2024 16:30:23 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cloud Services]]></category>
		<category><![CDATA[Consumer Internet]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[NVIDIA Hopper Architecture]]></category>
		<category><![CDATA[NVIDIA Jetson]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[RTX Mobile Workstations]]></category>
		<category><![CDATA[TensorRT]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71177</guid>

					<description><![CDATA[NVIDIA today announced optimizations across all its platforms to accelerate Meta Llama 3, the latest generation of the large language model (LLM). The open model combined with NVIDIA accelerated computing equips developers, researchers and businesses to innovate responsibly across a wide variety of applications. Trained on NVIDIA AI Meta engineers trained Llama 3 on computer		<a class="read-more" href="https://blogs.nvidia.com/blog/meta-llama3-inference-acceleration/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>NVIDIA today announced optimizations across all its platforms to accelerate <a href="https://ai.meta.com/blog/meta-llama-3/">Meta Llama 3</a>, the latest generation of the large language model (<a href="https://www.nvidia.com/en-us/glossary/large-language-models/">LLM</a>).</p>
<p>The open model combined with NVIDIA <a href="https://blogs.nvidia.com/blog/what-is-accelerated-computing/">accelerated computing</a> equips developers, researchers and businesses to innovate responsibly across a wide variety of applications.</p>
<h2><b>Trained on NVIDIA AI</b></h2>
<p>Meta engineers trained Llama 3 on computer clusters packing 24,576 <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100 Tensor Core GPUs</a>, linked with RoCE and <a href="https://www.nvidia.com/en-us/networking/quantum2/">NVIDIA Quantum-2 InfiniBand</a> networks.</p>
<p>To further advance the state of the art in <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a>, Meta <a href="https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/">recently described</a> plans to scale its infrastructure to 350,000 H100 GPUs.</p>
<h2><b>Putting Llama 3 to Work</b></h2>
<p>Versions of Llama 3, accelerated on NVIDIA GPUs, are available today for use in the cloud, data center, edge and PC.</p>
<p>From a browser, developers can try Llama 3 at <a href="http://ai.nvidia.com">ai.nvidia.com</a>. It‚Äôs packaged as an <a href="https://developer.nvidia.com/blog/nvidia-nim-offers-optimized-inference-microservices-for-deploying-ai-models-at-scale/">NVIDIA NIM</a> microservice with a standard application programming interface that can be deployed anywhere.</p>
<p>Businesses can fine-tune Llama 3 with their data using <a href="https://www.nvidia.com/en-us/ai-data-science/products/nemo/">NVIDIA NeMo</a>, an open-source framework for LLMs that‚Äôs part of the secure, supported <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> platform. Custom models can be optimized for inference with <a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-supercharges-large-language-model-inference-on-nvidia-h100-gpus/">NVIDIA TensorRT-LLM</a> and deployed with <a href="https://www.nvidia.com/en-us/ai-data-science/products/triton-inference-server/">NVIDIA Triton Inference Server</a>.</p>
<h2><b>Taking Llama 3 to Devices and PCs</b></h2>
<p>Llama 3 also runs on <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">NVIDIA Jetson Orin</a> for robotics and edge computing devices, creating interactive agents like those in the <a href="https://www.jetson-ai-lab.com/">Jetson AI Lab</a>.</p>
<p>What‚Äôs more, <a href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA RTX</a> and <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/">GeForce RTX</a> GPUs for workstations and PCs speed inference on Llama 3. These systems give developers a target of more than 100 million NVIDIA-accelerated systems worldwide.</p>
<h2><b>Get Optimal Performance with Llama 3</b></h2>
<p>Best practices in deploying an LLM for a chatbot involves a balance of low latency, good reading speed and optimal GPU use to reduce costs.</p>
<p>Such a service needs to deliver tokens ‚Äî the rough equivalent of words to an LLM ‚Äî at about twice a user‚Äôs reading speed which is about 10 tokens/second.</p>
<p>Applying these metrics, a single <a href="https://www.nvidia.com/en-us/data-center/h200/">NVIDIA H200 Tensor Core GPU</a> generated about 3,000 tokens/second ‚Äî enough to serve about 300 simultaneous users ‚Äî in an initial test using the version of Llama 3 with 70 billion parameters.</p>
<p>That means a single <a href="https://www.nvidia.com/en-us/data-center/hgx/">NVIDIA HGX</a> server with eight H200 GPUs could deliver 24,000 tokens/second, further optimizing costs by supporting more than 2,400 users at the same time.</p>
<p>For edge devices, the version of Llama 3 with eight billion parameters generated up to 40 tokens/second on Jetson AGX Orin and 15 tokens/second on Jetson Orin Nano.</p>
<h2><b>Advancing Community Models</b></h2>
<p>An active open-source contributor, NVIDIA is committed to optimizing community software that helps users address their toughest challenges. Open-source models also promote AI transparency and let users broadly share work on AI safety and resilience.</p>
<p>Learn more about how NVIDIA‚Äôs AI inference platform, including how NIM, TensorRT-LLM and Triton use state-of-the-art techniques such as <a href="https://developer.nvidia.com/blog/tune-and-deploy-lora-llms-with-nvidia-tensorrt-llm/">low-rank adaptation</a> to accelerate the latest LLMs.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/final-llm-corp-blog-meta-nv-logo-lockup-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/final-llm-corp-blog-meta-nv-logo-lockup-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Wide Open: NVIDIA Accelerates Inference on Meta Llama 3¬†¬†¬†]]></media:title>
			<media:description type="html">Image of NVIDIA and Meta logos</media:description>
			</media:content>
			</item>
		<item>
		<title>Up to No Good: ‚ÄòNo Rest for the Wicked‚Äô Early Access Launches on GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-no-rest-for-the-wicked/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 18 Apr 2024 13:00:07 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71183</guid>

					<description><![CDATA[It‚Äôs time to get a little wicked. Members can now stream No Rest for the Wicked from the cloud. It leads six new games joining the GeForce NOW library of more than 1,500 games. Holy Moly No Rest for the Wicked is the highly anticipated action role-playing game from Moon Studios, developer of the Ori		<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-no-rest-for-the-wicked/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>It‚Äôs time to get a little wicked. Members can now stream <i>No Rest for the Wicked</i> from the cloud.</p>
<p>It leads six new games joining the <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> library of more than 1,500 games.</p>
<h2><b>Holy Moly</b></h2>
<figure id="attachment_71187" aria-describedby="caption-attachment-71187" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/04/No_Rest_for_the_Wicked-Screenshot-scaled.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-71187" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/No_Rest_for_the_Wicked-Screenshot-672x378.jpg" alt="No Rest For The Wicked on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/No_Rest_for_the_Wicked-Screenshot-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/04/No_Rest_for_the_Wicked-Screenshot-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/No_Rest_for_the_Wicked-Screenshot-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/No_Rest_for_the_Wicked-Screenshot-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/04/No_Rest_for_the_Wicked-Screenshot-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/04/No_Rest_for_the_Wicked-Screenshot-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/04/No_Rest_for_the_Wicked-Screenshot-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/04/No_Rest_for_the_Wicked-Screenshot-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/04/No_Rest_for_the_Wicked-Screenshot-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71187" class="wp-caption-text">There‚Äôs always another fight to be won.</figcaption></figure>
<p><i>No Rest for the Wicked</i> is the highly anticipated action role-playing game from Moon Studios, developer of the <a href="https://blogs.nvidia.com/blog/the-day-before-avatar-ori/"><i>Ori</i> series</a>, and publisher Private Division. Amid a plague-ridden world, step into the boots of a Cerim, a holy warrior on a desperate mission. The Great Pestilence has ravaged the land of Sacra, and a new king reigns. As a colonialist inquisition unfolds, engage in visceral combat, battle plague-infested creatures and uncover the secrets of the continent. Make the character you want with the game‚Äôs flexible soft-class system, explore a rich storyline, and prepare for intense boss battles as you build up the town of Sacrament.</p>
<p>Embark on a dark and perilous journey, where no rest awaits the wicked. Rise to the challenge and stream from GeForce RTX 4080 servers with a <a href="http://geforcenow.com">GeForce NOW Ultimate membership</a> for the smoothest gameplay from the cloud. Be among the first to experience early access of the game, without having to wait for downloads.</p>
<h2><b>Shiny New Games</b></h2>
<figure id="attachment_71184" aria-describedby="caption-attachment-71184" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-evil-west-tw-li-2048x1024-1.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-71184" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-evil-west-tw-li-2048x1024-1-672x336.jpg" alt="Evil West on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-evil-west-tw-li-2048x1024-1-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-evil-west-tw-li-2048x1024-1-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-evil-west-tw-li-2048x1024-1-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-evil-west-tw-li-2048x1024-1-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-evil-west-tw-li-2048x1024-1-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-evil-west-tw-li-2048x1024-1-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-evil-west-tw-li-2048x1024-1-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-evil-west-tw-li-2048x1024-1-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-spotlight-evil-west-tw-li-2048x1024-1.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71184" class="wp-caption-text">&#8220;Yippie ki-yay, evil doers!&#8221;</figcaption></figure>
<p>Become a Wild West superhero in <i>Evil West</i>, streaming on GeForce NOW this week and part of PC Game Pass. It‚Äôs part of six newly supported games this week:</p>
<ul>
<li><i>Kill It With Fire 2 </i>(New release on <a href="https://store.steampowered.com/app/2357000?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 16)</li>
<li><i>The Crew Motorfest </i>(New release on <a href="https://store.steampowered.com/app/2698940?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 18)</li>
<li><i>No Rest for the Wicked </i>(New release on <a href="https://store.steampowered.com/app/1371980?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, April 18)</li>
<li><i>Evil West </i>(<a href="https://www.xbox.com/games/store/evil-west/9MW581HCJPM6?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Lightyear Frontier </i>(<a href="https://store.steampowered.com/app/1677110?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Tomb Raider I-III Remastered </i>(<a href="https://store.steampowered.com/app/2478970?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<p>Riot Games shared in its 14.8 patch notes that it will soon add its Vanguard security software to <i>League of Legends</i> as part of the publisher‚Äôs commitment to remove scripters, bots and bot-leveled accounts from the game and make it more challenging for them to continue. Since Vanguard won‚Äôt support virtual machines when it‚Äôs added to <i>League of Legends</i>, the game will be put under maintenance and will no longer be playable on GeForce NOW once the 14.9 update goes live globally ‚Äî currently planned for May 1, 2024. Members can continue to enjoy the game on GeForce NOW until then.</p>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-thursday-4-18-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/gfn-thursday-4-18-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Up to No Good: ‚ÄòNo Rest for the Wicked‚Äô Early Access Launches on GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Honors Partners of the Year in Europe, Middle East, Africa</title>
		<link>https://blogs.nvidia.com/blog/nvidia-partner-network-awards-emea-2024/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Thu, 18 Apr 2024 10:00:52 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Education]]></category>
		<category><![CDATA[NVIDIA DGX]]></category>
		<category><![CDATA[Omniverse]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71149</guid>

					<description><![CDATA[NVIDIA today recognized 18 partners in Europe, the Middle East and Africa for their achievements and commitment to driving AI adoption. The recipients were honored at the annual EMEA Partner Day hosted by the NVIDIA Partner Network (NPN). The awards span seven categories that highlight the various ways partners work with NVIDIA to transform the		<a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-partner-network-awards-emea-2024/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>NVIDIA today recognized 18 partners in Europe, the Middle East and Africa for their achievements and commitment to driving AI adoption.</p>
<p>The recipients were honored at the annual EMEA Partner Day hosted by the <a href="https://www.nvidia.com/en-us/about-nvidia/partners/" target="_blank" rel="noopener">NVIDIA Partner Network</a> (NPN). The awards span seven categories that highlight the various ways partners work with NVIDIA to transform the region‚Äôs industries with AI.</p>
<p>‚ÄúThis year marks another milestone for NVIDIA and our partners across EMEA as we pioneer technological breakthroughs and unlock new business opportunities using NVIDIA‚Äôs full-stack platform,‚Äù said Dirk Barfuss, director of EMEA channel at NVIDIA. ‚ÄúThese awards celebrate our partners‚Äô dedication and expertise in delivering groundbreaking solutions that drive cost efficiencies, enhance productivity and inspire innovation.‚Äù</p>
<p>The 2024 NPN award winners for EMEA are:</p>
<h2><b>Rising Star Awards</b></h2>
<ul>
<li><b>Vesper Technologies</b> received the Rising Star Northern Europe award for its exceptional revenue growth and broad customer base deploying NVIDIA AI solutions in data centers. The company has demonstrated outstanding growth in recent years, augmenting the success of its existing business.</li>
<li><b>AMBER AI &amp; Data Science Solutions GmbH </b>received the Rising Star Central Europe award for its revenue growth of more than 100% across the complete portfolio of NVIDIA technologies. Through extensive collaboration with NVIDIA, the company has become a cornerstone of the NVIDIA partner landscape in Germany.</li>
<li><b>HIPER Global Enterprise Ltd.</b>¬†received the Rising Star Southern Europe &amp; Middle East award for its excellence in serving its broad customer base with NVIDIA compute technologies. Last year, it supported one of the largest customer projects in the region, further accelerating its growth rate.</li>
</ul>
<h2><strong>Star Performer Awards</strong></h2>
<ul>
<li><b>Boston Limited</b>¬†received the Star Performer Northern Europe award for its consistent success in delivering full-stack implementations of NVIDIA technologies for customers across industries. The company over the last year achieved record revenue growth across its business areas.</li>
<li><b>DELTA Computer Products GmbH</b> received the Star Performer Central Europe award for its outstanding sales achievements and strong customer relationships. With a massive technical knowledge base, the company has served as a trusted advisor for customers deploying NVIDIA technologies across industry, higher education and research.</li>
<li><b>COMMit DMCC</b>¬†received the Star Performer Southern Europe &amp; Middle East award for its exceptional execution of strategic and complex solutions built on NVIDIA technologies, which led to record revenues for the United Arab Emirates-based company.</li>
</ul>
<h2><b>Distributor of the Year</b></h2>
<ul>
<li><b>PNY</b> received the Distributor of the Year award for the third consecutive year, underscoring its consistent investment in technology training and commitment to providing NVIDIA accelerated computing platforms and software across markets.</li>
<li><b>TD Synnex</b> received the Networking Distributor of the Year award for the second year in a row, highlighting its massive investments in NVIDIA‚Äôs portfolio of technologies ‚Äî¬† especially networking ‚Äî and dedication to delivering technical expertise to customers.</li>
</ul>
<h2><b>Go-to-Market Excellence¬†</b></h2>
<ul>
<li><b>Bynet Data Communications</b> <strong>Ltd.</strong> received the Go-to-Market Excellence award for its collaboration with NVIDIA regional leads to devise and execute effective go-to-market strategies for the Israeli market. This included identifying key opportunities and creating localized marketing campaigns. Its efforts led to great success with the installation of <a href="https://www.nvidia.com/en-us/data-center/dgx-superpod/" target="_blank" rel="noopener">NVIDIA DGX SuperPODs</a> into several new industries in the region.</li>
<li><b>Vesper Technologies</b> was Highly Commended in the Go-to-Market Excellence category for its fully integrated go-to-market strategy around the launch of the <a href="https://www.nvidia.com/en-us/data-center/grace-hopper-superchip/" target="_blank" rel="noopener">NVIDIA GH200 Grace Hopper Superchip</a>. The company successfully deployed a results-driven marketing campaign, demonstrated a commitment to technical training and developed a pre-sales trial and evaluation platform.</li>
<li><b>M Computers s.r.o.</b> was Highly Commended in the Go-to-Market Excellence category for its success and leadership in engaging AI customers in eastern Europe with NVIDIA technologies. The company‚Äôs marketing efforts, including speeches at AI events and social media campaigns, helped lead to the first <a href="https://www.nvidia.com/en-us/data-center/dgx-h100/" target="_blank" rel="noopener">NVIDIA DGX H100</a> and <a href="https://www.nvidia.com/en-us/data-center/grace-cpu-superchip/" target="_blank" rel="noopener">NVIDIA Grace CPU Superchip</a> projects in the region.</li>
</ul>
<h2><b>Industry Innovation¬†</b></h2>
<ul>
<li><b>WPP</b> received the Industry Innovation award for its innovative applications of AI and NVIDIA technology in the marketing and advertising sector. The company worked with NVIDIA to build a groundbreaking generative AI-powered content engine, built on the <a href="https://www.nvidia.com/en-us/omniverse/" target="_blank" rel="noopener">NVIDIA Omniverse</a> platform, that enables the creation of brand-consistent content at scale.</li>
<li><b>Ascon Systems</b> was Highly Commended in the Industry Innovation category for its cutting-edge Industrial Metaverse Portal, powered by NVIDIA Omniverse, that helped transform BMW Group‚Äôs manufacturing processes with real-time product control and enhanced visualization and interaction.</li>
<li><b>Gcore</b>¬†was Highly Commended in the Industry Innovation category for its creation of the first speech-to-text technology for Luxembourgish, using its fine-tuned LuxemBERT AI model. The technology integrates seamlessly into corporate systems and Luxembourgish messaging platforms, fostering the preservation of the traditionally spoken language, which lacked adequate tools for written communication.</li>
</ul>
<h2><b>Pioneer</b></h2>
<ul>
<li><b>Arrow Electronics &#8211;</b>¬†<b>Intelligent Business Solutions</b> received the Pioneer Award for its work promoting the <a href="https://www.nvidia.com/en-us/edge-computing/products/igx/" target="_blank" rel="noopener">NVIDIA IGX Orin</a> platform for healthcare applications and building strategies to drive adoption of the technology. The company‚Äôs innovative approach and support led to the first integration of the NVIDIA IGX Orin Developer Kit with an <a href="https://www.nvidia.com/en-us/design-visualization/rtx-6000/" target="_blank" rel="noopener">NVIDIA RTX 6000 Ada Generation GPU</a> for a robotic surgery platform.</li>
</ul>
<h2><b>Consulting Partner of the Year</b></h2>
<ul>
<li><b>SoftServe</b> received the Consulting Partner of the Year award for its excellence in working with partners to drive the adoption of NVIDIA‚Äôs full-stack technologies, helping transform customers‚Äô business with generative AI and NVIDIA Omniverse. Through its SoftServe University corporate learning hub, SoftServe trained its employees, customers and partners to expertly use NVIDIA technology.</li>
<li><b>Deloitte</b>¬†was Highly Commended in the Consulting Partner of the Year category for its focus on building sales and technical skills, efforts to deliver meaningful impact through projects and go-to-market strategy that helped drive enterprise-level AI transformation in the region.</li>
<li><b>Data Monsters</b> was highly commended in the Consulting Partner of the Year category for its development of a virtual assistant with lifelike hearing, speech and animation capabilities using <a href="https://developer.nvidia.com/ace" target="_blank" rel="noopener">NVIDIA Avatar Cloud Engine</a> and <a href="https://www.nvidia.com/en-us/glossary/large-language-models/" target="_blank" rel="noopener">large language models</a>.</li>
</ul>
<p>‚Äã‚ÄãLearn how to <a href="https://www.nvidia.com/en-us/about-nvidia/partners/become-a-partner/" target="_blank" rel="noopener">join NPN, or find a local NPN partner</a>.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/nvidiaheadquarters.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/nvidiaheadquarters-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Honors Partners of the Year in Europe, Middle East, Africa]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
	</channel>
</rss>
