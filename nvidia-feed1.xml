<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Tue, 28 May 2024 01:59:00 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.5.3</generator>
	<item>
		<title>NVIDIA Scoops Up Wins at COMPUTEX Best Choice Awards</title>
		<link>https://blogs.nvidia.com/blog/computex-best-choice-awards-2024/</link>
		
		<dc:creator><![CDATA[Melody Tu]]></dc:creator>
		<pubDate>Tue, 28 May 2024 03:00:53 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[COMPUTEX 2024]]></category>
		<category><![CDATA[Data Science]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<category><![CDATA[NVIDIA BlueField]]></category>
		<category><![CDATA[NVIDIA Hopper Architecture]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71806</guid>

					<description><![CDATA[Building on more than a dozen years of stacking wins at the COMPUTEX trade show’s annual Best Choice Awards, NVIDIA was today honored with BCAs for its latest technologies. The NVIDIA GH200 Grace Hopper Superchip won the Computer and System Category Award; the NVIDIA Spectrum-X AI Ethernet networking platform won the Networking and Communication Category	<a class="read-more" href="https://blogs.nvidia.com/blog/computex-best-choice-awards-2024/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Building on more than a dozen years of stacking wins at the <a href="https://www.nvidia.com/en-us/events/computex/" target="_blank" rel="noopener">COMPUTEX</a> trade show’s annual <a href="https://bcaward.computex.biz/default.aspx" target="_blank" rel="noopener">Best Choice Awards</a>, NVIDIA was today honored with BCAs for its latest technologies.</p>
<p>The <a href="https://www.nvidia.com/en-us/data-center/grace-hopper-superchip/" target="_blank" rel="noopener">NVIDIA GH200 Grace Hopper Superchip</a> won the Computer and System Category Award; the <a href="https://www.nvidia.com/en-us/networking/spectrumx/" target="_blank" rel="noopener">NVIDIA Spectrum-X</a> AI Ethernet networking platform won the Networking and Communication Category Award; and the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/" target="_blank" rel="noopener">NVIDIA AI Enterprise</a> software platform won a Golden Award.</p>
<p>The awards — judged on the functionality, innovation and market potential of products exhibited at the leading computer and technology expo — were announced ahead of the show, which runs from June 4-7, in Taipei.</p>
<p>NVIDIA founder and CEO Jensen Huang will deliver a COMPUTEX <a href="https://events.nvidia.com/jensen-huang-taipei-keynote-2024" target="_blank" rel="noopener">keynote address</a> on Sunday, June 2, at 7 p.m. Taiwan time, at the NTU Sports Center and online.</p>
<h2><b>NVIDIA AI Enterprise Takes Gold</b></h2>
<p>NVIDIA AI Enterprise — a cloud-native software platform that streamlines the development and deployment of copilots and other <a href="https://www.nvidia.com/en-us/glossary/generative-ai/" target="_blank" rel="noopener">generative AI</a> applications — won a Golden Award.</p>
<p>The platform lifts the burden of maintaining and securing complex AI software, so businesses can focus on building and harnessing the technology’s game-changing insights.</p>
<p>Microservices that come with NVIDIA AI Enterprise — including <a href="https://www.nvidia.com/en-us/ai/" target="_blank" rel="noopener">NVIDIA NIM</a> and <a href="https://www.nvidia.com/en-us/technologies/cuda-x/" target="_blank" rel="noopener">NVIDIA CUDA-X</a> — optimize model performance and run anywhere with enterprise-grade security, support and stability, offering users a smooth transition from prototype to production.</p>
<p>Plus, the platform’s ability to improve AI performance results in better overall utilization of computing resources. This means companies using NVIDIA AI Enterprise need fewer servers to support the same workloads, greatly reducing their energy costs and data center footprint.</p>
<h2><b>More BCA Wins for NVIDIA Technologies</b></h2>
<p>NVIDIA GH200 and Spectrum-X were named best in their respective categories.</p>
<p>The NVIDIA GH200 Grace Hopper Superchip is the world’s first truly heterogeneous accelerated platform for AI and high-performance computing workloads. It combines the power-efficient <a href="https://www.nvidia.com/en-us/data-center/grace-cpu/" target="_blank" rel="noopener">NVIDIA Grace CPU</a> with an <a href="https://www.nvidia.com/en-us/data-center/technologies/hopper-architecture/" target="_blank" rel="noopener">NVIDIA Hopper architecture-based GPU</a> over a high-bandwidth 900GB/s coherent <a href="https://www.nvidia.com/en-us/data-center/nvlink-c2c/" target="_blank" rel="noopener">NVIDIA NVLink </a>chip-to-chip interconnect.</p>
<p>The superchip — shipping worldwide and <a href="https://blogs.nvidia.com/blog/gh200-grace-hopper-superchip-powers-ai-supercomputers/" target="_blank" rel="noopener">powering more than 40 AI supercomputers</a> across global research centers, system makers and cloud providers — <a href="https://nvidianews.nvidia.com/news/nvidia-grace-hopper-ignites-new-era-of-ai-supercomputing" target="_blank" rel="noopener">supercharges scientific innovation</a> with accelerated computing and scale-out solutions for AI inference, <a href="https://www.nvidia.com/en-us/glossary/large-language-models/" target="_blank" rel="noopener">large language models</a>, recommenders, vector databases, HPC applications and more.</p>
<p>The Spectrum-X platform, featuring <a href="https://www.nvidia.com/en-us/networking/spectrumx/" target="_blank" rel="noopener">NVIDIA Spectrum SN5600 switches</a> and <a href="https://www.nvidia.com/en-us/networking/products/data-processing-unit/" target="_blank" rel="noopener">NVIDIA BlueField-3 SuperNICs</a>, is the world’s first Ethernet fabric built for AI, accelerating generative AI network performance 1.6x over traditional Ethernet fabrics.</p>
<p>It can serve as the backend AI fabric for any AI cloud or large enterprise deployment, and is available from major server manufacturers as part of the full NVIDIA AI stack.</p>
<h2><b>NVIDIA Partners Recognized</b></h2>
<p>Other BCA winners include NVIDIA partners Acer, ASUS, MSI and YUAN, which were given Golden Awards for their respective laptops, gaming motherboards and smart-city applications — all powered by NVIDIA technologies, such as <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4090/" target="_blank" rel="noopener">NVIDIA GeForce RTX 4090 GPUs</a>, the <a href="https://www.nvidia.com/en-us/studio/" target="_blank" rel="noopener">NVIDIA Studio platform</a> for creative workflows and the <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/" target="_blank" rel="noopener">NVIDIA Jetson platform</a> for edge AI and robotics.</p>
<p>ASUS also won a Computer and System Category Award, while MSI won a Gaming and Entertainment Category Award.</p>
<p><i>Learn more about the latest generative AI, HPC and networking technologies by joining </i><a href="https://www.nvidia.com/en-us/events/computex/" target="_blank" rel="noopener"><i>NVIDIA at COMPUTEX</i></a><i>.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/computex-bca-gh200-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/computex-bca-gh200-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Scoops Up Wins at COMPUTEX Best Choice Awards]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Into the Omniverse: SoftServe and Continental Drive Digitalization With OpenUSD and Generative AI</title>
		<link>https://blogs.nvidia.com/blog/softserve-and-continental-drive-digitalization-with-openusd-and-generative-ai/</link>
		
		<dc:creator><![CDATA[James McKenna]]></dc:creator>
		<pubDate>Thu, 23 May 2024 13:00:08 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Into the Omniverse]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Universal Scene Description]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71772</guid>

					<description><![CDATA[Leading German automotive technology company enhances manufacturing workflows with OpenUSD-powered virtual factory solutions.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><i>Editor’s note: This post is part of </i><a href="https://www.nvidia.com/en-us/omniverse/news/"><i>Into the Omniverse</i></a><i>, a series focused on how artists, developers and enterprises can transform their workflows using the latest advances in </i><a href="https://www.nvidia.com/en-us/omniverse/usd/"><i>OpenUSD</i></a><i> and </i><a href="https://www.nvidia.com/en-us/omniverse/usd/"><i>NVIDIA Omniverse</i></a><i>.</i></p>
<p>Industrial digitalization is driving automotive innovation.</p>
<p>In response to the industry’s growing demand for seamless, connected driving experiences, <a href="https://www.softserveinc.com/en-us">SoftServe</a>, a leading IT consulting and digital services provider, worked with <a href="https://www.continental.com/en/">Continental</a>, a leading German automotive technology company, to develop <a href="https://developer.nvidia.com/blog/spotlight-continental-and-softserve-deliver-generative-ai-powered-virtual-factory-solutions-with-openusd/">Industrial Co-Pilot</a>, a virtual agent powered by <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> that enables engineers to streamline maintenance workflows.</p>
<p>SoftServe helps manufacturers like Continental to further optimize their operations by integrating the Universal Scene Description, or <a href="https://www.nvidia.com/en-us/omniverse/usd/">OpenUSD</a>, framework into virtual factory solutions — such as Industrial Co-Pilot — developed on the <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> platform.</p>
<p>OpenUSD offers the flexibility and extensibility organizations need to harness the full potential of digital transformation, streamlining operations and driving efficiency. Omniverse is a platform of application programming interfaces, software development kits and services that enable developers to easily integrate OpenUSD and <a href="https://www.nvidia.com/en-us/design-visualization/technologies/rtx/">NVIDIA RTX</a> rendering technologies into existing software tools and simulation workflows.</p>
<h2><b>Realizing the Benefits of OpenUSD</b></h2>
<p>SoftServe and Continental’s Industrial Co-Pilot brings together generative AI and immersive 3D visualization to help factory teams increase productivity during equipment and production line maintenance. With the copilot, engineers can oversee production lines and monitor the performance of individual stations or the shop floor.</p>
<p>They can also interact with the copilot to conduct root cause analysis and receive step-by-step work instructions and recommendations, leading to reduced documentation processes and improved maintenance procedures. It’s expected that these advancements will contribute to increased productivity and a10% reduction in maintenance effort and downtime.</p>
<p><img fetchpriority="high" decoding="async" class="wp-image-71782 aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2.png" alt="" width="578" height="324" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2-400x224.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2-672x377.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2-768x431.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2-1536x861.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2-803x450.png 803w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2-384x215.png 384w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2-1280x718.png 1280w" sizes="(max-width: 578px) 100vw, 578px" /></p>
<p>In a <a href="https://www.youtube.com/live/cqggH5skWH8?si=ZMUXPYIH7A0K5el4">recent Omniverse community livestream</a>, Benjamin Huber, who leads advanced automation and digitalization in the user experience business area at Continental, highlighted the significance of the company’s collaboration with SoftServe and its adoption of Omniverse.</p>
<p>The Omniverse platform equips Continental and SoftServe developers with the tools needed to build a new era of AI-enabled industrial applications and services. And by breaking down data silos and fostering multi-platform cooperation with OpenUSD, SoftServe and Continental developers enable engineers to work seamlessly across disciplines and systems, driving efficiency and innovation throughout their processes.</p>
<p>“Any engineer, no matter what tool they’re working with, can transform their data into OpenUSD and then interchange data from one discipline to another, and from one tool to another,” said Huber.</p>
<p>This sentiment was echoed by Vasyl Boliuk, senior lead and test automation engineer at SoftServe, who shared how OpenUSD and Omniverse — along with other NVIDIA technologies like <a href="https://www.nvidia.com/en-us/ai-data-science/products/riva/">NVIDIA Riva</a>, <a href="https://www.nvidia.com/en-us/ai-data-science/products/nemo/">NVIDIA NeMo</a> and <a href="https://developer.nvidia.com/blog/nvidia-nim-offers-optimized-inference-microservices-for-deploying-ai-models-at-scale/">NVIDIA NIM</a> microservices — enabled SoftServe and Continental teams to develop custom large language models and connect them to new 3D workflows.</p>
<p>“OpenUSD allows us to add any attribute or any piece of metadata we want to our applications,” he said.</p>
<p>Boliuk, Huber and other SoftServe and Continental representatives joined the livestream to share more about the potential unlocked from these OpenUSD-powered solutions. Watch the replay:</p>
<p><iframe title="Generative AI-Powered Virtual Factory Solutions With OpenUSD" width="500" height="281" src="https://www.youtube.com/embed/cqggH5skWH8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>By embracing cutting-edge technologies and fostering collaboration, SoftServe and Continental are helping reshape automotive manufacturing.</p>
<h2><b>Get Plugged Into the World of OpenUSD</b></h2>
<p>Watch SoftServe and Continental’s on-demand NVIDIA GTC talks to learn more about their virtual factory solutions and experience developing on NVIDIA Omniverse with OpenUSD:</p>
<ul>
<li style="font-weight: 400"><a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62919/">Transforming Factory Planning and Manufacturing Operations Within Digital Mega Plants</a></li>
<li style="font-weight: 400"><a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s61799/">Getting Started With Generative AI and OpenUSD for Industrial Metaverse Applications</a></li>
</ul>
<p>Learn about the latest technologies driving the next industrial revolution by watching NVIDIA founder and CEO Jensen Huang’s <a href="https://www.nvidia.com/en-us/events/computex/">COMPUTEX keynote</a> on Sunday, June 2, at 7 p.m. Taiwan time.</p>
<p>Check out a new <a href="https://www.youtube.com/playlist?list=PL3jK4xNnlCVcUP08kj6eOzvCA82U_JKiy">video series</a> about how OpenUSD can improve 3D workflows. For more resources on OpenUSD, explore the Alliance for OpenUSD <a href="https://forum.aousd.org/">forum</a> and visit the <a href="https://aousd.org/">AOUSD website</a>.</p>
<p><i>Get started with NVIDIA Omniverse by downloading the standard license </i><a href="https://www.nvidia.com/en-us/omniverse/download/"><i>free</i></a><i>, access </i><a href="https://developer.nvidia.com/usd"><i>OpenUSD</i></a><i> resources and learn how </i><a href="https://www.nvidia.com/en-us/omniverse/enterprise/"><i>Omniverse Enterprise</i><i> can connect team</i></a><i>s. Follow Omniverse on </i><a href="https://www.instagram.com/nvidiaomniverse/"><i>Instagram</i></a><i>, </i><a href="https://medium.com/@nvidiaomniverse"><i>Medium</i></a><i> and </i><a href="https://twitter.com/nvidiaomniverse"><i>X</i></a><i>. For more, join the </i><a href="https://www.nvidia.com/en-us/omniverse/community/"><i>Omniverse community</i></a><i> on the </i><a href="https://forums.developer.nvidia.com/c/omniverse/300"><i>forums</i></a><i>, </i><a href="https://discord.com/invite/XWQNJDNuaC"><i>Discord server</i></a><i>, </i><a href="https://www.twitch.tv/nvidiaomniverse"><i>Twitch</i></a><i> and </i><a href="https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA"><i>YouTube</i></a><i> channels. </i></p>
<p><i>Featured image courtesy of SoftServe.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/nv-ov-ito-1280x680_softserve_052024-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/nv-ov-ito-1280x680_softserve_052024-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Into the Omniverse: SoftServe and Continental Drive Digitalization With OpenUSD and Generative AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Senua’s Story Continues: GeForce NOW Brings ‘Senua’s Saga: Hellblade II’ to the Cloud</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-senuas-saga-hellblade-2/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 23 May 2024 13:00:05 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71774</guid>

					<description><![CDATA[Every week, GFN Thursday brings new games to the cloud, featuring some of the latest and greatest titles for members to play. Leading the seven games joining GeForce NOW this week is the newest game in Ninja Theory’s Hellblade franchise, Senua’s Saga: Hellblade II. This day-and-date release expands the cloud gaming platform’s extensive library of	<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-senuas-saga-hellblade-2/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Every week, GFN Thursday brings new games to the cloud, featuring some of the latest and greatest titles for members to play.</p>
<p>Leading the seven games joining <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> this week is the newest game in Ninja Theory’s <i>Hellblade</i> franchise, <i>Senua’s Saga: Hellblade II</i>. This day-and-date release expands the cloud gaming platform’s extensive library of over 1,900 games.</p>
<p>Members can also look forward to a new reward — a free in-game mount — for <i>The Elder Scrolls Online </i>starting Thursday, May 30. Get ready by opting into <a href="https://www.nvidia.com/en-us/geforce-now/rewards/">GeForce NOW’s Rewards program</a>.</p>
<h2><b>Senua Returns</b></h2>
<figure id="attachment_71778" aria-describedby="caption-attachment-71778" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" class="size-large wp-image-71778" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-672x368.jpg" alt="Senua's Saga: Hellblade II screen" width="672" height="368" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-672x368.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-400x219.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-768x420.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-1536x840.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-823x450.jpg 823w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-393x215.jpg 393w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-183x100.jpg 183w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-1280x700.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71778" class="wp-caption-text">Head to the cloud to overcome the darkness.</figcaption></figure>
<p>In <i>Senua’s Saga: Hellblade II</i>, the sequel to the award-winning <i>Hellblade: Senua’s Sacrifice</i>, Senua returns in a brutal journey of survival through the myth and torment of Viking Iceland.</p>
<p>Intent on saving those who’ve fallen victim to the horrors of tyranny, Senua battles the forces of darkness within and without. Sink deep into the next chapter of Senua’s story, a crafted experience told through cinematic immersion, beautifully realized visuals and encapsulating sound.</p>
<p><a href="http://geforcenow.com">Priority and Ultimate members</a> can fully immerse themselves in Senua’s story with epic cinematic gameplay at higher resolutions and frame rates over free members. Ultimate members can stream at up to 4K 120 frames per second with exclusive access to GeForce RTX 4080 SuperPODs in the cloud, even on underpowered devices.</p>
<h2><b>Level Up With New Games</b></h2>
<p>Check out the full list of new games this week:</p>
<ul>
<li><i>Synergy </i>(New release on <a href="https://store.steampowered.com/app/1989070?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 21)</li>
<li><i>Senua’s Saga: Hellblade II</i> (New release on <a href="https://store.steampowered.com/app/2461850?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.xbox.com/games/store/senuas-saga-hellblade-ii/9pmbb7nghv95?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass, May 21)</li>
<li><i>Crown Wars: The Black Prince </i>(New release on <a href="https://store.steampowered.com/app/1658920?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 23)</li>
<li><i>Serum</i> (New release on <a href="https://store.steampowered.com/app/1610520?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 23)</li>
<li><i>Ships at Sea</i> (New release on <a href="https://store.steampowered.com/app/1266540?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 23)</li>
<li><i>Exo One </i>(<a href="https://store.steampowered.com/app/773370?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Phantom Brigade </i>(<a href="https://store.steampowered.com/app/553540?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">what&#39;s a life lesson you learned from a game?</p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1793310854592491909?ref_src=twsrc%5Etfw">May 22, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-thursday-5-23-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-thursday-5-23-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Senua’s Story Continues: GeForce NOW Brings ‘Senua’s Saga: Hellblade II’ to the Cloud]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Watt a Win: NVIDIA Sweeps New Ranking of World’s Most Energy-Efficient Supercomputers</title>
		<link>https://blogs.nvidia.com/blog/green500-energy-efficient-supercomputers/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Tue, 21 May 2024 16:11:03 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Supercomputing]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71762</guid>

					<description><![CDATA[In the latest ranking of the world’s most energy-efficient supercomputers, known as the Green500, NVIDIA-powered systems swept the top three spots, and took seven of the top 10. The strong showing demonstrates how accelerated computing represents the most energy-efficient method for high-performance computing. The top three systems were all powered by the NVIDIA GH200 Grace	<a class="read-more" href="https://blogs.nvidia.com/blog/green500-energy-efficient-supercomputers/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>In the latest ranking of the world’s most energy-efficient supercomputers, known as the <a href="https://top500.org/lists/green500/2024/06/">Green500</a>, NVIDIA-powered systems swept the top three spots, and took seven of the top 10.</p>
<p>The strong showing demonstrates how accelerated computing represents the most energy-efficient method for high-performance computing.</p>
<p>The top three systems were all powered by the <a href="https://www.nvidia.com/en-us/data-center/grace-hopper-superchip/">NVIDIA GH200 Grace Hopper Superchip</a>, showcasing the widespread adoption and efficiency of NVIDIA’s Grace Hopper architecture.</p>
<p>Leading the pack was the JEDI system, at Germany’s <a href="https://www.fz-juelich.de">Forschungszentrum Jülich</a>, which achieved an impressive 72.73 GFlops per Watt.</p>
<p>More’s coming. The ability to do more work using less power is driving the construction of more Grace Hopper supercomputers around the world.</p>
<h2><strong>Accelerating the Green Revolution in Supercomputing</strong></h2>
<p>Such achievements underscore NVIDIA’s pivotal role in advancing the global agenda for sustainable high-performance computing over the past decade.</p>
<p>Accelerated computing has proven to be the cornerstone of energy efficiency, with the majority of systems on the Green500 list — including 40 of the top 50 — now featuring this advanced technology.</p>
<p>Pioneered by NVIDIA, <a href="https://blogs.nvidia.com/blog/what-is-accelerated-computing/#:~:text=Accelerated%20computing%20uses%20parallel%20processing,analytics%20to%20simulations%20and%20visualizations.">accelerated computing</a> uses GPUs that optimize throughput — getting a lot done at once — to perform complex computations faster than systems based on CPUs alone.</p>
<p>And the Grace Hopper architecture is proving to be a game-changer by enhancing computational speed and dramatically increasing energy efficiency across multiple platforms.</p>
<p>For example, the GH200 chip embedded within the Grace Hopper systems offers over 1,000x more energy efficiency on mixed precision and AI tasks than previous generations.</p>
<h2><strong>Redefining Efficiency in Supercomputing</strong></h2>
<p>This capability is crucial for accelerating tasks that address complex scientific challenges, speeding up the work of researchers across various disciplines.</p>
<p>NVIDIA’s supercomputing technology excels in traditional benchmarks — and it’s set new standards in energy efficiency.</p>
<p><span>For instance, the Alps system, at the </span><span>Swiss National Supercomputing Centre (CSCS),</span><span> is equipped with NVIDIA Grace Hopper GH200. An optimized subset of the system, dubbed preAlps, placed fifth on the latest Green500. CSCS also submitted the full system to the TOP500 list, recording 270 petaflops on the High-Performance Linpack benchmark, used for solving complex linear equations. </span></p>
<p>The Green500 rankings highlight platforms that provide highly efficient FP64 performance, which is crucial for accurate simulations used in scientific computing. This result underscores NVIDIA&#8217;s commitment to powering supercomputers for tasks across a full range of capabilities.</p>
<p>This metric demonstrates substantial system performance, leading to its high ranking on the TOP500 list of the world&#8217;s fastest supercomputers. The high position on the Green500 list indicates that this scalable performance does not come at the cost of energy efficiency.</p>
<p>Such performance shows how the Grace Hopper architecture introduces a new era in processing technology, merging tightly coupled CPU and GPU functionalities to enhance not only performance but also significantly improve energy efficiency.</p>
<p>This advancement is supported by the incorporation of an optimized high-efficiency link that moves data between the CPU and GPU.</p>
<p>NVIDIA’s upcoming <a href="https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing">Blackwell platform</a> is set to build on this by offering the computational power of the Titan supercomputer launched 10 years ago — a $100 million system the size of a tennis court — yet be efficient enough to be powered by a wall socket just like a typical home appliance.</p>
<p>In short, over the past decade, NVIDIA innovations have enhanced the accessibility and sustainability of high-performance computing, making scientific breakthroughs faster, cheaper and greener.</p>
<h2><strong>A Future Defined by Sustainable Innovation</strong></h2>
<p>As NVIDIA continues to push the boundaries of what’s possible in high-performance computing, it remains committed to enhancing the energy efficiency of global computing infrastructure.</p>
<p>The success of the Grace Hopper supercomputers in the Green500 rankings highlights NVIDIA’s leadership and its commitment to more sustainable global computing.</p>
<p><a href="https://www.nvidia.com/en-us/data-center/sustainable-computing/">Explore how NVIDIA’s pioneering role in green computing</a> is advancing scientific research, as well as shaping a more sustainable future worldwide.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/JUPITER-supercomputer-2-in-Germany.jpg"
			type="image/jpeg"
			width="1389"
			height="737"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/JUPITER-supercomputer-2-in-Germany-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Watt a Win: NVIDIA Sweeps New Ranking of World’s Most Energy-Efficient Supercomputers]]></media:title>
			<media:description type="html">Image of JUPITER supercomputer in Germany</media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Expands Collaboration With Microsoft to Help Developers Build, Deploy AI Applications Faster</title>
		<link>https://blogs.nvidia.com/blog/microsoft-build-optimized-ai-developers/</link>
		
		<dc:creator><![CDATA[Dave Salvator]]></dc:creator>
		<pubDate>Tue, 21 May 2024 15:30:58 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cloud Services]]></category>
		<category><![CDATA[CUDA]]></category>
		<category><![CDATA[Developer Program]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71675</guid>

					<description><![CDATA[If optimized AI workflows are like a perfectly tuned orchestra — where each component, from hardware infrastructure to software libraries, hits exactly the right note — then the long-standing harmony between NVIDIA and Microsoft is music to developers’ ears. The latest AI models developed by Microsoft, including the Phi-3 family of small language models, are	<a class="read-more" href="https://blogs.nvidia.com/blog/microsoft-build-optimized-ai-developers/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>If optimized AI workflows are like a perfectly tuned orchestra — where each component, from hardware infrastructure to software libraries, hits exactly the right note — then the long-standing harmony between NVIDIA and Microsoft is music to developers’ ears.</p>
<p>The latest AI models developed by Microsoft, including the Phi-3 family of small language models, are being optimized to run on NVIDIA GPUs and made available as <a href="https://www.nvidia.com/en-us/ai/" target="_blank" rel="noopener">NVIDIA NIM</a> inference microservices. Other microservices developed by NVIDIA, such as the cuOpt route optimization AI, are regularly added to <a href="https://azuremarketplace.microsoft.com/en-us/" target="_blank" rel="noopener">Microsoft Azure Marketplace</a> as part of the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/" target="_blank" rel="noopener">NVIDIA AI Enterprise</a> software platform.</p>
<p>In addition to these AI technologies, NVIDIA and Microsoft are delivering a growing set of optimizations and integrations for developers creating high-performance AI apps for PCs powered by <a href="https://www.nvidia.com/en-us/geforce/rtx/" target="_blank" rel="noopener">NVIDIA GeForce RTX</a> and <a href="https://www.nvidia.com/en-us/design-visualization/technologies/rtx/" target="_blank" rel="noopener">NVIDIA RTX</a> GPUs.</p>
<p>Building on the <a href="https://nvidianews.nvidia.com/news/microsoft-nvidia-generative-ai-enterprises" target="_blank" rel="noopener">progress shared at NVIDIA GTC</a>, the two companies are furthering this ongoing collaboration at <a href="http://nvidia.com/en-us/events/microsoft-build/" target="_blank" rel="noopener">Microsoft Build</a>, an annual developer event, taking place this year in Seattle through May 23.</p>
<h2><b>Accelerating Microsoft’s Phi-3 Models </b></h2>
<p>Microsoft is expanding its family of <a href="https://aka.ms/Phi-3Build2024" target="_blank" rel="noopener">Phi-3</a> open small language models, adding small (7-billion-parameter) and medium (14-billion-parameter) models similar to its <a href="https://blogs.nvidia.com/blog/microsoft-open-phi-3-mini-language-models/">Phi-3-mini</a>, which has 3.8 billion parameters. It’s also introducing a new 4.2-billion-parameter multimodal model, Phi-3-vision, that supports images and text.</p>
<p>All of these models are GPU-optimized with <a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-supercharges-large-language-model-inference-on-nvidia-h100-gpus/" target="_blank" rel="noopener">NVIDIA TensorRT-LLM</a> and available as NVIDIA NIMs, which are accelerated inference microservices with a standard application programming interface (API) that can be deployed anywhere.</p>
<p>APIs for the NIM-powered Phi-3 models are available at <a href="http://ai.nvidia.com" target="_blank" rel="noopener">ai.nvidia.com</a> and through NVIDIA AI Enterprise on the Azure Marketplace.</p>
<h2><b>NVIDIA cuOpt Now Available on Azure Marketplace</b></h2>
<p>NVIDIA cuOpt, a GPU-accelerated AI microservice for route optimization, is <a href="https://azuremarketplace.microsoft.com/en-us/marketplace/apps/nvidia.nvidia-ai-enterprise?tab=overview" target="_blank" rel="noopener">now available in Azure Marketplace</a> via NVIDIA AI Enterprise. cuOpt features massively parallel algorithms that enable real-time logistics management for shipping services, railway systems, warehouses and factories.</p>
<p>The model has set two dozen world records on major routing benchmarks, demonstrating the best accuracy and fastest times. It could save billions of dollars for the logistics and supply chain industries by optimizing vehicle routes, saving travel time and minimizing idle periods.</p>
<p>Through Azure Marketplace, developers can easily <a href="https://aka.ms/azuremapscuopt" target="_blank" rel="noopener">integrate the cuOpt microservice</a> with Azure Maps to support teal-time logistics management and other cloud-based workflows, backed by enterprise-grade management tools and security.</p>
<h2><b>Optimizing AI Performance on PCs With NVIDIA RTX</b></h2>
<p>The NVIDIA accelerated computing platform is the backbone of modern AI — helping developers build solutions for over 100 million Windows GeForce RTX-powered PCs and NVIDIA RTX-powered workstations worldwide.</p>
<p>NVIDIA and Microsoft are delivering new optimizations and integrations to Windows developers to <a href="https://blogs.nvidia.com/blog/rtx-advanced-ai-windows-pc-build" target="_blank" rel="noopener">accelerate AI in next-generation PC and workstation applications</a>. These include:</p>
<ul>
<li>Faster inference performance for large language models via the <a href="https://developer.nvidia.com/directx" target="_blank" rel="noopener">NVIDIA DirectX</a> driver, the <a href="https://onnxruntime.ai/docs/genai/" target="_blank" rel="noopener">Generative AI ONNX Runtime</a> extension and <a href="https://learn.microsoft.com/en-us/windows/ai/directml/dml-intro" target="_blank" rel="noopener">DirectML</a>. These optimizations, available now in the GeForce Game Ready, NVIDIA Studio and NVIDIA RTX Enterprise Drivers, deliver up to 3x faster performance on NVIDIA and GeForce RTX GPUs.</li>
<li>Optimized performance on RTX GPUs for AI models like Stable Diffusion and Whisper via <a href="https://webmachinelearning.github.io/webnn-intro/" target="_blank" rel="noopener">WebNN</a>, an API that enables developers to accelerate AI models in web applications using on-device hardware.</li>
<li>With Windows set to support PyTorch through DirectML, thousands of Hugging Face models will work in Windows natively. NVIDIA and Microsoft are collaborating to scale performance on more than 100 million RTX GPUs.</li>
</ul>
<h2><b>Join NVIDIA at Microsoft Build </b></h2>
<p>Conference attendees can visit NVIDIA booth FP28 to meet developer experts and experience live demos of NVIDIA NIM, NVIDIA cuOpt, <a href="https://www.nvidia.com/en-us/omniverse/" target="_blank" rel="noopener">NVIDIA Omniverse</a> and the NVIDIA RTX AI platform. The booth also highlights the <a href="https://docs.nvidia.com/monai/index.html" target="_blank" rel="noopener">NVIDIA MONAI</a> platform for medical imaging workflows and <a href="https://www.nvidia.com/en-us/clara/bionemo/" target="_blank" rel="noopener">NVIDIA BioNeMo</a> generative AI platform for drug discovery — both <a href="https://news.microsoft.com/2024/03/18/microsoft-announces-collaboration-with-nvidia-to-accelerate-healthcare-and-life-sciences-innovation-with-advanced-cloud-ai-and-accelerated-computing-capabilities/" target="_blank" rel="noopener">available on Azure</a> as part of NVIDIA AI Enterprise.</p>
<p><a href="https://www.nvidia.com/en-us/events/microsoft-build/" target="_blank" rel="noopener">Attend sessions</a> with NVIDIA speakers to dive into the capabilities of the NVIDIA RTX AI platform on Windows PCs and discover how to deploy generative AI and digital twin tools on Microsoft Azure.</p>
<p>And sign up for the Developer Showcase, taking place Wednesday, to discover how developers are building innovative generative AI using NVIDIA AI software on Azure.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/partner-press-azure-promo-1280x680-2.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/partner-press-azure-promo-1280x680-2-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Expands Collaboration With Microsoft to Help Developers Build, Deploy AI Applications Faster]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>New Performance Optimizations Supercharge NVIDIA RTX AI PCs for Gamers, Creators and Developers</title>
		<link>https://blogs.nvidia.com/blog/rtx-advanced-ai-windows-pc-build/</link>
		
		<dc:creator><![CDATA[Jesse Clayton]]></dc:creator>
		<pubDate>Tue, 21 May 2024 15:30:08 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[AI Decoded]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Conversational AI]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71743</guid>

					<description><![CDATA[NVIDIA today announced at Microsoft Build new AI performance optimizations and integrations for Windows that help deliver maximum performance on NVIDIA GeForce RTX AI PCs and NVIDIA RTX workstations. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>NVIDIA today announced at <a href="https://www.nvidia.com/en-us/events/microsoft-build/">Microsoft Build</a> new AI performance optimizations and integrations for Windows that help deliver maximum performance on <a href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA GeForce RTX</a> AI PCs and <a href="https://www.nvidia.com/en-us/design-visualization/technologies/rtx/">NVIDIA RTX</a> workstations.</p>
<p>Large language models (<a href="https://blogs.nvidia.com/blog/what-are-large-language-models-used-for/">LLMs</a>) power some of the most exciting new use cases in <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> and now run up to 3x faster with <a href="https://developer.nvidia.com/blog/end-to-end-ai-for-nvidia-based-pcs-onnx-and-directml/">ONNX Runtime (ORT) and DirectML</a> using the new NVIDIA R555 Game Ready Driver. ORT and DirectML are high-performance tools used to run AI models locally on Windows PCs.</p>
<p>WebNN, an application programming interface for web developers to deploy AI models, is now accelerated with RTX via DirectML, enabling web apps to incorporate fast, AI-powered capabilities. And PyTorch will support DirectML execution backends, enabling Windows developers to train and infer complex AI models on Windows natively. NVIDIA and Microsoft are collaborating to scale performance on RTX GPUs.</p>
<p>These advancements build on NVIDIA’s world-leading AI platform, which accelerates more than 500 applications and games on over 100 million RTX AI PCs and workstations worldwide.</p>
<h2><b>RTX AI PCs — Enhanced AI for Gamers, Creators and Developers </b></h2>
<p>NVIDIA introduced the first PC GPUs with dedicated AI acceleration, the GeForce RTX 20 Series with Tensor Cores, along with the first widely adopted AI model to run on Windows, <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">NVIDIA DLSS</a>, in 2018. Its latest GPUs offer up to 1,300 trillion operations per second of dedicated AI performance.</p>
<p>In the coming months, Copilot+ PCs equipped with new power-efficient systems-on-a-chip and RTX GPUs will be released, giving gamers, creators, enthusiasts and developers increased performance to tackle demanding local AI workloads, along with Microsoft’s new Copilot+ features.</p>
<p>For gamers on RTX AI PCs, NVIDIA DLSS boosts frame rates by up to 4x, while <a href="https://developer.nvidia.com/ace">NVIDIA ACE</a> brings game characters to life with AI-driven dialogue, animation and speech.</p>
<p>For content creators, RTX powers AI-assisted production workflows in apps like Adobe Premiere, Blackmagic Design DaVinci Resolve and Blender to automate tedious tasks and streamline workflows. From 3D denoising and accelerated rendering to text-to-image and video generation, these tools empower artists to bring their visions to life.</p>
<p>For game modders, <a href="https://www.nvidia.com/en-us/geforce/rtx-remix/">NVIDIA RTX Remix</a>, built on the <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> platform, provides AI-accelerated tools to create RTX remasters of classic PC games. It makes it easier than ever to capture game assets, enhance materials with generative AI tools and incorporate full ray tracing.</p>
<p>For livestreamers, the <a href="https://www.nvidia.com/en-us/design-visualization/software/broadcast-app/">NVIDIA Broadcast</a> application delivers high-quality AI-powered background subtraction and noise removal, while <a href="https://blogs.nvidia.com/blog/rtx-video-hdr-remix-studio-driver/">NVIDIA RTX Video</a> provides AI-powered upscaling and auto-high-dynamic range to enhance streamed video quality.</p>
<p>Enhancing productivity, LLMs powered by RTX GPUs execute AI assistants and copilots faster, and can process multiple requests simultaneously.</p>
<p>And RTX AI PCs allow developers to build and fine-tune AI models directly on their devices using NVIDIA’s AI developer tools, which include <a href="https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/workbench/">NVIDIA AI Workbench</a>, <a href="https://developer.nvidia.com/cudnn">NVIDIA cuDNN</a> and CUDA on Windows Subsystem for Linux. Developers also have access to RTX-accelerated AI frameworks and software development kits like <a href="https://developer.nvidia.com/tensorrt-getting-started">NVIDIA TensorRT</a>, <a href="https://developer.nvidia.com/maxine">NVIDIA Maxine</a> and RTX Video.</p>
<p>The combination of AI capabilities and performance deliver enhanced experiences for gamers, creators and developers.</p>
<h2><b>Faster LLMs and New Capabilities for Web Developers</b></h2>
<p>Microsoft recently released the <a href="https://github.com/microsoft/onnxruntime-genai">generative AI extension for ORT</a>, a cross-platform library for AI inference. The extension adds support for optimization techniques like quantization for LLMs like Phi-3, Llama 3, Gemma and Mistral. ORT supports different execution providers for inferencing via various software and hardware stacks, including DirectML.</p>
<p>ORT with the DirectML backend offers Windows AI developers a quick path to develop AI capabilities, with stability and production-grade support for the broad Windows PC ecosystem. NVIDIA optimizations for the generative AI extension for ORT, available now in R555 Game Ready, Studio and NVIDIA RTX Enterprise Drivers, help developers get up to 3x faster performance on RTX compared to previous drivers.</p>
<figure id="attachment_71747" aria-describedby="caption-attachment-71747" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/llm-inference-perf.png"><img loading="lazy" decoding="async" class="size-large wp-image-71747" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/llm-inference-perf-672x386.png" alt="" width="672" height="386" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/llm-inference-perf-672x386.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/llm-inference-perf-400x230.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/llm-inference-perf-768x441.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/llm-inference-perf-1536x883.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/llm-inference-perf-783x450.png 783w, https://blogs.nvidia.com/wp-content/uploads/2024/05/llm-inference-perf-374x215.png 374w, https://blogs.nvidia.com/wp-content/uploads/2024/05/llm-inference-perf-174x100.png 174w, https://blogs.nvidia.com/wp-content/uploads/2024/05/llm-inference-perf-1280x736.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/05/llm-inference-perf.png 1999w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71747" class="wp-caption-text"><i>Inference performance for three LLMs using ONNX Runtime and the DirectML execution provider with the latest R555 GeForce driver compared to the previous R550 driver. INSEQ=2000 representative of document summarization workloads. All data captured with GeForce RTX 4090 GPU using batch size 1. The generative AI extension support for int4 quantization, plus the NVIDIA optimizations, result in up to 3x faster performance for LLMs.</i></figcaption></figure>
<p>Developers can unlock the full capabilities of RTX hardware with the new <a href="https://www.nvidia.com/download/index.aspx">R555 driver</a>, bringing better AI experiences to consumers, faster. It includes:</p>
<ul>
<li>Support for DQ-GEMM metacommand to handle INT4 weight-only quantization for LLMs</li>
<li>New RMSNorm normalization methods for Llama 2, Llama 3, Mistral and Phi-3 models</li>
<li>Group and multi-query attention mechanisms, and sliding window attention to support Mistral</li>
<li>In-place KV updates to improve attention performance</li>
<li>Support for GEMM of non-multiple-of-8 tensors to improve context phase performance</li>
</ul>
<p>Additionally, NVIDIA has optimized AI workflows within WebNN to deliver the powerful performance of RTX GPUs directly within browsers. The WebNN standard helps web app developers accelerate deep learning models with on-device AI accelerators, like Tensor Cores.</p>
<p>Now available in developer preview, WebNN uses DirectML and ORT Web, a Javascript library for in-browser model execution, to make AI applications more accessible across multiple platforms. With this acceleration, popular models like Stable Diffusion, SD Turbo and Whisper run up to 4x faster on WebNN compared to WebGPU and are now available for developers to use. Microsoft Build attendees can learn more about developing on RTX in the <a href="https://build.microsoft.com/en-US/sessions/689907b5-1bb8-4e4a-921f-2808a4dc823a"><i>Accelerating development on Windows PCs with RTX AI</i></a> in-person session on Wednesday, May 22, at 11 a.m. PT.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/partner-corp-blog-msft-ecosystem-announcement-promo-1280x680-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/partner-corp-blog-msft-ecosystem-announcement-promo-1280x680-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[New Performance Optimizations Supercharge NVIDIA RTX AI PCs for Gamers, Creators and Developers]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>A Superbloom of Updates in the May Studio Driver Gives Fresh Life to Content Creation</title>
		<link>https://blogs.nvidia.com/blog/studio-may-driver-rtx-video-remix/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 21 May 2024 13:00:54 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artficial Intelligence]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio Driver]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71705</guid>

					<description><![CDATA[A superbloom of creative app updates, included in the May Studio Driver, is ready for download today.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><i>Editor’s note: This post is part of our </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. We’re also deep diving on new </i><a href="https://www.nvidia.com/en-us/geforce/rtx/"><i>GeForce RTX GPU</i></a><i> features, technologies and resources, and how they dramatically accelerate content creation.</i></p>
<p>A superbloom of creative app updates, included in the May Studio Driver, is ready for <a href="https://www.nvidia.com/en-us/geforce/drivers/">download</a> today.</p>
<p>New GPU-accelerated and AI-powered apps and features are now available, backed by the <a href="https://www.nvidia.com/en-us/studio/">NVIDIA Studio</a> platform.</p>
<p>And this week’s featured<i> In the NVIDIA Studio </i>artist, Yao Chan, created the whimsical, spring-inspired 3D scene <i>By the Window</i> using her <a href="https://www.nvidia.com/en-us/design-visualization/desktop-graphics/">NVIDIA RTX GPU</a>.</p>
<h2><b>May’s Creative App Rundown</b></h2>
<p>RTX Video is a collection of AI enhancements that improves the quality of video played on apps like YouTube, Prime Video and Disney+. <a href="https://blogs.nvidia.com/blog/rtx-video-super-resolution/">RTX Video Super Resolution</a> (VSR) upscales video for cleaner, crisper imagery, while <a href="https://blogs.nvidia.com/blog/rtx-video-hdr-remix-studio-driver/">RTX Video HDR</a> transforms standard dynamic range video content to high-dynamic range (HDR10), improving its visibility, details and vibrancy.</p>
<p>Mozilla Firefox, the third most popular PC browser, has added support for RTX VSR and HDR, including AI-enhanced upscaling, de-artifacting and HDR effects for most streamed videos.</p>
<p><a href="https://www.nvidia.com/en-us/geforce/rtx-remix/">NVIDIA RTX Remix</a> allows modders to easily capture game assets, automatically enhance materials with <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> tools and create stunning RTX remasters with full ray tracing. RTX Remix recently added DLSS 3.5 support featuring Ray Reconstruction, an AI model that creates higher-quality images for intensive ray-traced games and apps, to the modding toolkit.</p>
<p><iframe loading="lazy" title="RTX Remix - Remaster the Classics with RTX" width="500" height="281" src="https://www.youtube.com/embed/27LkeFtuq48?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Game developers interested in creating their own ray-traced mod for a classic game can <a href="https://www.nvidia.com/en-us/geforce/rtx-remix/">download the RTX Remix Beta</a> and watch <a href="https://www.youtube.com/playlist?list=PL4w6jm6S2lzvgJ97T1_VbLGBR_l6zzOUm">tutorial videos</a> to get a head start.</p>
<p>Maxon’s Cinema 4D modeling software empowers 3D video effects artists and motion designers to create complex scenes with ease. The integration of the software’s Version 2024.4 with C4D’s Unified Simulation systems now enables control of emission fields to modify behaviors more precisely.</p>
<p><iframe loading="lazy" title="Maxon One Spring 2024 Release" width="500" height="281" src="https://www.youtube.com/embed/4ySqAzYSRms?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>This integration unlocks the ability to orchestrate object interactions with different simulation types, including Pyro, Cloth, soft bodies and rigid bodies. These simulations run considerably faster depending on the RTX GPU in use.</p>
<p>The <a href="https://www.nvidia.com/en-us/ai-data-science/audio2face/">NVIDIA Omniverse Audio2Face</a> app for iClone 8 uses AI to produce expressive facial animations solely from audio input. In addition to generating natural lip-sync animations for multilingual dialogue, the latest standalone release supports multilingual lip-sync and singing animations, as well as full-spectrum editing with slider controls and a keyframe editor.</p>
<p><iframe loading="lazy" title="Audio2Face - AI-Powered Facial &amp; Lip Sync Animation | iClone" width="500" height="281" src="https://www.youtube.com/embed/ScMb1f1M9yU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Along with accurate lip-sync, facial animations are significantly enhanced by nuanced facial expressions. Pairing Audio2Face with the iClone AccuFACE plug-in, powered by NVIDIA Maxine, Reallusion provides a flexible and multifaceted approach to facial animation, laying the groundwork with audio tracks and adding subtle expressions with webcams.</p>
<p>These latest AI-powered tools and creative app power ups are available for NVIDIA and GeForce RTX GPU owners.</p>
<h2><b>All Things Small, Bright and Beautiful</b></h2>
<p>China-based 3D visual effects artist Yao Chan finds inspiration and joy in the small things in life.</p>
<p>“As the weather gradually warms up, everything is rejuvenating and flowers are blooming,” said Chan. “I want to create an illustration that captures the warm and bright atmosphere of spring.”</p>
<p>Her 3D scene <i>By the Window</i> closely resembles a corner of her home filled with various succulent plants, pots and neatly arranged gardening tools.</p>
<p>“I think everyone has a place or moment that warms their heart in one way or another, and that&#8217;s an emotion I want to share with my audience,” said the artist.</p>
<p>Chan usually first sketches out her ideas in Adobe Photoshop, but with her real-life reference already set, she dove right into blocking out the scene in Blender.</p>
<p>Since she wanted to use a hand-painted texture style for modeling the vases and pots, Chan added Blender&#8217;s displace modifier and used a Voronoi texture to give the shapes a handcrafted effect.</p>
<figure id="attachment_71710" aria-describedby="caption-attachment-71710" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-particles-1280w.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-71710" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-particles-1280w-672x271.jpg" alt="" width="672" height="271" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-particles-1280w-672x271.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-particles-1280w-400x162.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-particles-1280w-768x310.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-particles-1280w-842x340.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-particles-1280w-406x164.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-particles-1280w-188x76.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-particles-1280w.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71710" class="wp-caption-text">Chan used hair from the particle system and played with roughness, kink and hair shape effects to accurately model fluffy plants like Kochia scoparia and moss.</figcaption></figure>
<p>Blender Cycles’ RTX-accelerated OptiX ray tracing in the viewport, unlocked by Chan’s GeForce RTX GPU, ensured smooth, interactive modeling throughout her creative workflow.</p>
<figure id="attachment_71713" aria-describedby="caption-attachment-71713" style="width: 366px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-clay-wire-render-1280w.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-71713" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-clay-wire-render-1280w-366x500.jpg" alt="" width="366" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-clay-wire-render-1280w-366x500.jpg 366w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-clay-wire-render-1280w-293x400.jpg 293w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-clay-wire-render-1280w-768x1048.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-clay-wire-render-1280w-1125x1536.jpg 1125w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-clay-wire-render-1280w-330x450.jpg 330w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-clay-wire-render-1280w-158x215.jpg 158w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-clay-wire-render-1280w-73x100.jpg 73w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-clay-wire-render-1280w.jpg 1280w" sizes="(max-width: 366px) 100vw, 366px" /></a><figcaption id="caption-attachment-71713" class="wp-caption-text">Modeling and mesh work — complete.</figcaption></figure>
<p>For texturing, Chan referred to former <i>In the NVIDIA Studio</i> featured artist <a href="https://www.youtube.com/watch?v=UfSw6428bcc&amp;t=174s">SouthernShotty’s tutorial</a>, using the precision of geometry nodes to highlight the structure of objects and gradient nodes to control the color and transparency of plants.</p>
<figure id="attachment_71716" aria-describedby="caption-attachment-71716" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-node-zone-1280w.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-71716" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-node-zone-1280w-672x361.jpg" alt="" width="672" height="361" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-node-zone-1280w-672x361.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-node-zone-1280w-400x215.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-node-zone-1280w-768x413.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-node-zone-1280w-837x450.jpg 837w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-node-zone-1280w-186x100.jpg 186w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-node-zone-1280w.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71716" class="wp-caption-text">Chan entered the node zone in Blender.</figcaption></figure>
<p>Chan then used the “pointiness” node to simulate the material of ceramic flower pots.</p>
<figure id="attachment_71719" aria-describedby="caption-attachment-71719" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-pointiness-node-1280w.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-71719" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-pointiness-node-1280w-672x340.jpg" alt="" width="672" height="340" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-pointiness-node-1280w-672x340.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-pointiness-node-1280w-400x203.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-pointiness-node-1280w-768x389.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-pointiness-node-1280w-842x426.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-pointiness-node-1280w-406x206.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-pointiness-node-1280w-188x95.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-pointiness-node-1280w.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71719" class="wp-caption-text">The “pointiness” node helped simulate materials.</figcaption></figure>
<p>Lighting was fairly straightforward, consisting of sunlight, a warm-toned key light, a cool-toned fill light and a small light source to illuminate the area beneath the table.</p>
<figure id="attachment_71722" aria-describedby="caption-attachment-71722" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-lights-1280w.jpg-scaled.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-71722" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-lights-1280w.jpg-672x357.jpg" alt="" width="672" height="357" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-lights-1280w.jpg-672x357.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-lights-1280w.jpg-400x213.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-lights-1280w.jpg-768x408.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-lights-1280w.jpg-1536x817.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-lights-1280w.jpg-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-lights-1280w.jpg-842x448.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-lights-1280w.jpg-404x215.jpg 404w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-lights-1280w.jpg-188x100.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-lights-1280w.jpg-1280x681.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71722" class="wp-caption-text">Several lights added brightness to the scene.</figcaption></figure>
<p>Chan also added a few volume lights in front of the camera.</p>
<figure id="attachment_71725" aria-describedby="caption-attachment-71725" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-side-lights-1280w.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-71725" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-side-lights-1280w-672x425.jpg" alt="" width="672" height="425" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-side-lights-1280w-672x425.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-side-lights-1280w-400x253.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-side-lights-1280w-768x485.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-side-lights-1280w-712x450.jpg 712w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-side-lights-1280w-340x215.jpg 340w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-side-lights-1280w-158x100.jpg 158w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-side-lights-1280w.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71725" class="wp-caption-text">Lighting from the side.</figcaption></figure>
<p>Finally, to give the image a more vintage look, Chan added noise to the final rendered image in compositing.</p>
<figure id="attachment_71728" aria-describedby="caption-attachment-71728" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-compositing-1280w.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-71728" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-compositing-1280w-672x478.jpg" alt="" width="672" height="478" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-compositing-1280w-672x478.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-compositing-1280w-400x285.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-compositing-1280w-768x547.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-compositing-1280w-632x450.jpg 632w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-compositing-1280w-302x215.jpg 302w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-compositing-1280w-141x100.jpg 141w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-compositing-1280w.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71728" class="wp-caption-text">Final compositing work.</figcaption></figure>
<p>Chan’s AI-powered simulations and viewport renderings were powered by her RTX GPU.</p>
<p>“RTX GPUs accelerate workflows and ensure fluent video editing,” she said.</p>
<p>Check out Chan’s latest work on <a href="https://www.instagram.com/magicwandyc/">Instagram</a>.</p>
<figure id="attachment_71731" aria-describedby="caption-attachment-71731" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-featured-setup-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-71731" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-featured-setup-1280w-672x183.png" alt="" width="672" height="183" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-featured-setup-1280w-672x183.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-featured-setup-1280w-400x109.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-featured-setup-1280w-768x209.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-featured-setup-1280w-842x230.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-featured-setup-1280w-406x111.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-featured-setup-1280w-188x51.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/05/studio-itns-yao-chan-wk110-featured-setup-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71731" class="wp-caption-text">3D artist Yao Chan.</figcaption></figure>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>X</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>. </i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/chan-nv-blog-header-preview-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/chan-nv-blog-header-preview-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[A Superbloom of Updates in the May Studio Driver Gives Fresh Life to Content Creation]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Every Company to Be an ‘Intelligence Manufacturer,’ Declares NVIDIA CEO Jensen Huang at Dell Technologies World</title>
		<link>https://blogs.nvidia.com/blog/dell-technologies-world-2024/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Mon, 20 May 2024 23:29:50 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71704</guid>

					<description><![CDATA[AI heralds a new era of innovation for every business in every industry, NVIDIA founder and CEO Jensen Huang said Monday during an appearance at Dell Technologies World. “We now have the ability to manufacture intelligence,” Huang said during an on-stage conversation with Dell CEO Michael Dell. “The last industrial revolution was the manufacturing of	<a class="read-more" href="https://blogs.nvidia.com/blog/dell-technologies-world-2024/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>AI heralds a new era of innovation for every business in every industry, NVIDIA founder and CEO Jensen Huang said Monday during an appearance at Dell Technologies World.</p>
<p>“We now have the ability to manufacture intelligence,” Huang said during an on-stage conversation with Dell CEO Michael Dell. “The last industrial revolution was the manufacturing of software; previously, it was manufacturing electricity — now we are manufacturing intelligence.”<br />
<i><br />
</i>Together with Michael Dell, ServiceNow CEO Bill McDermott and Samsung SDS President and CEO Hwang Sung-woo, Huang shared his insights on the transformative impact of generative AI on the global economy and various industries.</p>
<div class="docos-collapsible-replyview">
<div class="docos-replyview-static">
<div class="docos-replyview-body docos-anchoredreplyview-body docos-replyview-body-emoji-reactable docos-replyview-body-emoji-reactable-background" dir="ltr">“Every company at its foundation is intelligence — fundamentally every company is an intelligence manufacturer,” Huang emphasized, underscoring the potential of AI to create digital intelligence.</div>
</div>
</div>
<p><a href="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.dell.com%2Fen-us%2Fdt%2Fevents%2Fdelltechnologiesworld%2F2024%2Findex.htm%3Fdgc%3Dst%26cid%3Drsaad%26lid%3Dq1_home%26refid%3Dst_rsaad_q1_home%26gad_source%3D1%26hve%3Dwatch%2Bthe%2Breplay%26_gl%3D1*189qxh8*_up*MQ..%26gclid%3DEAIaIQobChMI5IyMofidhgMVxBitBh13UQM4EAAYASAAEgLoiPD_BwE%26gclsrc%3Daw.ds%23on-demand&amp;data=05%7C02%7Cbcaulfield%40nvidia.com%7C0ef9046ef90f451684f908dc7951b940%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638518639175880391%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=dyjIZobbpy5MKujA0kd7liufLiQmE%2BVwWfStFcaYKRI%3D&amp;reserved=0">During the keynote</a>, Dell and NVIDIA announced a slew of updates to the Dell AI Factory.</p>
<p>This includes the Dell PowerEdge XE9680L server with liquid cooling and eight NVIDIA Blackwell Tensor Core GPUs, the industry’s densest, energy-efficient rack-scale solutions for large Blackwell GPU deployments.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-large wp-image-71758" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Dell-AI-Factory-672x302.jpg" alt="" width="672" height="302" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/Dell-AI-Factory-672x302.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Dell-AI-Factory-400x180.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Dell-AI-Factory-768x346.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Dell-AI-Factory-1536x691.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Dell-AI-Factory-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Dell-AI-Factory-842x379.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Dell-AI-Factory-406x183.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Dell-AI-Factory-188x85.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Dell-AI-Factory-1280x576.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></p>
<p>The Dell NativeEdge platform will automate the delivery of <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> software, helping developers and IT operators easily deploy AI applications and solutions at the edge. Advancements also include the ability to simplify AI application development for faster time to value with the integration of <a href="https://www.nvidia.com/en-us/ai/">NVIDIA NIM</a> inference microservices, deployment automation and more.</p>
<p>Huang discussed the concept of an AI factory, likening it to the factories of the last industrial revolution that used water to produce electricity. In the current industrial revolution, data centers act as AI factories, transforming data and electricity into valuable data tokens distributed globally.</p>
<p>“What has happened is instead of just producing software, we’re now producing intelligence — that intelligence is formulated in the form of tokens that can then be expressed in any information modality that we’d like it to be,” Huang explained.</p>
<p>Huang underscored the importance of full-stack accelerated computing to enable this, noting NVIDIA’s advancements.</p>
<p>Together, NVIDIA and Dell are providing the world’s industries with a full-stack offering — including computing, networking, storage, services and software — that drives copilots, coding assistants, virtual customer service agents and industrial digital twins.</p>
<p><a href="https://www.google.com/url?q=https://www.dell.com/en-us/dt/corporate/newsroom/announcements/detailpage.press-releases~usa~2024~05~20240520-dell-technologies-expands-dell-ai-factory-with-nvidia-to-turbocharge-ai-adoption.htm&amp;sa=D&amp;source=docs&amp;ust=1716246952240677&amp;usg=AOvVaw239ghwfccj07Z8HHelPXR6">Michael Dell introduced the latest innovations for the Dell AI Factory with NVIDIA</a>, emphasizing their ability to simplify and accelerate customers’ AI journeys.</p>
<p>“We are unleashing this super genius power. Everyone is going to have access to this technology — and it&#8217;s gonna get smarter,” Dell said.</p>
<p>The Dell AI Factory with NVIDIA, announced earlier this year, offers a full stack of AI solutions from data center to edge, enabling organizations to quickly adopt and deploy AI at scale.</p>
<p>This platform integrates Dell’s AI capabilities with NVIDIA’s cutting-edge technologies, providing customers with an expansive AI portfolio and an open ecosystem of technology partners.</p>
<p>The Dell AI Factory, based on the NVIDIA partnership, will help establish <a href="https://blogs.nvidia.com/blog/what-is-sovereign-ai/">AI sovereignty</a> for countries by enabling strong data security and customized AI service development.</p>
<p>Together, Dell and NVIDIA will bring these capabilities to companies, help stand it up, and help develop new applications that enterprises can deploy, Huang said.</p>
<p>“Our partnership between us is really about that, literally from the ground up building AI factories and delivering it to the world’s enterprises as a solution,” Huang said.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/Jensen-Huang-Michael-Dell-Dell-Technologies-World-2024-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1365"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/Jensen-Huang-Michael-Dell-Dell-Technologies-World-2024-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Every Company to Be an ‘Intelligence Manufacturer,’ Declares NVIDIA CEO Jensen Huang at Dell Technologies World]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Fight for Honor in ‘Men of War II’ on GFN Thursday</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-men-of-war-ii/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 16 May 2024 13:00:10 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71656</guid>

					<description><![CDATA[Whether looking for new adventures, epic storylines or games to play with a friend, GeForce NOW members are covered. Start off with the much-anticipated sequel to the Men of War franchise or cozy up with some adorable pals in Palworld, both part of five games GeForce NOW is bringing to the cloud this week. No	<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-men-of-war-ii/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Whether looking for new adventures, epic storylines or games to play with a friend, <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> members are covered.</p>
<p>Start off with the much-anticipated sequel to the <i>Men of War</i> franchise or cozy up with some adorable pals in <i>Palworld</i>, both part of five games GeForce NOW is bringing to the cloud this week.</p>
<h2><b>No Guts, No Glory</b></h2>
<figure id="attachment_71660" aria-describedby="caption-attachment-71660" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71660" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/ss_cfb771929a3736ef501677344303ae60b1e4fe6a-672x378.jpg" alt="Men of War II on GeForce NOW screenshot" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/ss_cfb771929a3736ef501677344303ae60b1e4fe6a-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/ss_cfb771929a3736ef501677344303ae60b1e4fe6a-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/ss_cfb771929a3736ef501677344303ae60b1e4fe6a-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/ss_cfb771929a3736ef501677344303ae60b1e4fe6a-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/ss_cfb771929a3736ef501677344303ae60b1e4fe6a-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/05/ss_cfb771929a3736ef501677344303ae60b1e4fe6a-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/05/ss_cfb771929a3736ef501677344303ae60b1e4fe6a-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/05/ss_cfb771929a3736ef501677344303ae60b1e4fe6a-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/05/ss_cfb771929a3736ef501677344303ae60b1e4fe6a-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71660" class="wp-caption-text"><em>For the cloud!</em></figcaption></figure>
<p>Get transported to the battlefields of World War II with historical accuracy and attention to detail in <i>Men of War II</i>, the newest entry in the real-time strategy series from Fulqrum Publishing.</p>
<p>The game features an extensive roster of units, including tanks, airplanes and infantry. With advanced enemy AI and diverse gameplay modes, <i>Men of War II</i> promises an immersive experience for both history enthusiasts and casual gamers.</p>
<p>Gear up, strategize and prepare to rewrite history. Get an extra fighting chance with a GeForce NOW Ultimate membership, which streams at up to 4K resolution and provides longer gaming sessions and faster access to games over a free membership.</p>
<h2><b>Cloud Pals</b></h2>
<figure id="attachment_71663" aria-describedby="caption-attachment-71663" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71663" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-palworld-tw-li-2048x1024-1-672x336.jpg" alt="Palworld on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-palworld-tw-li-2048x1024-1-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-palworld-tw-li-2048x1024-1-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-palworld-tw-li-2048x1024-1-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-palworld-tw-li-2048x1024-1-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-palworld-tw-li-2048x1024-1-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-palworld-tw-li-2048x1024-1-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-palworld-tw-li-2048x1024-1-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-palworld-tw-li-2048x1024-1-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-palworld-tw-li-2048x1024-1.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71663" class="wp-caption-text"><em>Pal around in the cloud.</em></figcaption></figure>
<p>Step into a world teeming with enigmatic creatures known as “Pals” in the action-adventure survival game <i>Palworld</i> from Pocketpair. Navigate the wilderness, gather resources and construct a base to capture, tame and train Pals, each with distinct abilities. Explore the world, uncover secrets and forge alliances or rivalries with other survivors in online co-op play mode.</p>
<p>Embark on adventure with these trusty Pals through a GeForce NOW membership. With a Priority membership, enjoy up to six hours of uninterrupted gaming sessions, while Ultimate members can extend their playtime to eight hours.</p>
<h2><b>Master New Games</b></h2>
<figure id="attachment_71667" aria-describedby="caption-attachment-71667" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71667" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-die-by-the-blade-tw-li-2048x1024-1-672x336.jpg" alt="Die By The Blade on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-die-by-the-blade-tw-li-2048x1024-1-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-die-by-the-blade-tw-li-2048x1024-1-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-die-by-the-blade-tw-li-2048x1024-1-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-die-by-the-blade-tw-li-2048x1024-1-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-die-by-the-blade-tw-li-2048x1024-1-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-die-by-the-blade-tw-li-2048x1024-1-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-die-by-the-blade-tw-li-2048x1024-1-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-die-by-the-blade-tw-li-2048x1024-1-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-die-by-the-blade-tw-li-2048x1024-1.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71667" class="wp-caption-text"><em>More than a one-hit wonder.</em></figcaption></figure>
<p>Vanquish foes with a single strike in 1v1 weapon-based fighter <i>Die by the Blade </i>from Grindstone. Dive into a samurai punk world and wield a range of traditional Japanese weapons. Take up arms and crush friends in local or online multiplayer, or take on unknown warriors in online ranked matches. Outwit opponents in intense, tactical battles and master the art of the one-hit kill.</p>
<p>Check out the list of new games this week:</p>
<ul>
<li><i>Men of War II </i>(New release on <a href="https://store.steampowered.com/app/1128860?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 15)</li>
<li><i>Die by the Blade </i>(New release on <a href="https://store.steampowered.com/app/1154670?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 16)</li>
<li><i>Colony Survival </i>(<a href="https://store.steampowered.com/app/366090?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Palworld </i>(<a href="https://store.steampowered.com/app/1623730?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.xbox.com/en-us/games/store/palworld-game-preview/9nkv34xdw014">Xbox</a>, available on PC Game Pass)</li>
<li><i>Tomb Raider: Definitive Edition </i>(<a href="https://www.xbox.com/games/store/tomb-raider-definitive-edition/bqxts0sx4w0n?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">If you could be any video game character for a day, who would you choose and what would you do? <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f914.png" alt="🤔" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1790774139017412713?ref_src=twsrc%5Etfw">May 15, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-thursday-5-16-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-thursday-5-16-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Fight for Honor in ‘Men of War II’ on GFN Thursday]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA, Teradyne and Siemens Gather in the ‘City of Robotics’ to Discuss Autonomous Machines and AI</title>
		<link>https://blogs.nvidia.com/blog/nvidia-teradyne-siemens-robotics-autonomous-machines-ai/</link>
		
		<dc:creator><![CDATA[Gerard Andrews]]></dc:creator>
		<pubDate>Wed, 15 May 2024 21:31:13 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Digital Twin]]></category>
		<category><![CDATA[Industrial and Manufacturing]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71646</guid>

					<description><![CDATA[Senior executives from NVIDIA, Siemens and Teradyne Robotics gathered this week in Odense, Denmark, to mark the launch of Teradyne Robotics’ new headquarters and discuss the massive advances coming to the robotics industry. One of Denmark’s oldest cities and known as the city of robotics, Odense is home to over 160 robotics companies with 3,700	<a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-teradyne-siemens-robotics-autonomous-machines-ai/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Senior executives from NVIDIA, Siemens and Teradyne Robotics gathered this week in Odense, Denmark, to mark the launch of Teradyne Robotics’ new headquarters and discuss the massive advances coming to the <a href="https://www.nvidia.com/en-us/industries/robotics/" target="_blank" rel="noopener">robotics industry</a>.</p>
<p>One of Denmark’s oldest cities and known as the city of robotics, Odense is home to over 160 robotics companies with 3,700 employees and contributes profoundly to the industry’s progress.</p>
<p>Teradyne Robotics’ new hub there, which includes cobot company Universal Robots (UR) and autonomous mobile robot (AMR) company MiR, is set to help employees maximize collaborative efforts, foster innovation and provide an environment to revolutionize advanced robotics and autonomous machines.</p>
<p>The grand opening showcased the latest AI robotic applications and featured a <a href="https://www.youtube.com/watch?v=llKhAC5ncfs">panel discussion</a> on the future of advanced robotics. Speakers included Ujjwal Kumar, group president at Teradyne Robotics; Rainer Brehm, CEO of Siemens Factory Automation; and Deepu Talla, vice president of robotics and edge computing at NVIDIA.</p>
<p>“The advent of generative AI coupled with simulation and digital twins technology is at a tipping point right now, and that combination is going to change the trajectory of robotics,” commented Talla.</p>
<p><iframe loading="lazy" title="The Future of Advanced Robotics feat. NVIDIA, SIEMENS and TERADYNE" width="500" height="281" src="https://www.youtube.com/embed/llKhAC5ncfs?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<h2><b>The Power of Partnerships</b></h2>
<p>The discussion comes as the global robotics market continues to grow rapidly. The <a href="https://statzon.com/insights/global-collaborative-robot-market">cobots market in Europe</a> was valued at $286 million in 2022 and is projected to reach $6.7 billion by 2032, at a yearly growth rate of more than 37%.</p>
<p>Panelists discussed why teaming up is key to innovation for any company — whether a startup or an enterprise — and how physical AI is being used across businesses and workplaces, stressing the game-changing impact of advanced robotics.</p>
<p>The alliance between NVIDIA and Teradyne Robotics, which includes an AI-based intra-logistics solution alongside Siemens, showcases the strength of collaboration across the ecosystem. NVIDIA’s prominent role as a physical AI hardware provider is boosting the cobot and AMR sectors with accelerated computing, while its collaboration with <a href="https://www.nvidia.com/en-us/industries/industrial-sector/siemens/">Siemens</a> is transforming industrial automation.</p>
<p>“NVIDIA provides all the core AI capabilities that get integrated into the hundreds and thousands of companies building robotic platforms and robots, so our approach is 100% collaboration,” Talla said.</p>
<p>“What excites me most about AI and robots is that collaboration is at the core of solving our customers’ problems,” Kumar added. “No one company has all the technologies needed to address these problems, so we must work together to understand and solve them at a very fast pace.”</p>
<h2><b>Accelerating Innovation With AI </b></h2>
<p>AI has already made huge strides across industries and plays an important role in enhancing advanced robotics. Leveraging machine learning, computer vision and natural language processing, AI gives robots the cognitive capability to understand, learn and make decisions.</p>
<p>“For humans, we have our senses, but it’s not that easy for a robot, so you have to build these AI capabilities for autonomous navigation,” Talla said. “<a href="https://developer.nvidia.com/isaac" target="_blank" rel="noopener">NVIDIA’s Isaac platform</a> is enabling increased autonomy in robotics with rapid advancements in simulation, generative AI, foundation models and optimized edge computing.”</p>
<p>NVIDIA is working closely with the UR team to infuse AI into UR’s robotics software technology. In the case of <a href="https://blogs.nvidia.com/blog/isaac-amr-nova-orin-autonomous-mobile-robots/" target="_blank" rel="noopener">autonomous mobile robots</a> that move things from point A to B to C, it’s all about operating in unstructured environments and navigating autonomously.</p>
<p>Brehm emphasized the need to scale AI by industrializing it, allowing for automated deployment, inference and monitoring of models — making AI easily accessible on the shopfloor. He spoke about empowering customers to utilize AI effortlessly, even without AI expertise. “Our goal is to advance automation, moving towards a system that leverages skills-based automation in the future,” he said.</p>
<p>As a leading robotics company with one of the largest installed bases of collaborative and AMRs, Teradyne has identified a long list of industry problems and is working closely with NVIDIA to solve them.</p>
<p>“I use the term ‘physical AI’ as opposed to ‘digital AI’ because we are taking AI to a whole new level by applying it in the physical world,” said Kumar. “We see it helping our customers in three ways: adding new capabilities to our robots, making our robots smarter with advanced path planning and navigation, and further enhancing the safety and reliability of our collaborative robots.”</p>
<h2><b>The Impact of Real-World Robotics</b></h2>
<p>Autonomous machines, or AI robots, are already making a noticeable difference in the real world, from industries to our daily lives. Industries such as <a href="https://www.nvidia.com/en-us/industries/manufacturing/">manufacturing</a> are using advanced robotics to enhance efficiency, accuracy and productivity.</p>
<p>Companies want to produce goods close to where they are consumed, with sustainability being a key driver. But this often means setting up shop in high-cost countries. The challenge is twofold: producing at competitive prices and dealing with shrinking, aging workforces that are less available for factory jobs.</p>
<p>“The problem for large manufacturers is the same as what small and medium manufacturers have always faced: variability,” Kumar said. “High-volume industrial robots don’t suit applications requiring continuous design tweaks. Collaborative robots combined with AI offer solutions to the pain points that small and medium customers have lived with for years, and to the new challenges now faced by large manufacturers.”</p>
<p>Automation isn’t just about making things faster; it’s also about making the most of the workforce. In manufacturing, automation aids smoother processes, ramps up safety, saves time and relieves pressure on employees.</p>
<p>“Automation is crucial for solving problems and, to get there, AI is a game-changer. If you don’t have the people who want to work in the factory, and you don&#8217;t have the people to program the automation, you won’t have the flexibility to automate what you need in the future. And that’s what drives our customers,” Brehm said.</p>
<p>AI and computing technologies are set to redefine the robotics landscape, transforming robots from mere tools to intelligent partners capable of autonomy and adaptability across industries.</p>
<p><i>Feature image by Steffen Stamp. Left to right: Fleur Nielsen, head of communications at Universal Robots; Deepu Talla, head of robotics at NVIDIA; Rainer Brehm, CEO of Siemens Factory Automation; and Ujjwal Kumar, president of Teradyne Robotics.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/R2.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/R2-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA, Teradyne and Siemens Gather in the ‘City of Robotics’ to Discuss Autonomous Machines and AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Needle-Moving AI Research Trains Surgical Robots in Simulation</title>
		<link>https://blogs.nvidia.com/blog/orbit-surgical-robotics-research-icra/</link>
		
		<dc:creator><![CDATA[Isha Salian]]></dc:creator>
		<pubDate>Wed, 15 May 2024 13:00:54 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[Isaac]]></category>
		<category><![CDATA[NVIDIA Research]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Scientific Visualization]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<category><![CDATA[Social Impact]]></category>
		<category><![CDATA[Synthetic Data Generation]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71604</guid>

					<description><![CDATA[A collaboration between NVIDIA and academic researchers is prepping robots for surgery. ORBIT-Surgical — developed by researchers from the University of Toronto, UC Berkeley, ETH Zurich, Georgia Tech and NVIDIA — is a simulation framework to train robots that could augment the skills of surgical teams while reducing surgeons’ cognitive load. It supports more than	<a class="read-more" href="https://blogs.nvidia.com/blog/orbit-surgical-robotics-research-icra/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>A collaboration between NVIDIA and academic researchers is prepping robots for surgery.</p>
<p>ORBIT-Surgical — developed by researchers from the University of Toronto, UC Berkeley, ETH Zurich, Georgia Tech and NVIDIA — is a simulation framework to train robots that could augment the skills of surgical teams while reducing surgeons’ cognitive load.</p>
<p>It supports more than a dozen maneuvers inspired by the training curriculum for laparoscopic procedures, aka minimally invasive surgery, such as grasping small objects like needles, passing them from one arm to another and placing them with high precision.</p>
<p>The physics-based framework was built using <a href="https://developer.nvidia.com/isaac/sim">NVIDIA Isaac Sim</a>, a robotics simulation platform for designing, training and testing AI-based robots. The researchers trained reinforcement learning and imitation learning algorithms on NVIDIA GPUs and used <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, a platform for developing and deploying advanced 3D applications and pipelines based on <a href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description</a> (OpenUSD), to enable photorealistic rendering.</p>
<p>Using the community-supported da Vinci Research Kit, provided by the Intuitive Foundation, a nonprofit supported by robotic surgery leader Intuitive Surgical, the ORBIT-Surgical research team demonstrated how training a <a href="https://blogs.nvidia.com/blog/what-is-a-digital-twin/">digital twin</a> in simulation transfers to a physical robot in a lab environment in the video below.</p>
<p><iframe loading="lazy" title="ORBIT-Surgical: An Open-Simulation Framework for Learning Surgical Augmented Dexterity" width="500" height="281" src="https://www.youtube.com/embed/NA3xCRHcZsE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>ORBIT-Surgical will be <a href="https://ras.papercept.net/conferences/conferences/ICRA24/program/ICRA24_ContentListWeb_3.html" target="_blank" rel="noopener">presented Thursday at ICRA</a>, the IEEE International Conference on Robotics and Automation, taking place this week in Yokohama, Japan. The open-source code package is <a href="https://orbit-surgical.github.io/" target="_blank" rel="noopener">now available on GitHub</a>.</p>
<h2><b>A Stitch in AI Saves Nine</b></h2>
<p>ORBIT-Surgical is based on <a href="https://docs.omniverse.nvidia.com/isaacsim/latest/isaac_gym_tutorials/ext_omni_isaac_orbit.html">Isaac Orbit</a>, a modular framework for robot learning built on Isaac Sim. Orbit includes support for various libraries for <a href="https://blogs.nvidia.com/blog/deep-reinforcement-learning-gpus-robotics/">reinforcement learning</a> and imitation learning, where AI agents are trained to mimic ground-truth expert examples.</p>
<p>The surgical framework enables developers to train robots like the da Vinci Research Kit robot, or dVRK, to manipulate both rigid and soft objects using reinforcement learning and imitation learning frameworks running on <a href="https://www.nvidia.com/en-us/design-visualization/desktop-graphics/">NVIDIA RTX GPUs</a>.</p>
<p>ORBIT-Surgical introduces more than a dozen benchmark tasks for surgical training, including one-handed tasks such as picking up a piece of gauze, inserting a shunt into a blood vessel or lifting a suture needle to a specific position. It also includes two-handed tasks, like handing a needle from one arm to another, passing a threaded needle through a ring pole and reaching two arms to specific positions while avoiding obstacles.</p>
<div style="width: 1920px;" class="wp-video"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video class="wp-video-shortcode" id="video-71604-1" width="1920" height="1080" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Shunt-Insertion_Real-Sim.mp4?_=1" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/Shunt-Insertion_Real-Sim.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/05/Shunt-Insertion_Real-Sim.mp4</a></video></div>
<p><em>One of ORBIT-Surgical&#8217;s benchmark tests is inserting a shunt — shown on left with a real-world robot and on right in simulation. </em></p>
<p>By developing a surgical simulator that takes advantage of GPU acceleration and parallelization, the team is able to boost robot learning speed by an order of magnitude compared to existing surgical frameworks. They found that the robot digital twin could be trained to complete tasks like inserting a shunt and lifting a suture needle in under two hours on a single NVIDIA RTX GPU.</p>
<p>With the visual realism enabled by rendering in Omniverse, ORBIT-Surgical also allows researchers to generate high-fidelity synthetic data, which could help train AI models for perception tasks such as segmenting surgical tools in real-world videos captured in the operating room.</p>
<p>A proof of concept by the team showed that combining simulation and real data significantly improved the accuracy of an AI model to segment surgical needles from images — helping reduce the need for large, expensive real-world datasets for training such models.</p>
<p>Read the <a href="https://arxiv.org/pdf/2404.16027" target="_blank" rel="noopener">paper behind ORBIT-Surgical</a>, and learn more about <a href="https://developer.nvidia.com/blog/nvidia-presents-new-robotics-research-on-geometric-fabrics-surgical-robots-and-more-at-icra/">NVIDIA-authored papers at ICRA</a>.</p>
]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/05/Shunt-Insertion_Real-Sim.mp4" length="9570370" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/Threaded-Needle-still.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/Threaded-Needle-still-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Needle-Moving AI Research Trains Surgical Robots in Simulation]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>How Basecamp Research Helps Catalog Earth’s Biodiversity</title>
		<link>https://blogs.nvidia.com/blog/basecamp-research/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Wed, 15 May 2024 13:00:45 +0000</pubDate>
				<category><![CDATA[The AI Podcast]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71605</guid>

					<description><![CDATA[Basecamp Research is on a mission to capture the vastness of life on Earth at an unprecedented scale. Phil Lorenz, CTO at Basecamp Research, discusses using AI and biodiversity data to advance fields like medicine and environmental conservation with host Noah Kravitz in this AI Podcast episode recorded live at the NVIDIA GTC global AI	<a class="read-more" href="https://blogs.nvidia.com/blog/basecamp-research/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><span>Basecamp Research is on a mission to capture the vastness of life on Earth at an unprecedented scale. Phil Lorenz, CTO at Basecamp Research, discusses using AI and biodiversity data to advance fields like medicine and environmental conservation with host Noah Kravitz in this </span><a href="https://soundcloud.com/theaipodcast"><span>AI Podcast</span></a><span> episode recorded live at the </span><a href="https://www.nvidia.com/gtc/"><span>NVIDIA GTC</span></a><span> global AI conference. Lorenz explains Basecamp’s systematic collection of biodiversity data in partnership with nature parks worldwide and its use of deep learning to analyze and apply it for use cases such as protein structure prediction and gene editing. He also emphasizes the importance of ethical data governance and touches on technological advancements that will help drive the future of AI in biology. </span></p>
<p><span>Basecamp Research is a member of the </span><a href="https://www.nvidia.com/startups/?nvid=nv-int-tblg-295718-vt33"><span>NVIDIA Inception</span></a><span> program for cutting-edge startups. </span></p>
<p><span>Stay tuned for more episodes recorded live at GTC, and hear more from Lorenz in this </span><a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s61365/"><span>GTC session</span></a><span>.</span></p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1821274848%3Fsecret_token%3Ds-Qhi5VhaREqk&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="Basecamp's Phil Lorenz on Combining AI With Biodiversity Data - Ep. 223" href="https://soundcloud.com/theaipodcast/basecamp-phil-lorenz/s-Qhi5VhaREqk" target="_blank" rel="noopener">Basecamp&#8217;s Phil Lorenz on Combining AI With Biodiversity Data &#8211; Ep. 223</a></div>
<h2><b>Time Stamps</b></h2>
<p>1:31: What is Basecamp Research?<br />
3:08: How does the process of sequencing biodiversity work?<br />
5:15: What is the collected biodiversity data used for?<br />
7:56: Gene editing and how biodiversity data can enhance it<br />
9:00: How the development of AI has affected Basecamp’s work<br />
14:33: Basecamp’s breakthroughs<br />
16:49: AI and machine learning-related challenges Basecamp has encountered<br />
26:02: Ethical considerations in data collecting</p>
<h2><b>You Might Also Like…</b></h2>
<p><a href="https://soundcloud.com/theaipodcast/christopher-bretherton"><b>AI2’s Christopher Bretherton Discusses Using Machine Learning for Climate Modeling &#8211; Ep. 220</b><b><br />
</b><br />
</a>Can machine learning help predict extreme weather events and climate change? Christopher Bretherton, senior director of climate modeling at the Allen Institute for Artificial Intelligence, or AI2, explores the technology’s potential to enhance climate modeling.</p>
<p><a href="https://soundcloud.com/theaipodcast/cardiac-caristo-dr-keith-channon"><b>Cardiac Clarity: Dr. Keith Channon Talks Revolutionizing Heart Health With AI &#8211; Ep. 212</b></a></p>
<p>Here’s some news to still beating hearts: AI is helping bring some clarity to cardiology. In this episode of NVIDIA’s AI Podcast, Dr. Keith Channon, cofounder and chief medical officer at the startup, speaks with host Noah Kravitz about Caristo, an AI-powered solution for detecting inflammation in cardiac CT scans.</p>
<p><a href="https://soundcloud.com/theaipodcast/matice"><b>Matice Founder Jessica Whited on Harnessing Regenerative Species for Medical Breakthroughs &#8211; Ep. 198</b></a></p>
<p>Scientists at Matice Biosciences are using AI to study the regeneration of tissues in animals known as super-regenerators, such as salamanders and planarians. The research aims to develop new treatments that will help humans heal from injuries without scarring.</p>
<p><a href="https://soundcloud.com/theaipodcast/crowdsource"><b>Bojan Tunguz, Johnny Israeli on How AI and Crowdsourcing Can Advance Vaccine Distribution &#8211; Ep. 195</b></a></p>
<p>Artificial intelligence is teaming up with crowdsourcing to improve the thermo-stability of mRNA vaccines, making distribution more accessible worldwide. In this episode of NVIDIA&#8217;s AI podcast, host Noah Kravitz interviewed Bojan Tunguz, a physicist and senior system software engineer at NVIDIA, and Johnny Israeli, senior manager of AI and cloud software at NVIDIA, about AI’s potential in drug discovery.</p>
<h2><b>Subscribe to the AI Podcast</b></h2>
<p>Get the<a href="https://blogs.nvidia.com/ai-podcast/"> AI Podcast</a> through<a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439"> iTunes</a>,<a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjI2NDAzNDEzMy9zb3VuZHMucnNz"> Google Podcasts</a>,<a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm"> Google Play</a>, <a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">Amazon Music, </a><a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us">Castbox</a>, DoggCatcher,<a href="https://overcast.fm/itunes1186480811/the-ai-podcast"> Overcast</a>,<a href="https://player.fm/series/the-ai-podcast"> PlayerFM</a>, Pocket Casts,<a href="http://www.podbay.fm/show/1186480811"> Podbay</a>,<a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast"> PodBean</a>, PodCruncher, PodKicker,<a href="https://soundcloud.com/theaipodcast"> Soundcloud</a>,<a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L"> Spotify</a>,<a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr"> Stitcher</a> and<a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/"> TuneIn</a>.</p>
<p>Make the AI Podcast better: Have a few minutes to spare? Fill out<a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short"> this listener survey</a>.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/biodiversity-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1536"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/biodiversity-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[How Basecamp Research Helps Catalog Earth’s Biodiversity]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Fire It Up: Mozilla Firefox Adds Support for AI-Powered NVIDIA RTX Video</title>
		<link>https://blogs.nvidia.com/blog/ai-decoded-rtxvideo-firefox/</link>
		
		<dc:creator><![CDATA[Brian Choi]]></dc:creator>
		<pubDate>Wed, 15 May 2024 13:00:42 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[AI Decoded]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71641</guid>

					<description><![CDATA[Mozilla Firefox, the popular open-source browser, is the latest partner to incorporate NVIDIA RTX Video, a technology that uses AI to improve video quality on Windows PCs and workstations. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><em>Editor’s note: This post is part of the </em><a href="https://blogs.nvidia.com/blog/tag/ai-decoded/" target="_blank" rel="noopener"><em>AI Decoded series</em></a><em>, which demystifies AI by making the technology more accessible, and which showcases new hardware, software, tools and accelerations for RTX PC users.</em></p>
<p>Mozilla Firefox, the popular open-source browser, is the latest partner to incorporate NVIDIA RTX Video, a technology that uses AI to improve video quality on Windows PCs and workstations. The browser’s latest release taps local <a href="https://www.nvidia.com/en-us/design-visualization/desktop-graphics/" target="_blank" rel="noopener">NVIDIA RTX GPUs</a> to make streaming and video better than ever.</p>
<h2><strong>Pixel Perfect</strong></h2>
<p>First announced at CES in January 2023, RTX Video is a collection of AI video enhancements that improve the quality of videos played on browsers through platforms like YouTube, Prime Video and Disney+. The technology makes videos streamed on <a href="https://www.nvidia.com/en-us/geforce/rtx/" target="_blank" rel="noopener">NVIDIA GeForce RTX</a>-powered PCs and RTX-powered workstations appear sharper and more detailed without requiring a higher-resolution source.</p>
<p><iframe loading="lazy" title="Introducing RTX Video HDR: AI-Upscale Video to HDR Quality" width="500" height="281" src="https://www.youtube.com/embed/hlrk_qqqUNA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>RTX Video is made up of two parts. <a href="https://blogs.nvidia.com/blog/rtx-video-super-resolution/" target="_blank" rel="noopener">RTX Video Super Resolution</a> upscales low-resolution video for cleaner, crisper imagery. It works by analyzing the lower-resolution video and using deep learning to predict what the higher-resolution version should look like. The algorithm then combines this predicted image with a traditionally upscaled version to reduce or eliminate compression artifacts and sharpen the final output.</p>
<p><a href="https://blogs.nvidia.com/blog/rtx-video-hdr-remix-studio-driver/" target="_blank" rel="noopener">RTX Video HDR</a> goes one step further: when enabled, it analyzes standard dynamic range (SDR) video content through AI neural networks to add high-dynamic range (HDR) information, improving visibility, details and vibrancy.</p>
<p>Since 90% of video online is 1080p or lower and SDR, enabling RTX Video is like pushing the “remaster” button on most of the content users watch everyday.</p>
<h2><strong>Pretty Foxy</strong></h2>
<p>Mozilla Firefox now supports RTX Video Super Resolution and HDR in its latest stable version (v126). It’s never been easier for users to access AI-enhanced upscaling, de-artifacting and HDR effects for online videos.</p>
<p>“Video is a core pillar of the modern web, and we are committed to delivering a great experience for our users,” said Bobby Holley, chief technology officer of Firefox at Mozilla. “Mozilla is integrating RTX Video into Firefox to improve video quality for our users with compatible GPUs.”</p>
<p>Firefox joins other Chromium-based browsers, including Google Chrome and Microsoft Edge, in supporting RTX Video. RTX Video Super Resolution is also supported in popular video players like VLC.</p>
<p>Enabling RTX Video is easy:</p>
<ol>
<li>Update to the latest GeForce RTX Game Ready Driver, <a href="https://www.nvidia.com/en-us/studio/">NVIDIA Studio</a> or NVIDIA RTX Enterprise Driver.</li>
<li>Ensure Windows HDR features are enabled by navigating to System &gt; Display &gt; HDR.</li>
<li>Open the NVIDIA Control Panel and navigate to Adjust Video Image Settings &gt; RTX Video Enhancement.</li>
<li>Turn on “Super Resolution” and “High Dynamic Range.”</li>
</ol>
<p>Note that RTX Video HDR requires an NVIDIA GeForce RTX or RTX professional GPU connected to an HDR10-compatible monitor or TV.</p>
<p>For more information, check out the <a href="https://nvidia.custhelp.com/app/answers/detail/a_id/5448/~/rtx-video-faq" target="_blank" rel="noopener">RTX Video FAQ</a>.</p>
<p><em>Generative AI is transforming gaming, videoconferencing and interactive experiences of all kinds. Make sense of what’s new and what’s next by subscribing to the </em><a href="https://www.nvidia.com/en-us/ai-on-rtx/?modal=subscribe-ai" target="_blank" rel="noopener"><em>AI Decoded newsletter</em></a><em>.</em></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/firefox-rtx-video-nv-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/firefox-rtx-video-nv-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Fire It Up: Mozilla Firefox Adds Support for AI-Powered NVIDIA RTX Video]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Gemma, Meet NIM: NVIDIA Teams Up With Google DeepMind to Drive Large Language Model Innovation</title>
		<link>https://blogs.nvidia.com/blog/gemma-nim-google-deepmind/</link>
		
		<dc:creator><![CDATA[Dave Salvator]]></dc:creator>
		<pubDate>Tue, 14 May 2024 19:40:49 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[DGX Cloud]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[TensorRT]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71636</guid>

					<description><![CDATA[Large language models that power generative AI are seeing intense innovation — models that handle multiple types of data such as text, image and sounds are becoming increasingly common. However, building and deploying these models remains challenging. Developers need a way to quickly experience and evaluate models to determine the best fit for their use	<a class="read-more" href="https://blogs.nvidia.com/blog/gemma-nim-google-deepmind/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Large language models that power generative AI are seeing intense innovation — models that handle multiple types of data such as text, image and sounds are becoming increasingly common.</p>
<p>However, building and deploying these models remains challenging. Developers need a way to quickly experience and evaluate models to determine the best fit for their use case, and then optimize the model for performance in a way that not only is cost-effective but offers the best performance.</p>
<p>To make it easier for developers to create AI-powered applications with world-class performance, NVIDIA and Google today announced three new collaborations at Google I/O ‘24.</p>
<h2><b>Gemma + NIM</b></h2>
<p>Using <a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-supercharges-large-language-model-inference-on-nvidia-h100-gpus/">TensorRT-LLM</a>, NVIDIA is working with Google to optimize two new models it introduced at the event: Gemma 2 and PaliGemma. These models are built from the same research and technology used to create the Gemini models, and each is focused on a specific area:</p>
<ul>
<li><b>Gemma 2 </b>is the next generation of Gemma models for a broad range of use cases and features a brand new architecture designed for breakthrough performance and efficiency.</li>
<li><b>PaliGemma</b> is an open vision language model (VLM) inspired by <a href="https://arxiv.org/abs/2310.09199">PaLI-3</a>. Built on open components including the SigLIP vision model and the Gemma language model, PaliGemma is designed for vision-language tasks such as image and short video captioning, visual question answering, understanding text in images, object detection and object segmentation. PaliGemma is designed for class-leading fine-tuning performance on a wide range of vision-language tasks and is also supported by <a href="https://github.com/NVIDIA/JAX-Toolbox">NVIDIA JAX-Toolbox</a>.</li>
</ul>
<p>Gemma 2 and PaliGemma will be offered with <a href="https://www.nvidia.com/en-us/ai/">NVIDIA NIM</a> inference microservices, part of the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> software platform, which simplifies the deployment of AI models at scale. NIM support for the two new models are available from the API catalog, starting with <a href="https://build.nvidia.com/google/google-paligemma">PaliGemma</a> today; they soon will be released as containers on <a href="https://catalog.ngc.nvidia.com/">NVIDIA NGC</a> and GitHub.</p>
<h2><b>Bringing Accelerated Data Analytics to Colab</b></h2>
<p>Google also announced that <a href="https://developer.nvidia.com/blog/rapids-cudf-accelerates-pandas-nearly-150x-with-zero-code-changes/">RAPIDS cuDF, an open-source GPU dataframe library</a>, is now supported by default on Google Colab, one of the most popular developer platforms for data scientists. It now takes just a few seconds for <a href="https://blog.google/technology/ai/democratizing-access-to-ai-enabled-coding-with-colab/">Google Colab’s 10 million monthly users</a> to accelerate pandas-based Python workflows by up to 50x using <a href="https://www.nvidia.com/en-us/data-center/l4/">NVIDIA L4 Tensor Core GPUs</a>, with zero code changes.</p>
<p>With RAPIDS cuDF, developers using Google Colab can speed up exploratory analysis and production data pipelines. While pandas is one of the world’s most popular data processing tools due to its intuitive API, applications often struggle as their data sizes grow. With even 5-10GB of data, many simple operations can take minutes to finish on a CPU, slowing down exploratory analysis and production data pipelines.</p>
<p>RAPIDS cuDF is designed to solve this problem by seamlessly accelerating pandas code on GPUs where applicable, and falling back to CPU-pandas where not. With RAPIDS cuDF available by default on Colab, all developers everywhere can leverage accelerated data analytics.</p>
<h2><b>Taking AI on the Road </b></h2>
<p>By employing AI PCs using NVIDIA RTX graphics, Google and NVIDIA also announced a Firebase Genkit collaboration that enables app developers to easily integrate generative AI models, like the new family of Gemma models, into their web and mobile applications to deliver custom content, provide semantic search and answer questions. Developers can start work streams using local RTX GPUs before moving their work seamlessly to Google Cloud infrastructure.</p>
<p>To make this even easier, developers can build apps with Genkit using JavaScript, a programming language mobile developers commonly use to build their apps.</p>
<h2><b>The Innovation Beat Goes On</b></h2>
<p>NVIDIA and Google Cloud are collaborating in multiple domains to propel AI forward. From the upcoming Grace Blackwell-powered DGX Cloud platform and JAX framework support, to bringing the NVIDIA NeMo framework to Google Kubernetes Engine, the companies’ full-stack partnership expands the possibilities of what customers can do with AI using NVIDIA technologies on Google Cloud.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/google-cloud-logo.jpg"
			type="image/jpeg"
			width="1920"
			height="1080"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/04/google-cloud-logo-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Gemma, Meet NIM: NVIDIA Teams Up With Google DeepMind to Drive Large Language Model Innovation]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>CaLLM, Cool and Connected: Cerence Uses Generative AI to Transform the In-Car Experience</title>
		<link>https://blogs.nvidia.com/blog/cerence-generative-ai-in-car-experience/</link>
		
		<dc:creator><![CDATA[Norm Marks]]></dc:creator>
		<pubDate>Tue, 14 May 2024 16:30:03 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[DGX Cloud]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71593</guid>

					<description><![CDATA[The integration of AI has become pivotal in shaping the future of driving experiences. As vehicles transition into smart, connected entities, the demand for intuitive human-machine interfaces and advanced driver assistance systems has surged. In this journey toward automotive intelligence, Cerence, a global leader in AI-powered mobility solutions, is tapping NVIDIA’s core expertise in cloud	<a class="read-more" href="https://blogs.nvidia.com/blog/cerence-generative-ai-in-car-experience/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>The integration of AI has become pivotal in shaping the future of driving experiences. As vehicles transition into smart, connected entities, the demand for intuitive human-machine interfaces and advanced driver assistance systems has surged.</p>
<p>In this journey toward automotive intelligence, Cerence, a global leader in AI-powered mobility solutions, is tapping NVIDIA’s core expertise in cloud and edge technologies to redefine the in-car user experience.</p>
<p>In a recent video, Iqbal Arshad, chief technology officer of Cerence, emphasized the point, stating: “Generative AI is the single biggest change that’s happening in the tech industry overall.”</p>
<p><iframe loading="lazy" title="Cerence and NVIDIA: Generative AI for Next-Generation In-Vehicle Experiences" width="500" height="281" src="https://www.youtube.com/embed/XTknC-3PV00?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>The cornerstone of Cerence’s vision lies in the development of its automotive-specific Cerence Automotive Large Language Model, or <a href="https://www.cerence.com/news-releases/news-release-details/cerence-pioneers-automotive-specific-llm-collaboration-nvidia" target="_blank" rel="noopener">CaLLM</a>. It serves as the foundation for the company’s next-gen in-car computing platform, running on <a href="https://developer.nvidia.com/drive" target="_blank" rel="noopener">NVIDIA DRIVE</a>.</p>
<p>The platform, unveiled in December, showcases the future of in-car interaction, with an automotive- and mobility-specific assistant that provides an integrated in-cabin experience.</p>
<p>“We have datasets from the last 20 years of experience working in the automotive space,” Iqbal said. “And we’re able to take that data and make that an automotive-ready LLM.”</p>
<h2><strong>Generative AI a Game-Changer for the Automotive Industry</strong></h2>
<p><a href="https://www.nvidia.com/en-us/glossary/generative-ai/" target="_blank" rel="noopener">Generative AI</a> enables vehicles to comprehend and respond to human language with remarkable accuracy, revolutionizing the way drivers interact with their cars.</p>
<p>Whether it’s initiating voice commands for navigation, controlling infotainment systems or even engaging in natural language conversations, generative AI opens a realm of possibilities for creating more convenient and enjoyable driving experiences.</p>
<p>Cerence is striving to empower vehicles with the cognitive capabilities necessary to seamlessly assist drivers in navigating their daily routines.</p>
<p>The company leverages <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/" target="_blank" rel="noopener">NVIDIA DGX Cloud</a> on Microsoft Azure, providing dedicated, scalable access to the latest NVIDIA architecture, co-engineered at every layer with Microsoft Azure, optimized for peak performance in AI workload training. NVIDIA’s inferencing technology helps Cerence deliver real-time performance, facilitating seamless user experiences.</p>
<p>As Cerence sees it, the future is one of intelligent driving, where vehicles aren’t just modes of transportation, but trusted companions on the road ahead.</p>
<p>“Generative computing is going to change your in-car experience,” said Iqbal.</p>
<p>With generative AI at its core, driving will evolve into a personalized, connected and, ultimately, safer experience for all.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/cerencegenai-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/cerencegenai-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[CaLLM, Cool and Connected: Cerence Uses Generative AI to Transform the In-Car Experience]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA to Help Elevate Japan’s Sovereign AI Efforts Through Generative AI Infrastructure Build-Out</title>
		<link>https://blogs.nvidia.com/blog/japan-sovereign-ai/</link>
		
		<dc:creator><![CDATA[Masataka Osaki]]></dc:creator>
		<pubDate>Tue, 14 May 2024 13:00:42 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Generative AI]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71602</guid>

					<description><![CDATA[Following an announcement by Japan’s Ministry of Economy, Trade and Industry, NVIDIA will play a central role in developing the nation’s generative AI infrastructure as Japan seeks to capitalize on the technology’s economic potential and further develop its workforce. NVIDIA is collaborating with key digital infrastructure providers, including GMO Internet Group, Highreso, KDDI Corporation, RUTILEA,	<a class="read-more" href="https://blogs.nvidia.com/blog/japan-sovereign-ai/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Following an announcement by Japan’s Ministry of Economy, Trade and Industry, NVIDIA will play a central role in developing the nation’s generative AI infrastructure as Japan seeks to capitalize on the technology’s economic potential and further develop its workforce.</p>
<p>NVIDIA is collaborating with key digital infrastructure providers, including GMO Internet Group, Highreso, KDDI Corporation, RUTILEA, SAKURA internet Inc. and SoftBank Corp., which the ministry has certified to spearhead the development of cloud infrastructure crucial for AI applications.</p>
<p>Over the last two months, the ministry announced plans to allocate $740 million, approximately ¥114.6 billion, to assist six local firms in this initiative. Following on from last year, this is a significant effort by the Japanese government to subsidize AI computing resources, by expanding the number of companies involved.</p>
<p>With this move, Japan becomes the latest nation to embrace the concept of <a href="https://blogs.nvidia.com/blog/what-is-sovereign-ai/">sovereign AI</a>, aiming to fortify its local startups, enterprises and research efforts with advanced AI technologies.</p>
<p>Across the globe, nations are building up domestic computing capacity through various models. Some procure and operate sovereign AI clouds with state-owned <a href="https://www.nvidia.com/en-us/industries/telecommunications/ai-factories/">telecommunications providers</a> or utilities. Others are sponsoring local cloud partners to provide a shared AI computing platform for public and private sector use.</p>
<p>Japan’s initiative follows NVIDIA founder and CEO Jensen Huang&#8217;s visit last year, where he met with political and business leaders — including Japanese Prime Minister Fumio Kishida — to discuss the future of AI.</p>
<p>During his trip, Huang emphasized that “AI factories” — next-generation data centers designed to handle the most computationally intensive AI tasks — are crucial for turning vast amounts of data into intelligence. “The AI factory will become the bedrock of modern economies across the world,” Huang said during a meeting with the Japanese press in December.</p>
<p>The Japanese government plans to subsidize a significant portion of the costs for building AI supercomputers, which will facilitate AI adoption, enhance workforce skills, support Japanese language model development and bolster resilience against natural disasters and climate change.</p>
<p>Under the country’s Economic Security Promotion Act, the ministry aims to secure a stable supply of local cloud services, reducing the time and cost of developing next-generation AI technologies.</p>
<p>Japan’s technology powerhouses are already moving fast to embrace AI. Last week, SoftBank Corp. announced that it will invest ¥150 billion, approximately $960 million, for its plan to expand the infrastructure needed to develop Japan’s top-class AI, including purchases of NVIDIA accelerated computing.</p>
<p>The news follows Huang’s meetings with leaders in Canada, France, India, Japan, Malaysia, Singapore and Vietnam over the past year, as countries seek to supercharge their regional economies and embrace challenges such as climate change with AI.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/tokyo-crop2-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1454"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/tokyo-crop2-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA to Help Elevate Japan’s Sovereign AI Efforts Through Generative AI Infrastructure Build-Out]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Drug Discovery, STAT! NVIDIA, Recursion Speed Pharma R&#038;D With AI Supercomputer</title>
		<link>https://blogs.nvidia.com/blog/drug-discovery-recursion-supercomputer/</link>
		
		<dc:creator><![CDATA[Rory Kelleher]]></dc:creator>
		<pubDate>Mon, 13 May 2024 09:00:20 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artficial Intelligence]]></category>
		<category><![CDATA[Customer Stories]]></category>
		<category><![CDATA[DGX Cloud]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[New GPU Uses]]></category>
		<category><![CDATA[NVIDIA Hopper Architecture]]></category>
		<category><![CDATA[NVIDIA Quantum-2]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Supercomputing]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71542</guid>

					<description><![CDATA[Described as the largest system in the pharmaceutical industry, BioHive-2 at the Salt Lake City headquarters of Recursion debuts today at No. 35, up more than 100 spots from its predecessor on the latest TOP500 list of the world’s fastest supercomputers. The advance represents the company’s most recent effort to accelerate drug discovery with NVIDIA	<a class="read-more" href="https://blogs.nvidia.com/blog/drug-discovery-recursion-supercomputer/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Described as the largest system in the pharmaceutical industry, BioHive-2 at the Salt Lake City headquarters of Recursion debuts today at No. 35, up more than 100 spots from its predecessor on the latest TOP500 list of the world’s fastest supercomputers.</p>
<p>The advance represents the company’s most recent effort to accelerate drug discovery with NVIDIA technologies.</p>
<p>“Just as with large language models, we see AI models in the biology domain improve performance substantially as we scale our training with more data and compute horsepower, which ultimately leads to greater impacts on patients’ lives,” said Recursion’s CTO, Ben Mabey, who’s been applying machine learning to healthcare for more than a decade.</p>
<p>BioHive-2 packs 504 <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100 Tensor Core GPUs</a> linked on an <a href="https://www.nvidia.com/en-us/networking/quantum2/">NVIDIA Quantum-2</a> InfiniBand network to deliver 2 exaflops of AI performance. The resulting <a href="https://www.nvidia.com/en-us/data-center/dgx-superpod/">NVIDIA DGX SuperPOD</a> is nearly 5x faster than Recursion’s first-generation system, BioHive-1.</p>
<h2><b>Performance Powers Through Complexity</b></h2>
<p>That performance is key to rapid progress because “biology is insanely complex,” Mabey said.</p>
<p>Finding a new drug candidate can take scientists years performing millions of wet-lab experiments.</p>
<p>That work is vital; Recursion’s scientists run more than 2 million such experiments a week. But going forward, they’ll use AI models on BioHive-2 to direct their platform to the most promising biology areas to run their experiments.</p>
<p>“With AI in the loop today, we can get 80% of the value with 40% of the wet lab work, and that ratio will improve going forward,” he said.</p>
<h2><b>Biological Data Propels Healthcare AI</b></h2>
<p>Recursion is collaborating with biopharma companies such as Bayer AG, Roche and Genentech. Over time, it also amassed a more than 50-petabyte database of biological, chemical and patient data, helping it build powerful AI models that are accelerating drug discovery.</p>
<p>“We believe it’s one of the largest biological datasets on Earth — it was built with AI training in mind, intentionally spanning biology and chemistry,” said Mabey, who joined the company more than seven years ago in part due to its commitment to building such a dataset.</p>
<h2><b>Creating an AI Phenomenon</b></h2>
<p>Processing that data on BioHive-1, Recursion developed a family of <a href="https://blogs.nvidia.com/blog/what-are-foundation-models/">foundation models</a> called Phenom. They turn a series of microscopic cellular images into meaningful representations for understanding the underlying biology.</p>
<p>A member of that family, <a href="https://www.recursion.com/news/nothing-short-of-phenomenal-new-deep-learning-model-available-on-nvidias-bionemo-platform">Phenom-Beta</a>, is now available as a cloud API and the first third-party model on <a href="https://www.nvidia.com/en-us/clara/bionemo/">NVIDIA BioNeMo</a>, a <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> platform for drug discovery.</p>
<p>Over several months of research and iteration, BioHive-1 trained <a href="http://arxiv.org/abs/2404.10242">Phenom-1</a> using more than 3.5 billion cellular images. Recursion’s expanded system enables training even more powerful models with larger datasets in less time.</p>
<p>The company also used <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a>, powered by Oracle Cloud Infrastructure, to provide additional supercomputing resources to power their work.</p>
<figure id="attachment_71588" aria-describedby="caption-attachment-71588" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/Recursion-Phenom-AI-model-animation.gif"><img loading="lazy" decoding="async" class="size-large wp-image-71588" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Recursion-Phenom-AI-model-animation-672x338.gif" alt="Animation of how Recursion trains AI models for drug discovery on NVIDIA GPUs" width="672" height="338" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/Recursion-Phenom-AI-model-animation-672x338.gif 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Recursion-Phenom-AI-model-animation-400x201.gif 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Recursion-Phenom-AI-model-animation-768x386.gif 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Recursion-Phenom-AI-model-animation-842x423.gif 842w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Recursion-Phenom-AI-model-animation-406x204.gif 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Recursion-Phenom-AI-model-animation-188x94.gif 188w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-71588" class="wp-caption-text">Much like how LLMs are trained to generate missing words in a sentence, Phenom models are trained by asking them to generate the masked out pixels in images of cells.</figcaption></figure>
<p>The Phenom-1 model serves Recursion and its partners in several ways, including finding and optimizing molecules to treat a variety of diseases and cancers. Earlier models helped Recursion predict drug candidates for COVID-19 nine out of 10 times.</p>
<p>The company announced its <a href="https://ir.recursion.com/news-releases/news-release-details/recursion-announces-collaboration-and-50-million-investment">collaboration with NVIDIA</a> in July. Less than 30 days later, the combination of BioHive-1 and DGX Cloud <a href="https://ir.recursion.com/news-releases/news-release-details/recursion-bridges-protein-and-chemical-space-massive-protein">screened and analyzed</a> a massive chemical library to predict protein targets for approximately 36 billion chemical compounds.</p>
<p>In January, the company <a href="https://ir.recursion.com/news-releases/news-release-details/recursion-unveils-lowe-drug-discovery-software-jp-morgan">demonstrated</a> LOWE, an AI workflow engine with a natural-language interface to help make its tools more accessible to scientists. And in April it <a href="https://portal.valencelabs.com/blogs/post/introducing-molgps---a-foundational-gnn-for-molecular-property-prediction-Ti4InC3788me9f5">described</a> a billion-parameter AI model it built to provide a new way to predict the properties of key molecules of interest in healthcare.</p>
<p>Recursion uses NVIDIA software to optimize its systems.</p>
<p>“We love CUDA and <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a>, and we’re looking to see if <a href="https://www.nvidia.com/en-us/ai/">NVIDIA NIM</a> can help us distribute our models more easily, both internally and to partners,” he said.</p>
<h2><b>A Shared Vision for Healthcare</b></h2>
<p>The efforts are part of a broad vision that Jensen Huang, NVIDIA founder and CEO, described in a <a href="https://blogs.nvidia.com/blog/nvidia-ceo-ai-drug-discovery-jp-morgan-healthcare-2024/">fireside chat</a> with Recursion’s chairman as moving toward simulating biology.</p>
<p>“You can now recognize and learn the language of almost anything with structure, and you can translate it to anything with structure … This is the generative AI revolution,” Huang said.</p>
<p>“We share a similar view,” said Mabey.</p>
<p>“We are in the early stages of a very interesting time where just as computers accelerated chip design, AI can speed up drug design. Biology is much more complex, so it will take years to play out, but looking back, people will see this was a real turning point in healthcare,” he added.</p>
<p><i>Learn about </i><a href="https://www.nvidia.com/en-us/clara/"><i>NVIDIA’s AI platform for healthcare and life sciences</i></a><i> and subscribe to </i><a href="https://www.nvidia.com/en-us/industries/healthcare-life-sciences/healthcare-news-sign-up/"><i>NVIDIA healthcare news</i></a><i>.</i></p>
<p><i>Pictured at top: BioHive-2 with a few members of the Recursion team (from left) Paige Despain, John Durkin, Joshua Fryer, Jesse Dean, Ganesh Jagannathan, Chris Gibson, Lindsay Ellinger, Michael Secora, Alex Timofeyev, and Ben Mabey. </i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/BioHive2-with-Recursion-crop-team-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1085"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/BioHive2-with-Recursion-crop-team-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Drug Discovery, STAT! NVIDIA, Recursion Speed Pharma R&D With AI Supercomputer]]></media:title>
			<media:description type="html">Picture of Recursion team with BioHive-2 AI supercomputer for drug discovery</media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Blackwell Platform Pushes the Boundaries of Scientific Computing</title>
		<link>https://blogs.nvidia.com/blog/blackwell-scientific-computing/</link>
		
		<dc:creator><![CDATA[Dion Harris]]></dc:creator>
		<pubDate>Mon, 13 May 2024 06:00:30 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[CUDA]]></category>
		<category><![CDATA[HPC Stories]]></category>
		<category><![CDATA[RAPIDS]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71547</guid>

					<description><![CDATA[Quantum computing. Drug discovery. Fusion energy. Scientific computing and physics-based simulations are poised to make giant steps across domains that benefit humanity as advances in accelerated computing and AI drive the world’s next big breakthroughs. NVIDIA unveiled at GTC in March the NVIDIA Blackwell platform, which promises generative AI on trillion-parameter large language models (LLMs)	<a class="read-more" href="https://blogs.nvidia.com/blog/blackwell-scientific-computing/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Quantum computing. Drug discovery. Fusion energy. Scientific computing and physics-based simulations are poised to make giant steps across domains that benefit humanity as advances in accelerated computing and AI drive the world’s next big breakthroughs.</p>
<p>NVIDIA unveiled at GTC in March <a href="https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing">the NVIDIA Blackwell platform</a>, which promises generative AI on trillion-parameter large language models (LLMs) at up to 25x less cost and energy consumption than the NVIDIA Hopper architecture.</p>
<p>Blackwell has powerful implications for AI workloads, and its technology capabilities can also help to deliver discoveries across all types of scientific computing applications, including traditional numerical simulation.</p>
<p>By reducing energy costs, accelerated computing and AI drive <a href="https://www.nvidia.com/en-us/data-center/sustainable-computing/">sustainable computing</a>. Many scientific computing applications already benefit. Weather can be simulated at 200x lower cost and with 300x less energy, while digital twin simulations have 65x lower cost and 58x less energy consumption versus traditional CPU-based systems and others.</p>
<h2><b>Multiplying Scientific Computing Simulations With Blackwell</b></h2>
<p>Scientific computing and physics-based simulation often rely on what’s known as double-precision formats, or <a href="https://blogs.nvidia.com/blog/double-precision-tensor-cores/">FP64 (floating point</a>), to solve problems. <a href="https://resources.nvidia.com/en-us-blackwell-architecture">Blackwell GPUs</a> deliver 30% more FP64 and FP32 FMA (fused multiply-add) performance  than Hopper.</p>
<p>Physics-based simulations are critical to product design and development. From planes and trains to bridges, silicon chips and pharmaceuticals — testing and improving products in simulation saves researchers and developers billions of dollars.</p>
<p>Today application-specific integrated circuits (ASICs) are designed almost exclusively on CPUs in a long and complex workflow, including analog analysis to identify voltages and currents.</p>
<p>But that’s changing. The <a href="https://www.nvidia.com/en-us/industries/industrial-sector/cadence/">Cadence</a> SpectreX simulator is one example of an analog circuit design solver. SpectreX circuit simulations are projected to run 13x quicker on a GB200 Grace Blackwell Superchip — which connects Blackwell GPUs and Grace CPUs — than on a traditional CPU.</p>
<p>Also, GPU-accelerated computational fluid dynamics, or CFD, has become a key tool. Engineers and equipment designers use it to predict the behavior of designs. Cadence Fidelity runs CFD simulations that are projected to run as much as 22x faster on GB200 systems than on traditional CPU-powered systems. With parallel scalability and 30TB of memory per GB200 NVL72 rack, it’s possible to capture flow details like never before.</p>
<p>In another application, Cadence Reality’s digital twin software can be used to create a virtual replica of a physical data center, including all its components — servers, cooling systems and power supplies. Such a virtual model allows engineers to test different configurations and scenarios before implementing them in the real world, saving time and costs.</p>
<p>Cadence Reality’s magic happens from physics-based algorithms that can simulate how heat, airflow and power usage affect data centers. This helps engineers and data center operators to more effectively manage capacity, predict potential operational problems and make informed decisions to optimize the layout and operation of the data center for improved efficiency and capacity utilization. With Blackwell GPUs, these simulations are projected to run up to 30x faster than with CPUs, offering accelerated timelines and higher energy efficiency.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/Cadence-Chart.jpg"><img loading="lazy" decoding="async" class="aligncenter wp-image-71581 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Cadence-Chart-672x379.jpg" alt="" width="672" height="379" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/Cadence-Chart-672x379.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Cadence-Chart-400x226.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Cadence-Chart-381x215.jpg 381w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Cadence-Chart-177x100.jpg 177w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Cadence-Chart.jpg 752w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<h2><b>AI for Scientific Computing</b></h2>
<p>New Blackwell accelerators and networking will deliver leaps in performance for advanced simulation.</p>
<p>The NVIDIA GB200 kicks off a new era for high-performance computing (HPC). Its architecture sports a second-generation transformer engine optimized to accelerate inference workloads for LLMs.</p>
<p>This delivers a 30x speedup on resource-intensive applications like the 1.8-trillion-parameter GPT-MoE (generative pretrained transformer-mixture of experts) model compared to the H100 generation, unlocking new possibilities for HPC. By enabling LLMs to process and decipher vast amounts of scientific data, HPC applications can sooner reach valuable insights that can accelerate scientific discovery.</p>
<p>Sandia National Laboratories <a href="https://blogs.nvidia.com/blog/generative-ai-science-isc/">is building</a> an LLM copilot for parallel programming. Traditional AI can generate basic serial computing code efficiently, but when it comes to parallel computing code for HPC applications, LLMs can falter. Sandia researchers are tackling this issue head-on with an ambitious project — automatically generating parallel code in Kokkos, a specialized programming language designed by multiple national labs for running tasks across tens of thousands of processors in the world’s most powerful supercomputers.</p>
<p>Sandia is using an AI technique known as <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">retrieval-augmented generation</a>, or RAG, which combines information-retrieval capabilities with language generation models. The team is creating a Kokkos database and integrating it with AI models using RAG.</p>
<p>Initial results are promising. Different RAG approaches from Sandia have demonstrated autonomously generated Kokkos code for parallel computing applications. By overcoming hurdles in AI-based parallel code generation, Sandia aims to unlock new possibilities in HPC across leading supercomputing facilities worldwide. Other examples <a href="https://developer.nvidia.com/blog/ai-for-a-scientific-computing-revolution/">include</a> renewables research, climate science and drug discovery.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-scaled.jpg"><img loading="lazy" decoding="async" class="aligncenter wp-image-71567 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-672x378.jpg" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GB200NVL72-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<h2><b>Driving Quantum Computing Advances</b></h2>
<p>Quantum computing unlocks a time machine trip for fusion energy, climate research, drug discovery and many more areas. So researchers are hard at work simulating future quantum computers on NVIDIA GPU-based systems and software to develop and test quantum algorithms faster than ever.</p>
<p>The <a href="https://developer.nvidia.com/blog/introducing-cuda-quantum-the-platform-for-hybrid-quantum-classical-computing/">NVIDIA CUDA-Q platform</a> enables both simulation of quantum computers and hybrid application development with a unified programming model for CPUs, GPUs and <a href="https://blogs.nvidia.com/blog/what-is-a-qpu/">QPUs</a> (quantum processing units) working together.</p>
<p>CUDA-Q is speeding simulations in chemistry workflows for BASF, high-energy and nuclear physics for Stony Brook and quantum chemistry for NERSC.</p>
<p>NVIDIA Blackwell architecture will help drive quantum simulations to new heights. Utilizing the latest NVIDIA NVLink multi-node interconnect technology helps shuttle data faster for speedup benefits to quantum simulations.</p>
<h2><b>Accelerating Data Analytics for Scientific Breakthroughs </b></h2>
<p>Data processing with RAPIDS is popular for scientific computing. Blackwell introduces a hardware decompression engine to decompress compressed data and speed up analytics in RAPIDS.</p>
<p>The decompression engine provides performance improvements up to 800GB/s and enables Grace Blackwell to perform 18x faster than CPUs — on Sapphire Rapids — and 6x faster than NVIDIA H100 Tensor Core GPUs for query benchmarks.</p>
<p>Rocketing data transfers with 8TB/s of high-memory bandwidth and the Grace CPU high-speed NVLink Chip-to-Chip (C2C) interconnect, the engine speeds up the entire process of database queries. Yielding top-notch performance across data analytics and data science use cases, Blackwell speeds data insights and reduces costs.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333.jpg"><img loading="lazy" decoding="async" class="aligncenter wp-image-71578 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-580x500.jpg" alt="" width="580" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-580x500.jpg 580w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-400x345.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-768x662.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-1536x1325.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-522x450.jpg 522w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-249x215.jpg 249w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-406x350.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-116x100.jpg 116w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333-1280x1104.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Bar-chart333.jpg 2048w" sizes="(max-width: 580px) 100vw, 580px" /></a></p>
<h2><b>Driving Extreme Performance for Scientific Computing with NVIDIA Networking</b></h2>
<p>The NVIDIA Quantum-X800 InfiniBand networking platform offers the highest throughput for scientific computing infrastructure.</p>
<p>It includes NVIDIA Quantum Q3400 and Q3200 switches and the NVIDIA ConnectX-8 SuperNIC, together hitting twice the bandwidth of the prior generation. The Q3400 platform offers 5x higher bandwidth capacity and 14.4Tflops of in-network computing with NVIDIA’s scalable hierarchical aggregation and reduction protocol (SHARPv4), providing a 9x increase compared with the prior generation.</p>
<p>The performance leap and power efficiency translates to significant reductions in workload completion time and energy consumption for scientific computing.</p>
<p><i>Learn more about </i><a href="https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/"><i>NVIDIA Blackwell</i></a><i>. </i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gb200-nvl-rack-gtc24-press-1920x1080-1.jpg"
			type="image/jpeg"
			width="1920"
			height="1080"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gb200-nvl-rack-gtc24-press-1920x1080-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Blackwell Platform Pushes the Boundaries of Scientific Computing]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
	</channel>
</rss>
