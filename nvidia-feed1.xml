<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Tue, 26 Sep 2023 20:37:19 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.3</generator>
	<item>
		<title>NVIDIA CEO and Founder Jensen Huang Returns to Denny’s Where NVIDIA Launched a Trillion-Dollar Vision</title>
		<link>https://blogs.nvidia.com/blog/2023/09/26/nvidia-dennys-trillion/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Tue, 26 Sep 2023 20:37:19 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67152</guid>

					<description><![CDATA[Talk about a Grand Slam. Denny’s CEO Kelli Valade was joined Tuesday by NVIDIA CEO Jensen Huang Tuesday to unveil a plaque at the Silicon Valley Denny’s where NVIDIA’s founders hatched their idea for a chip that would enable realistic 3D graphics on personal computers. “This is a place where we fuel ideas, your story <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/26/nvidia-dennys-trillion/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Talk about a Grand Slam.</p>
<p>Denny’s CEO Kelli Valade was joined Tuesday by NVIDIA CEO Jensen Huang Tuesday to unveil a plaque at the Silicon Valley Denny’s where NVIDIA’s founders hatched their idea for a chip that would enable realistic 3D graphics on personal computers.</p>
<p>“This is a place where we fuel ideas, your story is so inspiring it will continue to inspire people at Dennny’s,” Valade said, as she presented the plaque to Huang.</p>
<p>“Denny’s has taught me so many lessons,” Huang said.</p>
<p>Both CEOs got their start working in diners. Valade got her first job as a waitress at a diner when she was 16. Huang got his first job at Denny’s in Portland when he was 15.</p>
<p>“I was a dishwasher, I was a busboy, I waited tables,” Huang said. “No one can carry more coffee cups than I can.”</p>
<p>To fuel even more great ideas, Valade announced the Denny’s Trillion-Dollar Incubator Contest — offering $25,000 in seed money for the next $1 trillion idea.</p>
<p><img decoding="async" fetchpriority="high" class="alignleft wp-image-67166 size-medium" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-278x400.jpg" alt="https://apimages.photoshelter.com/galleries/C0000IW9ydIWWwzE/2023-09-30-Denny-s-Trillion-Dollar-Incubator" width="278" height="400" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-278x400.jpg 278w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-347x500.jpg 347w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-768x1106.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-1067x1536.jpg 1067w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-scaled.jpg 1422w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-312x450.jpg 312w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-149x215.jpg 149w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-69x100.jpg 69w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dennys-Plaque-1280x1843.jpg 1280w" sizes="(max-width: 278px) 100vw, 278px" />The contest is open to anyone with a creative and innovative idea that could impact the world. The only catch? The idea must originate — like NVIDIA — in a Denny’s booth.</p>
<p>NVIDIA, the leading accelerated computing and AI company, got its start at the 24-hour diner chain known for favorites such as its signature Grand Slam combo.</p>
<p>In 1993, three friends — Huang, Chris Malachowsky and Curtis Priem — met at Denny’s to discuss creating a chip that would enable realistic 3D graphics on personal computers.</p>
<p>The Denny’s just off a busy thoroughfare in the heart of Silicon Valley was the perfect place to start a business, said Huang, who lived nearby at the time with his wife and kids.</p>
<p>“It had all the coffee you could drink and no one could chase you out,” Huang told Valade.</p>
<p>Tuesday’s event took place in a corner of the bustling restaurant — one of the most popular Denny’s locations in Northern California — as families, retirees, and workers coming off the night shift piled in for plates piled high with eggs and pancakes, sausage and bacon.</p>
<p>Huang was among them, starting the day with a meeting where he and his table polished off a Lumberjack Slam, Moons Over My Hammy, and a Super Bird sandwich — washed down with plenty of coffee.  <b><br />
</b><br />
Huang, whose family immigrated to the United States from Taiwan when he was a child, told Valade he had his first hamburger at Dennys and his first milkshake.</p>
<p>“We make the best pancakes here,” Huang said.</p>
<p>“I love how you still say ‘we,’” Valade said.</p>
<p>“Made fresh every day,” Huang added with a grin.</p>
<p>Valade and Huang said Denny’s can be a great launching pad, not just for great ideas, but for great careers.</p>
<p>“Start your first job in the restaurant business,” Huang said. “It teaches you humility, it teaches you hard work, it teaches you hospitality.”</p>
<p>Valade agreed wholeheartedly, who, after talking shop with Huang, checked in with diners like Alfred, who was tucking into a stack of pancakes amid the morning rush.</p>
<p>For people across Silicon Valley, it&#8217;s the place to be. “I come here every day,” the retired roofer said.</p>
<p><b>Full contest details for the Denny’s Trillion Dollar Incubator Contest can be found at </b><a href="http://www.dennys.com/trilliondollarincubator"><b>www.dennys.com/trilliondollarincubator</b></a><b>. Contestants can submit their ideas online or at Denny’s restaurant by Nov. 21st at 8:59 am. The winner will be announced early next year.</b></p>
<p>&nbsp;</p>
<p>IMAGE CREDIT: Don Feria/AP Images for Denny&#8217;s</p>
<p><b> </b></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/Valade-Huang-Dennys-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1365"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/Valade-Huang-Dennys-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA CEO and Founder Jensen Huang Returns to Denny’s Where NVIDIA Launched a Trillion-Dollar Vision]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI Power Players: GeForce and NVIDIA RTX GPUs Supercharge Creativity, Gaming, Development, Productivity and More</title>
		<link>https://blogs.nvidia.com/blog/2023/09/26/itns-rtx-ai-windows/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 26 Sep 2023 13:00:49 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67123</guid>

					<description><![CDATA[From gaming to creating to everyday productivity, NVIDIA RTX graphics cards feature specialized Tensor Cores that deliver cutting-edge performance and transformative capabilities for AI. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. We’re also deep-diving on new </i><a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/"><i>GeForce RTX 40 Series GPU</i></a> <i>features, technologies and resources and how they dramatically accelerate content creation.</i></p>
<p>Improving gaming, creating and everyday productivity, NVIDIA RTX graphics cards feature specialized Tensor Cores that deliver cutting-edge performance and transformative capabilities for AI.</p>
<p>An arsenal of 100 million AI-ready, RTX-powered Windows 11 PCs and workstations are primed to excel in AI workflows and help launch a new wave of training models and apps.</p>
<p>This week <i>In the NVIDIA Studio</i>, learn more about these AI power-players and read about Victor de Martrin, a self-taught 3D artist who shares the creative process behind his viral video <i>Ascension</i>, which features an assist from AI and uses a new visual effect process involving point clouds.</p>
<p><iframe title="3D TRANSITION with Point Clouds" width="500" height="281" src="https://www.youtube.com/embed/S_zKwzaVsP4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>AI on the Prize</b></h2>
<p>AI can elevate both work and play.</p>
<p>Content creators with <a href="https://www.nvidia.com/en-us/studio/laptops-desktops/">NVIDIA Studio hardware</a> can access over 100 AI-enabled and RTX-accelerated creative apps, including the Adobe Creative Cloud suite, Blender, Blackmagic Design’s DaVinci Resolve, OBS Studio and more.</p>
<p>This includes the NVIDIA Studio suite of AI tools and exclusive next-generation technology such as NVIDIA DLSS 3.5, featuring <a href="https://www.nvidia.com/en-us/geforce/news/dlss-3-5-available-september-21/">Ray Reconstruction</a> and <a href="https://developer.nvidia.com/rtx/ray-tracing/optix">OptiX</a>. AI image generation on a GeForce RTX 4090-powered PC can be completed at lightning speed — the same task would take 8x longer with an Apple M2 Ultra.</p>
<p>3D modelers can benefit immensely from AI, with dramatic improvements in real-time viewport rendering and upscaling with DLSS in NVIDIA Omniverse, Adobe Substance, Adobe Painter, Blender, D5 Render, Unreal Engine and more.</p>
<figure id="attachment_67139" aria-describedby="caption-attachment-67139" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1.png"><img decoding="async" class="size-large wp-image-67139" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1-672x383.png" alt="" width="672" height="383" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1-672x383.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1-400x228.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1-768x437.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1-790x450.png 790w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1-378x215.png 378w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1-176x100.png 176w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67139" class="wp-caption-text">D5 Render full ray-tracing preview with Ray Reconstruction.</figcaption></figure>
<p>Gamers are primed for AI boosts with <a href="https://www.nvidia.com/en-us/geforce/news/dlss-3-5-available-september-21/">DLSS</a> in over 300 games, including <i>Alan Wake 2</i>, coming soon, and <i>Cyberpunk 2077: Phantom Liberty</i>, available for download today.</p>
<p><iframe loading="lazy" title="Cyberpunk 2077: Phantom Liberty | NVIDIA DLSS 3.5 &amp; Full Ray Tracing Technology Overview" width="500" height="281" src="https://www.youtube.com/embed/DbuKZgZpDP8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Modders can breathe new life into classic games with <a href="https://www.nvidia.com/en-us/geforce/rtx-remix/">NVIDIA RTX Remix’s</a> revolutionary AI upscaling and texture enhancements. Game studios deploying the NVIDIA Avatar Cloud Engine (ACE) can build intelligent game characters, interactive avatars and digital humans in apps at scale — saving time and money.</p>
<p><iframe loading="lazy" title="NVIDIA ACE for Games Sparks Life Into Virtual Characters With Generative AI" width="500" height="281" src="https://www.youtube.com/embed/5R8xZb6J3r0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Everyday tasks also get a boost. AI can draft emails, summarize content and upscale video to stunning 4K on YouTube and Netflix with RTX Video Super Resolution. Frequent video chat users can harness the power of <a href="https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/">NVIDIA Broadcast</a> for AI-enhanced voice and video features. And livestreamers can take advantage of AI-powered features like virtual backgrounds, noise removal and eye contact, which moves the eyes of the speaker to simulate eye contact with the camera.</p>
<p>NVIDIA hardware powers AI natively and in the cloud — including for the world’s leading cloud AIs like ChatGPT, Midjourney, Microsoft 365 Copilot, Adobe Firefly and more.</p>
<p>Get further with AI — faster on RTX — and <a href="https://blogs.nvidia.com/blog/2023/09/21/ai-on-local-rtx-windows-pc/">learn more</a> to get started.</p>
<h2><b>AI on Windows</b></h2>
<p>NVIDIA AI, the world’s leading AI development platform, is supported by <a href="https://blogs.nvidia.com/blog/2023/05/28/computex-generative-ai-rtx/#:~:text=NVIDIA%20Brings%20New%20Generative%20AI,is%20set%20to%20improve%20efficiency.">100 million AI-ready RTX-powered Windows 11 PCs and workstations</a>.</p>
<p>State-of-the-art technologies behind the Windows platform and NVIDIA’s AI hardware and software enable GPU-accelerated workflows for training and deploying AI models, exclusive tools, containers, software development kits and new open-source models optimized for RTX.</p>
<figure id="attachment_67136" aria-describedby="caption-attachment-67136" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1.png"><img decoding="async" loading="lazy" class="wp-image-67136 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1-672x382.png" alt="" width="672" height="382" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1-672x382.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1-400x227.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1-768x436.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1-792x450.png 792w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1-379x215.png 379w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1-176x100.png 176w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67136" class="wp-caption-text">100 million RTX-powered Windows 11 PCs and workstations are already AI-ready.</figcaption></figure>
<p>With these integrations, Windows and NVIDIA are <a href="https://blogs.nvidia.com/blog/2023/09/21/ai-on-local-rtx-windows-pc/">making it easier</a> for developers to create the next generation of AI-powered Windows apps.</p>
<h2><b>AI on Viral Content</b></h2>
<p>3D content creator Martrin saw content creation as a means to gain financial, creative and geographical freedom — as well as a sense of gratification that he wasn’t getting in his day job in advertising.</p>
<p>“To gain recognition as an artist nowadays, unless you have connections, you’ve got to grind it out on social media,” admitted Martrin. As he began to showcase artwork to wider audiences, Martrin unexpectedly enjoyed the process of creating art aimed at garnering social media attention.</p>
<p>Best known for his viral video series<i> Satisfying Marble Music — </i>in which he replicates melodies by simulating a marble bouncing on xylophone notes — Martrin also takes a keen interest in the latest trends and advancements in the world of 3D to consistently meet his clients’ evolving demands.</p>
<p>In his recent project <i>Ascension</i>, he experimented with a point-cloud modeling technique for the first time, aiming to create a transition between reality and 3D.<i> </i></p>
<p>Martrin used several 3D apps to refine video footage and animate himself in 3D. The initial stages involved modeling and animating a portrait of himself, which he used Daz Studio and Blender to accomplish. His PC, equipped with two NVIDIA GeForce RTX 4090 GPUs, easily handled this task.</p>
<figure id="attachment_67133" aria-describedby="caption-attachment-67133" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1.png"><img decoding="async" loading="lazy" class="size-large wp-image-67133" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1-672x355.png" alt="" width="672" height="355" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1-672x355.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1-400x212.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1-768x406.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1-842x445.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1-406x215.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67133" class="wp-caption-text">Animations come to life in Blender.</figcaption></figure>
<p>He then used the GPU-accelerated Marvelous Designer cloth simulation engine to craft and animate his clothing.</p>
<figure id="attachment_67130" aria-describedby="caption-attachment-67130" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/image5.png"><img decoding="async" loading="lazy" class="size-large wp-image-67130" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image5-672x365.png" alt="" width="672" height="365" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image5-672x365.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image5-400x217.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image5-768x417.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image5-829x450.png 829w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image5-396x215.png 396w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image5-184x100.png 184w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image5.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67130" class="wp-caption-text">Realistic clothes generated in Marvelous Designer.</figcaption></figure>
<p>Martrin stressed the importance of GPU acceleration in his creative workflow. “When did I use it? The countless times I checked my live viewer and during the creation of every render,” said Martrin.</p>
<p>From there, Martrin tested point-cloud modeling techniques. He first 3D-scanned his room. Then, instead of using the room as conventional 3D mesh, he deployed it as a set of data points in space to create a unique visual style.</p>
<figure id="attachment_67127" aria-describedby="caption-attachment-67127" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1.png"><img decoding="async" loading="lazy" class="size-large wp-image-67127" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1-672x362.png" alt="" width="672" height="362" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1-672x362.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1-400x216.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1-768x414.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1-835x450.png 835w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1-399x215.png 399w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1-186x100.png 186w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67127" class="wp-caption-text">Background elements added in Cinema 4D.</figcaption></figure>
<p>He then used Cinema 4D and OctaneRender with RTX-accelerated ray tracing to render the animation.</p>
<p>Martrin completed the project by applying a GPU-accelerated composition and special effects in Adobe After Effects, achieving faster rendering with <a href="https://developer.nvidia.com/cuda-toolkit">NVIDIA CUDA</a> technology.</p>
<p>“No matter how tough it is at the start, keep grinding and challenging — odds are, success will eventually follow,” said Martrin.</p>
<figure id="attachment_67124" aria-describedby="caption-attachment-67124" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1.png"><img decoding="async" loading="lazy" class="size-large wp-image-67124" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1-672x247.png" alt="" width="672" height="247" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1-672x247.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1-400x147.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1-768x283.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1-842x310.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1-406x149.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1-188x69.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67124" class="wp-caption-text">3D content creator Victor de Martrin.</figcaption></figure>
<p>Check out Martrin’s viral content on <a href="https://www.tiktok.com/@victordemartrin/video/7218928551737691398">TikTok</a>.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>Twitter</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/image1-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/image1-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI Power Players: GeForce and NVIDIA RTX GPUs Supercharge Creativity, Gaming, Development, Productivity and More]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Six Steps Toward AI Security</title>
		<link>https://blogs.nvidia.com/blog/2023/09/25/ai-security-steps/</link>
		
		<dc:creator><![CDATA[David Reber Jr.]]></dc:creator>
		<pubDate>Mon, 25 Sep 2023 15:00:22 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Explainer]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cybersecurity]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[NGC]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67098</guid>

					<description><![CDATA[In the wake of ChatGPT, every company is trying to figure out its AI strategy, work that quickly raises the question: What about security? Some may feel overwhelmed at the prospect of securing new technology. The good news is policies and practices in place today provide excellent starting points. Indeed, the way forward lies in <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/25/ai-security-steps/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>In the wake of ChatGPT, every company is trying to figure out its AI strategy, work that quickly raises the question: What about security?</p>
<p>Some may feel overwhelmed at the prospect of securing new technology. The good news is policies and practices in place today provide excellent starting points.</p>
<p>Indeed, the way forward lies in extending the existing foundations of enterprise and cloud security. It’s a journey that can be summarized in six steps:</p>
<ul>
<li style="font-weight: 400;" aria-level="1">Expand analysis of the threats</li>
<li style="font-weight: 400;" aria-level="1">Broaden response mechanisms</li>
<li style="font-weight: 400;" aria-level="1">Secure the data supply chain</li>
<li style="font-weight: 400;" aria-level="1">Use AI to scale efforts</li>
<li style="font-weight: 400;" aria-level="1">Be transparent</li>
<li style="font-weight: 400;" aria-level="1">Create continuous improvements</li>
</ul>
<figure id="attachment_67103" aria-describedby="caption-attachment-67103" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-scaled.jpg"><img decoding="async" loading="lazy" class="size-large wp-image-67103" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-672x408.jpg" alt="Chart on scaling AI security" width="672" height="408" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-672x408.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-400x243.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-768x467.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-1536x933.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-741x450.jpg 741w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-354x215.jpg 354w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-165x100.jpg 165w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Scaling-AI-security-NU-1280x778.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67103" class="wp-caption-text">AI security builds on protections enterprises already rely on.</figcaption></figure>
<h2><b>Take in the Expanded Horizon</b></h2>
<p>The first step is to get familiar with the new landscape.</p>
<p>Security now needs to cover the AI development lifecycle. This includes new attack surfaces like training data, models and the people and processes using them.</p>
<p>Extrapolate from the known types of threats to identify and anticipate emerging ones. For instance, an attacker might try to alter the behavior of an AI model by accessing data while it’s training the model on a cloud service.</p>
<p>The security researchers and red teams who probed for vulnerabilities in the past will be great resources again. They’ll need access to AI systems and data to identify and act on new threats as well as help building solid working relationships with data science staff.</p>
<h2><b>Broaden Defenses</b></h2>
<p>Once a picture of the threats is clear, define ways to defend against them.</p>
<p>Monitor AI model performance closely. Assume it will drift, opening new attack surfaces, just as it can be assumed that traditional security defenses will be breached.</p>
<p>Also build on the PSIRT (product security incident response team) practices that should already be in place.</p>
<p>For example, NVIDIA released <a href="https://www.nvidia.com/en-us/security/psirt-policies/">product security policies</a> that encompass its AI portfolio. Several organizations — including the <a href="https://llmtop10.com/">Open Worldwide Application Security Project</a> — have released AI-tailored implementations of key security elements such as the common vulnerability enumeration method used to identify traditional IT threats.</p>
<p>Adapt and apply to AI models and workflows traditional defenses like:</p>
<ul>
<li style="font-weight: 400;" aria-level="1">Keeping network control and data planes separate</li>
<li style="font-weight: 400;" aria-level="1">Removing any unsafe or personal identifying data</li>
<li style="font-weight: 400;" aria-level="1">Using <a href="https://blogs.nvidia.com/blog/2022/06/07/what-is-zero-trust">zero-trust security</a> and authentication</li>
<li style="font-weight: 400;" aria-level="1">Defining appropriate event logs, alerts and tests</li>
<li style="font-weight: 400;" aria-level="1">Setting flow controls where appropriate</li>
</ul>
<h2><b>Extend Existing Safeguards</b></h2>
<p>Protect the datasets used to train AI models. They’re valuable and vulnerable.</p>
<p>Once again, enterprises can leverage existing practices. Create secure data supply chains, similar to those created to secure channels for software. It’s important to establish access control for training data, just like other internal data is secured.</p>
<p>Some gaps may need to be filled. Today, security specialists know how to use hash files of applications to ensure no one has altered their code. That process may be challenging to scale for petabyte-sized datasets used for AI training.</p>
<p>The good news is researchers see the need, and they’re working on tools to address it.</p>
<h2><b>Scale Security With AI</b></h2>
<p>AI is not only a new attack area to defend, it’s also a new and powerful security tool.</p>
<p>Machine learning models can detect subtle changes no human can see in mountains of network traffic. That makes AI an ideal technology to prevent many of the most widely used attacks, like identity theft, phishing, malware and ransomware.</p>
<p><a href="https://developer.nvidia.com/morpheus-cybersecurity">NVIDIA Morpheus</a>, a cybersecurity framework, can build AI applications that create, read and update digital fingerprints that scan for many kinds of threats. In addition, generative AI and Morpheus can enable <a href="https://developer.nvidia.com/blog/nvidia-morpheus-helps-defend-against-spear-phishing-with-generative-ai/">new ways to detect spear phishing attempts</a>.</p>
<figure id="attachment_67112" aria-describedby="caption-attachment-67112" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-scaled.jpg"><img decoding="async" loading="lazy" class="wp-image-67112 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-672x356.jpg" alt="Chart of AI security use cases" width="672" height="356" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-672x356.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-400x212.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-768x406.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-1536x813.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-842x446.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-406x215.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-188x100.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Security-Use-Cases-NU2-1280x677.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67112" class="wp-caption-text">Machine learning is a powerful tool that spans many use cases in security.</figcaption></figure>
<h2><b>Security Loves Clarity</b></h2>
<p>Transparency is a key component of any security strategy. Let customers know about any new AI security policies and practices that have been put in place.</p>
<p>For example, NVIDIA publishes details about the AI models in <a href="https://www.nvidia.com/en-us/gpu-cloud/">NGC</a>, its hub for accelerated software. Called <a href="https://developer.nvidia.com/blog/enhancing-ai-transparency-and-ethical-considerations-with-model-card/">model cards</a>, they act like truth-in-lending statements, describing AIs, the data they were trained on and any constraints for their use.</p>
<p>NVIDIA uses an expanded set of fields in its model cards, so users are clear about the history and limits of a neural network before putting it into production. That helps advance security, establish trust and ensure models are robust.</p>
<h2><b>Define Journeys, Not Destinations</b></h2>
<p>These six steps are just the start of a journey. Processes and policies like these need to evolve.</p>
<p>The emerging practice of <a href="https://blogs.nvidia.com/blog/2023/03/01/what-is-confidential-computing/">confidential computing</a>, for instance, is extending security across cloud services where AI models are often trained and run in production.</p>
<p>The industry is already beginning to see basic versions of code scanners for AI models. They’re a sign of what’s to come. Teams need to keep an eye on the horizon for best practices and tools as they arrive.</p>
<p>Along the way, the community needs to share what it learns. An excellent example of that occurred at the recent <a href="https://blogs.nvidia.com/blog/2023/08/10/nvidia-generative-red-team-challenge/">Generative Red Team Challenge</a>.</p>
<p>In the end, it’s about creating a collective defense. We’re all making this journey to AI security together, one step at a time.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/Six-levels-pixabay-1280.jpg"
			type="image/jpeg"
			width="1280"
			height="677"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/Six-levels-pixabay-1280-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Six Steps Toward AI Security]]></media:title>
			<media:description type="html">Pix of six lines in the sky representing six steps</media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Studio Lineup Adds RTX-Powered Microsoft Surface Laptop Studio 2</title>
		<link>https://blogs.nvidia.com/blog/2023/09/21/surface-studio-chaos-dlss-resolve-tensor-rt/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Thu, 21 Sep 2023 15:00:42 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio Driver]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67040</guid>

					<description><![CDATA[The NVIDIA Studio laptop lineup is expanding with the new Microsoft Surface Laptop Studio 2, powered by GeForce RTX 4060, GeForce RTX 4050 or NVIDIA RTX 2000 Ada Generation Laptop GPUs, providing powerful performance and versatility for creators.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows.</i></p>
<p>The <a href="https://www.nvidia.com/en-us/studio/laptops-desktops/">NVIDIA Studio laptop</a> lineup is expanding with the new Microsoft Surface Laptop Studio 2, powered by <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4060-4060ti/">GeForce RTX 4060</a>, GeForce RTX 4050 or <a href="https://www.nvidia.com/en-us/design-visualization/rtx-professional-laptops/?ncid=ref-pr-584767#">NVIDIA RTX 2000 Ada Generation</a> Laptop GPUs, providing powerful performance and versatility for creators.</p>
<figure id="attachment_67047" aria-describedby="caption-attachment-67047" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67047" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w-672x473.png" alt="" width="672" height="473" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w-672x473.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w-400x281.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w-768x540.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w-640x450.png 640w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w-306x215.png 306w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w-142x100.png 142w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-creating-environment-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67047" class="wp-caption-text">The Microsoft Surface Laptop Studio 2.</figcaption></figure>
<p>Backed by the NVIDIA Studio platform, the Surface Laptop Studio 2, announced today, offers maximum stability with preinstalled Studio Drivers, plus exclusive tools to accelerate professional and creative workflows.</p>
<p>NVIDIA today also launched DLSS 3.5, adding Ray Reconstruction to the suite of AI-powered DLSS technologies. The latest feature puts a powerful new AI neural network at the fingertips of creators on RTX PCs, producing higher-quality, lifelike ray-traced images in real time before generating a full render.</p>
<p>Chaos Vantage is the first creative application to integrate Ray Reconstruction. For gamers, Ray Reconstruction is now available in <i>Cyberpunk 2077</i> and is slated for the <i>Phantom Liberty </i>expansion on Sept. 26.</p>
<p>Blackmagic Design has adopted <a href="https://developer.nvidia.com/tensorrt">NVIDIA TensorRT</a> acceleration in update 18.6 for its popular DaVinci Resolve software for video editing, color correction, visual effects, motion graphics and audio post-production. By integrating TensorRT, the software now runs AI tools like Magic Mask, Speed Warp and Super Scale over 50% faster than before. With this acceleration, AI runs up to 2.3x faster on GeForce RTX and NVIDIA RTX GPUs compared to Macs.</p>
<p>The September Studio Driver is now available for download — providing support for the Surface Laptop Studio 2, new app releases and more.</p>
<figure id="attachment_67050" aria-describedby="caption-attachment-67050" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67050" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-studio-driver-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67050" class="wp-caption-text">NVIDIA and GeForce RTX GPUs get NVIDIA Studio Drivers free of charge.</figcaption></figure>
<p>This week’s <i>In the NVIDIA Studio</i> installment features Studio Spotlight artist Gavin O’Donnell, who created a Wild West-inspired piece using a workflow streamlined with AI and RTX acceleration in Blender and Unreal Engine running on a <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3090-3090ti/">GeForce RTX 3090 GPU</a>.</p>
<h2><b>Create Without Compromise</b></h2>
<p>The Surface Laptop Studio 2, when configured with NVIDIA laptop GPUs, delivers up to 2x the graphics performance compared to the previous generation, and is NVIDIA Studio validated.</p>
<figure id="attachment_67053" aria-describedby="caption-attachment-67053" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67053" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-672x340.png" alt="" width="672" height="340" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-672x340.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-400x202.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-768x388.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-842x426.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-406x205.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w-188x95.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-navia-left-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67053" class="wp-caption-text">The versatile Microsoft Surface Laptop Studio 2.</figcaption></figure>
<p>In addition to NVIDIA graphics, the Surface Laptop Studio 2 comes with 13th Gen Intel Core processors, up to 64GB of RAM and a 2TB SSD. It features a bright, vibrant 14.4-inch PixelSense Flow touchscreen, with true-to-life color and up to 120Hz refresh rate, and now comes with Dolby Vision IQ and HDR to deliver sharper colors.</p>
<p>The system’s unique design adapts to fit any workflow. It instantly transitions from a pro-grade laptop to a perfectly angled display for entertainment to a portable creative canvas for drawing and sketching with the Surface Slim Pen 2.</p>
<p>NVIDIA Studio systems deliver upgraded performance thanks to dedicated ray tracing, AI and video encoding hardware. They also provide AI app acceleration, advanced rendering and Ray Reconstruction with NVIDIA DLSS, plus exclusive software like <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, <a href="https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/">NVIDIA Broadcast</a>, <a href="https://www.nvidia.com/en-us/studio/canvas/">NVIDIA Canvas</a> and RTX Video Super Resolution — helping creators go from concept to completion faster.</p>
<p>The Surface Laptop Studio 2 will be available beginning October 3.</p>
<h2><b>An AI for RTX</b></h2>
<p>NVIDIA GeForce and RTX GPUs feature powerful local accelerators that are critical for AI performance, supercharging creativity by unlocking AI capabilities on Windows 11 PCs — including the Surface Laptop Studio 2.​</p>
<figure id="attachment_67056" aria-describedby="caption-attachment-67056" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67056" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w-672x340.png" alt="" width="672" height="340" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w-672x340.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w-400x202.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w-768x388.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w-842x426.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w-406x205.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w-188x95.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-ai-ray-construction-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67056" class="wp-caption-text">AI-powered Ray Resstruction.</figcaption></figure>
<p>With the launch of <a href="https://www.nvidia.com/en-us/geforce/news/dlss-3-5-available-september-21">DLSS 3.5 with Ray Reconstruction</a>, an NVIDIA supercomputer-trained AI network replaces hand-tuned denoisers to generate higher-quality pixels between sampled rays.</p>
<p>Ray Reconstruction improves the real-time editing experience by sharpening images and reducing noise — even while panning around a scene. The benefits of Ray Reconstruction shine in the viewport, as rendering during camera movement is notoriously difficult.</p>
<figure id="attachment_67059" aria-describedby="caption-attachment-67059" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67059" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w-672x367.png" alt="" width="672" height="367" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w-672x367.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w-400x218.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w-768x419.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w-824x450.png 824w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w-394x215.png 394w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w-183x100.png 183w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-dlss-3-5-chaos-vanage-comparison-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67059" class="wp-caption-text">Chaos Vantage DLSS 3.5 with Ray Reconstruction technology.</figcaption></figure>
<p>By adding DLSS 3.5 support, Chaos Vantage will enable creators to explore large scenes in a fully ray-traced environment at high frame rates with improved image quality. Ray Reconstruction joins other AI-accelerated features in Vantage, including the <a href="https://developer.nvidia.com/optix-denoiser">NVIDIA OptiX denoiser</a> and Super Resolution.</p>
<p>DLSS 3.5 and AI-powered Ray Reconstruction today join performance-multiplying AI Frame Generation in <i>Cyberpunk 2077</i> with the new 2.0 update. On Sept. 26, <i>Cyberpunk 2077: Phantom Liberty</i> will launch with full ray tracing and DLSS 3.5.</p>
<p><iframe loading="lazy" title="Cyberpunk 2077: Phantom Liberty | NVIDIA DLSS 3.5 &amp; Full Ray Tracing Technology Overview" width="500" height="281" src="https://www.youtube.com/embed/DbuKZgZpDP8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>NVIDIA TensorRT — the high-performance inference optimizer that delivers low latency and high throughput for deep learning inference applications and features — has been added to DaVinci Resolve in version 18.6.</p>
<figure id="attachment_67094" aria-describedby="caption-attachment-67094" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2.png"><img decoding="async" loading="lazy" class="size-large wp-image-67094" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2-672x168.png" alt="" width="672" height="168" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2-672x168.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2-400x100.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2-768x192.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2-842x210.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2-406x101.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2-188x47.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-studio-itns-wk75-ada-perf-charts-davinci-resolve-ai-effects-blog-1280w-dark-r2.png 1281w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67094" class="wp-caption-text">Performance testing conducted by NVIDIA in August 2023. NVIDIA Driver 536.75. Windows 11. Measures time to apply various AI effects in DaVinci Resolve 18.6: Magic Mask, Speed Warp, Super Res, Depth Map.</figcaption></figure>
<p>The added acceleration dramatically increases performance. AI effects now run on a <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4090/">GeForce RTX 4090 GPU</a> up to 2.3x faster than on M2 Ultra, and 5.4x faster than on 7900 XTX.</p>
<p>Stay tuned for updates in the weeks ahead for more AI on RTX, including DLSS 3.5 support coming to Omniverse this October.</p>
<h2><b>Welcome to the Wild, Wild West</b></h2>
<p>Gavin O’Donnell — an Ireland-based senior environment concept artist at Disruptive Games — is no stranger to interactive entertainment.</p>
<p>He also does freelance work on the side including promo art, environment design and matte painting for an impressive client list, including Disney, Giant Animation, ImagineFX, Netflix and more.</p>
<p><iframe loading="lazy" title="The Wild, Wild West - Community Digital Art Showcase | NVIDIA Studio Standouts" width="500" height="281" src="https://www.youtube.com/embed/Dyu-lkHgdIk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>O’Donnell’s series of Western-themed artwork — the<i> Wild West Project </i>— was directly inspired by the critically acclaimed classic open adventure game <i>Red Dead Redemption 2</i>.</p>
<figure id="attachment_67062" aria-describedby="caption-attachment-67062" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67062" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w-672x286.png" alt="" width="672" height="286" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w-672x286.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w-400x170.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w-768x327.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w-842x359.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w-406x173.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w-188x80.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-lookout-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67062" class="wp-caption-text">Prospector, lawman or vigilante?</figcaption></figure>
<p>“I really enjoyed how immersive the storyline and the world in general was, so I wanted to create a scene that might exist in that fictional world,” said O’Donnell. Furthermore, it presented him an opportunity to practice new workflows within 3D apps Blender and Unreal Engine.</p>
<figure id="attachment_67066" aria-describedby="caption-attachment-67066" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67066" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w-672x319.png" alt="" width="672" height="319" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w-672x319.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w-400x190.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w-768x365.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w-842x400.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w-406x193.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w-188x89.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-2-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67066" class="wp-caption-text">‘Wild West Project’ brings the American Frontier to life.</figcaption></figure>
<p>Workflows combining NVIDIA technologies including RTX GPU acceleration at the intersection of AI were of especially great interest — accelerated by his <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3090-3090ti/">GeForce RTX 3090 laptop GPU</a>.</p>
<p>In Blender — O&#8217;Donnell sampled AI-powered Blender Cycles RTX-accelerated OptiX ray tracing in the viewport for interactive, photoreal rendering for modeling and animation.</p>
<figure id="attachment_67069" aria-describedby="caption-attachment-67069" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_.png"><img decoding="async" loading="lazy" class="size-large wp-image-67069" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_-672x289.png" alt="" width="672" height="289" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_-672x289.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_-400x172.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_-768x331.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_-842x362.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_-406x175.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_-188x81.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-artwork-3-1280w_.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67069" class="wp-caption-text">On a beautiful journey.</figcaption></figure>
<p>Meanwhile — in Unreal Engine — O’Donnell sampled <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">NVIDIA DLSS</a> to increase the interactivity of the viewport by using AI to upscale frames rendered at lower resolution while still retaining high-fidelity detail. On top of RTX-accelerated rendering for high-fidelity visualization of 3D designs, virtual production and game development, the artist could simply create better, more detailed artwork, faster and easier.</p>
<p>O’Donnell credits his success to a constant state of creative evaluation — ensuring everything from his content creation techniques, methods of gaining inspiration, and technological knowledge — enabling the highest quality artwork possible — all while maintaining resource and efficiency gains.</p>
<p>As such, O&#8217;Donnell recently upgraded to an NVIDIA Studio laptop equipped with a GeForce RTX 4090 GPU with spectacular results. His rendering speeds in Blender, already very fast, sped up 73%, a massive time savings for the artist.</p>
<figure id="attachment_67072" aria-describedby="caption-attachment-67072" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w.png"><img decoding="async" loading="lazy" class="size-large wp-image-67072" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w-672x193.png" alt="" width="672" height="193" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w-672x193.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w-400x115.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w-768x221.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w-842x242.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w-406x117.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w-188x54.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/itns-week75-gavin-odonnell-artist-feature-gallery-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-67072" class="wp-caption-text">Senior environment concept artist Gavin O’Donnell.</figcaption></figure>
<p>Check out O’Donnell’s portfolio on <a href="https://www.artstation.com/gavinodonnell">ArtStation</a>.</p>
<p>And finally, don’t forget to enter the #StartToFinish community challenge! Show us a photo or video of how one of your art projects started — and then one of the final result — using the hashtag #StartToFinish and tagging @NVIDIAStudio for a chance to be featured! Submissions considered through Sept. 30.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>Twitter</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/nv-blog-header-preview-1280x680-2.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/nv-blog-header-preview-1280x680-2-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Studio Lineup Adds RTX-Powered Microsoft Surface Laptop Studio 2]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Run AI on Your PC? GeForce Users Are Ahead of the Curve</title>
		<link>https://blogs.nvidia.com/blog/2023/09/21/ai-on-local-rtx-windows-pc/</link>
		
		<dc:creator><![CDATA[Jesse Clayton]]></dc:creator>
		<pubDate>Thu, 21 Sep 2023 15:00:33 +0000</pubDate>
				<category><![CDATA[Explainer]]></category>
		<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[LLM]]></category>
		<category><![CDATA[NVIDIA]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67078</guid>

					<description><![CDATA[Gone are the days when AI was the domain of sprawling data centers or elite researchers. For GeForce RTX users, AI is now running on your PC. It’s personal, enhancing every keystroke, every frame and every moment. Gamers are already enjoying the benefits of AI in over 300 RTX games. Meanwhile, content creators have access <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/21/ai-on-local-rtx-windows-pc/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Gone are the days when AI was the domain of sprawling data centers or elite researchers.</p>
<p>For <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/">GeForce RTX</a> users, AI is now running on your PC. It’s personal, enhancing every keystroke, every frame and every moment.</p>
<p>Gamers are already enjoying the benefits of AI in <a href="https://www.nvidia.com/en-us/geforce/rtx/">over 300 RTX games</a>. Meanwhile, content creators have access to <a href="https://www.nvidia.com/en-us/studio/software/">over 100 RTX creative and design apps</a>, with AI enhancing everything from video and photo editing to asset generation.</p>
<p>And for GeForce enthusiasts, it’s just the beginning. <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/">RTX</a> is the platform for today and the accelerator that will power the AI of tomorrow.</p>
<h2><b>How Did AI and Gaming Converge?</b></h2>
<p>NVIDIA pioneered the integration of AI and gaming with <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">DLSS</a>, a technique that uses AI to generate pixels in video games automatically and which has increased frame rates by up to 4x.</p>
<p><iframe loading="lazy" title="YouTube video player" src="https://www.youtube.com/embed/QGI8EIgf8Y8?si=61LChYlnTp9RjMUx" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>And with the recent introduction of DLSS 3.5, NVIDIA has enhanced the visual quality in some of the world’s top titles, setting a new standard for visually richer and more immersive gameplay.</p>
<p>But NVIDIA’s AI integration doesn’t stop there. Tools like <a href="https://www.nvidia.com/en-us/geforce/rtx-remix/">RTX Remix</a> empower game modders to remaster classic content using high-quality textures and materials generated by AI.</p>
<p><iframe loading="lazy" title="YouTube video player" src="https://www.youtube.com/embed/cSSSn10HgZA?si=m5iqhpA5fCZFYioO" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>With <a href="https://nvidianews.nvidia.com/news/nvidia-ace-for-games-sparks-life-into-virtual-characters-with-generative-ai">NVIDIA ACE for Games</a>, AI-powered avatars come to life on the PC, marking a new era of immersive gaming.</p>
<h2><b>How Are RTX and AI Powering Creators?</b></h2>
<p>Creators use AI to imagine new concepts, automate tedious tasks and create stunning works of art. They rely on RTX because it accelerates top creator applications, including the world’s most popular photo editing, video editing, broadcast and 3D apps.</p>
<p>With over 100 RTX apps now AI-enabled, creators can get more done and deliver incredible results.</p>
<p>The performance metrics are staggering.</p>
<p>RTX GPUs boost AI image generation speeds in tools like Stable Diffusion by 4.5x compared to competing processors. Meanwhile, in 3D rendering, Blender experiences a speed increase of 5.4x.</p>
<p><iframe loading="lazy" title="YouTube video player" src="https://www.youtube.com/embed/DhBFuU8Gnik?si=rLXp0VcjntRUhN9G" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>Video editing in DaVinci Resolve powered by AI doubles its speed, and Adobe Photoshop’s photo editing tasks become 3x as swift.</p>
<p>NVIDIA RTX AI tech demonstrates a staggering 10x faster speeds in distinct workflows when juxtaposed against its competitors.</p>
<p>NVIDIA provides various <a href="https://www.nvidia.com/en-us/studio/resources/">AI tools, apps and software development kits</a> designed specifically for creators. This includes exclusive offerings like <a href="https://www.nvidia.com/en-us/omniverse/creators/">NVIDIA Omniverse</a>, <a href="https://developer.nvidia.com/optix-denoiser">OptiX Denoiser</a>, <a href="https://www.nvidia.com/en-us/studio/canvas/">NVIDIA Canvas</a>, <a href="https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/">NVIDIA Broadcast</a> and <a href="https://developer.nvidia.com/rtx/dlss/get-started">NVIDIA DLSS</a>.</p>
<h2><b>How Is AI Changing Our Digital Experience Beyond Chatbots?</b></h2>
<p>Beyond gaming and content creation, RTX GPUs bring AI to all types of users.</p>
<p>Add Microsoft to the equation and <a href="https://blogs.nvidia.com/blog/2023/05/28/computex-generative-ai-rtx/#:~:text=NVIDIA%20Brings%20New%20Generative%20AI,is%20set%20to%20improve%20efficiency.">100 million RTX-powered Windows 11 PCs and workstations</a> are already AI-ready.</p>
<p><img decoding="async" loading="lazy" class="aligncenter wp-image-67083 size-full" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-microsoft-annoucement-nv-blog-header-preview-1280x680-1.jpg" alt="" width="1280" height="680" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-microsoft-annoucement-nv-blog-header-preview-1280x680-1.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-microsoft-annoucement-nv-blog-header-preview-1280x680-1-400x213.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-microsoft-annoucement-nv-blog-header-preview-1280x680-1-672x357.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-microsoft-annoucement-nv-blog-header-preview-1280x680-1-768x408.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-microsoft-annoucement-nv-blog-header-preview-1280x680-1-842x447.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-microsoft-annoucement-nv-blog-header-preview-1280x680-1-406x215.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-microsoft-annoucement-nv-blog-header-preview-1280x680-1-188x100.jpg 188w" sizes="(max-width: 1280px) 100vw, 1280px" /></p>
<p>The complementary technologies behind the Windows platform and NVIDIA’s dynamic AI hardware and software stack are the driving forces that power hundreds of Windows apps and games.</p>
<ul>
<li style="font-weight: 400;" aria-level="1"><b>Gamers</b>: RTX-accelerated AI has been adopted in more than 300 games, increasing frame rates and enhancing visual fidelity.</li>
<li style="font-weight: 400;" aria-level="1"><b>Creators</b>: More than 100 AI-enabled creative applications benefit from RTX acceleration — including the top apps for image generation, video editing, photo editing and 3D. AI helps artists work faster, automate tedious tasks and  expand the boundaries of creative expression.</li>
<li style="font-weight: 400;" aria-level="1"><b>Video Streamers</b>: <a href="https://blogs.nvidia.com/blog/2023/02/28/rtx-video-super-resolution/">RTX Video Super Resolution</a> uses AI to increase the resolution and improve the quality of streamed video, elevating the home video experience.</li>
<li style="font-weight: 400;" aria-level="1"><b>Office Workers and Students</b>: Teleconferencing and remote learning get an RTX boost with NVIDIA Broadcast. AI improves video and audio quality and adds unique effects to make virtual interactions smoother and collaboration more efficient.</li>
<li style="font-weight: 400;" aria-level="1"><b>Developers</b>: Thanks to NVIDIA’s world-leading AI development platform and technology developed by Microsoft and NVIDIA called <a href="https://developer.nvidia.com/cuda/wsl">CUDA on Windows Subsystem for Linux</a>, developers can now do early AI development and training from the comfort of Windows, and easily migrate to servers for large training runs.</li>
</ul>
<h2><b>What Are the Emerging AI Applications for RTX PCs?</b></h2>
<p><a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/">Generative AI</a> enables users to quickly generate new content based on a variety of inputs — text, images, sounds, animation, 3D models or other types of data — bringing easy-to-use AI to more PCs.</p>
<p><a href="https://blogs.nvidia.com/blog/2023/01/26/what-are-large-language-models-used-for/">Large language models (LLMs)</a> are at the heart of many of these use cases.</p>
<p><img decoding="async" loading="lazy" class="aligncenter wp-image-67086 size-full" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/llm-explainer.jpg" alt="" width="1280" height="680" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/llm-explainer.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/llm-explainer-400x213.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/llm-explainer-672x357.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/llm-explainer-768x408.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/llm-explainer-842x447.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/llm-explainer-406x215.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/llm-explainer-188x100.jpg 188w" sizes="(max-width: 1280px) 100vw, 1280px" /></p>
<p>Perhaps the best known is ChatGPT, a chatbot that runs in the cloud and one of the fastest growing applications in history.</p>
<p>Many of these LLMs now run directly on PC, enabling new end-user applications like automatically drafting documents and emails, summarizing web content, extracting insights from spreadsheet data, planning travel, and powering general-purpose AI assistants.</p>
<p>LLMs are some of the most demanding PC workloads, requiring a powerful AI accelerator — like an RTX GPU.</p>
<h2><b>What Powers the AI Revolution on Our Desktops (and Beyond)?</b></h2>
<p>What’s fueling the PC AI revolution?</p>
<p>Three pillars: lightning-fast graphics processing from GPUs, AI capabilities integral to GeForce and the omnipresent cloud.</p>
<p>Gamers already know all about the parallel processing power of GPUs. But what role did the GPU play in enabling AI in the cloud?</p>
<p>NVIDIA GPUs have transformed cloud services. These advanced systems power everything from voice recognition to autonomous factory operations.</p>
<p>In 2016, NVIDIA hand-delivered to OpenAI the <a href="https://nvidianews.nvidia.com/news/nvidia-launches-world-s-first-deep-learning-supercomputer">first NVIDIA DGX AI supercomputer</a> — the engine behind the LLM breakthrough powering ChatGPT.</p>
<p><a href="https://www.nvidia.com/en-us/data-center/dgx-platform/">NVIDIA DGX supercomputers</a>, packed with GPUs and used initially as an AI research instrument, are now running 24/7 at businesses worldwide to refine data and process AI. Half of all Fortune 100 companies have installed DGX AI supercomputers.</p>
<p>The cloud, in turn, provides more than just vast quantities of training data for advanced AI models running on these machines.</p>
<h2><b>Why Choose Desktop AI?</b></h2>
<p>But why run AI on your desktop when the cloud seems limitless?</p>
<p>GPU-equipped desktops — where the AI revolution began — are still where the action is.</p>
<ul>
<li style="font-weight: 400;" aria-level="1"><b>Availability</b>: Whether a gamer or a researcher, everyone needs tools — from games to sophisticated AI models used by wildlife researchers in the field — that can function even when offline.</li>
<li style="font-weight: 400;" aria-level="1"><b>Speed</b>: Some applications need instantaneous results. Cloud latency doesn’t always cut it.</li>
<li style="font-weight: 400;" aria-level="1"><b>Data size</b>: Uploading and downloading large datasets from the cloud can be inefficient and cumbersome.</li>
<li style="font-weight: 400;" aria-level="1"><b>Privacy</b>: Whether you’re a Fortune 500 company or just editing family photos and videos, we all have data we want to keep close to home.</li>
</ul>
<p>RTX GPUs are based on the same architecture that fuels <a href="https://www.nvidia.com/en-us/data-center/gpu-cloud-computing/">NVIDIA’s cloud performance</a>. They blend the benefits of running AI locally with access to tools and the performance only NVIDIA can deliver.</p>
<p>NPUs, often called inference accelerators, are now finding their way into modern CPUs, highlighting the growing understanding of AI’s critical role in every application.</p>
<p>While NPUs are designed to offload light AI tasks, NVIDIA’s GPUs stand unparalleled for demanding AI models with raw performance ranging from a 20x-100x increase.</p>
<h2><b>What’s Next for AI in Our Everyday Lives?</b></h2>
<p>AI isn’t just a trend — it will impact many aspects of our daily lives.</p>
<p>AI functionality will expand as research advances and user expectations will evolve. Keeping up will require GPUs — and a rich software stack built on top of them — that are up to the challenge.</p>
<p>NVIDIA is at the forefront of this transformative era, offering end-to-end optimized development solutions.</p>
<p>NVIDIA provides developers with tools to add more AI features to PCs, enhancing value for users, all powered by RTX.</p>
<p>From gaming innovations with RTX Remix to the <a href="https://developer.nvidia.com/nemo">NVIDIA NeMo</a> LLM language model for assisting coders, the AI landscape on the PC is rich and expanding.</p>
<p>Whether it’s stunning new gaming content, AI avatars, incredible tools for creators or the next generation of digital assistants, the promise of AI-powered experiences will continuously redefine the standard of personal computing.</p>
<p><i>Learn more about </i><a href="https://www.geforce.com"><i>GeForce’s AI capabilities</i></a><i>.</i><b><br />
</b></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/nv-blog-header-preview-1280x680-4.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/nv-blog-header-preview-1280x680-4-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Run AI on Your PC? GeForce Users Are Ahead of the Curve]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Into the Omniverse: Blender 4.0 Alpha Release Sets Stage for New Era of OpenUSD Artistry</title>
		<link>https://blogs.nvidia.com/blog/2023/09/21/omniverse-blender-release-openusd/</link>
		
		<dc:creator><![CDATA[Dane Johnston]]></dc:creator>
		<pubDate>Thu, 21 Sep 2023 13:00:34 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[Into the Omniverse]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Universal Scene Description]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67011</guid>

					<description><![CDATA[For seasoned 3D artists and budding digital creation enthusiasts alike, an alpha version of the popular 3D software Blender is elevating creative journeys. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of </i><a href="https://www.nvidia.com/en-us/omniverse/news/" target="_blank" rel="noopener"><i>Into the Omniverse</i></a><i>, a series focused on how artists, developers and enterprises can transform their workflows using the latest advances in </i><a href="https://www.nvidia.com/en-us/omniverse/usd/" target="_blank" rel="noopener"><i>OpenUSD</i></a><i> and </i><a href="https://www.nvidia.com/en-us/omniverse/usd/" target="_blank" rel="noopener"><i>NVIDIA Omniverse</i></a><i>.</i></p>
<p>For seasoned 3D artists and budding digital creation enthusiasts alike, an <a href="https://wiki.blender.org/wiki/Reference/Release_Notes/4.0" target="_blank" rel="noopener">alpha</a> version of the popular 3D software Blender is elevating creative journeys.</p>
<p>With the update’s features for intricate shader network creation and enhanced asset-export capabilities, the development community using Blender and the <a href="https://www.nvidia.com/en-us/omniverse/usd/" target="_blank" rel="noopener">Universal Scene Description</a> framework, aka OpenUSD, is helping to evolve the 3D landscape.</p>
<p>NVIDIA engineers play a key role in enhancing the OpenUSD capabilities of Blender which also brings enhancements for use with <a href="https://www.nvidia.com/en-us/omniverse/" target="_blank" rel="noopener">NVIDIA Omniverse</a>, a development platform for connecting and building OpenUSD-based tools and applications.</p>
<h2><b>A Universal Upgrade for Blender Workflows</b></h2>
<p>With Blender 4.0 Alpha, 3D creators across industries and enterprises can access optimized OpenUSD workflows for various use cases.</p>
<p>For example, <a href="https://blogs.nvidia.com/blog/2023/09/19/industrial-designer-blender-openusd-ai/" target="_blank" rel="noopener">Emily Boehmer</a>, a design intern at BMW Group’s Technology Office in Munich, is using the combined power of Omniverse, Blender and Adobe Substance 3D Painter to create realistic, OpenUSD-based assets to train computer vision AI models.</p>
<p>Boehmer worked with her team to create assets for use with <a href="https://sordi.ai/" target="_blank" rel="noopener">SORDI.ai</a>, an AI dataset published by BMW Group that contains over 800,000 photorealistic images.</p>
<p style="text-align: center"><img decoding="async" loading="lazy" class=" wp-image-67013 aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/ezgif.com-video-to-gif-36.gif" alt="" width="623" height="351" /><i>A clip of an industrial crate virtually “aging.”</i></p>
<p>USD helped optimize Boehmer’s workflow. “It’s great to see USD support for both Blender and Substance 3D Painter,” she said. “When I create 3D assets using USD, I can be confident that they’ll look and behave as I expect them to in the scenes that they’ll be placed in because I can add physical properties to them.”</p>
<p>Australian animator <a href="https://blogs.nvidia.com/blog/2022/07/15/marko-matosevic-omniverse-animator/" target="_blank" rel="noopener">Marko Matosevic</a> is also harnessing the combined power of Blender, Omniverse and USD in his 3D workflows.</p>
<p>Matosevic began creating tutorials for his YouTube channel, <a href="https://www.youtube.com/c/Markom3D/featured" target="_blank" rel="noopener">Markom3D</a>, to help artists of all levels. He now shares his vast 3D knowledge with over 77,000 subscribers.</p>
<p>Most recently, Matosevic <a href="https://youtu.be/e90afeuxRC8" target="_blank" rel="noopener">created a 3D spaceship in Blender</a> that he later enhanced in Omniverse through <a href="https://docs.omniverse.nvidia.com/create-xr/latest/index.html" target="_blank" rel="noopener">virtual reality</a>.</p>
<p><iframe loading="lazy" title="Inside My 3D Spaceship: Blender Design Enhanced in Omniverse VR" width="500" height="281" src="https://www.youtube.com/embed/dsH-TM8Xmpk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Individual creators aren’t the only ones seeing success with Blender and USD. Multimedia entertainment studio <a href="https://developer.nvidia.com/blog/creating-immersive-events-with-openusd-and-digital-twins" target="_blank" rel="noopener">Moment Factory</a> creates OpenUSD-based <a href="https://www.nvidia.com/en-us/omniverse/solutions/digital-twins/" target="_blank" rel="noopener">digital twins</a> to simulate their immersive events — including live performances, multimedia shows and interactive installations — in Omniverse with USD before deploying them in the real world.</p>
<p style="text-align: center"><img decoding="async" loading="lazy" class="wp-image-67016 aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-scaled.jpg" alt="" width="651" height="446" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-400x274.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-672x461.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-768x526.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-1536x1053.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-657x450.jpg 657w, https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-314x215.jpg 314w, https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-146x100.jpg 146w, https://blogs.nvidia.com/wp-content/uploads/2023/09/InfoComm2023_moment-factory_06588-1280x877.jpg 1280w" sizes="(max-width: 651px) 100vw, 651px" /><i></i><i>Moment Factory&#8217;s interactive installation at InfoComm 2023.</i></p>
<p>Team members can work in the digital twin at the same time, including designers using Blender to create and render eye-catching beauty shots to share their creative vision with customers.</p>
<p>See how Moment Factory uses Omniverse, Blender and USD to bring their immersive events to life in <a href="https://www.youtube.com/live/ikpP7bQ6kXA?si=t5s5QLLsA2aAk6z-" target="_blank" rel="noopener">their recent livestream</a>.</p>
<p>These 3D workflow enhancements are available to all. Blender users and <a href="https://resources.nvidia.com/en-us-omniverse-usd/ov-openusd-allstars" target="_blank" rel="noopener">USD creators</a>, including Boehmer, showcased their unique 3D pipeline on this recent Omniverse community livestream:</p>
<p><iframe loading="lazy" title="Explore the Power of OpenUSD and Blender Across 3D Use Cases | Omniverse Live" width="500" height="281" src="https://www.youtube.com/embed/tjiQZixHlkA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>New Features Deliver Elevated 3D Experience</b></h2>
<p>The latest USD improvements in Blender are the result of collaboration among many contributors, including AMD, Apple, Unity and NVIDIA, enabled by the Blender Foundation.</p>
<p>For example, hair object support — which improves USD import and export capabilities for digital hair — was added by a Unity software engineer. And a new Python IO callback system — which lets technical artists use Python to access USD application programming interfaces — was developed by a software engineer at NVIDIA, with support from others at Apple and AMD.</p>
<p>NVIDIA engineers are continuing to work on other USD contributions to include in future Blender updates.</p>
<p>Coming soon, the <a href="https://docs.omniverse.nvidia.com/connect/latest/blender/release-notes.html" target="_blank" rel="noopener">Blender 4.0 Alpha 201.0 Omniverse Connector</a> will offer new features for USD and Omniverse users, including:</p>
<ul>
<li style="font-weight: 400"><b>Universal Material Mapper 2 add-on:</b> This allows for more complex shader networks, or the blending of multiple textures and materials, to be round-tripped between Omniverse apps and Blender through USD.</li>
<li style="font-weight: 400"><b>Improved UsdPreviewSurface support and USDZ import/export capabilities</b>: This enables creators to export 3D assets for viewing in AR and VR applications.</li>
<li style="font-weight: 400"><b>Generic attribute support:</b> This allows geometry artists to generate vertex colors — red, green or blue values — or other per-vertex (3D point) values and import/export them between Blender and other 3D applications.</li>
</ul>
<p>Learn more about the Blender updates by watching this tutorial:</p>
<p><iframe loading="lazy" title="NVIDIA Omniverse |" width="500" height="281" src="https://www.youtube.com/embed/Y5o9f2dt6pI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Get Plugged Into the Omniverse </b></h2>
<p>Learn from industry experts on how OpenUSD is enabling custom 3D pipelines, easing 3D tool development and delivering interoperability between 3D applications in sessions from SIGGRAPH 2023, now available <a href="https://www.youtube.com/playlist?list=PL3jK4xNnlCVevpoiQ8YR-kYz5h0_9GTD9" target="_blank" rel="noopener">on demand</a>.</p>
<p>Anyone can build their own <a href="https://developer.nvidia.com/omniverse" target="_blank" rel="noopener">Omniverse extension or Connector</a> to enhance their 3D workflows and tools. Explore the Omniverse ecosystem’s <a href="https://www.nvidia.com/en-us/omniverse/ecosystem/" target="_blank" rel="noopener">growing catalog</a> of connections, extensions, foundation applications and third-party tools.</p>
<p>Share your Blender and Omniverse work as part of the latest community challenge, #StartToFinish. Use the hashtag to submit a screenshot of a project featuring both its beginning and ending stages for a chance to be featured on the @NVIDIAStudio and @NVIDIAOmniverse social channels.</p>
<p>To learn more about how OpenUSD can improve 3D workflows, check out a <a href="https://www.youtube.com/playlist?list=PL3jK4xNnlCVcUP08kj6eOzvCA82U_JKiy" target="_blank" rel="noopener">new video series </a>about the framework. For more resources on OpenUSD, explore the Alliance for OpenUSD <a href="https://forum.aousd.org/" target="_blank" rel="noopener">forum</a> or visit the <a href="https://aousd.org/" target="_blank" rel="noopener">AOUSD website</a>.</p>
<p><i>Get started with NVIDIA Omniverse by downloading the standard license for </i><a href="https://www.nvidia.com/en-us/omniverse/download/" target="_blank" rel="noopener"><i>free</i></a><i> or learn how </i><a href="https://www.nvidia.com/en-us/omniverse/enterprise/" target="_blank" rel="noopener"><i>Omniverse Enterprise</i><i> can connect your team</i></a><i>. </i></p>
<p><i>Developers can check out these </i><a href="https://developer.nvidia.com/omniverse/get-started/" target="_blank" rel="noopener"><i>Omniverse resources</i></a><i> to begin building on the platform. </i></p>
<p><i>Stay up to date on the platform by subscribing to the </i><a href="https://nvda.ws/3u5KPv1"><i>newsletter</i></a><i> and following NVIDIA Omniverse on </i><a href="https://www.instagram.com/nvidiaomniverse/" target="_blank" rel="noopener"><i>Instagram</i></a><i>, </i><a href="https://www.linkedin.com/showcase/nvidia-omniverse" target="_blank" rel="noopener"><i>LinkedIn</i></a><i>, </i><a href="https://medium.com/@nvidiaomniverse" target="_blank" rel="noopener"><i>Medium</i></a><i>, </i><a href="https://www.threads.net/@nvidiaomniverse" target="_blank" rel="noopener"><i>Threads</i></a><i> and </i><a href="https://twitter.com/nvidiaomniverse" target="_blank" rel="noopener"><i>Twitter</i></a><i>.</i></p>
<p><i>For more, check out our </i><a href="https://forums.developer.nvidia.com/c/omniverse/300" target="_blank" rel="noopener"><i>forums</i></a><i>, </i><a href="https://discord.com/invite/XWQNJDNuaC" target="_blank" rel="noopener"><i>Discord server</i></a><i>, </i><a href="https://www.twitch.tv/nvidiaomniverse" target="_blank" rel="noopener"><i>Twitch</i></a><i> and </i><a href="https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA" target="_blank" rel="noopener"><i>YouTube</i></a><i> channels.</i></p>
<p><i>Featured image courtesy of Alex Trevino.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/ov-corp-blog-sept-ito-1280x680-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/ov-corp-blog-sept-ito-1280x680-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Into the Omniverse: Blender 4.0 Alpha Release Sets Stage for New Era of OpenUSD Artistry]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA CEO Jensen Huang to Headline AI Summit in Tel Aviv</title>
		<link>https://blogs.nvidia.com/blog/2023/09/21/ai-summit/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Thu, 21 Sep 2023 13:00:27 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Events]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=67032</guid>

					<description><![CDATA[NVIDIA founder and CEO Jensen Huang will highlight the newest in generative AI and cloud computing at the NVIDIA AI Summit in Tel Aviv from Oct. 15-16. The two-day summit is set to attract more than 2,500 developers, researchers and decision-makers from across one of the world’s most vibrant technology hubs. With over 6,000 startups, <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/21/ai-summit/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>NVIDIA founder and CEO Jensen Huang will highlight the newest in generative AI and cloud computing at the <a href="https://www.nvidia.com/en-il/ai-summit-israel/">NVIDIA AI Summit in Tel Aviv</a> from Oct. 15-16.</p>
<p>The two-day summit is set to attract more than 2,500 developers, researchers and decision-makers from across one of the world’s most vibrant technology hubs.</p>
<p>With over 6,000 startups, Israel consistently ranks among the world’s top countries for VC investments per capita. The 2023 Global Startup Ecosystem report places Tel Aviv among the top 5 cities globally for startups.</p>
<p>The summit features more than 60 live sessions led by experts from NVIDIA and the region’s tech leaders, who will dive deep into topics like accelerated computing, robotics, cybersecurity and climate science.</p>
<p>Attendees will be able to network and gain insights from some of NVIDIA’s foremost experts, including Kimberly Powell, vice president and general manager of healthcare; Deepu Talla, vice president and general manager of embedded and edge computing; Gilad Shainer, senior vice president of networking and HPC; and Gal Chechik, senior director and head of the Israel AI Research Center.</p>
<p>Key events and features of the summit include:</p>
<ul>
<li><b>Livestream</b>: The keynote by Huang will take place Monday, Oct. 16, at 10 a.m. Israel time (11 p.m. Pacific) and will be available for livestreaming, with on-demand access to follow.</li>
<li><b>Ecosystem exhibition</b>: An exhibition space at the Summit will showcase NVIDIA’s tech demos, paired with contributions from partners and emerging startups from the <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception program</a>.</li>
<li><b>Deep dive into AI</b>: The first day is dedicated to intensive learning sessions hosted by the <a href="https://www.nvidia.com/en-us/training/">NVIDIA Deep Learning Institute</a>. Workshops encompass topics like “Fundamentals of Deep Learning” and “Building AI-Based Cybersecurity Pipelines,” among a range of other topics. Edge AI &amp; Robotics Developer Day activities will explore innovations in AI and the <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">NVIDIA Jetson Orin platform</a>.</li>
<li><b>Multitrack sessions</b>: The second day will include multiple tracks, covering areas such as generative AI and LLMs, AI in healthcare, networking and developer tools and <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>.</li>
</ul>
<p>Learn more at <a href="https://www.nvidia.com/en-il/ai-summit-israel/">https://www.nvidia.com/en-il/ai-summit-israel/</a>.</p>
<p><em>Featured image credit: Gady Munz via the <a href="http://www.pikiwiki.org.il/?action=gallery&amp;img_id=51036">PikiWiki &#8211; Israel free image collection project</a></em></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2019/03/tel-aviv.jpg"
			type="image/jpeg"
			width="1080"
			height="689"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2019/03/tel-aviv-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA CEO Jensen Huang to Headline AI Summit in Tel Aviv]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Cash In: ‘PAYDAY 3’ Streams on GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/2023/09/21/geforce-now-thursday-sep-21/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 21 Sep 2023 13:00:19 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=66999</guid>

					<description><![CDATA[Time to get the gang back together — PAYDAY 3 streams on GeForce NOW this week. It’s one of 11 titles joining the cloud this week, including Party Animals. The Perfect Heist PAYDAY 3 is the highly anticipated sequel to one of the world’s most popular co-op shooters. Step out of retirement and back into <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/21/geforce-now-thursday-sep-21/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Time to get the gang back together — <i>PAYDAY 3</i> streams on <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> this week.</p>
<p>It’s one of 11 titles joining the cloud this week, including <i>Party Animals</i>.</p>
<h2><b>The Perfect Heist</b></h2>
<figure id="attachment_67007" aria-describedby="caption-attachment-67007" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" loading="lazy" class="size-large wp-image-67007" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-672x378.png" alt="PAYDAY 3 on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-PAYDAY_3-1280x720.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-67007" class="wp-caption-text"><em>Not pictured: the crew member in a fuzzy bunny mask. He stayed home.</em></figcaption></figure>
<p><i>PAYDAY 3</i> is the highly anticipated sequel to one of the world’s most popular co-op shooters. Step out of retirement and back into the life of crime in the shoes of the Payday Gang — who bring the envy of their peers and the nightmare of law enforcement wherever they go. Set several years after the end of the crew’s reign of terror over Washington, D.C., the game reassembles the group to deal with the threat that’s roused them out of early retirement.</p>
<p>Upgrade to a GeForce NOW <a href="https://www.nvidia.com/en-us/geforce-now/memberships/">Ultimate</a> membership to pull off every heist at the highest quality. Ultimate members can stream on GeForce RTX 4080 rigs with support for up to 4K at 120 frames per second gameplay on PCs and Macs, providing a gaming experience so seamless that it would be a crime to stream on anything less.</p>
<h2><b>Game On</b></h2>
<figure id="attachment_67003" aria-describedby="caption-attachment-67003" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" loading="lazy" class="size-large wp-image-67003" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-672x336.jpg" alt="Party Animals on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Party_Animals.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-67003" class="wp-caption-text"><em>Paw it out with friends on nearly any device.</em></figcaption></figure>
<p>There’s always more action every GFN Thursday. Here’s the full list of this week’s GeForce NOW library additions:<i></i></p>
<ul>
<li><i>HumanitZ </i>(New release on <a href="https://store.steampowered.com/app/1766060?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Sept. 18)</li>
<li><i>Party Animals</i> (New release on <a href="https://store.steampowered.com/app/1260320?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Sept. 20)</li>
<li><i>PAYDAY 3 </i>(New release on <a href="https://store.steampowered.com/app/1272080?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.epicgames.com/store/p/payday-3?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>, <a href="https://www.xbox.com/games/store/payday-3/9npzvdch73sx?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> PC Game Pass, Sept. 21)</li>
<li><i>Warhaven </i>(New release on <a href="https://store.steampowered.com/app/2107670?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>911 Operator</i> (<a href="https://www.epicgames.com/store/p/911-operator-585edd?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Ad Infinitum</i> (<a href="https://store.steampowered.com/app/1234430?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Chained Echoes</i> (<a href="https://www.xbox.com/games/store/chained-echoes/9N1WWRPJ12FK?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Deceit 2</i> (<a href="https://store.steampowered.com/app/2064870?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>The Legend of Tianding</i> (<a href="https://www.xbox.com/games/store/the-legend-of-tianding/9NCBTKXHFF8K?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Mechwarrior 5: Mercenaries</i> (<a href="https://www.xbox.com/games/store/mechwarrior-5-mercenaries/9PB86W3JK8Z5?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Sprawl </i>(<a href="https://store.steampowered.com/app/1549690?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<p><span>Starting today, the </span><i><span>Cyberpunk 2077 </span></i><span>2.0 patch will also be supported, adding </span><a href="https://www.nvidia.com/en-us/geforce/news/dlss-3-5-available-september-21/"><span>DLSS 3.5</span></a><span> technology and other new features.</span></p>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">Twitter</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Form a team of video game characters to perform a heist, who are you recruiting? <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f4b0.png" alt="💰" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1704525826446823629?ref_src=twsrc%5Etfw">September 20, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/gfn-thursday-9-21-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/gfn-thursday-9-21-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Cash In: ‘PAYDAY 3’ Streams on GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Virtually Incredible: Mercedes-Benz Prepares Its Digital Production System for Next-Gen Platform With NVIDIA Omniverse, MB.OS and Generative AI</title>
		<link>https://blogs.nvidia.com/blog/2023/09/20/mercedes-benz-ev-nvidia-omniverse-generative-ai/</link>
		
		<dc:creator><![CDATA[Mike Geyer]]></dc:creator>
		<pubDate>Wed, 20 Sep 2023 18:08:16 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<category><![CDATA[NVIDIA DRIVE Sim]]></category>
		<category><![CDATA[Omniverse Enterprise]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=66953</guid>

					<description><![CDATA[Mercedes-Benz is using digital twins for production with help from NVIDIA Omniverse, a platform for developing Universal Scene Description (OpenUSD) applications to design, collaborate, plan and operate manufacturing and assembly facilities. Mercedes-Benz’s new production techniques will bring its next-generation vehicle portfolio into its manufacturing facilities operating in Rastatt, Germany; Kecskemét, Hungary; and Beijing, China — <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/20/mercedes-benz-ev-nvidia-omniverse-generative-ai/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Mercedes-Benz is using digital twins for production with help from <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, a platform for developing <a href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description (OpenUSD)</a> applications to design, collaborate, plan and operate manufacturing and assembly facilities.</p>
<p>Mercedes-Benz’s new production techniques will bring its next-generation vehicle portfolio into its manufacturing facilities operating in Rastatt, Germany; Kecskemét, Hungary; and Beijing, China — and offer a blueprint for its more than 30 factories worldwide. This “Digital First” approach enhances efficiency, avoids defects and saves time, marking a step-change in the flexibility, resilience and intelligence of the Mercedes-Benz MO360 production system.</p>
<p>The digital twin in production helps ensure Mercedes-Benz assembly lines can be retooled, configured and optimized in physically accurate simulations first. The new assembly lines in the Kecskemét plant will enable production of vehicles based on the newly launched Mercedes Modular Architecture that are developed virtually using digital twins in Omniverse.</p>
<p>By leveraging Omniverse, Mercedes-Benz can interact directly with its suppliers, reducing coordination processes by 50%. Using a digital twin in production doubles the speed for converting or constructing an assembly hall, while improving the quality of the processes, according to the automaker.</p>
<p>“Using NVIDIA Omniverse and AI, Mercedes-Benz is building a connected, digital-first approach to optimize its manufacturing processes, ultimately reducing construction time and production costs,” said Rev Lebaredian, vice president of Omniverse and simulation technology at NVIDIA, during a digital event held earlier today.</p>
<p>In addition, the introduction of AI opens up new areas of energy and cost savings. The Rastatt plant is being used to pioneer digital production in the paint shop. Mercedes-Benz used AI to monitor relevant sub-processes in the pilot testing, which led to energy savings of 20%.</p>
<h2><b>Supporting State-of-the-Art Software Systems</b></h2>
<p>Next-generation Mercedes-Benz vehicles will feature its new operating system “MB.OS,” which will be standard across its entire vehicle portfolio and deliver premium software capabilities and experiences across all vehicle domains.</p>
<p>Mercedes-Benz has <a href="https://blogs.nvidia.com/blog/2020/06/23/mercedes-benz-nvidia-software-defined-vehicles/">partnered with NVIDIA</a> to develop software-defined vehicles. NVIDIA will provide its <a href="https://www.nvidia.com/en-us/self-driving-cars/drive-platform/hardware/">DRIVE Orin</a> system-on-a-chip and DRIVE software, with intelligent driving capabilities tested and validated in the <a href="https://www.nvidia.com/en-us/self-driving-cars/simulation/">NVIDIA DRIVE Sim</a> platform, which is also built on Omniverse.</p>
<p>The automaker’s MO360 production system will enable it to produce electric, hybrid and gas models on the same production lines and to scale the manufacturing of electric vehicles. The implementation of MB.OS in production will allow its cars to roll off assembly lines with the latest versions of vehicle software.</p>
<p>“Mercedes-Benz is initiating a new era of automotive manufacturing thanks to the integration of artificial intelligence, MB.OS and the digital twin based on NVIDIA Omniverse into the MO360 ecosystem,” said Jörg Burzer, member of the board of the Mercedes-Benz Group AG, Production, Quality and Supply Chain Management. “With our new ‘Digital First’ approach, we unlock efficiency potential even before the launch of our MMA models in our global production network and can accelerate the ramp-up significantly.”</p>
<h2><b>Flexible Factories of the Future</b></h2>
<p>Avoiding costly manufacturing production shutdowns is critical. Running simulations in NVIDIA Omniverse enables factory planners to optimize factory floor and production line layouts for supply routes, and production lines can be validated without having to disrupt production.</p>
<p>This virtual approach also enables efficient design of new lines and change management for existing lines while reducing downtime and helping improve product quality. For the world’s automakers, much is at stake across the entire software development stack, from chip to cloud.</p>
<h2><b>Omniverse Collaboration for Efficiencies </b></h2>
<p>The Kecskemét plant is the first with a full digital twin of the entire factory. This virtual area enables development at the heart of assembly, between its tech and trim lines. And plans are for the new Kecskemét factory hall to launch into full production.</p>
<p>Collaboration in Omniverse has enabled plant suppliers and planners to interact with each other interactively in the virtual environment, so that layout options and automation changes can be incorporated and validated in real time. This accelerates how quickly new production lines can reach maximum capacity and reduces the risk of re-work or stoppages.</p>
<p>Virtual collaboration with <a href="https://blogs.nvidia.com/blog/2021/12/14/what-is-a-digital-twin/">digital twins</a> can accelerate planning and implementation of projects by weeks, as well as translate to significant cost savings for launching new manufacturing lines.</p>
<p><i>Learn more about </i><a href="https://www.nvidia.com/en-us/omniverse/"><i>NVIDIA Omniverse</i></a><i> and </i><a href="https://developer.nvidia.com/drive/ecosystem-orin"><i>DRIVE Orin</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/23C0321_004-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1152"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/23C0321_004-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Virtually Incredible: Mercedes-Benz Prepares Its Digital Production System for Next-Gen Platform With NVIDIA Omniverse, MB.OS and Generative AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Oracle Cloud Infrastructure Offers New NVIDIA GPU-Accelerated Compute Instances</title>
		<link>https://blogs.nvidia.com/blog/2023/09/19/oracle-cloud-infrastructure-nvidia-gpu-accelerated-compute-instances/</link>
		
		<dc:creator><![CDATA[Dave Salvator]]></dc:creator>
		<pubDate>Tue, 19 Sep 2023 23:40:06 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cloud Services]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[Inference]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=66948</guid>

					<description><![CDATA[With generative AI and large language models (LLMs) driving groundbreaking innovations, the computational demands for training and inference are skyrocketing. These modern-day generative AI applications demand full-stack accelerated compute, starting with state-of-the-art infrastructure that can handle massive workloads with speed and accuracy. To help meet this need, Oracle Cloud Infrastructure today announced general availability of <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/19/oracle-cloud-infrastructure-nvidia-gpu-accelerated-compute-instances/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>With <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/" target="_blank" rel="noopener">generative AI</a> and <a href="https://developer.nvidia.com/blog/tag/large-language-models/" target="_blank" rel="noopener">large language models</a> (LLMs) driving groundbreaking innovations, the computational demands for training and inference are skyrocketing.</p>
<p>These modern-day generative AI applications demand full-stack accelerated compute, starting with state-of-the-art infrastructure that can handle massive workloads with speed and accuracy. To help meet this need, Oracle Cloud Infrastructure today announced general availability of <a href="https://www.nvidia.com/en-us/data-center/h100/" target="_blank" rel="noopener">NVIDIA H100 Tensor Core GPUs</a> on <a href="https://www.oracle.com/cloud/compute/" target="_blank" rel="noopener">OCI Compute</a>, with <a href="https://www.nvidia.com/en-us/data-center/l40s/" target="_blank" rel="noopener">NVIDIA L40S GPUs</a> coming soon.</p>
<h2><strong>NVIDIA H100 Tensor Core GPU Instance on OCI</strong></h2>
<p>The OCI Compute bare-metal instances with NVIDIA H100 GPUs, powered by the <a href="https://www.nvidia.com/en-us/data-center/technologies/hopper-architecture/" target="_blank" rel="noopener">NVIDIA Hopper architecture</a>, enable an order-of-magnitude leap for large-scale AI and high-performance computing, with unprecedented performance, scalability and versatility for every workload.</p>
<p>Organizations using NVIDIA H100 GPUs obtain up to a <a href="https://resources.nvidia.com/en-us-tensor-core/nvidia-tensor-core-gpu-datasheet" target="_blank" rel="noopener">30x increase in AI inference performance</a> and a <a href="https://resources.nvidia.com/en-us-tensor-core/nvidia-tensor-core-gpu-datasheet" target="_blank" rel="noopener">4x boost in AI training</a> compared with tapping the <a href="https://www.nvidia.com/en-us/data-center/a100/" target="_blank" rel="noopener">NVIDIA A100 Tensor Core GPU</a>. The H100 GPU is designed for resource-intensive computing tasks, including training LLMs and inference while running them.</p>
<p>The BM.GPU.H100.8 OCI Compute shape includes eight NVIDIA H100 GPUs, each with 80GB of HBM2 GPU memory. Between the eight GPUs, 3.2TB/s of bisectional bandwidth enables each GPU to communicate directly with all seven other GPUs via NVIDIA <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener">NVSwitch and NVLink 4.0 technology</a>. The shape includes 16 local NVMe drives with a capacity of 3.84TB each and also includes 4th Gen Intel Xeon CPU processors with 112 cores, as well as 2TB of system memory.</p>
<p>In a nutshell, this shape is optimized for organizations’ most challenging workloads.</p>
<p>Depending on timelines and sizes of workloads, <a href="https://www.oracle.com/ai-infrastructure/" target="_blank" rel="noopener">OCI Supercluster</a> allows organizations to scale their NVIDIA H100 GPU usage from a single node to up to tens of thousands of H100 GPUs over a high-performance, ultra-low-latency network.</p>
<h2><strong>NVIDIA L40S GPU Instance on OCI</strong></h2>
<p>The NVIDIA L40S GPU, based on the NVIDIA <a href="https://www.nvidia.com/en-us/geforce/ada-lovelace-architecture/" target="_blank" rel="noopener">Ada Lovelace architecture</a>, is a universal GPU for the data center, delivering breakthrough multi-workload acceleration for LLM inference and training, visual computing and video applications. The OCI Compute bare-metal instances with NVIDIA L40S GPUs will be available for early access later this year, with general availability coming early in 2024.</p>
<p>These instances will offer an alternative to the NVIDIA H100 and A100 GPU instances for tackling smaller- to medium-sized AI workloads, as well as for graphics and video compute tasks. The NVIDIA L40S GPU achieves up to a <a href="https://resources.nvidia.com/en-us-l40s/l40s-datasheet-28413" target="_blank" rel="noopener">20% performance boost</a> for generative AI workloads and as much as a <a href="https://resources.nvidia.com/en-us-l40s/l40s-datasheet-28413" target="_blank" rel="noopener">70% improvement in fine-tuning AI models</a> compared with the NVIDIA A100.</p>
<p>The BM.GPU.L40S.4 OCI Compute shape includes four NVIDIA L40S GPUs, along with the latest-generation Intel Xeon CPU with up to 112 cores, 1TB of system memory, 15.36TB of low-latency NVMe local storage for caching data and 400GB/s of cluster network bandwidth. This instance was created to tackle a wide range of use cases, ranging from LLM training, fine-tuning and inference to <a href="https://www.nvidia.com/en-us/omniverse/" target="_blank" rel="noopener">NVIDIA Omniverse</a> workloads and industrial digitalization, 3D graphics and rendering, video transcoding and FP32 HPC.</p>
<h2><strong>NVIDIA and OCI: Enterprise AI</strong></h2>
<p>This collaboration between OCI and NVIDIA will enable organizations of all sizes to join the generative AI revolution by providing them with state-of-the-art NVIDIA H100 and L40S GPU-accelerated infrastructure.</p>
<p>Access to NVIDIA GPU-accelerated instances may not be enough, however. Unlocking the maximum potential of NVIDIA GPUs on OCI Compute means having an optimal software layer. <a href="https://blogs.oracle.com/cloud-infrastructure/post/announcing-support-nvidia-ai-enterprise-oci" target="_blank" rel="noopener">NVIDIA AI Enterprise</a> streamlines the development and deployment of enterprise-grade accelerated AI software with open-source containers and frameworks optimized for the underlying NVIDIA GPU infrastructure, all with the help of <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise-suite/support/" target="_blank" rel="noopener">support services</a>.</p>
<p>To learn more, join <a href="https://www.nvidia.com/en-us/events/oracle-cloudworld/" target="_blank" rel="noopener">NVIDIA at Oracle Cloud World</a> in the AI Pavillion, attend this <a href="https://reg.rf.oracle.com/flow/oracle/cwoh23/catalog/page/catalog/session/1692128535060001je8W" target="_blank" rel="noopener">session</a> on the new OCI instances on Wednesday, Sept. 20, and visit these web pages on <a href="https://www.oracle.com/cloud/" target="_blank" rel="noopener">Oracle Cloud Infrastructure</a>, <a href="https://www.oracle.com/cloud/compute/" target="_blank" rel="noopener">OCI Compute</a>, <a href="https://www.oracle.com/artificial-intelligence/" target="_blank" rel="noopener">how Oracle approaches AI</a> and the <a href="https://www.nvidia.com/en-us/ai-data-science/" target="_blank" rel="noopener">NVIDIA AI Platform</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2022/10/Copy-of-oracle-blog-logo-lockup-promo-package-2508744-1260x680-r3.png"
			type="image/png"
			width="1260"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2022/10/Copy-of-oracle-blog-logo-lockup-promo-package-2508744-1260x680-r3-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Oracle Cloud Infrastructure Offers New NVIDIA GPU-Accelerated Compute Instances]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Meet the Omnivore: Industrial Designer Blends Art and OpenUSD to Create 3D Assets for AI Training</title>
		<link>https://blogs.nvidia.com/blog/2023/09/19/industrial-designer-blender-openusd-ai/</link>
		
		<dc:creator><![CDATA[Nicole Castro]]></dc:creator>
		<pubDate>Tue, 19 Sep 2023 18:15:19 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Meet the Omnivore]]></category>
		<category><![CDATA[NVIDIA Isaac Sim]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Rendering]]></category>
		<category><![CDATA[Synthetic Data Generation]]></category>
		<category><![CDATA[Universal Scene Description]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=66954</guid>

					<description><![CDATA[Editor’s note: This post is a part of our Meet the Omnivore series, which features individual creators and developers who use NVIDIA Omniverse and OpenUSD to accelerate their 3D workflows and create virtual worlds. As a student at the Queensland University of Technology (QUT) in Australia, Emily Boehmer was torn between pursuing the creative arts <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/19/industrial-designer-blender-openusd-ai/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is a part of our </i><a href="https://blogs.nvidia.com/blog/tag/meet-the-omnivore/"><i>Meet the Omnivore</i></a><i> series, which features individual creators and developers who use </i><a href="https://www.nvidia.com/en-us/omniverse/"><i>NVIDIA Omniverse</i></a><i> and </i><a href="https://www.nvidia.com/en-us/omniverse/usd/"><i>OpenUSD</i></a><i> to accelerate their 3D workflows and create virtual worlds.</i></p>
<p>As a student at the Queensland University of Technology (QUT) in Australia,<a href="https://eboehmer00.myportfolio.com/" target="_blank" rel="noopener"> Emily Boehmer</a> was torn between pursuing the creative arts or science.</p>
<p>And then she discovered industrial design, which allowed her to dive into research and coding while exploring visualization workflows like sketching, animation and 3D modeling.</p>
<p><img decoding="async" loading="lazy" class="wp-image-66955 size-thumbnail alignleft" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/emily-boehmer-150x150.png" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/emily-boehmer-150x150.png 150w, https://blogs.nvidia.com/wp-content/uploads/2023/09/emily-boehmer-400x400.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/emily-boehmer-500x500.png 500w, https://blogs.nvidia.com/wp-content/uploads/2023/09/emily-boehmer-768x768.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/emily-boehmer-1536x1536.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/emily-boehmer-450x450.png 450w, https://blogs.nvidia.com/wp-content/uploads/2023/09/emily-boehmer-215x215.png 215w, https://blogs.nvidia.com/wp-content/uploads/2023/09/emily-boehmer-100x100.png 100w, https://blogs.nvidia.com/wp-content/uploads/2023/09/emily-boehmer-1280x1280.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/emily-boehmer.png 1600w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p>Now, Boehmer is putting her skills to practice as a design intern at BMW Group’s Technology Office in Munich. The team uses <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, a platform for developing and connecting 3D tools and applications, and <a href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description</a> — aka OpenUSD — to enhance its <a href="https://www.nvidia.com/en-us/omniverse/synthetic-data/">synthetic data generation</a> pipelines.</p>
<p>Boehmer creates realistic 3D assets that can be used with<a href="http://sordi.ai/" target="_blank" rel="noopener"> SORDI.ai</a>, short for Synthetic Object Recognition Dataset for Industries. Published by BMW Group, Microsoft and NVIDIA, <a href="https://www.nvidia.com/en-us/on-demand/session/gtcspring22-s41142/?playlistId=playList-1f1c32ea-247f-4959-864f-78703b4c78de" target="_blank" rel="noopener">SORDI.ai</a> helps developers and researchers streamline and accelerate the training of AI for production. To automate image generation, the team developed an <a href="https://docs.omniverse.nvidia.com/extensions/latest/overview.html">extension</a> based on <a href="https://developer.nvidia.com/omniverse/replicator">Omniverse Replicator</a>, a software development kit for creating custom synthetic data generation tools.</p>
<p>As part of the SORDI.ai team, Boehmer uses <a href="https://docs.omniverse.nvidia.com/connect/latest/blender.html">Blender</a> and <a href="https://substance3d.adobe.com/plugins/substance-in-omniverse/">Adobe Substance Painter</a> to design 3D assets with high levels of physical accuracy and photorealism, helping ensure that synthetic data can be used to efficiently train AI models.</p>
<p>All the assets Boehmer creates are used to test and simulate autonomous robots on the <a href="https://developer.nvidia.com/isaac-sim">NVIDIA Isaac Sim</a> platform, which provides developers a suite of synthetic data generation capabilities that can power photorealistic, physically accurate virtual environments.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/Stillages.png"><img decoding="async" loading="lazy" class="aligncenter size-large wp-image-66958" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/Stillages-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/Stillages-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Stillages-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Stillages-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Stillages-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Stillages.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Stillages-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Stillages-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Stillages-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Stillages-1280x720.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<h2><b>Creating Realistic 3D Assets for Training AI </b></h2>
<p>As a design intern, Boehmer’s main tasks are animation and 3D modeling. The process starts with taking photos of target objects. Then, she uses the 2D photos as references by lining them up with the 3D models in Blender.</p>
<p>3D objects can consist of thousands of polygons, so Boehmer creates two versions of the asset — one with a low number of polygons and one with a higher polygon count. The details of the high-poly version can be baked onto the low-poly model, helping maintain more details so the asset looks realistic.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/boehmer-blender-1.png"><img decoding="async" loading="lazy" class="aligncenter wp-image-66984 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/boehmer-blender-1-672x357.png" alt="" width="672" height="357" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/boehmer-blender-1-672x357.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/boehmer-blender-1-400x213.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/boehmer-blender-1-768x408.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/boehmer-blender-1-842x447.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/boehmer-blender-1-406x215.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/boehmer-blender-1-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/boehmer-blender-1.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<p>Once the 3D assets are created, Boehmer uses the models to start assembling scenes. Her favorite aspect of the Omniverse platform is the flexibility of USD, because it allows her to easily make changes to 3D models.</p>
<p>USD workflows have enabled the BMW Group’s design teams to create many different scenes using the same components, as they can easily access all the USD files stored on Omniverse Nucleus. When creating portions of a scene, Boehmer pulls from dozens of USD models from SORDI.ai and adds them into scenes that will be used by other designers to assemble larger factory scenes.</p>
<p>Boehmer only has to update the USD file of the original asset to automatically apply changes to all reference files containing it.</p>
<p>“It’s great to see USD support for both Blender and Substance Painter,” she said. “When I create 3D assets using USD, I can be confident that they’ll look and behave as expected in the scenes they’ll be placed in.”</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/Emily-Boehmer-Process-1.png"><img decoding="async" loading="lazy" class="aligncenter wp-image-66990 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/Emily-Boehmer-Process-1-672x357.png" alt="" width="672" height="357" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/Emily-Boehmer-Process-1-672x357.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Emily-Boehmer-Process-1-400x213.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Emily-Boehmer-Process-1-768x408.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Emily-Boehmer-Process-1-842x447.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Emily-Boehmer-Process-1-406x215.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Emily-Boehmer-Process-1-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Emily-Boehmer-Process-1.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<h2><b>Building Factory Scenes With Synthetic Data</b></h2>
<p>The Isaac Sim platform is a key part of the SORDI.ai team’s workflow. It’s used to develop pipelines that use generative AI and procedural algorithms for 3D scene generation. The team also developed an extension based on Omniverse Replicator that automates randomization within a scene when generating synthetic images.</p>
<p>“The role of design interns like me is to realistically model and texture the assets used for scenes built in Isaac Sim,” Boehmer said. “The more realistic the assets are, the more realistic the synthetic images can be and the more effective they are for training AI models for real scenarios.”</p>
<p>Data annotation — the process of labeling data like images, text, audio or video with relevant tags — makes it easier for AI to understand the data, but the manual process can be incredibly time-consuming, especially for large quantities of content. SORDI.ai addresses these challenges by using synthetic data to train AI.</p>
<p>When importing assets into Omniverse and creating USD versions of the files, Boehmer tags them with the appropriate data label. Once these assets have been put together in a scene, she can use Omniverse Replicator to generate images that are automatically annotated using the original labels.</p>
<p>And using SORDI.ai, designers can set up scenes and generate thousands of annotated images with just one click.</p>
<p>Boehmer will be a guest on an <a href="https://www.addevent.com/event/IH18643084" target="_blank" rel="noopener">Omniverse livestream</a> on Wednesday, Sept. 20, where she’ll demonstrate how she uses Blender and Substance Painter in Omniverse for synthetic image generation pipelines.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/Dolly.png"><img decoding="async" loading="lazy" class="aligncenter size-large wp-image-66967" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/Dolly-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/Dolly-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dolly-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dolly-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dolly-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dolly.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dolly-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dolly-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dolly-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Dolly-1280x720.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<h2><b>Join In on the Creation</b></h2>
<p>Anyone can build their own <a href="https://developer.nvidia.com/omniverse">Omniverse extension or Connector</a> to enhance their 3D workflows and tools. <a href="https://www.nvidia.com/en-us/omniverse/creators/">Creators</a> and <a href="https://developer.nvidia.com/nvidia-omniverse-platform">developers</a> can download <a href="https://www.nvidia.com/en-us/omniverse/">Omniverse for free</a>, and <a href="https://www.nvidia.com/en-us/omniverse/enterprise/">enterprise teams</a> can use the platform for their 3D projects.</p>
<p>Check out artwork from other “Omnivores” and submit projects in the <a href="https://www.nvidia.com/en-us/omniverse/gallery-submissions/">gallery</a>. See how creators are using OpenUSD to accelerate a variety of 3D workflows in the latest <a href="https://resources.nvidia.com/en-us-omniverse-usd/ov-openusd-allstars">OpenUSD All Stars</a>. And connect workflows to Omniverse with software from Adobe, Autodesk, Blender, Epic Games, Reallusion <a href="https://www.nvidia.com/en-us/omniverse/ecosystem/">and more</a>.</p>
<p><i>Get started with NVIDIA Omniverse by downloading the standard license </i><a href="https://www.nvidia.com/en-us/omniverse/download/"><i>free</i></a><i>, or learn how </i><a href="https://www.nvidia.com/en-us/omniverse/enterprise/"><i>Omniverse Enterprise</i><i> can connect your team</i></a><i>. Developers can </i><a href="https://developer.nvidia.com/omniverse/get-started/"><i>get started with Omniverse</i></a><i> resources and learn about </i><a href="https://developer.nvidia.com/usd"><i>OpenUSD</i></a><i>. Explore the </i><a href="https://www.nvidia.com/en-us/omniverse/ecosystem/"><i>growing ecosystem of 3D tools</i></a><i> connected to Omniverse.</i></p>
<p><i>Stay up to date on the platform by subscribing to the </i><a href="https://nvda.ws/3u5KPv1"><i>newsletter</i></a><i>, and follow NVIDIA Omniverse on </i><a href="https://www.instagram.com/nvidiaomniverse/"><i>Instagram</i></a><i>, </i><a href="https://medium.com/@nvidiaomniverse" target="_blank" rel="noopener"><i>Medium</i></a><i> and </i><a href="https://twitter.com/nvidiaomniverse" target="_blank" rel="noopener"><i>Twitter</i></a><i>. For more, join the </i><a href="https://www.nvidia.com/en-us/omniverse/community/"><i>Omniverse community</i></a><i> and check out the Omniverse </i><a href="https://forums.developer.nvidia.com/c/omniverse/300"><i>forums</i></a><i>, </i><a href="https://discord.com/invite/XWQNJDNuaC" target="_blank" rel="noopener"><i>Discord server</i></a><i>, </i><a href="https://www.twitch.tv/nvidiaomniverse" target="_blank" rel="noopener"><i>Twitch</i></a><i> and </i><a href="https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA" target="_blank" rel="noopener"><i>YouTube</i></a><i> channels. </i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/Dolly.png"
			type="image/png"
			width="2048"
			height="1152"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/Dolly-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Meet the Omnivore: Industrial Designer Blends Art and OpenUSD to Create 3D Assets for AI Training]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Ray Shines With NVIDIA AI: Anyscale Collaboration to Help Developers Build, Tune, Train and Scale Production LLMs</title>
		<link>https://blogs.nvidia.com/blog/2023/09/18/llm-anyscale-nvaie/</link>
		
		<dc:creator><![CDATA[Adel El Hallak]]></dc:creator>
		<pubDate>Mon, 18 Sep 2023 13:00:09 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[NVIDIA Hopper Architecture]]></category>
		<category><![CDATA[NVIDIA Triton]]></category>
		<category><![CDATA[Open Source]]></category>
		<category><![CDATA[TensorRT]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=66926</guid>

					<description><![CDATA[Large language model development is about to reach supersonic speed thanks to a collaboration between NVIDIA and Anyscale. At its annual Ray Summit developers conference, Anyscale — the company behind the fast growing open-source unified compute framework for scalable computing —  announced today that it is bringing NVIDIA AI to Ray open source and the <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/18/llm-anyscale-nvaie/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Large language model development is about to reach supersonic speed thanks to a collaboration between NVIDIA and Anyscale.</p>
<p>At its annual Ray Summit developers conference, Anyscale — the company behind the fast growing open-source unified compute framework for scalable computing —  <a href="https://www.anyscale.com/anyscale-teams-with-nvidia-to-supercharge-llm-performance-and-efficiency">announced</a> today that it is bringing NVIDIA AI to <a href="https://www.anyscale.com/ray-open-source">Ray open source</a> and the <a href="https://www.globenewswire.com/news-release/2022/11/29/2564268/0/en/The-Anyscale-Platform-built-on-Ray-Introduces-New-Breakthroughs-in-AI-Development-Experimentation-and-AI-Scaling.html">Anyscale Platform</a>. It will also be integrated into Anyscale Endpoints, a new service <a href="https://www.anyscale.com/anyscale-launches-anyscale-endpoints-the-most-cost-efficient-service-for-the-most-popular-open-source-llms">announced today</a> that makes it easy for application developers to cost-effectively embed LLMs in their applications using the most popular open source models.</p>
<p>These integrations can dramatically speed generative AI development and efficiency while boosting security for production AI, from proprietary LLMs to open models such as Code Llama, Falcon, Llama 2, SDXL and more.</p>
<p>Developers will have the flexibility to deploy open-source NVIDIA software with Ray or opt for <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> software running on the Anyscale Platform for a fully supported and secure production deployment.</p>
<p>Ray and the Anyscale Platform are widely used by developers building advanced LLMs for generative AI applications capable of powering ‌intelligent chatbots, coding copilots and powerful search and summarization tools.</p>
<h2><b>NVIDIA and Anyscale Deliver Speed, Savings and Efficiency</b></h2>
<p>Generative AI applications are captivating the attention of businesses around the globe. Fine-tuning, augmenting and running LLMs requires significant investment and expertise. Together, NVIDIA and Anyscale can help reduce costs and complexity for generative AI development and deployment with a number of application integrations.</p>
<p><a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-supercharges-large-language-model-inference-on-nvidia-h100-gpus/">NVIDIA TensorRT-LLM</a>, new open-source software announced last week, will support Anyscale offerings to supercharge LLM performance and efficiency to deliver cost savings. Also supported in the NVIDIA AI Enterprise software platform, Tensor-RT LLM automatically scales inference to run models in parallel over multiple GPUs, which can provide up to 8x higher performance when running on NVIDIA H100 Tensor Core GPUs, compared to prior-generation GPUs.</p>
<p>TensorRT-LLM automatically scales inference to run models in parallel over multiple GPUs and includes custom GPU kernels and optimizations for a wide range of popular LLM models. It also implements the new FP8 numerical format available in the <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100</a> Tensor Core GPU Transformer Engine and offers an easy-to-use and customizable Python interface.</p>
<p><a href="https://developer.nvidia.com/triton-inference-server">NVIDIA Triton Inference Server</a> software supports inference across cloud, data center, edge and embedded devices on GPUs, CPUs and other processors. Its integration can enable Ray developers to boost efficiency when deploying AI models from multiple deep learning and machine learning frameworks, including TensorRT, TensorFlow, PyTorch, ONNX, OpenVINO, Python, RAPIDS XGBoost and more.</p>
<p>With the <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/">NVIDIA NeMo</a> framework, Ray users will be able to easily fine-tune and customize LLMs with business data,  paving the way for LLMs that understand the unique offerings of individual businesses.</p>
<p>NeMo is an end-to-end, cloud-native framework to build, customize and deploy generative AI models anywhere. It features training and inferencing frameworks, guardrailing toolkits, data curation tools and pretrained models, offering enterprises an easy, cost-effective and fast way to adopt generative AI.</p>
<h2><b>Options for Open-Source or Fully Supported Production AI </b></h2>
<p>Ray open source and the Anyscale Platform enable developers to effortlessly move from open source to deploying production AI at scale in the cloud.</p>
<p>The Anyscale Platform provides fully managed, enterprise-ready unified computing that makes it easy to build, deploy and manage scalable AI and Python applications using Ray, helping customers bring AI products to market faster at significantly lower cost.</p>
<p>Whether developers use Ray open source or the supported Anyscale Platform, Anyscale’s core functionality helps them easily orchestrate LLM workloads. The NVIDIA AI integration can help developers build, train, tune and scale AI with even greater efficiency.</p>
<p>Ray and the Anyscale Platform run on accelerated computing from leading clouds, with the option to run on hybrid or multi-cloud computing. This helps developers easily scale up as they need more computing to power a successful LLM deployment.</p>
<p>The collaboration will also enable developers to begin building models on their workstations through <a href="https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/workbench/">NVIDIA AI Workbench</a> and scale them easily across hybrid or multi-cloud accelerated computing once it’s time to move to production.</p>
<p>NVIDIA AI integrations with Anyscale are in development and expected to be available by the end of the year.</p>
<p>Developers can sign up to get the latest news on this integration as well as a free<a href="https://enterpriseproductregistration.nvidia.com/?LicType=EVAL&amp;ProductFamily=NVAIEnterprise&amp;Partner=Anyscale"> 90-day evaluation of NVIDIA AI Enterprise</a>.</p>
<p>To learn more, attend the <a href="https://raysummit.anyscale.com/">Ray Summit</a> in San Francisco this week or watch the demo video below.</p>
<p><iframe loading="lazy" title="Easily Scale LLM-Based Copilots with NVIDIA and Anyscale" width="500" height="281" src="https://www.youtube.com/embed/XGR-3dQbmWA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p><i>See this </i><a href="https://www.nvidia.com/en-us/about-nvidia/legal-info/"><i>notice</i></a><i> regarding NVIDIA’s software roadmap.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/NVIDIA-Anyscale-logos-x1280.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/NVIDIA-Anyscale-logos-x1280-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Ray Shines With NVIDIA AI: Anyscale Collaboration to Help Developers Build, Tune, Train and Scale Production LLMs]]></media:title>
			<media:description type="html">NVIDIA and Anyscale logos</media:description>
			</media:content>
			</item>
		<item>
		<title>Shout at the Devil: Capcom’s ‘Devil May Cry 5’ Joins GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/2023/09/14/geforce-now-thursday-sep-14/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 14 Sep 2023 13:00:20 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=66903</guid>

					<description><![CDATA[GFN Thursday is downright demonic, as Devil May Cry 5 comes to GeForce NOW. Capcom’s action-packed third-person brawler leads 15 titles joining the GeForce NOW library this week, including Gears Tactics and The Crew Motorfest. It’s also the last week to take on the Ultimate KovaaK’s Challenge. Get on the leaderboard today for a chance <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/14/geforce-now-thursday-sep-14/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>GFN Thursday is downright demonic, as <i>Devil May Cry 5</i> comes to <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a>.</p>
<p>Capcom’s action-packed third-person brawler leads 15 titles joining the GeForce NOW library this week, including <i>Gears Tactics</i> and <i>The Crew Motorfest</i>.</p>
<p>It’s also the last week to take on the <a href="https://www.nvidia.com/en-us/geforce-now/ultimate-challenge/">Ultimate KovaaK’s Challenge</a>. Get on the leaderboard today for a chance to win a 240Hz gaming monitor, a gaming Chromebook, GeForce NOW memberships or other prizes. The challenge ends on Thursday, Sept. 21.</p>
<h2><b>The Devil Returns</b></h2>
<figure id="attachment_66907" aria-describedby="caption-attachment-66907" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Devil_May_Cry_5.jpg"><img decoding="async" loading="lazy" class="size-large wp-image-66907" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Devil_May_Cry_5-672x378.jpg" alt="Devil May Cry 5 on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Devil_May_Cry_5-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Devil_May_Cry_5-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Devil_May_Cry_5-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Devil_May_Cry_5-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Devil_May_Cry_5-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Devil_May_Cry_5-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Devil_May_Cry_5-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Devil_May_Cry_5-1280x720.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Devil_May_Cry_5.jpg 1920w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-66907" class="wp-caption-text"><i>Jackpot!</i></figcaption></figure>
<p><i>Devil May Cry 5</i> is the next title from Capcom’s catalog to come to GeForce NOW. Members can stream all of its high-octane, stylish action at GeForce RTX quality to nearly any device, thanks to the power of GeForce NOW cloud gaming servers.</p>
<p>The threat of demonic power has returned to menace the world once again. Take on hordes of enemies as Nero, V or the legendary Dante with the ramped-up sword-and-gun gameplay that the series is known for. Battle epic bosses in adrenaline-fueled fights across the overrun Red Grave City — all to the beat of a truly killer soundtrack.</p>
<p>Take the action on the go thanks to the power of the cloud. <a href="http://geforcenow.com/membership">GeForce NOW Priority members</a> can take the fight with them across nearly any device at up to 1080p and 60 frames per second.</p>
<h2><b>Kickin’ It Into High Gear</b></h2>
<figure id="attachment_66910" aria-describedby="caption-attachment-66910" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gears_Tactics.jpg"><img decoding="async" loading="lazy" class="size-large wp-image-66910" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gears_Tactics-672x336.jpg" alt="Gears Tactics on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gears_Tactics-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gears_Tactics-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gears_Tactics-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gears_Tactics-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gears_Tactics-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gears_Tactics-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gears_Tactics-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gears_Tactics-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gears_Tactics.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-66910" class="wp-caption-text"><i>A squad of survivors is all it takes to stop the Locust threat.</i></figcaption></figure>
<p>Rise up and fight, members. <i>Gears Tactics</i> is the next PC Game Pass title to arrive in the cloud.</p>
<p><i>Gears Tactics</i> is a fast-paced, turn-based strategy game from one of the most acclaimed video game franchises — <i>Gears of War</i>. Set a dozen years before the first <i>Gears of War</i> game, the <i>Gears Tactics </i>story opens as cities on the planet Sera begin falling to the monstrous threat rising from underground: the Locust Horde. With the government in disarray, a squad of survivors emerges as humanity’s last hope. Play as the defiant soldier Gabe Diaz to recruit, develop and command squads on a desperate mission to hunt down the relentless and powerful leader of the Locust army, Ukkon, the group’s monster-making mastermind.</p>
<p>Fight for survival and outsmart the enemy with the sharpness of 4K resolution streaming from the cloud with a <a href="https://www.nvidia.com/en-us/geforce-now/memberships/">GeForce NOW Ultimate membership</a>.</p>
<h2><b>Hit the Road, Jack</b></h2>
<figure id="attachment_66913" aria-describedby="caption-attachment-66913" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-The_Crew_Motorfest.jpg"><img decoding="async" loading="lazy" class="size-large wp-image-66913" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-The_Crew_Motorfest-672x336.jpg" alt="The Crew Motorfest on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-The_Crew_Motorfest-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-The_Crew_Motorfest-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-The_Crew_Motorfest-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-The_Crew_Motorfest-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-The_Crew_Motorfest-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-The_Crew_Motorfest-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-The_Crew_Motorfest-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-The_Crew_Motorfest-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-The_Crew_Motorfest.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-66913" class="wp-caption-text"><i>The best way to see Hawaii is by car, at 100 mph.</i></figcaption></figure>
<p><i>The Crew Motorfest</i> also comes to GeForce NOW this week. The latest entry in Ubisoft’s racing franchise drops drivers into the open roads of Oahu, Hawaii. Get behind the wheel of 600+ iconic vehicles from the past, present and future, including sleek sports cars, rugged off-road vehicles and high-performance racing machines. Race alone or with friends through the bustling city of Honolulu, test off-roading skills on the ashy slopes of a volcano or kick back on the sunny beaches behind the wheel of a buggy.</p>
<p>Members can take a test drive from Sept. 14-17 with a five-hour free trial. Explore the vibrant Hawaiian open world, participate in thrilling driving activities and collect prestigious cars, with all progress carrying over to the full game purchase.</p>
<p>Take the pole position with a GeForce NOW Ultimate membership to stream <i>The Crew</i> <i>Motorfest</i> and more than 1,600 other titles at the highest frame rates. <a href="http://geforcenow.com/">Upgrade</a> today.</p>
<h2><b>A New Challenge</b></h2>
<figure id="attachment_66916" aria-describedby="caption-attachment-66916" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gunbrella.jpg"><img decoding="async" loading="lazy" class="size-large wp-image-66916" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gunbrella-672x336.jpg" alt="Gunbrella on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gunbrella-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gunbrella-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gunbrella-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gunbrella-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gunbrella-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gunbrella-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gunbrella-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gunbrella-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/GFN_Thursday-Gunbrella.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-66916" class="wp-caption-text"><i>Rain, rain, go away. The umbrella is also a gun today.</i></figcaption></figure>
<p>With GeForce NOW, there’s always something new to play. Here’s what’s hitting the playlist this week:</p>
<ul>
<li><i>Tavernacle!</i> (New release on <a href="https://store.steampowered.com/app/1937820?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Sept. 11)</li>
<li><i>Gunbrella</i> (New release on <a href="https://store.steampowered.com/app/1580180?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Sept. 13)</li>
<li><i>The Crew Motorfest</i> (New release on <a href="https://store.ubi.com/63bc67dbd406ab22f1174305.html#ucid=AFL-ID_152062&amp;maltcode=geforcenow_convst_AFL_geforcenow_vg__STORE____&amp;addinfo=">Ubisoft Connect</a>, Sept. 14)</li>
<li><i>Amnesia: The Bunker </i>(<a href="https://www.xbox.com/games/store/amnesia-the-bunker/9PC15H56NGJK?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Descenders </i>(<a href="https://www.xbox.com/games/store/descenders/C37XBX7DCBZ0?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Devil May Cry 5 </i>(<a href="https://store.steampowered.com/app/601150?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Gears Tactics </i>(<a href="https://store.steampowered.com/app/1184050?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.xbox.com/games/store/gears-tactics/9NN3HCKW5TPC?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Last Call BBS</i> (<a href="https://www.xbox.com/games/store/last-call-bbs/9NF0SNBQWN63?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>)</li>
<li><i>The Matchless Kungfu</i> (<a href="https://store.steampowered.com/app/1696440?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Mega City Police</i> (<a href="https://store.steampowered.com/app/2259210?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Opus Magnum</i> (<a href="https://www.xbox.com/games/store/opus-magnum/9P5QNLWDKHPF?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>)</li>
<li><i>Remnant II</i> (<a href="https://www.epicgames.com/store/p/remnant-2?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Space Hulk: Deathwing &#8211; Enhanced Edition</i> (<a href="https://www.xbox.com/games/store/space-hulk-deathwing-enhanced-edition-windows-10/9N8DKG2R0HKZ?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>)</li>
<li><i>Superhot </i>(<a href="https://www.xbox.com/games/store/superhot-windows-10/9NV17MJB26PG?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>)</li>
<li><i>Vampyr</i> (<a href="https://www.xbox.com/games/store/vampyr/9NT2QNP382V6?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">Twitter</a> or in the comments below.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/gfn-thursday-9-14-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/gfn-thursday-9-14-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Shout at the Devil: Capcom’s ‘Devil May Cry 5’ Joins GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Unlocking the Language of Genomes and Climates: Anima Anandkumar on Using Generative AI to Tackle Global Challenges</title>
		<link>https://blogs.nvidia.com/blog/2023/09/13/anima-anandkumar-generative-ai/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Wed, 13 Sep 2023 13:00:11 +0000</pubDate>
				<category><![CDATA[The AI Podcast]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=66807</guid>

					<description><![CDATA[Generative AI-based models can not only learn and understand natural languages — they can learn the very language of nature itself, presenting new possibilities for scientific research. Anima Anandkumar, Bren Professor at Caltech and senior director of AI research at NVIDIA, was recently invited to speak at the President’s Council of Advisors on Science and <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/13/anima-anandkumar-generative-ai/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Generative AI-based models can not only learn and understand natural languages — they can learn the very language of nature itself, presenting new possibilities for scientific research.</p>
<p>Anima Anandkumar, Bren Professor at Caltech and senior director of AI research at NVIDIA, was recently invited to speak at the <a href="https://www.youtube.com/watch?v=gZb7Yr4C8po">President’s Council of Advisors on Science and Technology</a>.</p>
<p>At the talk, Anandkumar said that generative AI was described as “an inflection point in our lives,” with discussions swirling around how to “harness it to benefit society and humanity through scientific applications.”</p>
<p>On the latest episode of NVIDIA’s <a href="https://blogs.nvidia.com/ai-podcast/">AI Podcast</a>, host Noah Kravitz spoke with Anandkumar on generative AI’s potential to make splashes in the scientific community.</p>
<p>It can, for example, be fed DNA, RNA, viral and bacterial data to craft a model that understands the language of genomes. That model can help predict dangerous coronavirus variants to accelerate drug and vaccine research.</p>
<p>Generative AI can also predict extreme weather events like hurricanes or heat waves. Even with an AI boost, trying to predict natural events is challenging because of the sheer number of variables and unknowns.</p>
<p>“Those are the aspects we’re working on at NVIDIA and Caltech, in collaboration with many other organizations, to say, ‘How do we capture the multitude of scales present in the natural world?’” she said. “With the limited data we have, can we hope to extrapolate to finer scales? Can we hope to embed the right constraints and come up with physically valid predictions that make a big impact?”</p>
<p>Anandkumar adds that to ensure AI models are responsibly and safely used, existing laws must be strengthened to prevent dangerous downstream applications.</p>
<p>She also talks about the AI boom, which is transforming the role of humans across industries, and problems yet to be solved.</p>
<p>“This is the research advice I give to everyone: the most important thing is the question, not the answer,” she said.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1613940966%3Fsecret_token%3Ds-AMzlwyAPES3&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="Anima Anandkumar on Using Generative AI to Tackle Global Challenges - Ep. 203" href="https://soundcloud.com/theaipodcast/anima-anandkumar/s-AMzlwyAPES3" target="_blank" rel="noopener">Anima Anandkumar on Using Generative AI to Tackle Global Challenges &#8211; Ep. 203</a></div>
<h2>You Might Also Like</h2>
<p><a href="https://soundcloud.com/theaipodcast/jules-anh-tuan-nguyen-explains-how-ai-lets-amputee-control-prosthetic-hand-video-games-ep-149">Jules Anh Tuan Nguyen Explains How AI Lets Amputee Control Prosthetic Hand, Video Games<br />
</a>A postdoctoral researcher at the University of Minnesota discusses his efforts to allow amputees to control their prosthetic limb — right down to the finger motions — with their minds.</p>
<p><a href="https://soundcloud.com/theaipodcast/ai-overjet">Overjet’s Ai Wardah Inam on Bringing AI to Dentistry<br />
</a>Overjet, a member of <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a>, is moving fast to bring AI to dentists’ offices. Dr. Wardah Inam, CEO of the company, discusses using AI to improve patient care.</p>
<p><a href="https://soundcloud.com/theaipodcast/ai-luis-voloch">Immunai CTO and Co-Founder Luis Voloch on Using Deep Learning to Develop New Drugs<br />
</a>Luis Voloch talks about tackling the challenges of the immune system with a machine learning and data science mindset.</p>
<h2>Subscribe to the AI Podcast: Now Available on Amazon Music</h2>
<p><a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">The AI Podcast is now available through Amazon Music</a>.</p>
<p>In addition, get the <a href="https://blogs.nvidia.com/ai-podcast/">AI Podcast</a> through <a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439">iTunes</a>, <a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjI2NDAzNDEzMy9zb3VuZHMucnNz">Google Podcasts</a>, <a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm">Google Play</a>, <a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us">Castbox</a>, DoggCatcher, <a href="https://overcast.fm/itunes1186480811/the-ai-podcast">Overcast</a>, <a href="https://player.fm/series/the-ai-podcast">PlayerFM</a>, Pocket Casts, <a href="http://www.podbay.fm/show/1186480811">Podbay</a>, <a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast">PodBean</a>, PodCruncher, PodKicker, <a href="https://soundcloud.com/theaipodcast">Soundcloud</a>, <a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L">Spotify</a>, <a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr">Stitcher</a> and <a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/">TuneIn</a>.</p>
<p>Make the AI Podcast better. Have a few minutes to spare? Fill out <a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short">this listener survey</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2020/12/20181026-BJ-MB-CC__6881-M-Anima-Anandkumar-US-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1365"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2020/12/20181026-BJ-MB-CC__6881-M-Anima-Anandkumar-US-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Unlocking the Language of Genomes and Climates: Anima Anandkumar on Using Generative AI to Tackle Global Challenges]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Lends Support to Washington’s Efforts to Ensure AI Safety</title>
		<link>https://blogs.nvidia.com/blog/2023/09/12/ai-safety-washington/</link>
		
		<dc:creator><![CDATA[Ned Finkle]]></dc:creator>
		<pubDate>Tue, 12 Sep 2023 20:35:31 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Corporate Responsibility]]></category>
		<category><![CDATA[Cybersecurity]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Public Sector]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=66820</guid>

					<description><![CDATA[In an event at the White House today, NVIDIA announced support for voluntary commitments that the Biden Administration developed to ensure advanced AI systems are safe, secure and trustworthy. The news came the same day NVIDIA’s chief scientist, Bill Dally, testified before a U.S. Senate subcommittee seeking input on potential legislation covering generative AI. Separately, <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/12/ai-safety-washington/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>In an event at the White House today, NVIDIA announced support for voluntary commitments that the Biden Administration developed to ensure advanced AI systems are safe, secure and trustworthy.</p>
<p>The news came the same day NVIDIA’s chief scientist, Bill Dally, testified before a U.S. Senate subcommittee seeking input on potential legislation covering<a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/"> generative AI</a>. Separately, NVIDIA founder and CEO Jensen Huang will join other industry leaders in a closed-door meeting on AI Wednesday with the full Senate.</p>
<p>Seven companies including Adobe, IBM, Palantir and Salesforce joined NVIDIA in supporting the<a href="https://www.whitehouse.gov/wp-content/uploads/2023/07/Ensuring-Safe-Secure-and-Trustworthy-AI.pdf"> eight agreements</a> the Biden-Harris administration released in July with support from Amazon, Anthropic, Google, Inflection, Meta, Microsoft and OpenAI.</p>
<p>The commitments are designed to advance common standards and best practices to ensure the safety of generative AI systems until regulations are in place, the White House said. They include:</p>
<ul>
<li style="font-weight: 400;" aria-level="1">Testing the safety and capabilities of AI products before they’re deployed,</li>
<li style="font-weight: 400;" aria-level="1">Safeguarding AI models against cyber and insider threats, and</li>
<li style="font-weight: 400;" aria-level="1">Using AI to help meet society’s greatest challenges, from cancer to climate change.</li>
</ul>
<h2><b>Dally Shares NVIDIA’s Experience</b></h2>
<p>In his testimony, Dally told the Senate subcommittee that government and industry should balance encouraging innovation in AI with ensuring models are deployed responsibly.</p>
<p>The subcommittee’s hearing, “Oversight of AI: Rules for Artificial Intelligence,” is among actions from policymakers around the world trying to identify and address potential risks of generative AI.</p>
<p>Earlier this year, the subcommittee heard testimonies from leaders of Anthropic, IBM and OpenAI, as well as academics such as Yoshua Bengio, a University of Montreal professor considered one of the godfathers of AI.</p>
<p>Dally, who leads a global team of more than 300 at NVIDIA Research, shared the witness table on Tuesday with Brad Smith, Microsoft’s president and vice chair. Dally’s testimony briefly encapsulated NVIDIA’s unique role in the evolution of AI over the last two decades.</p>
<h2><b>How Accelerated Computing Sparked AI</b></h2>
<p>He described how NVIDIA invented the GPU in 1999 as a graphics processing unit, then fit it for a broader role in parallel processing in 2006 with the CUDA programming software. Over time, developers across diverse scientific and technical computing fields found this new form of <a href="https://blogs.nvidia.com/blog/2021/09/01/what-is-accelerated-computing/">accelerated computing</a> could significantly advance their work.</p>
<p>Along the way, researchers discovered GPUs also were a natural fit for AI’s neural networks, because they require massive parallel processing.</p>
<p>In 2012, the AlexNet model, trained on two NVIDIA GPUs, demonstrated human-like capabilities in image recognition. That result helped spark a decade of rapid advances using GPUs, leading to ChatGPT and other generative AI models used by hundreds of millions worldwide.</p>
<p>Today, accelerated computing and generative AI are showing the potential to transform industries, address global challenges and profoundly benefit society, said Dally, who chaired Stanford University’s computer science department before joining NVIDIA.</p>
<h2><b>AI’s Potential and Limits</b></h2>
<p>In written testimony, Dally provided examples of how AI is empowering professionals to do their jobs better than they might have imagined in fields as diverse as business, healthcare and climate science.</p>
<p>Like any technology, AI products and services have risks and are subject to existing laws and regulations that aim to mitigate those risks.</p>
<p>Industry also has a role to play in deploying AI responsibly. Developers set limits for AI models when they train them and define their outputs.</p>
<p>Dally noted that NVIDIA released in April<a href="https://blogs.nvidia.com/blog/2023/04/25/ai-chatbot-guardrails-nemo/"> NeMo Guardrails</a>, open-source software developers can use to guide generative AI applications in producing accurate, appropriate and secure text responses. He said that NVIDIA also maintains internal risk-management guidelines for AI models.</p>
<h2><b>Eyes on the Horizon</b></h2>
<p>Making sure that new and exceptionally large AI models are accurate and safe is a natural role for regulators, Dally suggested.</p>
<figure id="attachment_66896" aria-describedby="caption-attachment-66896" style="width: 400px" class="wp-caption alignleft"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/Bluemnthal-greets-Dally-before-hearing-CROP.jpg"><img decoding="async" loading="lazy" class="wp-image-66896 size-medium" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/Bluemnthal-greets-Dally-before-hearing-CROP-400x289.jpg" alt="Picture of Sen Blumenthal welcoming Dally to the hearing" width="400" height="289" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/Bluemnthal-greets-Dally-before-hearing-CROP-400x289.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Bluemnthal-greets-Dally-before-hearing-CROP-672x486.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Bluemnthal-greets-Dally-before-hearing-CROP-768x555.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Bluemnthal-greets-Dally-before-hearing-CROP-622x450.jpg 622w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Bluemnthal-greets-Dally-before-hearing-CROP-297x215.jpg 297w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Bluemnthal-greets-Dally-before-hearing-CROP-138x100.jpg 138w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Bluemnthal-greets-Dally-before-hearing-CROP.jpg 777w" sizes="(max-width: 400px) 100vw, 400px" /></a><figcaption id="caption-attachment-66896" class="wp-caption-text">Subcommittee chair Sen. Richard Blumenthal welcomed Dally to the hearing.</figcaption></figure>
<p>He said that these “frontier” models are being developed at a gigantic scale. They exceed the capabilities of ChatGPT and other existing models that have already been well-explored by developers and users.</p>
<p>Dally urged the subcommittee to balance thoughtful regulation with the need to encourage innovation in an AI developer community that includes thousands of startups, researchers and enterprises worldwide. AI tools should be widely available to ensure a level playing field, he said.</p>
<p>During questioning, Senator Amy Klobuchar asked Dally why NVIDIA announced<a href="https://blogs.nvidia.com/blog/2023/03/21/generative-ai-getty-images/"> in March</a> it’s working with Getty Images.</p>
<p>“At NVIDIA, we believe in respecting people’s intellectual property rights,” Dally replied. “We partnered with Getty to train large language models with a service called<a href="https://www.nvidia.com/en-us/gpu-cloud/picasso/"> Picasso</a>, so people who provided the original content got remunerated.”</p>
<p>In closing, Dally reaffirmed NVIDIA’s dedication to innovating generative AI and accelerated computing in ways that serve the best interests of all.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/Dally-in-Senate-QA-best-x1280.jpg"
			type="image/jpeg"
			width="1547"
			height="823"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/Dally-in-Senate-QA-best-x1280-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Lends Support to Washington’s Efforts to Ensure AI Safety]]></media:title>
			<media:description type="html">Dally testifies at Senate hearing on AI</media:description>
			</media:content>
			</item>
		<item>
		<title>Mobility Gets Amped: IAA Show Floor Energized by Surge in EV Reveals, Generative AI</title>
		<link>https://blogs.nvidia.com/blog/2023/09/12/iaa-drive-ecosystem-roundup/</link>
		
		<dc:creator><![CDATA[Marie Labrie]]></dc:creator>
		<pubDate>Tue, 12 Sep 2023 18:08:26 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[Digital Twin]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Industrial and Manufacturing]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=66802</guid>

					<description><![CDATA[Generative AI’s transformative effect on the auto industry took center stage last week at the International Motor Show Germany, known as IAA, in Munich. NVIDIA’s Danny Shapiro, VP of automotive marketing, explained in his IAA keynote how this driving force is accelerating innovation and streamlining processes — from advancing design, engineering and digital-twin deployment for <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/12/iaa-drive-ecosystem-roundup/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Generative AI’s transformative effect on the auto industry took center stage last week at the International Motor Show Germany, known as IAA, in Munich.</p>
<p>NVIDIA’s Danny Shapiro, VP of automotive marketing, explained in <a href="https://www.youtube.com/watch?v=f1Emp-SjDvk&amp;t=2s&amp;ab_channel=IAAMOBILITY" target="_blank" rel="noopener">his IAA keynote</a> how this driving force is accelerating innovation and streamlining processes — from advancing design, engineering and digital-twin deployment for optimizing manufacturing…to accelerating AV development with simulation…to enhancing retail experiences.</p>
<p>The gen AI message was also shared just ahead of the show in a <a href="https://www.youtube.com/watch?v=u8DVEIqo89s&amp;ab_channel=IAAMOBILITY" target="_blank" rel="noopener">fireside chat</a> at NVIDIA headquarters with NVIDIA VP of Automotive Ali Kani and Aakash Arora, managing director and partner at Boston Consulting Group, who discussed the rapid pace of innovation, and how genAI will improve in-car experiences and transform the way vehicles are designed, manufactured and sold.</p>
<h2><strong>Electric Vehicles Dominate the Show Floor </strong></h2>
<p>The auto industry’s move toward electrification was on full display at IAA, with a number of global automakers showcasing their current and upcoming electric mobility lineup.</p>
<p><b>Mercedes-Benz</b> took the wraps off its Concept CLA Class, giving visitors insight into the brand’s future vision for the entry-level segment.</p>
<p>Designed on the upcoming Mercedes-Benz Modular Architecture (MMA) platform, the exterior of the Concept CLA Class teases an iconic design and evokes dynamic performance. Its interior provides the ultimate customer experience with exceptional comfort and convenience.</p>
<p>The combination of high performance, sustainability, safety and comfort paired with an outstanding digital experience will help Mercedes-Benz realize its Ambition 2039 vision to be net carbon neutral across its entire fleet of new vehicles by the end of the next decade.</p>
<p>As the first car to be developed on the MMA platform, the Concept CLA Class paves the way for next-gen electric-drive technology, and features Mercedes-Benz’s new operating system, MB.OS, with automated driving capabilities powered by <a href="https://www.nvidia.com/en-us/self-driving-cars/" target="_blank" rel="noopener">NVIDIA DRIVE</a>. With an anticipated range of more than 466 miles, the CLA Class has an 800V electric architecture to maximize efficiency and performance and rapid charging. Configured for a sporty, rear-wheel drive, its modular design will also be scalable for other vehicle segments.</p>
<p><b>Lotus </b>conducted test drives at IAA of its <a href="https://blogs.nvidia.com/blog/2022/10/31/lotus-eletre-ai-drive-orin/" target="_blank" rel="noopener">Lotus Eletre Hyper-SUV</a>, which features an immersive digital cockpit, a battery range of up to 370 miles and autonomous-driving capabilities powered by the <a href="https://www.nvidia.com/en-us/self-driving-cars/hardware/" target="_blank" rel="noopener">NVIDIA DRIVE Orin</a> system-on-a-chip. With DRIVE at the wheel, the all-electric car offers server-level computing power that can be continuously enhanced during the car’s lifetime through over-the-air updates.</p>
<figure id="attachment_66872" aria-describedby="caption-attachment-66872" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" loading="lazy" class="wp-image-66872 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-672x336.png" alt="" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-672x336.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-400x200.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-768x384.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-842x421.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-406x203.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-188x94.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6-1280x640.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image6.png 1400w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-66872" class="wp-caption-text">Lotus Eletre Hyper-SUV. Image courtesy of Lotus.</figcaption></figure>
<p>U.S.-based<b> Lucid Motors</b> premiered during IAA its limited-production Lucid Air Midnight Dream Edition electric sedan, which provides up to 496 miles of range. The sedan was created with the European market in mind.</p>
<p>The automaker also showcased <a href="https://blogs.nvidia.com/blog/2022/11/17/lucid-gravity-suv-nvidia-drive/" target="_blank" rel="noopener">other models</a>, including its Lucid Air Pure, Air Touring and Air Grand Touring, which come with the DreamDrive Pro advanced driver-assistance system (ADAS) powered by the high-performance compute of <a href="https://developer.nvidia.com/drive" target="_blank" rel="noopener">NVIDIA DRIVE</a> for a seamless automated driving experience.</p>
<figure id="attachment_66875" aria-describedby="caption-attachment-66875" style="width: 672px" class="wp-caption alignnone"><img decoding="async" loading="lazy" class="wp-image-66875 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-672x448.png" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-672x448.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-400x267.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-768x513.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1536x1025.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-674x450.png 674w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-322x215.png 322w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-150x100.png 150w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2-1280x854.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image2.png 1999w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-66875" class="wp-caption-text">Lucid Air Midnight Dream. Image courtesy of Lucid Motors.</figcaption></figure>
<p>China’s emerging EV makers — which have been quick to embrace the shift to electric powertrains and software-defined strategies — were also in force at IAA as they set their sights on the European market.</p>
<p>Auto giant <b>BYD</b> presented a diverse lineup of five EVs targeting the European market, along with the seven-seater <b>DENZA</b> D9 MPV, or multi-purpose vehicle, which features significant safety, performance and convenience options for drivers and passengers. <a href="https://blogs.nvidia.com/blog/2023/08/08/denza-wpp-car-configurators-nvidia-omniverse-cloud/" target="_blank" rel="noopener">DENZA</a> is a joint venture brand between BYD and Mercedes-Benz.</p>
<p>The eco-friendly EVs demonstrate the latest in next-gen electric technology and underscore BYD’s position as a leading global car brand.</p>
<figure id="attachment_66878" aria-describedby="caption-attachment-66878" style="width: 672px" class="wp-caption alignnone"><img decoding="async" loading="lazy" class="wp-image-66878 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-672x448.png" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-672x448.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-400x267.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-768x512.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1536x1024.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-675x450.png 675w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-322x215.png 322w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-150x100.png 150w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3-1280x854.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image3.png 1999w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-66878" class="wp-caption-text">BYD booth at IAA. Image courtesy of BYD.</figcaption></figure>
<p><b>LeapMotor</b> unveiled its new model, the C10 SUV, built on its LEAP 3.0 architecture. The vehicle is equipped with 30 high-resolution sensors, including lidar and 8-megapixel high-definition cameras, for accurate surround-perception capabilities. It’s powered by NVIDIA DRIVE Orin, which delivers 254 TOPS of compute to enable safe, high-speed and urban intelligent-driving capabilities.</p>
<figure id="attachment_66881" aria-describedby="caption-attachment-66881" style="width: 672px" class="wp-caption alignnone"><img decoding="async" loading="lazy" class="wp-image-66881 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-672x389.png" alt="" width="672" height="389" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-672x389.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-400x231.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-768x444.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1536x889.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-778x450.png 778w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-372x215.png 372w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-173x100.png 173w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4-1280x741.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image4.png 1628w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-66881" class="wp-caption-text">LeapMotor C10 SUV. Image courtesy of LeapMotor.</figcaption></figure>
<p><b>XPENG’s</b> inaugural presence at IAA served as the ideal opportunity to introduce its latest models to Europe, including its <a href="https://blogs.nvidia.com/blog/2022/09/23/xpeng-g9-ev-innovation-drive-orin/" target="_blank" rel="noopener">G9</a> and <a href="https://blogs.nvidia.com/blog/2020/04/27/xpeng-p7-intelligent-transportation/" target="_blank" rel="noopener">P7</a> EVs, with NVIDIA DRIVE Orin under the hood. Deliveries of the P7 recently commenced, with the vehicles now available in<a href="https://blogs.nvidia.com/blog/2023/02/09/xpeng-electric-vehicles-expand-in-europe/" target="_blank" rel="noopener"> Norway, Sweden, Denmark and the Netherlands</a>. The automaker’s intelligent <a href="https://blogs.nvidia.com/blog/2023/07/05/xpeng-g6-coupe-suv-drive-orin/" target="_blank" rel="noopener">G6</a> Coupe SUV, also powered by NVIDIA DRIVE Orin, will be made available to the European market next year.</p>
<figure id="attachment_66884" aria-describedby="caption-attachment-66884" style="width: 672px" class="wp-caption alignnone"><img decoding="async" loading="lazy" class="wp-image-66884 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-672x448.png" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-672x448.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-400x267.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-768x512.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1536x1024.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-675x450.png 675w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-322x215.png 322w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-150x100.png 150w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7-1280x854.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image7.png 1999w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-66884" class="wp-caption-text">XPENG G9 and P7. Image courtesy of XPENG.</figcaption></figure>
<h2><strong>Ecosystem Partners Paint IAA Show Floor Green</strong></h2>
<p>In addition to automakers, NVIDIA ecosystem partners at IAA showcased their latest innovations and developments in the mobility space:</p>
<ul>
<li><b>DeepRoute.ai</b> showed its Driver 3.0 HD Map-Free solution built on NVIDIA DRIVE Orin and designed to offer a non-geofenced solution for mass-produced ADAS vehicles. The company plans to bring this NVIDIA-powered solution to the European market and expand beyond later next year.</li>
<li><b>DeepScenario </b>showed how it’s using NVIDIA hardware for training and inference on its AI models.</li>
<li><b>dRISK</b>, an NVIDIA DRIVE Sim ecosystem member, demonstrated its full-stack solution for training, testing and validating on <a href="https://blogs.nvidia.com/blog/2019/02/06/what-is-level-2-automated-driving/" target="_blank" rel="noopener">level 2-level 5</a> ADAS/AV/ADS software, preparing autonomy to handle regulatory requirements and the full complexity of the real world for the next generation of highly effective and commercially viable autonomous solutions.</li>
<li><b>NODAR</b> introduced GridDetect, its latest 3D vision product for level 3 driving. Using off-the-shelf cameras and NVIDIA DRIVE Orin, NODAR’s latest system provides high-resolution, real-time 3D sensing at up to 1,000m and can detect objects as small as 10cm at 150m. GridDetect also provides a comprehensive bird’s-eye view of objects in all conditions — including in challenging scenarios like nighttime, adverse weather and severe fog.</li>
<li><b>SafeAD</b> demonstrated its perception technology for mapless driving, fleet map updates and validation processes.</li>
</ul>
<figure id="attachment_66887" aria-describedby="caption-attachment-66887" style="width: 652px" class="wp-caption alignnone"><img decoding="async" loading="lazy" class="wp-image-66887 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/image1-652x500.png" alt="" width="652" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/image1-652x500.png 652w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image1-400x307.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image1-768x589.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image1-1536x1177.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image1-587x450.png 587w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image1-280x215.png 280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image1-130x100.png 130w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image1-1280x981.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/image1.png 2000w" sizes="(max-width: 652px) 100vw, 652px" /><figcaption id="caption-attachment-66887" class="wp-caption-text">NODAR GridDetect system for high-resolution, real-time 3D sensing. Image courtesy of NODAR.</figcaption></figure>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/new-iaa-feature.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/new-iaa-feature-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Mobility Gets Amped: IAA Show Floor Energized by Surge in EV Reveals, Generative AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>A Quantum Boost: cuQuantum With PennyLane Lets Simulations Ride Supercomputers</title>
		<link>https://blogs.nvidia.com/blog/2023/09/12/quantum-supercomputers-pennylane/</link>
		
		<dc:creator><![CDATA[Sam Stanwyck]]></dc:creator>
		<pubDate>Tue, 12 Sep 2023 15:00:56 +0000</pubDate>
				<category><![CDATA[Research]]></category>
		<category><![CDATA[Supercomputing]]></category>
		<category><![CDATA[Customer Stories]]></category>
		<category><![CDATA[GPU Computing]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[New GPU Uses]]></category>
		<category><![CDATA[NVIDIA Ampere Architecture]]></category>
		<category><![CDATA[Open Source]]></category>
		<category><![CDATA[Parallel Computing]]></category>
		<category><![CDATA[Science]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=66694</guid>

					<description><![CDATA[Ten miles in from Long Island’s Atlantic coast, Shinjae Yoo is revving his engine. The computational scientist and machine learning group lead at the U.S. Department of Energy’s Brookhaven National Laboratory is one of many researchers gearing up to run quantum computing simulations on a supercomputer for the first time, thanks to new software. Yoo’s <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/12/quantum-supercomputers-pennylane/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Ten miles in from Long Island’s Atlantic coast, Shinjae Yoo is revving his engine.</p>
<p>The computational scientist and machine learning group lead at the U.S. Department of Energy’s Brookhaven National Laboratory is one of many researchers gearing up to run quantum computing simulations on a supercomputer for the first time, thanks to new software.</p>
<p>Yoo’s engine, <a href="https://blogs.nvidia.com/blog/2021/05/27/nersc-perlmutter-ai-supercomputer/">the Perlmutter supercomputer</a> at the National Energy Research Scientific Computing Center (NERSC), is using the latest version of <a href="https://pennylane.ai/">PennyLane</a>, a quantum programming framework from Toronto-based Xanadu. The open-source software, which builds on the <a href="https://developer.nvidia.com/cuquantum-sdk">NVIDIA cuQuantum software development kit</a>, lets simulations run on high-performance clusters of NVIDIA GPUs.</p>
<p>The performance is key because researchers like Yoo need to process ocean-size datasets. He’ll run his programs across as many as 256 <a href="https://www.nvidia.com/en-us/data-center/a100/">NVIDIA A100 Tensor Core GPUs</a> on Perlmutter to simulate about three dozen <a href="https://blogs.nvidia.com/blog/2022/07/29/what-is-a-qpu/">qubits</a> — the powerful calculators quantum computers use.</p>
<p>That’s about twice the number of qubits most researchers can model these days.</p>
<h2><b>Powerful, Yet Easy to Use</b></h2>
<p>The so-called multi-node version of PennyLane, used in tandem with the NVIDIA cuQuantum SDK, simplifies the complex job of accelerating massive simulations of quantum systems.</p>
<p>“This opens the door to letting even my interns run some of the largest simulations — that’s why I’m so excited,” said Yoo, whose team has six projects using PennyLane in the pipeline.</p>
<figure id="attachment_66812" aria-describedby="caption-attachment-66812" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/Shinjae-Yoo-Brookhaven-crop-scaled.jpg"><img decoding="async" loading="lazy" class="size-large wp-image-66812" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/Shinjae-Yoo-Brookhaven-crop-672x443.jpg" alt="Pic of Brookhaven’s Shinjae Yoo prepares to scale up his quantum work on the Perlmutter supercomputer." width="672" height="443" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/Shinjae-Yoo-Brookhaven-crop-672x443.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Shinjae-Yoo-Brookhaven-crop-400x264.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Shinjae-Yoo-Brookhaven-crop-768x507.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Shinjae-Yoo-Brookhaven-crop-1536x1013.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Shinjae-Yoo-Brookhaven-crop-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Shinjae-Yoo-Brookhaven-crop-682x450.jpg 682w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Shinjae-Yoo-Brookhaven-crop-326x215.jpg 326w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Shinjae-Yoo-Brookhaven-crop-152x100.jpg 152w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Shinjae-Yoo-Brookhaven-crop-1280x844.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-66812" class="wp-caption-text">Brookhaven’s Shinjae Yoo prepares to scale up his quantum work on the Perlmutter supercomputer.</figcaption></figure>
<p>His work aims to advance high-energy physics and machine learning. Other researchers use quantum simulations to take chemistry and materials science to new levels.</p>
<p>Quantum computing is alive in corporate R&amp;D centers, too.</p>
<p>For example, Xanadu is helping companies like <a href="https://www.prnewswire.com/news-releases/xanadu-and-rolls-royce-to-build-quantum-computing-tools-with-pennylane-301723158.html">Rolls-Royce</a> develop quantum algorithms to design state-of-the-art jet engines for sustainable aviation and <a href="https://www.volkswagen-newsroom.com/en/press-releases/volkswagen-group-and-xanadu-establish-quantum-simulation-program-for-battery-materials-15253">Volkswagen Group</a> invent more powerful batteries for electric cars.</p>
<p><b>Four More Projects on Perlmutter</b></p>
<p>Meanwhile, at NERSC, at least four other projects are in the works this year using multi-node Pennylane, according to Katherine Klymko, who leads the quantum computing program there. They include efforts from NASA Ames and the University of Alabama.</p>
<p>“Researchers in my field of chemistry want to study molecular complexes too large for classical computers to handle,&#8221; she said. &#8220;Tools like Pennylane let them extend what they can currently do classically to prepare for eventually running algorithms on large-scale quantum computers.”</p>
<h2><b>Blending AI, Quantum Concepts</b></h2>
<p>PennyLane is the product of a novel idea. It adapts popular deep learning techniques like backpropagation and tools like PyTorch to programming quantum computers.</p>
<p>Xanadu designed the code to run across as many types of quantum computers as possible, so the software got traction in the quantum community soon after its introduction in <a href="https://arxiv.org/pdf/2207.14734.pdf">a 2018 paper</a>.</p>
<p>“There was engagement with our content, making cutting-edge research accessible, and people got excited,” recalled Josh Izaac, director of product at Xanadu and a quantum physicist who was an author of the paper and a developer of PennyLane.</p>
<h2><b>Calls for More Qubits</b></h2>
<p>A common comment on the PennyLane forum these days is, “I want more qubits,” said Lee J. O’Riordan, a senior quantum software developer at Xanadu, responsible for PennyLane’s performance.</p>
<p>“When we started work in 2022 with cuQuantum on a single GPU, we got 10x speedups pretty much across the board … we hope to scale by the end of the year to 1,000 nodes — that’s 4,000 GPUs — and that could mean simulating more than 40 qubits,” O’Riordan said.</p>
<p>Scientists are still formulating the questions they’ll address with that performance — the kind of problem they like to have.</p>
<p>Companies designing quantum computers will use the boost to test ideas for building better systems. Their work feeds a virtuous circle, enabling new software features in PennyLane that, in turn, enable more system performance.</p>
<h2><b>Scaling Well With GPUs</b></h2>
<p>O’Riordan saw early on that GPUs were the best vehicle for scaling PennyLane’s performance. He co-authored last year <a href="https://arxiv.org/abs/2207.14734">a paper</a> on a method for splitting a quantum program across more than 100 GPUs to simulate more than 60 qubits, split into many 30 qubit sub-circuits.</p>
<figure id="attachment_66815" aria-describedby="caption-attachment-66815" style="width: 381px" class="wp-caption alignleft"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/Lee-ORiordan.jpg"><img decoding="async" loading="lazy" class="size-medium wp-image-66815" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/Lee-ORiordan-381x400.jpg" alt="Picture of Lee J. O’Riordan, PennyLane developer at Xanadu" width="381" height="400" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/Lee-ORiordan-381x400.jpg 381w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Lee-ORiordan-476x500.jpg 476w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Lee-ORiordan-429x450.jpg 429w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Lee-ORiordan-205x215.jpg 205w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Lee-ORiordan-95x100.jpg 95w, https://blogs.nvidia.com/wp-content/uploads/2023/09/Lee-ORiordan.jpg 520w" sizes="(max-width: 381px) 100vw, 381px" /></a><figcaption id="caption-attachment-66815" class="wp-caption-text">Lee J. O’Riordan</figcaption></figure>
<p>“We wanted to extend our work to even larger workloads, so when we heard NVIDIA was adding multi-node capability to cuQuantum, we wanted to support it as soon as possible,” he said.</p>
<p>Within four months, multi-node PennyLane was born.</p>
<p>“For a big, distributed GPU project, that was a great turnaround time. Everyone working on cuQuantum helped make the integration as easy as possible,” O’Riordan said.</p>
<p>A <a href="https://pennylane.ai/blog/2023/09/distributing-quantum-simulations-using-lightning-gpu-with-NVIDIA-cuQuantum/">Xanadu blog</a> details how developers can simulate large-scale systems with more than 30 qubits using PennyLane and cuQuantum.</p>
<p>The team is still collecting data, but so far on “sample-based workloads, we see almost linear scaling,” he said.</p>
<p>Or, as NVIDIA founder and CEO Jensen Huang might say, “<a href="https://www.youtube.com/live/3qSQjRaseos?feature=share&amp;t=3062">The more you buy, the more you save</a>.”</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/Pennylane-KV-Final.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/Pennylane-KV-Final-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[A Quantum Boost: cuQuantum With PennyLane Lets Simulations Ride Supercomputers]]></media:title>
			<media:description type="html">PennyLane software with cuQuantum for quantum simulations on supercomputers</media:description>
			</media:content>
			</item>
		<item>
		<title>One Small Step for Artists, One Giant Leap for Creative-Kind</title>
		<link>https://blogs.nvidia.com/blog/2023/09/12/aendom-blender-adobe-substance-3d-painter/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 12 Sep 2023 13:00:35 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=66825</guid>

					<description><![CDATA[Editor’s note: This post is part of our weekly In the NVIDIA Studio series, which celebrates featured artists, offers creative tips and tricks and demonstrates how NVIDIA Studio technology improves creative workflows.  When it comes to converting 2D concepts into 3D masterpieces, self-taught visual development artist Alex Treviño has confidence in the potential of all <a class="read-more" href="https://blogs.nvidia.com/blog/2023/09/12/aendom-blender-adobe-substance-3d-painter/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. </i></p>
<p>When it comes to converting 2D concepts into 3D masterpieces, self-taught visual development artist Alex Treviño has confidence in the potential of all aspiring creators.</p>
<p>“You may think it’s a complicated process, but trust me, it’s easier than you think,” he said.</p>
<p>The featured content creator of this week’s <i>In the NVIDIA Studio </i>installment, Treviño is the founder of <a href="https://www.aendom.com/en/about/">AENDOM</a>, a project with the mission of creating artwork rooted in storytelling elements and sharing creative processes to educate and inspire the next generation of artists.</p>
<div style="width: 1280px;" class="wp-video"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video class="wp-video-shortcode" id="video-66825-1" width="1280" height="720" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/360-textured.mp4?_=1" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/360-textured.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/09/360-textured.mp4</a></video></div>
<p>&nbsp;</p>
<p>From this initiative, the Lunar Rover collection was born.</p>
<h2><b>Shooting for the Moon</b></h2>
<p>The story behind the <i>Lunar Rover</i> collection comes from an exploration of grief and inspired by the work of artist <a href="https://mattiasadolfsson.com/">Mattias Adolfsson</a>.</p>
<p>However, Treviño wanted to translate Adolfsson’s detailed and playful caricature style into his own 3D design.</p>
<figure id="attachment_66829" aria-describedby="caption-attachment-66829" style="width: 1280px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-alex-trevino-concept-1280w_.png"><img decoding="async" loading="lazy" class="size-full wp-image-66829" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-alex-trevino-concept-1280w_.png" alt="" width="1280" height="683" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-alex-trevino-concept-1280w_.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-alex-trevino-concept-1280w_-400x213.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-alex-trevino-concept-1280w_-672x359.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-alex-trevino-concept-1280w_-768x410.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-alex-trevino-concept-1280w_-842x450.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-alex-trevino-concept-1280w_-403x215.png 403w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-alex-trevino-concept-1280w_-188x100.png 188w" sizes="(max-width: 1280px) 100vw, 1280px" /></a><figcaption id="caption-attachment-66829" class="wp-caption-text">Treviño’s inspiration, credit Mattias Adolfsson.</figcaption></figure>
<p>Treviño started gathering reference imagery and creating mood boards with the standalone program PureRef, which allowed him to play with different perspectives and styles while in the conceptual phase.</p>
<p>“I wanted the character to explore a desolate landscape where it is clear that, despite loneliness and abandonment, he continues to explore in allusion to the emotions of grief,” Treviño said.</p>
<figure id="attachment_66832" aria-describedby="caption-attachment-66832" style="width: 1280px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-secondphase-1280w_.png"><img decoding="async" loading="lazy" class="wp-image-66832 size-full" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-secondphase-1280w_.png" alt="" width="1280" height="800" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-secondphase-1280w_.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-secondphase-1280w_-400x250.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-secondphase-1280w_-672x420.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-secondphase-1280w_-768x480.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-secondphase-1280w_-720x450.png 720w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-secondphase-1280w_-344x215.png 344w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-secondphase-1280w_-160x100.png 160w" sizes="(max-width: 1280px) 100vw, 1280px" /></a><figcaption id="caption-attachment-66832" class="wp-caption-text">Advanced sculpting in Blender.</figcaption></figure>
<p>He then shaped and sculpted models in his preferred 3D app, Blender. Using its Cycles’ RTX-accelerated OptiX ray tracing in the viewport, powered by his <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3080-3080ti/">GeForce RTX 3080 Ti GPU</a>-equipped PC, Treviño unlocked interactive, photorealistic modeling with smooth movement in the viewport.</p>
<p>“NVIDIA GPUs have a wide range of support and powerful performance, which ensures that I can rely on my GPU to work correctly and render images faster and with higher quality,” said Treviño.</p>
<p>Next, Treviño applied UV mapping to his models, which allowed him to texture them in Adobe Substance 3D Painter to create realistic, detailed textures.</p>
<figure id="attachment_66835" aria-describedby="caption-attachment-66835" style="width: 1280px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-uvs-1280w.png"><img decoding="async" loading="lazy" class="size-full wp-image-66835" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-uvs-1280w.png" alt="" width="1280" height="800" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-uvs-1280w.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-uvs-1280w-400x250.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-uvs-1280w-672x420.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-uvs-1280w-768x480.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-uvs-1280w-720x450.png 720w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-uvs-1280w-344x215.png 344w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-uvs-1280w-160x100.png 160w" sizes="(max-width: 1280px) 100vw, 1280px" /></a><figcaption id="caption-attachment-66835" class="wp-caption-text">UV mapping in Blender.</figcaption></figure>
<p>RTX-accelerated <a href="https://blogs.nvidia.com/blog/2022/08/04/direct-indirect-lighting/">light and ambient occlusion</a> baking optimized assets in mere moments.</p>
<figure id="attachment_66838" aria-describedby="caption-attachment-66838" style="width: 1280px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-textured-1280w.png"><img decoding="async" loading="lazy" class="size-full wp-image-66838" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-textured-1280w.png" alt="" width="1280" height="800" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-textured-1280w.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-textured-1280w-400x250.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-textured-1280w-672x420.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-textured-1280w-768x480.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-textured-1280w-720x450.png 720w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-textured-1280w-344x215.png 344w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-textured-1280w-160x100.png 160w" sizes="(max-width: 1280px) 100vw, 1280px" /></a><figcaption id="caption-attachment-66838" class="wp-caption-text">Textures created in Adobe Substance 3D Painter.</figcaption></figure>
<p>“My GeForce RTX GPU’s capabilities were essential while texturing,” Treviño said. “Movement without lag and the ability to make speedy material changes effortlessly were especially helpful while swapping looks.”</p>
<p>Treviño moved to Adobe Illustrator to create alphas — color components that represent degrees of transparency or opacity of colors — as well as masks and patterns.</p>
<p>“GPU acceleration and AI-enabled features are essential tools, as they allow me to work more efficiently and produce higher-quality results,” said Treviño.</p>
<p>He returned to Blender, taking advantage of RTX-accelerated OptiX ray tracing in Blender Cycles for the fastest final-frame render.</p>
<p>Finally, Treviño imported the project into Adobe Photoshop for postproduction work, including adjusting color grading, sharpness, noise and chromatic aberration, and using look-up tables for retouching — just a few of the 30+ GPU-accelerated features at his disposal.</p>
<figure id="attachment_66841" aria-describedby="caption-attachment-66841" style="width: 1280px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-03-tele-1280w.png"><img decoding="async" loading="lazy" class="size-full wp-image-66841" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-03-tele-1280w.png" alt="" width="1280" height="508" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-03-tele-1280w.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-03-tele-1280w-400x159.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-03-tele-1280w-672x267.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-03-tele-1280w-768x305.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-03-tele-1280w-842x334.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-03-tele-1280w-406x161.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-03-tele-1280w-188x75.png 188w" sizes="(max-width: 1280px) 100vw, 1280px" /></a><figcaption id="caption-attachment-66841" class="wp-caption-text">Stunning details in post-production and color correction thanks to Adobe Photoshop.</figcaption></figure>
<p>The end result achieved Treviño’s goal of creating a desolate landscape and alluding to the emotions of grief.</p>
<figure id="attachment_66844" aria-describedby="caption-attachment-66844" style="width: 1280px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-05-tele-1280w.png"><img decoding="async" loading="lazy" class="size-full wp-image-66844" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-05-tele-1280w.png" alt="" width="1280" height="508" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-05-tele-1280w.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-05-tele-1280w-400x159.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-05-tele-1280w-672x267.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-05-tele-1280w-768x305.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-05-tele-1280w-842x334.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-05-tele-1280w-406x161.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week74-05-tele-1280w-188x75.png 188w" sizes="(max-width: 1280px) 100vw, 1280px" /></a><figcaption id="caption-attachment-66844" class="wp-caption-text">Beautiful yet desolate.</figcaption></figure>
<p>For a more detailed look at Treviño’s creative process, check out his five-part tutorial series, <i>Creating 3D Lunar Rover w/ Alex Treviño,</i> live on the NVIDIA Studio <a href="https://www.youtube.com/@NVIDIA-Studio/featured">YouTube channel</a>.</p>
<p><a href="https://www.youtube.com/playlist?list=PL4w6jm6S2lzvy-mfeIHJiAmqN6ARz-DJt"><i>https://www.youtube.com/playlist?list=PL4w6jm6S2lzvy-mfeIHJiAmqN6ARz-DJt</i></a></p>
<p>Discover exclusive step-by-step tutorials from industry-leading artists, inspiring community showcases and more, powered by <a href="https://www.nvidia.com/en-us/studio/laptops-desktops/">NVIDIA Studio hardware</a> and <a href="https://www.nvidia.com/en-us/studio/">software</a>.</p>
<h2>Lunar Lessons Learned</h2>
<p>Treviño has three monumental pieces of advice for aspiring artists:</p>
<ol>
<li><b>Learn the basics of the entire pipeline process</b>. Learn about modeling, texturing, rendering, post-production, marketing and promotion. Expertise across the board isn’t required but general understanding of each step is.</li>
<li><b>Don’t be afraid to experiment</b>. The best way to learn is by doing. Try new things and experiment with different techniques. Mistakes will lead to growth and evolved artistry.</li>
<li><b>Find a community of like-minded artists</b>. Connect in multiple communities to learn from others, share work and get valuable feedback.</li>
</ol>
<figure id="attachment_66847" aria-describedby="caption-attachment-66847" style="width: 1280px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/09/week70-jiffyvfx-artist-feature-gallery-1280w.png"><img decoding="async" loading="lazy" class="size-full wp-image-66847" src="https://blogs.nvidia.com/wp-content/uploads/2023/09/week70-jiffyvfx-artist-feature-gallery-1280w.png" alt="" width="1280" height="403" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/09/week70-jiffyvfx-artist-feature-gallery-1280w.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week70-jiffyvfx-artist-feature-gallery-1280w-400x126.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week70-jiffyvfx-artist-feature-gallery-1280w-672x212.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week70-jiffyvfx-artist-feature-gallery-1280w-768x242.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week70-jiffyvfx-artist-feature-gallery-1280w-842x265.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week70-jiffyvfx-artist-feature-gallery-1280w-406x128.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/09/week70-jiffyvfx-artist-feature-gallery-1280w-188x59.png 188w" sizes="(max-width: 1280px) 100vw, 1280px" /></a><figcaption id="caption-attachment-66847" class="wp-caption-text">3D visual development artist Alex Treviño.</figcaption></figure>
<p>Check out Treviño’s portfolio on <a href="https://www.instagram.com/aendom/">Instagram</a>.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>Twitter</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/09/360-textured.mp4" length="1994733" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/nv-blog-header-preview-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/09/nv-blog-header-preview-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[One Small Step for Artists, One Giant Leap for Creative-Kind]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
	</channel>
</rss>
