<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Mon, 01 Apr 2024 21:44:53 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.4.3</generator>
	<item>
		<title>Greater Scope: Doctors Get Inside Look at Gut Health With AI-Powered Endoscopy</title>
		<link>https://blogs.nvidia.com/blog/ai-powered-endoscopy-odin-vision-olympus/</link>
		
		<dc:creator><![CDATA[Isha Salian]]></dc:creator>
		<pubDate>Thu, 28 Mar 2024 15:00:11 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[Social Impact]]></category>
		<category><![CDATA[TensorRT]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70912</guid>

					<description><![CDATA[From humble beginnings as a university spinoff to an acquisition by the leading global medtech company in its field, Odin Vision has been on an accelerated journey since its founding less than five years ago. An alum of the NVIDIA Inception program for cutting-edge startups, Odin Vision builds cloud-connected AI software that helps clinicians detect		<a class="read-more" href="https://blogs.nvidia.com/blog/ai-powered-endoscopy-odin-vision-olympus/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>From humble beginnings as a university spinoff to an acquisition by the leading global medtech company in its field, Odin Vision has been on an accelerated journey since its founding less than five years ago.</p>
<p>An alum of the <a href="https://www.nvidia.com/startups/?nvid=nv-int-tblg-295718-vt33">NVIDIA Inception</a> program for cutting-edge startups, Odin Vision builds cloud-connected AI software that helps clinicians detect and characterize areas of concern during endoscopy, a procedure where a tiny camera mounted on a tube is inserted into the gastrointestinal tract.</p>
<p>Network-connected devices in the endoscopy room capture and stream real-time video data to the cloud, where powerful NVIDIA GPUs run AI inference. The models’ results are then streamed back to the endoscopy room so that clinicians can see the AI insights overlaid on the live video feed with minimal latency.</p>
<p>The startup was in 2022 acquired by Japanese medtech leader Olympus, which has a 70% global market share in gastrointestinal endoscopic equipment.</p>
<p>“We believe the acquisition brings us much closer to achieving our vision to revolutionize endoscopy through AI and cloud technology,” said Daniel Toth, cofounder and chief technology officer of Odin Vision. “Our software can reach Olympus’ global customer base, enabling us to bring our solutions to as many patients as possible.”</p>
<p>Olympus is also collaborating with NVIDIA on Olympus Office Hours, an advisory program that connects Inception startups with the medical device company’s experts, who will offer deep industry expertise and guidance to help the startups build AI solutions in key areas including gastroenterology, urology and surgery.</p>
<p>Eight leading AI startups have joined the inaugural cohort of the program — which is part of the NVIDIA Inception Alliance for Healthcare, an initiative that brings together medical AI startups with NVIDIA and its healthcare industry partners — to help accelerate their product development and go-to-market goals.</p>
<h2><b>An Extra Set of AIs for Clinicians</b></h2>
<p>Around <a href="https://newsnetwork.mayoclinic.org/discussion/ai-reduces-miss-rate-of-precancerous-polyps-in-colorectal-cancer-screening/#:~:text=The%20rate%20at%20which%20precancerous%20colorectal%20polyps%20is%20missed%20has,that%20had%20standard%20colonoscopy%20first." target="_blank" rel="noopener">a quarter of precancerous polyps are missed</a> during colonoscopies, a kind of endoscopy procedure that examines the lower digestive tract.</p>
<p>While some are missed because the endoscope doesn’t capture video footage of every angle, others remain undetected by clinicians. That’s where AI can help provide a second set of eyes to support clinical decision-making.</p>
<p>Seamless AI integration into the video feeds that medical professionals view during an endoscopy provides an extra data source that can help doctors detect and remove polyps sooner, helping prevent cancer development.</p>
<p>“Polyps develop slowly, and can take five or 10 years to appear as cancer,” Toth said. “If a clinician can detect and remove them in time, it can help save lives.”</p>
<p>CADDIE, the company’s AI software for detecting and classifying polyps, has received the CE Mark of regulatory approval in Europe and is deployed across hospitals in the U.K., Spain, Germany, Poland and Italy — with plans for use in the U.S as well.</p>
<p>Odin Vision also has AI software that has received the CE Mark to assist gastroscopy, where doctors inspect the esophagus for signs of throat cancer.</p>
<h2><b>Accelerated Inference for Real-Time Insights</b></h2>
<p>Odin Vision began as a research project by two professors and a Ph.D. student at University College London who were developing AI techniques for polyp detection. In 2019, they teamed with Toth and Odin’s CEO, Peter Mountney, both from Siemens Healthineers, to commercialize their work.</p>
<p>“NVIDIA GPUs were part of our work from the start — they’ve been essential to train our AI models and were part of our first product prototypes for inference, too,” Toth said. “Since moving to a cloud-based deployment, we’ve begun using the NVIDIA Triton Inference Server for dynamic processing in the cloud.”</p>
<p>The team uses <a href="https://www.nvidia.com/en-us/data-center/tensor-cores/">NVIDIA Tensor Core GPUs</a> for accelerated inference — most recently transitioning to <a href="https://www.nvidia.com/en-us/data-center/l4/">NVIDIA L4 GPUs</a>. Adopting <a href="https://www.nvidia.com/en-us/ai-data-science/products/triton-inference-server/">NVIDIA Triton Inference Server</a> software and the <a href="https://developer.nvidia.com/tensorrt">NVIDIA TensorRT</a> software development kit enabled them to meet the low-latency threshold needed for real-time video-processing AI applications.</p>
<p>In addition to supporting doctors during specific procedures, Odin Vision plans to develop generative AI models that can automate a first draft of the clinical notes doctors prepare afterward — as well as models that can aggregate data across procedures. These would allow endoscopy teams to review analytics and assess how well a procedure is performed compared to clinical guidelines.</p>
<p>“Once you get to a point where there are dozens of AI models tracking different elements of these procedures, we can see if a healthcare professional is inspecting a particular area of the digestive tract for only three minutes, when it’s supposed to take six minutes,” Toth said. “The system can provide a nudge to remind the clinician to follow the guidelines.”</p>
<h2><b>Cloud-Connected Cancer Screening</b></h2>
<p>Membership in NVIDIA Inception provided the Odin Vision team access to technical expertise from NVIDIA and cloud credits through leading cloud service providers.</p>
<p>“Cloud credits helped us massively speed up our technology development and deployment, enabling us to release our products to market months earlier than initially planned,” Toth said. “NVIDIA experts also validated our product concept from a technology perspective and provided consultation about GPU and accelerated software optimizations.”</p>
<p>The team found that a cloud-based solution made it easier to push software updates over the air to deployments across hospital customers.</p>
<p>“Some AI companies are sending boxes that need to sit in clinical sites and require regular maintenance, which can prevent normal clinical workflows from running smoothly,” Toth said. “With network-connected devices, we can instead update a single server and the changes reach all end users at the same time.”</p>
<p><i>Learn more about </i><a href="https://www.nvidia.com/startups/?nvid=nv-int-tblg-295718-vt33"><i>NVIDIA Inception</i></a><i> and </i><a href="https://www.nvidia.com/en-us/industries/healthcare-life-sciences/healthcare-news-sign-up/"><i>subscribe to NVIDIA healthcare news</i></a><i>. </i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/AdobeStock_309555032_crop.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/AdobeStock_309555032_crop-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Greater Scope: Doctors Get Inside Look at Gut Health With AI-Powered Endoscopy]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Get Cozy With ‘Palia’ on GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-palia/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 28 Mar 2024 13:00:18 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70939</guid>

					<description><![CDATA[Ease into spring with the warm, cozy vibes of Palia, coming to the cloud this GFN Thursday. It’s part of six new titles joining the GeForce NOW library of over 1,800 games. Welcome Home Escape to a cozy world with Palia, a free-to-play massively multiplayer online game from Singularity 6 Corporation. The game, which has		<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-palia/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Ease into spring with the warm, cozy vibes of <i>Palia</i>, coming to the cloud this GFN Thursday.</p>
<p>It’s part of six new titles joining the <a href="http://play.geforcenow.com">GeForce NOW library</a> of over 1,800 games.</p>
<h2><b>Welcome Home</b></h2>
<figure id="attachment_70943" aria-describedby="caption-attachment-70943" style="width: 672px" class="wp-caption aligncenter"><img fetchpriority="high" decoding="async" class="size-large wp-image-70943" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Palia-672x378.jpg" alt="Palia on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Palia-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Palia-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Palia-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Palia-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Palia-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Palia-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Palia-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Palia-1280x720.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Palia.jpg 1920w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70943" class="wp-caption-text"><em>Better together.</em></figcaption></figure>
<p>Escape to a cozy world with <i>Palia</i>, a free-to-play massively multiplayer online game from Singularity 6 Corporation. The game, which has made its way onto more than 200,000 wishlists on Steam, has launched in the cloud this week.</p>
<p>Farm, fish, craft and explore with friendly villagers across a stunning variety of different biomes — from sprawling flower fields to hilly forests and rocky beaches — in the world of Palia. Inhabit the land, furnish a dream home, unravel ancient mysteries and interact with a vibrant online community.</p>
<p>Get ready for a captivating adventure across devices by streaming <i>Palia</i> from the cloud. GeForce NOW Ultimate and Priority members get faster access to servers and longer gaming sessions over Free members.</p>
<h2><b>Time to Play</b></h2>
<figure id="attachment_70946" aria-describedby="caption-attachment-70946" style="width: 672px" class="wp-caption aligncenter"><img decoding="async" class="size-large wp-image-70946" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Milennia-672x336.jpg" alt="Millennia on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Milennia-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Milennia-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Milennia-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Milennia-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Milennia-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Milennia-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Milennia-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Milennia-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Milennia.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70946" class="wp-caption-text"><em>10,000 years of history, all in the cloud.</em></figcaption></figure>
<p>Shape the course of history across 10,000 years in <i>Millennia</i> from C Prompt Games and Paradox Interactive. GeForce NOW members can customize their own nations, explore unique combinations of traits and adapt to alternative histories in this captivating journey.</p>
<p>In addition, members can look for the following:</p>
<ul>
<li><i>Palia </i>(New release on <a href="https://store.steampowered.com/app/2707930?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, March 25)</li>
<li><i>Bulwark: Falconeer Chronicles </i>(New release on <a href="https://store.steampowered.com/app/290100?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, March 26)</li>
<li><i>Millennia </i>(New release on <a href="https://store.steampowered.com/app/1268590?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, March 26)</li>
<li><i>Outpost: Infinity Siege </i>(New release on <a href="https://store.steampowered.com/app/1566690?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, March 26)</li>
<li><i>SOUTH PARK: SNOW DAY! </i>(New release on <a href="https://store.steampowered.com/app/1214650?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, March 26)</li>
<li><i>Tchia</i> (<a href="https://store.steampowered.com/app/1496590?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">if you could live in a video game, which one would it be and why? <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f914.png" alt="🤔" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1773017134517346499?ref_src=twsrc%5Etfw">March 27, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/gfn-thursday-3-28-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/gfn-thursday-3-28-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Get Cozy With ‘Palia’ on GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Software Developers Launch OpenUSD and Generative AI-Powered Product Configurators Built on NVIDIA Omniverse</title>
		<link>https://blogs.nvidia.com/blog/3d-product-configurators-omniverse-openusd/</link>
		
		<dc:creator><![CDATA[Dane Johnston]]></dc:creator>
		<pubDate>Wed, 27 Mar 2024 23:26:27 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Digital Twin]]></category>
		<category><![CDATA[Generative AI]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70924</guid>

					<description><![CDATA[From designing dream cars to customizing clothing, 3D product configurators are ringing in a new era of hyper-personalization that will benefit retailers and consumers. Developers are delivering innovative virtual product experiences and automated personalization using Universal Scene Description (aka OpenUSD), NVIDIA RTX technologies from NVIDIA Omniverse software development kits (SDKs) and application programming interfaces (APIs),		<a class="read-more" href="https://blogs.nvidia.com/blog/3d-product-configurators-omniverse-openusd/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>From designing dream cars to customizing clothing, 3D product configurators are ringing in a new era of hyper-personalization that will benefit retailers and consumers.</p>
<p>Developers are delivering innovative virtual product experiences and automated personalization using <a href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description (aka OpenUSD)</a>, <a href="https://www.nvidia.com/en-us/design-visualization/technologies/rtx/">NVIDIA RTX</a> technologies from <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> software development kits (SDKs) and application programming interfaces (APIs), and generative AI from <a href="https://blogs.nvidia.com/blog/edify-3d-generative-ai-custom-fine-tuning/">NVIDIA Edify</a> models.</p>
<p>Together, these technologies enable developers to create configurator applications that deliver physically accurate, photoreal <a href="https://www.nvidia.com/en-us/omniverse/solutions/digital-twins/">digital twins</a> of products, revolutionizing the way brands personalize buyer journeys at unprecedented scale.</p>
<p>For example, <a href="https://blog.3ds.com/brands/3dexcite/dassault-systemes-collaborates-with-nvidia-to-showcase-the-future-of-storytelling-with-generative-ai/">Dassault Systèmes’ 3DEXCITE</a> brand is adopting <a href="https://nvidianews.nvidia.com/news/omniverse-cloud-apis-industrial-digital-twin">Omniverse Cloud APIs</a> to enable interoperability with generative AI services, such as Shutterstock’s Edify3D or Edify 360, directly inside its web-based application.</p>
<p>By using NVIDIA Edify-powered models, trained by Shutterstock, Dassault Systèmes can generate stunning 3D environments from text prompts to instantly personalize scenes representing physically accurate products. And with Omniverse APIs, the company can supercharge the web-based app with real-time ray-traced rendering.</p>
<p><iframe title="The Future of Storytelling with Generative AI and NVIDIA" width="500" height="281" src="https://www.youtube.com/embed/h30brb7-taU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Many other developers are also building 3D product configurator software and solutions with NVIDIA Omniverse SDKs and APIs.</p>
<p>CGI studio <a href="https://www.katanaus.com/">Katana</a> has developed a content creation application, COATCreate, used by manufacturers such as <a href="https://www.nissanusa.com/">Nissan</a>, that allows marketing assets to be staged and created faster with product digital twins. COATCreate also enables users to <a href="https://blogs.nvidia.com/blog/omniverse-apple-vision-pro/">view and customize the digital twin while wearing an Apple Vision Pro headset</a>, unlocking real-time ray-traced extended reality experiences.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-1.jpg"><img loading="lazy" decoding="async" class="aligncenter size-large wp-image-70931" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-1-672x357.jpg" alt="" width="672" height="357" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-1-672x357.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-1-400x213.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-1-768x408.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-1-842x447.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-1-406x215.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-1-188x100.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-1.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<p><a href="https://www.brickland.se/">Brickland</a>, another CGI studio, is developing real-time virtual experiences that allow users to customize clothing by choosing from predefined parameters such as color and material. Through their <a href="https://www.brickland.se/digitex/winter">Digitex initiative</a>, Brickland is expanding into digital textures and allowing consumers to visualize and interact with extreme levels of detail in their 3D assets thanks to RTX real-time rendering</p>
<p><a href="https://configit.com/">Configit</a> connected its powerful configurator logic tool Configit Ace to Omniverse and OpenUSD by streamlining the management of the complex rules system behind the creation of configurators and combining it with the rendering capabilities of Omniverse and RTX. This allows for rapid creation of articulated product configurators and enables the configurator developers to power real-time ray-traced rendering in their solutions.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-2.jpg"><img loading="lazy" decoding="async" class="aligncenter size-large wp-image-70934" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-2-672x357.jpg" alt="" width="672" height="357" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-2-672x357.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-2-400x213.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-2-768x408.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-2-842x447.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-2-406x215.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-2-188x100.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Copy-2.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<p><a href="https://www.wpp.com/wpp-iq/2024/03/wpp-puts-itself-at-the-heart-of-collaborative-3d-worlds">WPP</a> has developed a <a href="https://www.wpp.com/en/news/2023/05/wpp-partners-with-nvidia-to-build-generative-ai-enabled-content-engine-for-digital-advertising">content engine that harnesses OpenUSD and AI</a> to enable creative teams to produce high-quality commercial content faster, more efficiently and at scale while remaining aligned with a client’s brand.</p>
<p><a href="https://media.monks.com/">Media.Monks</a> has developed an AI-centric professional managed service that leverages Omniverse called Monks.Flow, which helps brands virtually explore different customizable product designs and unlock scale and hyper-personalization across any customer journey.</p>
<p><a href="https://newsroom.accenture.com/news/2024/accenture-teams-with-nvidia-to-showcase-ai-powered-immersive-client-experiences-for-defender">Accenture Song</a>, the world’s largest tech-powered creative group, is using Omniverse SDKs to generate marketing content for Defender vehicles. Using it with the Edify-powered generative AI microservice, Accenture Song is enabling the creation of cinematic 3D environments via conversational prompts.</p>
<h2><b>Product Digital Twins in the Era of Industrial Digitalization</b></h2>
<p>Forecasts indicate that consumer purchases, including high-value items like vehicles and luxury goods, <a href="https://www.forbes.com/advisor/business/ecommerce-statistics/">will increasingly take place online</a> in the coming decade. 3D product digital twins and automated personalization with generative AI serve as invaluable tools for brands to showcase their products and enhance customer engagement in the changing retail landscape.</p>
<p>3D configurators provide tangible benefits for businesses, including increased average selling prices, reduced return rates and stronger brand loyalty. Once a digital twin is built, it can serve many purposes and be updated to meet shifting consumer preferences with minimal time, cost and effort.</p>
<p><iframe loading="lazy" title="Develop 3D Product Configurators With Generative AI and OpenUSD" width="500" height="281" src="https://www.youtube.com/embed/LAVXuDK83iA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<h2><b>Creating a 3D Product Configurator</b></h2>
<p>The process of creating a 3D product configurator begins with harnessing OpenUSD’s powerful composition engine and interoperability. These features enable developers to create dynamic, interactive experiences that accurately reflect the nuances of each product.</p>
<p>Teams can also integrate generative AI technologies into OpenUSD-based product configurators using NVIDIA Omniverse APIs to enhance the realism and customization options available to users. By leveraging AI, configurators can intelligently adapt to user inputs, offering personalized recommendations and dynamically adjusting product configurations in real time. And with <a href="https://www.nvidia.com/en-us/omniverse/solutions/stream-3d-apps/">NVIDIA Graphics Delivery Network</a> , high-quality, real-time viewports can be embedded into web applications so consumers can browse products in full fidelity, on nearly any device.</p>
<p>The possibilities for 3D product configurators are virtually limitless, applicable across a wide range of industries and use cases.</p>
<p>To start, get <a href="https://www.nvidia.com/en-us/omniverse/#get-started">NVIDIA Omniverse</a> and follow along with a <a href="https://www.youtube.com/watch?v=xoY2Cyxy9pQ&amp;list=PL3jK4xNnlCVdruh1y5cIwJx3FPBwoZtXR&amp;index=1">tutorial series</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Header.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/OV-Dev-Blog-Header-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Software Developers Launch OpenUSD and Generative AI-Powered Product Configurators Built on NVIDIA Omniverse]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Hopper Leaps Ahead in Generative AI at MLPerf</title>
		<link>https://blogs.nvidia.com/blog/tensorrt-llm-inference-mlperf/</link>
		
		<dc:creator><![CDATA[Dave Salvator]]></dc:creator>
		<pubDate>Wed, 27 Mar 2024 15:40:47 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[NGC]]></category>
		<category><![CDATA[NVIDIA Hopper Architecture]]></category>
		<category><![CDATA[TensorRT]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70672</guid>

					<description><![CDATA[It’s official: NVIDIA delivered the world’s fastest platform in industry-standard tests for inference on generative AI. In the latest MLPerf benchmarks, NVIDIA TensorRT-LLM — software that speeds and simplifies the complex job of inference on large language models — boosted the performance of NVIDIA Hopper architecture GPUs on the GPT-J LLM nearly 3x over their		<a class="read-more" href="https://blogs.nvidia.com/blog/tensorrt-llm-inference-mlperf/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>It’s official: NVIDIA delivered the world’s fastest platform in industry-standard tests for inference on <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/">generative AI</a>.</p>
<p>In the latest MLPerf benchmarks, <a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-supercharges-large-language-model-inference-on-nvidia-h100-gpus/">NVIDIA TensorRT-LLM</a> — software that speeds and simplifies the complex job of inference on <a href="https://www.nvidia.com/en-us/glossary/large-language-models/">large language models</a> — boosted the performance of <a href="https://www.nvidia.com/en-us/data-center/technologies/hopper-architecture/">NVIDIA Hopper architecture GPUs</a> on the GPT-J LLM nearly 3x over their results just six months ago.</p>
<p>The dramatic speedup demonstrates the power of NVIDIA’s full-stack platform of chips, systems and software to handle the demanding requirements of running generative AI.</p>
<p>Leading companies <a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-supercharges-large-language-model-inference-on-nvidia-h100-gpus/">are using</a> TensorRT-LLM to optimize their models. And <a href="https://www.nvidia.com/en-us/launchpad/ai/generative-ai-inference-with-nim/">NVIDIA NIM</a>  — a set of inference microservices that includes inferencing engines like TensorRT-LLM — makes it easier than ever for businesses to deploy NVIDIA’s inference platform.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-1-GPTJ-LLM-3x.jpg"><img loading="lazy" decoding="async" class="aligncenter wp-image-70917 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-1-GPTJ-LLM-3x-672x378.jpg" alt="Chart of NVIDIA Hopper GPUs with TensorRT-LLM on MLPerf Inference GPT-J" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-1-GPTJ-LLM-3x-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-1-GPTJ-LLM-3x-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-1-GPTJ-LLM-3x-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-1-GPTJ-LLM-3x-1536x865.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-1-GPTJ-LLM-3x-799x450.jpg 799w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-1-GPTJ-LLM-3x-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-1-GPTJ-LLM-3x-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-1-GPTJ-LLM-3x-1280x721.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-1-GPTJ-LLM-3x.jpg 2014w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<h2><b>Raising the Bar in Generative AI</b></h2>
<p>TensorRT-LLM running on <a href="https://www.nvidia.com/en-us/data-center/h200/">NVIDIA H200 Tensor Core GPUs</a> — the latest, memory-enhanced Hopper GPUs — delivered the fastest performance running inference in MLPerf’s biggest test of generative AI to date.</p>
<p>The new benchmark uses the largest version of Llama 2, a state-of-the-art large language model packing 70 billion parameters. The model is more than 10x larger than the GPT-J LLM first used in the <a href="https://blogs.nvidia.com/blog/grace-hopper-inference-mlperf/">September benchmarks</a>.</p>
<p>The memory-enhanced H200 GPUs, in their MLPerf debut, used TensorRT-LLM to produce up to 31,000 tokens/second, a record on MLPerf’s Llama 2 benchmark.</p>
<p>The H200 GPU results include up to 14% gains from a custom thermal solution. It’s one example of innovations beyond standard air cooling that systems builders are applying to their <a href="https://www.nvidia.com/en-us/data-center/products/mgx/">NVIDIA MGX</a> designs to take the performance of Hopper GPUs to new heights.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-2-Llama-2-win.jpg"><img loading="lazy" decoding="async" class="aligncenter wp-image-70920 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-2-Llama-2-win-672x371.jpg" alt="Chart of NVIDIA performance on MLPerf inference Llama 2 70B" width="672" height="371" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-2-Llama-2-win-672x371.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-2-Llama-2-win-400x221.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-2-Llama-2-win-768x424.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-2-Llama-2-win-1536x847.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-2-Llama-2-win-816x450.jpg 816w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-2-Llama-2-win-390x215.jpg 390w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-2-Llama-2-win-181x100.jpg 181w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-2-Llama-2-win-1280x706.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-MLPerf-2-Llama-2-win.jpg 2018w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<h2><b>Memory Boost for NVIDIA Hopper GPUs</b></h2>
<p>NVIDIA is sampling H200 GPUs to customers today and shipping in the second quarter. They’ll be available soon from nearly 20 leading system builders and cloud service providers.</p>
<p>H200 GPUs pack 141GB of HBM3e running at 4.8TB/s. That’s 76% more memory flying 43% faster compared to H100 GPUs. These accelerators plug into the same boards and systems and use the same software as H100 GPUs.</p>
<p>With HBM3e memory, a single H200 GPU can run an entire Llama 2 70B model with the highest throughput, simplifying and speeding inference.</p>
<h2><b>GH200 Packs Even More Memory</b></h2>
<p>Even more memory — up to 624GB of fast memory, including 144GB of HBM3e — is packed in <a href="https://www.nvidia.com/en-us/data-center/grace-hopper-superchip/">NVIDIA GH200 Superchips</a>, which combine on one module a Hopper architecture GPU and a power-efficient <a href="https://www.nvidia.com/en-us/data-center/grace-cpu/">NVIDIA Grace CPU</a>. NVIDIA accelerators are the first to use HBM3e memory technology.</p>
<p>With nearly 5 TB/second memory bandwidth, GH200 Superchips delivered standout performance, including on memory-intensive MLPerf tests such as <a href="https://blogs.nvidia.com/blog/grace-hopper-recommender-systems/">recommender systems</a>.</p>
<h2><b>Sweeping Every MLPerf Test</b></h2>
<p>On a per-accelerator basis, Hopper GPUs swept every test of AI inference in the latest round of the MLPerf industry benchmarks.</p>
<p>In addition, <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">NVIDIA Jetson Orin</a> remains at the forefront in MLPerf’s edge category. In the last two inference rounds, Orin ran the most diverse set of models in the category, including GPT-J and Stable Diffusion XL.</p>
<p>The MLPerf benchmarks cover today’s most popular AI workloads and scenarios, including generative AI, recommendation systems, natural language processing, speech and computer vision. NVIDIA was the only company to submit results on every workload in the latest round and every round since MLPerf’s data center inference benchmarks began in October 2020.</p>
<p>Continued performance gains translate into lower costs for inference, a large and growing part of the daily work for the millions of NVIDIA GPUs deployed worldwide.</p>
<h2><b>Advancing What’s Possible</b></h2>
<p>Pushing the boundaries of what’s possible, NVIDIA demonstrated three innovative techniques in a special section of the benchmarks called the open division, created for testing advanced AI methods.</p>
<p>NVIDIA engineers used a technique called <a href="https://developer.nvidia.com/blog/accelerating-inference-with-sparsity-using-ampere-and-tensorrt/">structured sparsity</a> — a way of reducing calculations, first introduced with <a href="https://www.nvidia.com/en-us/data-center/a100/">NVIDIA A100 Tensor Core GPUs</a> — to deliver up to 33% speedups on inference with Llama 2.</p>
<p>A second open division test found inference speedups of up to 40% using pruning, a way of simplifying an AI model — in this case, an LLM — to increase inference throughput.</p>
<p>Finally, an optimization called DeepCache reduced the math required for inference with the Stable Diffusion XL model, accelerating performance by a whopping 74%.</p>
<p>All these results were run on <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100 Tensor Core GPUs</a>.</p>
<h2><b>A Trusted Source for Users</b></h2>
<p>MLPerf’s tests are transparent and objective, so users can rely on the results to make informed buying decisions.</p>
<p>NVIDIA’s partners participate in MLPerf because they know it’s a valuable tool for customers evaluating AI systems and services. Partners submitting results on the NVIDIA AI platform in this round included ASUS, Cisco, Dell Technologies, Fujitsu, GIGABYTE, Google, Hewlett Packard Enterprise, Lenovo, Microsoft Azure, Oracle, QCT, Supermicro, VMware (recently acquired by Broadcom) and Wiwynn.</p>
<p>All the software NVIDIA used in the tests is available in the MLPerf repository. These optimizations are continuously folded into containers available on <a href="https://ngc.nvidia.com/catalog">NGC</a>, NVIDIA’s software hub for GPU applications, as well as <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> — a secure, supported platform that includes NIM inference microservices.</p>
<h2><b>The Next Big Thing  </b></h2>
<p>The use cases, model sizes and datasets for generative AI continue to expand. That’s why MLPerf continues to evolve, adding real-world tests with popular models like Llama 2 70B and Stable Diffusion XL.</p>
<p>Keeping pace with the explosion in LLM model sizes, NVIDIA founder and CEO Jensen Huang announced last week at GTC that the <a href="https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/">NVIDIA Blackwell architecture GPUs</a> will deliver new levels of performance required for the multitrillion-parameter AI models.</p>
<p>Inference for large language models is difficult, requiring both expertise and the full-stack architecture NVIDIA demonstrated on MLPerf with Hopper architecture GPUs and TensorRT-LLM. There’s much more to come.</p>
<p>Learn more about <a href="https://www.nvidia.com/en-us/data-center/resources/mlperf-benchmarks/">MLPerf benchmarks</a> and the <a href="https://developer.nvidia.com/blog/nvidia-h200-tensor-core-gpus-and-nvidia-tensorrt-llm-set-mlperf-llm-inference-records/">technical details</a> of this inference round.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/NVIDIA-H200-HGX-image.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/NVIDIA-H200-HGX-image-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Hopper Leaps Ahead in Generative AI at MLPerf]]></media:title>
			<media:description type="html">NVIDIA HGX H200 GPU system running TensorRT-LLM</media:description>
			</media:content>
			</item>
		<item>
		<title>Unlocking Peak Generations: TensorRT Accelerates AI on RTX PCs and Workstations</title>
		<link>https://blogs.nvidia.com/blog/ai-decoded-tensorrt-stable-diffusion-automatic1111/</link>
		
		<dc:creator><![CDATA[Jesse Clayton]]></dc:creator>
		<pubDate>Wed, 27 Mar 2024 13:00:13 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[AI Decoded]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70900</guid>

					<description><![CDATA[As generative AI advances and becomes widespread across industries, the importance of running generative AI applications on local PCs and workstations grows.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of the </i><a href="https://blogs.nvidia.com/blog/tag/ai-decoded/"><i>AI Decoded series</i></a><i>, which demystifies AI by making the technology more accessible, and which showcases new hardware, software, tools and accelerations for RTX PC users.</i></p>
<p>As <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> advances and becomes widespread across industries, the importance of running generative AI applications on local PCs and workstations grows. Local <a href="https://blogs.nvidia.com/blog/difference-deep-learning-training-inference-ai/">inference</a> gives consumers reduced latency, eliminates their dependency on the network and enables more control over their data.</p>
<p>NVIDIA GeForce and NVIDIA RTX GPUs feature Tensor Cores, dedicated AI hardware accelerators that provide the horsepower to run generative AI locally.</p>
<p>Stable Video Diffusion is now optimized for the <a href="https://developer.nvidia.com/tensorrt">NVIDIA TensorRT</a> software development kit, which unlocks the highest-performance generative AI on the more than 100 million Windows PCs and workstations powered by RTX GPUs.</p>
<p>Now, the TensorRT extension for the popular Stable Diffusion WebUI by Automatic1111 is adding support for ControlNets, tools that give users more control to refine generative outputs by adding other images as guidance.</p>
<p><iframe loading="lazy" title="Accelerate Stable Diffusion with NVIDIA RTX GPUs" width="500" height="281" src="https://www.youtube.com/embed/fUAEBoJCJW8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>TensorRT acceleration can be put to the test in the new UL Procyon AI Image Generation benchmark, which internal tests have shown accurately replicates real-world performance. It delivered speedups of 50% on a GeForce RTX 4080 SUPER GPU compared with the fastest non-TensorRT implementation.</p>
<h2><b>More Efficient and Precise AI</b></h2>
<p>TensorRT enables developers to access the hardware that provides fully optimized AI experiences. AI performance typically doubles compared with running the application on other frameworks.</p>
<p>It also <a href="https://developer.nvidia.com/blog/new-stable-diffusion-models-accelerated-with-nvidia-tensorrt/">accelerates</a> the most popular generative AI models, like Stable Diffusion and SDXL. <a href="https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt-1-1-tensorrt">Stable Video Diffusion</a>, Stability AI’s image-to-video generative AI model, experiences a 40% speedup with TensorRT.</p>
<p>The optimized <a href="https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt-1-1-tensorrt">Stable Video Diffusion 1.1 Image-to-Video</a> model can be downloaded on Hugging Face.</p>
<p>Plus, the TensorRT extension for Stable Diffusion WebUI boosts performance by up to 2x — significantly streamlining Stable Diffusion workflows.</p>
<p>With the extension’s latest update, TensorRT optimizations extend to ControlNets — a set of AI models that help guide a diffusion model’s output by adding extra conditions. With TensorRT, ControlNets are 40% faster.</p>
<figure id="attachment_70907" aria-describedby="caption-attachment-70907" style="width: 1280px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/03/Auto1111-ControlNet-Visual_1.jpg"><img loading="lazy" decoding="async" class="size-full wp-image-70907" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/Auto1111-ControlNet-Visual_1.jpg" alt="" width="1280" height="720" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/Auto1111-ControlNet-Visual_1.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Auto1111-ControlNet-Visual_1-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Auto1111-ControlNet-Visual_1-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Auto1111-ControlNet-Visual_1-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Auto1111-ControlNet-Visual_1-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Auto1111-ControlNet-Visual_1-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/03/Auto1111-ControlNet-Visual_1-178x100.jpg 178w" sizes="(max-width: 1280px) 100vw, 1280px" /></a><figcaption id="caption-attachment-70907" class="wp-caption-text">TensorRT optimizations extend to ControlNets for improved customization.</figcaption></figure>
<p>Users can guide aspects of the output to match an input image, which gives them more control over the final image. They can also use multiple ControlNets together for even greater control. A ControlNet can be a depth map, edge map, normal map or keypoint detection model, among others.</p>
<p>Download the TensorRT extension for Stable Diffusion Web UI on <a href="https://github.com/NVIDIA/Stable-Diffusion-WebUI-TensorRT">GitHub</a> today.</p>
<h2><b>Other Popular Apps Accelerated by TensorRT</b></h2>
<p>Blackmagic Design <a href="https://blogs.nvidia.com/blog/surface-studio-chaos-dlss-resolve-tensor-rt/">adopted NVIDIA TensorRT acceleration</a> in update 18.6 of DaVinci Resolve. Its AI tools, like Magic Mask, Speed Warp and Super Scale, run more than 50% faster and up to 2.3x faster on RTX GPUs compared with Macs.</p>
<p>In addition, with TensorRT integration, <a href="https://www.topazlabs.com/">Topaz Labs</a> saw an up to 60% performance increase in its Photo AI and Video AI apps — such as photo denoising, sharpening, photo super resolution, video slow motion, video super resolution, video stabilization and more — all running on RTX.</p>
<p>Combining Tensor Cores with TensorRT software brings unmatched generative AI performance to local PCs and workstations. And by running locally, several advantages are unlocked:</p>
<ul>
<li><strong>Performance</strong>: Users experience lower latency, since latency becomes independent of network quality when the entire model runs locally. This can be important for real-time use cases such as gaming or video conferencing. NVIDIA RTX offers the fastest AI accelerators, scaling to more than 1,300 AI trillion operations per second, or TOPS.</li>
<li><strong>Cost</strong>: Users don’t have to pay for cloud services, cloud-hosted application programming interfaces or infrastructure costs for large language model inference.</li>
<li><strong>Always on</strong>: Users can access LLM capabilities anywhere they go, without relying on high-bandwidth network connectivity.</li>
<li><strong>Data privacy</strong>: Private and proprietary data can always stay on the user’s device.</li>
</ul>
<h2><b>Optimized for LLMs</b></h2>
<p>What TensorRT brings to deep learning, <a href="https://developer.nvidia.com/tensorrt#inference">NVIDIA TensorRT-LLM</a> brings to the latest <a href="https://blogs.nvidia.com/blog/ai-decoded-rtx-pc-llms-chatbots/">LLMs</a>.</p>
<p>TensorRT-LLM, an open-source library that accelerates and optimizes LLM inference, includes out-of-the-box support for popular community models, including Phi-2, Llama2, Gemma, Mistral and Code Llama. Anyone — from developers and creators to enterprise employees and casual users — can experiment with TensorRT-LLM-optimized models in the <a href="https://build.nvidia.com/explore/discover">NVIDIA AI Foundation models</a>. Plus, with the <a href="https://blogs.nvidia.com/blog/chat-with-rtx-available-now/">NVIDIA ChatRTX</a> tech demo, users can see the performance of various models running locally on a Windows PC. ChatRTX is built on TensorRT-LLM for optimized performance on RTX GPUs.</p>
<p>NVIDIA is collaborating with the open-source community to develop native TensorRT-LLM connectors to popular application frameworks, including LlamaIndex and LangChain.</p>
<p>These innovations make it easy for developers to use TensorRT-LLM with their applications and experience the best LLM performance with RTX.</p>
<p><i>Get weekly updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/ai-on-rtx/?modal=subscribe-ai"><i>AI Decoded newsletter</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/ai-decoded-tensor-nv-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/ai-decoded-tensor-nv-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Unlocking Peak Generations: TensorRT Accelerates AI on RTX PCs and Workstations]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Viome’s Guru Banavar Discusses AI for Personalized Health</title>
		<link>https://blogs.nvidia.com/blog/viome-guru-banavar/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Wed, 27 Mar 2024 13:00:02 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[The AI Podcast]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70901</guid>

					<description><![CDATA[In the latest episode of NVIDIA’s AI Podcast, Viome Chief Technology Officer Guru Banavar spoke with host Noah Kravitz about how AI and RNA sequencing are revolutionizing personalized healthcare. The startup aims to tackle the root causes of chronic diseases by delving deep into microbiomes and gene expression. With a comprehensive testing kit, Viome translates		<a class="read-more" href="https://blogs.nvidia.com/blog/viome-guru-banavar/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>In the latest episode of NVIDIA’s <a href="https://soundcloud.com/theaipodcast">AI Podcast</a>, Viome Chief Technology Officer Guru Banavar spoke with host Noah Kravitz about how AI and RNA sequencing are revolutionizing personalized healthcare. The startup aims to tackle the root causes of chronic diseases by delving deep into microbiomes and gene expression.</p>
<p>With a comprehensive testing kit, Viome translates biological data into practical dietary recommendations. Viome is forging ahead with professional healthcare solutions, such as early detection tests for diseases, and integrating state-of-the-art technology with traditional medical practices for a holistic approach to wellness.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1785368577%3Fsecret_token%3Ds-NmWVdaGTqp7&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="Personalized Health: Viome's Guru Banavar Discusses Startup’s AI-Driven Approach – Ep. 352" href="https://soundcloud.com/theaipodcast/personalized-health-viomes-guru-banavar-discusses-startups-ai-driven-approach-ep-352/s-NmWVdaGTqp7" target="_blank" rel="noopener">Personalized Health: Viome&#8217;s Guru Banavar Discusses Startup’s AI-Driven Approach – Ep. 352</a></div>
<h2>Time Stamps:</h2>
<p>2:00: Introduction to Viome and the science of nutrigenomics<br />
4:25: The significance of RNA over DNA in health analysis<br />
7:40: The crucial role of the microbiome in understanding chronic diseases<br />
12:50: From sample collection to personalized nutrition recommendations<br />
17:35: Viome&#8217;s expansion into professional healthcare solutions and early disease detection</p>
<p>&nbsp;</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2021/08/ai-podcast-2600x1472_-1-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1159"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2021/08/ai-podcast-2600x1472_-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Viome’s Guru Banavar Discusses AI for Personalized Health]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Boom in AI-Enabled Medical Devices Transforms Healthcare</title>
		<link>https://blogs.nvidia.com/blog/ai-medical-devices-gtc-2024/</link>
		
		<dc:creator><![CDATA[David Niewolny]]></dc:creator>
		<pubDate>Tue, 26 Mar 2024 18:13:22 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Embedded Computing]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70860</guid>

					<description><![CDATA[The future of healthcare is software-defined and AI-enabled. Around 700 FDA-cleared, AI-enabled medical devices are now on the market — more than 10x the number available in 2020.   Many of the innovators behind this boom announced their latest AI-powered solutions at NVIDIA GTC, a global conference that last week attracted more than 16,000 business leaders,		<a class="read-more" href="https://blogs.nvidia.com/blog/ai-medical-devices-gtc-2024/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><span data-contrast="none">The future of healthcare is software-defined and AI-enabled. </span><a href="https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices" target="_blank" rel="noopener"><span data-contrast="none">Around 700 FDA-cleared, AI-enabled medical devices</span></a><span data-contrast="none"> are now on the market — </span><a href="https://www.nature.com/articles/s41746-020-00324-0" target="_blank" rel="noopener"><span data-contrast="none">more than 10x the number available in 2020</span></a><span data-contrast="none">. </span><span data-ccp-props="{}"> </span></p>
<p><span data-contrast="auto">Many of the innovators behind this boom announced their latest AI-powered solutions at </span><a href="https://www.nvidia.com/gtc/"><span data-contrast="none">NVIDIA GTC</span></a><span data-contrast="auto">, a global conference that last week attracted more than 16,000 business leaders, developers and researchers in Silicon Valley </span><span data-contrast="none">—</span><span data-contrast="auto"> and many more online.</span><span data-ccp-props="{}"> </span></p>
<p><span data-contrast="auto">Designed to make healthcare more efficient and help improve patient outcomes, these new technologies include </span><a href="https://blogs.nvidia.com/blog/what-are-foundation-models/"><span data-contrast="none">foundation models</span></a><span data-contrast="auto"> to accelerate ultrasound analysis, augmented and virtual reality solutions for cardiac imaging, and </span><a href="https://www.nvidia.com/en-us/glossary/generative-ai/"><span data-contrast="none">generative AI</span></a><span data-contrast="auto"> software to support surgeons.</span><span data-ccp-props="{}"> </span></p>
<h2><b><span data-contrast="auto">Shifting From Hardware to Software-Defined Medical Devices</span></b><span data-ccp-props="{}"> </span></h2>
<p><span data-contrast="auto">Medical devices have long been hardware-centric, relying on intricate designs and precise engineering. They’re now shifting to be software-defined, </span><span data-contrast="none">meaning they can be enhanced over time through software updates — the same way that smartphones can be upgraded with new apps and features for years before a user upgrades to a new device. </span><span data-ccp-props="{}"> </span></p>
<p><span data-contrast="auto">This new approach, supported by NVIDIA’s domain-specific platforms for real-time accelerated computing, is taking center stage because of its potential to transform patient care, increase efficiencies, enhance the clinician experience and drive better outcomes.</span><span data-ccp-props="{}"> </span></p>
<p><span data-contrast="auto">Leading medtech companies such as GE Healthcare are using NVIDIA technology to develop, fine-tune and deploy AI for software-defined medical imaging applications. </span><span data-ccp-props="{&quot;335559685&quot;:-20,&quot;335559737&quot;:-20,&quot;335559739&quot;:0}"> </span><span data-ccp-props="{&quot;335559685&quot;:-20,&quot;335559737&quot;:-20,&quot;335559739&quot;:0}"> </span></p>
<p><a href="https://www.businesswire.com/news/home/20240318340678/en/GE-HealthCare-Accelerates-AI-Innovation-with-Healthcare-Specific-Foundation-Models-Powered-by-NVIDIA" target="_blank" rel="noopener"><b><span data-contrast="none">GE Healthcare</span></b></a><span data-contrast="none"> announced at GTC that it used NVIDIA tools including the </span><a href="https://developer.nvidia.com/tensorrt"><span data-contrast="none">TensorRT software development kit</span></a><span data-contrast="none"> to develop and optimize SonoSAMTrack, a recent research foundation model that delineates and tracks organs, structures or lesions across medical images with just a few clicks. The research model has the potential to simplify and speed up ultrasound analysis for healthcare professionals.</span><span data-ccp-props="{&quot;335559737&quot;:-20,&quot;335559739&quot;:0}"> </span></p>
<h2><b><span data-contrast="auto">Powering the Next Generation of Digital Surgery</span></b><span data-ccp-props="{}"> </span></h2>
<p><span data-contrast="auto">With the </span><a href="https://developer.nvidia.com/blog/powering-mission-critical-ai-at-the-edge-with-ai-enterprise-igx/"><span data-contrast="none">NVIDIA IGX</span></a> <span data-contrast="none">edge computing platform and </span><a href="https://developer.nvidia.com/blog/developing-production-ready-ai-sensor-processing-applications-with-nvidia-holoscan-1-0/"><span data-contrast="none">NVIDIA Holoscan</span></a><span data-contrast="none"> medical-grade edge AI platform</span><span data-contrast="auto">, medical device companies are accelerating the development and deployment of AI-powered innovation in the operating room.</span><span data-ccp-props="{&quot;335559737&quot;:-20,&quot;335559739&quot;:0}"> </span><span data-ccp-props="{&quot;335559737&quot;:-20,&quot;335559739&quot;:0}"> </span></p>
<p><a href="https://blogs.nvidia.com/blog/johnson-and-johnson-medtech-ai-surgery/"><b><span data-contrast="none">Johnson &amp; Johnson MedTech</span></b></a><span data-contrast="auto"> is working with NVIDIA </span><span data-contrast="none">to test new AI capabilities for the company’s connected digital ecosystem for surgery. It aims to enable open innovation and accelerate the delivery of real-time insights at scale to support medical professionals before, during and after procedures.</span><span data-contrast="auto"> </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559737&quot;:-20,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"> </span></p>
<p><span data-contrast="auto">Paris-based robotic surgery company </span><a href="https://www.prnewswire.com/news-releases/moon-surgicals-maestro-system-powered-by-nvidia-holoscan-paves-the-way-to-next-generation-laparoscopy-with-over-200-patients-treated-302092824.html" target="_blank" rel="noopener"><b><span data-contrast="none">Moon Surgical</span></b></a>, a member of the <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a> program for cutting-edge startups,<span data-contrast="auto"> is using Holoscan and IGX to power its Maestro System, which is used in </span><span data-contrast="none">laparoscopy, a technique where surgeons </span><span data-contrast="auto">operate through small incisions with an internal camera and instruments. </span><span data-ccp-props="{}"> </span></p>
<p><span data-contrast="auto">Maestro’s ScoPilot enables surgeons to control a laparoscope without taking their hands off other surgical tools during an operation.  To date, it’s been used to treat over 200 patients successfully. </span><span data-ccp-props="{}"> </span></p>
<p><span data-contrast="auto">Moon Surgical and NVIDIA are also collaborating to bring generative AI features to the operating room using Maestro and Holoscan.</span><span data-ccp-props="{}"> </span></p>
<h2><b><span data-contrast="auto">NVIDIA Platforms Power Thriving Medtech Ecosystem</span></b><span data-ccp-props="{}"> </span></h2>
<p><span data-contrast="auto">A growing number of medtech companies and solution providers is making it easier for customers to adopt NVIDIA’s edge AI platforms to enhance and accelerate healthcare. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559740&quot;:257}"> </span></p>
<p><a href="https://www.arrow.com/ais/resource-library/blog/arrow-electronics-to-boost-nvidia-igx-edge-ai-adoption-with-platform-as-a-service-programs-for-industrial-and-medical-applications" target="_blank" rel="noopener"><b><span data-contrast="none">Arrow Electronics</span></b></a><span data-contrast="auto"> is delivering IGX as a subscription-like platform-as-a-service for industrial and medical customers. Customers who have adopted Arrow’s business model to accelerate application deployment include </span><strong><a href="https://blogs.nvidia.com/blog/ai-orthopedic-surgery/">Kaliber AI</a></strong><span data-contrast="auto">, an NVIDIA Inception member developing AI tools to assist minimally invasive surgery.</span> <span data-contrast="auto">At GTC, Kaliber showcased </span><a href="https://www.kaliber.ai/post/kaliber-exhibition-at-nvidia-gtc-2024" target="_blank" rel="noopener"><span data-contrast="none">AI-generated insights for surgeons</span></a><span data-contrast="auto"> and a </span><a href="https://www.nvidia.com/en-us/glossary/large-language-models/"><span data-contrast="none">large language model</span></a><span data-contrast="auto"> to respond to patient questions.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559740&quot;:257}"> </span></p>
<p><span data-contrast="auto">￼</span><span data-contrast="auto">Global</span> <span data-contrast="auto">visualization leader </span><a href="https://www.barco.com/en/about/press-releases/2024/2024-03-18-collaboration-barco-nvidia-softacuity" target="_blank" rel="noopener"><b><span data-contrast="none">Barco</span></b></a><span data-contrast="auto"> is adopting Holoscan and IGX to build a turnkey surgical AI platform for customers seeking an off-the-shelf offering that allows them to focus their engineering resources on application development. The company is working with SoftAcuity on two Holoscan-based products that will include generative AI voice control and AI-powered data analytics. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559740&quot;:257}"> </span></p>
<p><span data-contrast="auto">And </span><a href="https://www.magicleap.com/newsroom/nvidia-igx-magic-leap-2-xr-bundle" target="_blank" rel="noopener"><b><span data-contrast="none">Magic Leap</span></b></a><span data-contrast="auto"> has integrated Holoscan in its </span><a href="https://blogs.nvidia.com/blog/what-is-extended-reality/"><span data-contrast="none">extended reality</span></a><span data-contrast="auto"> software stack, enhancing the capabilities of customers like </span><a href="https://www.prnewswire.com/news-releases/medical-isight-to-showcase-its-leading-surgical-xrai-software-at-nvidia-gtc-302089569.html" target="_blank" rel="noopener"><span data-contrast="none">Medical iSight</span></a><span data-contrast="auto"> — a software developer building real-time, intraoperative support </span><span data-contrast="none">for minimally invasive treatments of stroke and neurovascular conditions.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559740&quot;:257}"> </span></p>
<p><span data-contrast="auto">Learn more about </span><a href="https://www.nvidia.com/en-us/industries/healthcare-life-sciences/medical-devices/"><span data-contrast="none">NVIDIA-accelerated medtech</span></a><span data-contrast="auto">. </span><span data-ccp-props="{&quot;201341983&quot;:1,&quot;335557856&quot;:16777215,&quot;335559740&quot;:330}"> </span></p>
<p><span data-contrast="auto">Get started on </span><a href="https://catalog.ngc.nvidia.com/?filters=&amp;orderBy=weightPopularDESC&amp;query="><span data-contrast="none">NVIDIA NGC</span></a><span data-contrast="auto"> or visit </span><a href="http://ai.nvidia.com/"><span data-contrast="none">ai.nvidia.com</span></a><span data-contrast="auto"> to experiment with </span><a href="https://nvidianews.nvidia.com/news/healthcare-generative-ai-microservices"><span data-contrast="none">more than two dozen healthcare microservices</span></a><span data-contrast="auto">. </span><span data-ccp-props="{&quot;201341983&quot;:1,&quot;335557856&quot;:16777215,&quot;335559740&quot;:330}"> </span></p>
<p><a href="https://www.nvidia.com/en-us/industries/healthcare-life-sciences/healthcare-news-sign-up/"><i><span data-contrast="none">Subscribe to NVIDIA healthcare news</span></i></a><i><span data-contrast="auto">. </span></i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/MedTech-blog.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/MedTech-blog-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Boom in AI-Enabled Medical Devices Transforms Healthcare]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Model Innovators: How Digital Twins Are Making Industries More Efficient</title>
		<link>https://blogs.nvidia.com/blog/digital-twins-modulus-wistron/</link>
		
		<dc:creator><![CDATA[Rick Merritt]]></dc:creator>
		<pubDate>Tue, 26 Mar 2024 15:00:51 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Customer Stories]]></category>
		<category><![CDATA[Digital Twin]]></category>
		<category><![CDATA[Industrial and Manufacturing]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[New GPU Uses]]></category>
		<category><![CDATA[NVIDIA in Europe]]></category>
		<category><![CDATA[NVIDIA Modulus]]></category>
		<category><![CDATA[Omniverse]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70673</guid>

					<description><![CDATA[A manufacturing plant near Hsinchu, Taiwan’s Silicon Valley, is among facilities worldwide boosting energy efficiency with AI-enabled digital twins. A virtual model can help streamline operations, maximizing throughput for its physical counterpart, say engineers at Wistron, a global designer and manufacturer of computers and electronics systems. In the first of several use cases, the company		<a class="read-more" href="https://blogs.nvidia.com/blog/digital-twins-modulus-wistron/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>A manufacturing plant near Hsinchu, Taiwan’s Silicon Valley, is among facilities worldwide boosting <a href="https://www.nvidia.com/en-us/glossary/energy-efficiency/">energy efficiency</a> with AI-enabled digital twins.</p>
<p>A virtual model can help streamline operations, maximizing throughput for its physical counterpart, say engineers at Wistron, a global designer and manufacturer of computers and electronics systems.</p>
<p>In the first of several use cases, the company built a digital copy of a room where <a href="https://www.nvidia.com/en-gb/data-center/dgx-systems/">NVIDIA DGX systems</a> undergo thermal stress tests (pictured above). Early results were impressive.</p>
<h2><b>Making Smart Simulations</b></h2>
<p>Using <a href="https://developer.nvidia.com/modulus">NVIDIA Modulus</a>, a framework for building AI models that understand the laws of physics, Wistron created digital twins that let them accurately predict the airflow and temperature in test facilities that must remain between 27 and 32 degrees C.</p>
<p>A simulation that would’ve taken nearly 15 hours with traditional methods on a CPU took just 3.3 seconds on an NVIDIA GPU running inference with an AI model developed using Modulus, a whopping 15,000x speedup.</p>
<p>The results were fed into tools and applications built by Wistron developers with <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, a platform for creating 3D workflows and applications based on OpenUSD.</p>
<figure id="attachment_70881" aria-describedby="caption-attachment-70881" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-birdseye-image-of-Wixstron-digital-twin-scaled.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-70881" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-birdseye-image-of-Wixstron-digital-twin-672x306.jpg" alt="A bird's eye view of Wistron's digital twin" width="672" height="306" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-birdseye-image-of-Wixstron-digital-twin-672x306.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-birdseye-image-of-Wixstron-digital-twin-400x182.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-birdseye-image-of-Wixstron-digital-twin-768x349.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-birdseye-image-of-Wixstron-digital-twin-1536x699.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-birdseye-image-of-Wixstron-digital-twin-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-birdseye-image-of-Wixstron-digital-twin-842x383.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-birdseye-image-of-Wixstron-digital-twin-406x185.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-birdseye-image-of-Wixstron-digital-twin-188x86.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/NU-birdseye-image-of-Wixstron-digital-twin-1280x580.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-70881" class="wp-caption-text">A bird&#8217;s eye view of Wistron&#8217;s digital twin</figcaption></figure>
<p>With their Omniverse-powered software, Wistron created realistic and immersive simulations that operators interact with via VR headsets. And thanks to the AI models they developed using Modulus, the airflows in the simulation obey the laws of physics.</p>
<p>“Physics-informed models let us control the test process and the room’s temperature remotely in near real time, saving time and energy,” said John Lu, a manufacturing operations director at Wistron.</p>
<p>Specifically, Wistron combined separate models for predicting air temperature and airflow to eliminate risks of overheating in the test room. It also created a recommendation system to identify the best locations to test computer baseboards.</p>
<p>The digital twin, linked to thousands of networked sensors, enabled Wistron to increase the facility’s overall energy efficiency up to 10%. That amounts to using up to 121,600 kWh less electricity a year, reducing carbon emissions by a whopping 60,192 kilograms.</p>
<h2><b>An Expanding Effort</b></h2>
<p>Currently, the group is expanding its AI model to track more than a hundred variables in a space that holds 50 computer racks. The team is also simulating all the mechanical details of the servers and testers.</p>
<p>“The final model will help us optimize test scheduling as well as the energy efficiency of the facilities’ air conditioning system,” said Derek Lai, a Wistron technical supervisor with expertise in physics-informed neural networks.</p>
<p>Looking ahead, “The tools and applications we’re building with Omniverse help us improve the layout of our DGX factories to provide the best throughput, further improving efficiency,” said Lu.</p>
<h2><b>Efficiently Generating Energy</b></h2>
<p>Half a world away, Siemens Energy is demonstrating the power of digital industrialization using Modulus and Omniverse.</p>
<p>The Munich-based company, whose technology generates one-sixth of the world’s electricity, achieved a 10,000x speedup simulating a heat-recovery steam generator using a physics-informed AI model (see video below).</p>
<p>Using a digital twin to detect corrosion early on, these massive systems can reduce downtime by 70%, potentially saving the industry $1.7 billion annually compared to a standard simulation that took half a month.</p>
<p>“The reduced computational time enables us to develop <a href="https://nvdam.widen.net/s/6qxcqjqhmj/energy-efficiency-solution-brief-physics-ml-simulations-cta-2746611">energy-efficient digital twins</a> for a sustainable, reliable and affordable energy ecosystem,” said Georg Rollmann, head of advanced analytics and AI at Siemens Energy.</p>
<p><iframe loading="lazy" title="Siemens Energy HRSG Digital Twin Simulation Using NVIDIA Modulus and Omniverse" width="500" height="281" src="https://www.youtube.com/embed/JLboPXn6sKI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<h2><b>Digital Twins Drive Science and Industry</b></h2>
<p>Automotive companies are applying the technology to the design of new cars and manufacturing plants. Scientists are using it in fields as diverse as astrophysics, genomics and weather forecasting. It’s even being used to create a <a href="https://blogs.nvidia.com/blog/digital-twins-climate-collaboration/">digital twin of Earth</a> to understand and mitigate the impacts of climate change.</p>
<p>Every year, physics simulations, typically run on supercomputer-class systems, consume an estimated 200 billion CPU core hours and 4 terawatt hours of energy. Physics-informed AI is accelerating these complex workflows 200x on average, saving time, cost and energy.</p>
<p>For more insights, listen to a <a href="https://www.nvidia.com/gtc/session-catalog/?search=Wistron&amp;tab.allsessions=1700692987788001F1cG&amp;search=Wistron#/session/1696527142214001ZTwl">talk</a> from GTC describing Wistron’s work and <a href="https://www.nvidia.com/gtc/session-catalog/?search=Wistron&amp;tab.allsessions=1700692987788001F1cG&amp;search=Wistron#/session/1698243453095001ZyfC">a panel</a> about industries using generative AI.</p>
<p>Learn more about the <a href="https://www.nvidia.com/en-us/data-center/sustainable-computing/">impact accelerated computing is having on sustainability</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/Final-image-of-Wistrons-digital-twin-of-a-test-room.png"
			type="image/png"
			width="1920"
			height="1021"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/Final-image-of-Wistrons-digital-twin-of-a-test-room-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Model Innovators: How Digital Twins Are Making Industries More Efficient]]></media:title>
			<media:description type="html">Image from Wistron&#039;s digital twin of a testing room</media:description>
			</media:content>
			</item>
		<item>
		<title>Into the Omniverse: Groundbreaking OpenUSD Advancements Put NVIDIA GTC Spotlight on Developers</title>
		<link>https://blogs.nvidia.com/blog/openusd-advancements-gtc-developers/</link>
		
		<dc:creator><![CDATA[Greer Hoyem]]></dc:creator>
		<pubDate>Tue, 26 Mar 2024 13:00:50 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Digital Twin]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[Into the Omniverse]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Universal Scene Description]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70752</guid>

					<description><![CDATA[Editor’s note: This post is part of Into the Omniverse, a series focused on how artists, developers and enterprises can transform their workflows using the latest advances in OpenUSD and NVIDIA Omniverse. The Universal Scene Description framework, aka OpenUSD, has emerged as a game-changer for building virtual worlds and accelerating creative workflows. It can ease		<a class="read-more" href="https://blogs.nvidia.com/blog/openusd-advancements-gtc-developers/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of </i><a href="https://www.nvidia.com/en-us/omniverse/news/"><i>Into the Omniverse</i></a><i>, a series focused on how artists, developers and enterprises can transform their workflows using the latest advances in </i><a href="https://www.nvidia.com/en-us/omniverse/usd/"><i>OpenUSD</i></a><i> and </i><a href="https://www.nvidia.com/en-us/omniverse/usd/"><i>NVIDIA Omniverse</i></a><i>.</i></p>
<p>The Universal Scene Description framework, aka <a href="https://www.nvidia.com/en-us/omniverse/usd/">OpenUSD</a>, has emerged as a game-changer for building virtual worlds and accelerating creative workflows. It can ease the handling of complex datasets, facilitate collaboration and enable seamless interoperability between 3D applications.</p>
<p>The latest news and demos from <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>, a global AI conference that ran last week, put on display the power developers gain from <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> — a platform of application programming interfaces (APIs) and software development kits (SDKs) that enable them to build 3D pipelines, tools, applications and services.<b><br />
</b><br />
Newly announced <a href="https://nvidianews.nvidia.com/news/omniverse-cloud-apis-industrial-digital-twin">NVIDIA Omniverse Cloud APIs</a>, coming first to <a href="https://www.youtube.com/watch?v=3hLEj0i7fug" target="_blank" rel="noopener">Microsoft Azure</a>, allow developers to send their OpenUSD industrial scenes from content-creation applications to the <a href="https://www.nvidia.com/en-us/omniverse/solutions/stream-3d-apps/">NVIDIA Graphics Delivery Network</a>.</p>
<p>Such a workflow was showcased in a demo featuring an interactive car configurator application, developed by computer-generated-imagery studio Katana using Omniverse, streamed in full fidelity to an <a href="https://blogs.nvidia.com/blog/omniverse-apple-vision-pro/">Apple Vision Pro</a>’s high-resolution display. A designer wearing the Vision Pro toggled through paint and trim options, and even entered the vehicle.</p>
<p><iframe loading="lazy" title="Develop 3D Product Configurators With Generative AI and OpenUSD" width="500" height="281" src="https://www.youtube.com/embed/LAVXuDK83iA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>In a <a href="https://youtu.be/h30brb7-taU" target="_blank" rel="noopener">separate demo</a>, Dassault Systèmes showcased, using its 3DEXCITE portfolio, a powerful web-based application for 3D data preparation supercharged with NVIDIA AI and Omniverse Cloud APIs to deliver new generative storytelling capabilities.</p>
<p>OpenUSD also played a part in the announcement of NVIDIA’s latest <a href="https://blogs.nvidia.com/blog/omniverse-next-gen-data-center/">AI supercomputer</a>, a powerful cluster based on the NVIDIA GB200 NVL72 liquid-cooled system, which was showcased as a <a href="https://www.nvidia.com/en-us/omniverse/solutions/digital-twins/">digital twin</a> in Omniverse.</p>
<p>Engineers unified and visualized multiple computer-aided design datasets with full physical accuracy and photorealism using OpenUSD through the Cadence Reality digital twin platform, powered by Omniverse APIs. The technologies together provided a powerful computing platform for developing OpenUSD-based 3D tools, workflows and applications.</p>
<p><iframe loading="lazy" title="Accelerating Data Center Design With Digital Twins" width="500" height="281" src="https://www.youtube.com/embed/h68kXLIRilM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p><a href="https://blogs.nvidia.com/blog/siemens-immersive-visualization-generative-ai/">Siemens</a> announced it has integrated OpenUSD into its Xcelerator platform applications via Omniverse Cloud APIs, enabling its customers to unify their 3D data and services in digital twins with physically based rendering.</p>
<p>A demo showcased how ship manufacturer HD Hyundai used Siemens’ Teamcenter X, which is part of Xcelerator, to design digital twins of complex engineering projects, delivering accelerated collaboration, minimized workflow waste, time and cost savings, and reduced manufacturing defects.</p>
<p><iframe loading="lazy" title="Siemens Teamcenter X Powered by NVIDIA Omniverse APIs" width="500" height="281" src="https://www.youtube.com/embed/rrb2tPHiLRo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>OpenUSD Ecosystem Updates on Replay</b></h2>
<p>The latest OpenUSD ecosystem updates shared at GTC include:</p>
<ul>
<li><a href="http://www.ansys.com/news-center/press-releases/3-18-24-ansys-and-nvidia-pioneer-next-era-of-cae" target="_blank" rel="noopener"><b>Ansys</b></a> is adopting OpenUSD and Omniverse Cloud APIs to enable data interoperability and <a href="https://www.nvidia.com/en-us/design-visualization/">NVIDIA RTX</a> visualization in technologies such as Ansys AVxcelerate for autonomous vehicles, Ansys Perceive EM for 6G simulation, and NVIDIA-accelerated solvers such as Ansys Fluent.</li>
<li><a href="https://blog.3ds.com/brands/netvibes/dassault-systemes-collaborates-with-nvidia-to-showcase-the-future-of-storytelling-with-generative-ai" target="_blank" rel="noopener"><b>Dassault Systèmes</b></a> is using OpenUSD, Omniverse Cloud APIs and Shutterstock 3D AI Services for generative storytelling in 3DEXCITE applications.</li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=Continental&amp;tab.allsessions=1700692987788001F1cG#/session/1701169295496001kxqH" target="_blank" rel="noopener"><b>Continental</b></a> is developing an OpenUSD-based digital twin platform to optimize factory operations and speed time to market.</li>
<li><a href="https://hxgn.biz/3VcFK1s" target="_blank" rel="noopener"><b>Hexagon</b></a> is integrating reality-capture sensors and digital-reality platforms with OpenUSD and Omniverse Cloud APIs for hyperrealistic simulation and visualization.</li>
<li><a href="https://media.monks.com/articles/GTC-2024"><b>Media.Monks</b></a> is adopting Omniverse for a generative AI- and OpenUSD-enabled content-creation pipeline for scalable hyper-personalization.</li>
<li><a href="https://news.microsoft.com/2024/03/18/microsoft-and-nvidia-announce-major-integrations-to-accelerate-generative-ai-for-enterprises-everywhere/"><b>Microsoft</b></a><span> is integrating Omniverse Cloud APIs with Microsoft Power BI, so factory operators can see real-time factory data overlaid on a 3D digital twin to speed up production.</span></li>
<li><a href="https://rok.auto/4cg6fcg" target="_blank" rel="noopener"><b>Rockwell Automation</b></a> is using OpenUSD and Omniverse Cloud APIs for RTX-enabled visualization in industrial automation and digital transformation.</li>
<li><a href="https://www.trimble.com/en/thought-leadership/3d-interoperability-and-standardization-improve-usd-workflows" target="_blank" rel="noopener"><b>Trimble</b></a> is enabling interactive NVIDIA Omniverse RTX viewers with Trimble model data using OpenUSD and Omniverse Cloud APIs.</li>
<li><a href="https://www.youtube.com/watch?v=OAdqXZGUb70&amp;t=3s" target="_blank" rel="noopener"><b>Wistron</b></a> is building OpenUSD-based digital twins of <a href="https://www.nvidia.com/en-us/data-center/dgx-platform/">NVIDIA DGX</a> and <a href="https://www.nvidia.com/en-us/data-center/hgx/">HGX</a> factories using custom software developed with Omniverse SDKs and APIs.</li>
<li><a href="https://www.wpp.com/wpp-iq/2024/03/wpp-puts-itself-at-the-heart-of-collaborative-3d-worlds" target="_blank" rel="noopener"><b>WPP</b></a> is expanding its Omniverse Cloud-based OpenUSD and generative AI content-generation engine to the retail and consumer packaged goods sector.</li>
</ul>
<h2><b>Get Plugged In to the World of OpenUSD</b></h2>
<p>Several GTC sessions expanded on the latest OpenUSD advancements. Register free to watch them on demand:</p>
<ul>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=big%20bang&amp;search=big+bang%2C+big%2Bbang&amp;tab.allsessions=1700692987788001F1cG#/session/1698243138347001uvVR"><b>The Big Bang of OpenUSD</b></a>: Hear from technical luminaries at Pixar, Adobe, Apple, Autodesk and NVIDIA on the potential of OpenUSD.</li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=62642#/session/1696633560488001qMg1"><b>An Introduction to OpenUSD</b></a>: Learn why OpenUSD is more than just a file format and how it can revolutionize 3D workflows.</li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=62169#/session/1695224451463001HXMF"><b>Mastering USD and Adobe Substance 3D</b></a>: Learn how to master real-world material capture, seamlessly integrate workflows with OpenUSD and enhance realism with Adobe Substance 3D.</li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=62483#/session/1696276623678001MzjX"><b>Enabling 3D Geospatial Workflows for Industrial Digital Twins</b></a>: Learn how Cesium is using OpenUSD to enable high-fidelity streaming and rendering for global-scale digital twins.</li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=62783#/session/1698243453095001ZyfC"><b>Digitalizing the World’s Largest Industries With OpenUSD and Generative AI</b></a>: Explore how global industries are becoming software-defined.</li>
</ul>
<p><i>Get started with NVIDIA Omniverse by downloading the standard license </i><a href="https://www.nvidia.com/en-us/omniverse/download/"><i>free</i></a><i>, access </i><a href="https://developer.nvidia.com/usd"><i>OpenUSD</i></a><i> resources, and learn how </i><a href="https://www.nvidia.com/en-us/omniverse/enterprise/"><i>Omniverse Enterprise</i><i> can connect your team</i></a><i>. Stay up to date on </i><a href="https://www.instagram.com/nvidiaomniverse/"><i>Instagram</i></a><i>, </i><a href="https://medium.com/@nvidiaomniverse"><i>Medium</i></a><i> and </i><a href="https://twitter.com/nvidiaomniverse"><i>X</i></a><i>. For more, join the </i><a href="https://www.nvidia.com/en-us/omniverse/community/"><i>Omniverse community</i></a><i> on the </i><a href="https://forums.developer.nvidia.com/c/omniverse/300"><i>forums</i></a><i>, </i><a href="https://discord.com/invite/XWQNJDNuaC"><i>Discord server</i></a><i>, </i><a href="https://www.twitch.tv/nvidiaomniverse"><i>Twitch</i></a><i> and </i><a href="https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA"><i>YouTube</i></a><i> channels. </i></p>
<p><i>Featured image courtesy of Siemens, HD Hyundai.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/march-ito.png"
			type="image/png"
			width="1165"
			height="651"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/march-ito-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Into the Omniverse: Groundbreaking OpenUSD Advancements Put NVIDIA GTC Spotlight on Developers]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Blackwell and Automotive Industry Innovators Dazzle at NVIDIA GTC</title>
		<link>https://blogs.nvidia.com/blog/blackwell-auto-ecosystem-gtc/</link>
		
		<dc:creator><![CDATA[Calisa Cole]]></dc:creator>
		<pubDate>Tue, 26 Mar 2024 02:07:33 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[Isaac]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<category><![CDATA[Omniverse]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70773</guid>

					<description><![CDATA[Generative AI, in the data center and in the car, is making vehicle experiences safer and more enjoyable. The latest advancements in automotive technology were on display last week at NVIDIA GTC, a global AI conference that drew tens of thousands of business leaders, developers and researchers from around the world. The event kicked off		<a class="read-more" href="https://blogs.nvidia.com/blog/blackwell-auto-ecosystem-gtc/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><a href="https://www.nvidia.com/en-us/glossary/generative-ai/">Generative AI</a>, in the data center and in the car, is making vehicle experiences safer and more enjoyable.</p>
<p>The latest advancements in automotive technology were on display last week at <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>, a global AI conference that drew tens of thousands of business leaders, developers and researchers from around the world.</p>
<p>The event kicked off with NVIDIA founder and CEO Jensen Huang’s <a href="https://www.youtube.com/watch?v=Y2F8yisiS6E">keynote</a>, which included the announcement of the <a href="https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing">NVIDIA Blackwell platform</a> — purpose-built to power a new era of AI computing.</p>
<p>The NVIDIA Blackwell GPU architecture will be integrated into the <a href="https://nvidianews.nvidia.com/news/nvidia-drive-powers-next-generation-transportation">NVIDIA DRIVE Thor</a> centralized car computer to enable generative AI applications and immersive in-vehicle experiences. <a href="https://www.nvidia.com/en-us/glossary/large-language-models/">Large language models</a> will be able to run in the car, enabling an intelligent copilot that understands and speaks in natural language.</p>
<p><a href="https://nvidianews.nvidia.com/news/nvidia-drive-powers-next-generation-transportation">BYD</a>, the world’s largest electric-vehicle maker, announced it will adopt DRIVE Thor as the AI brain of its future fleets. In addition, the company will use NVIDIA’s AI infrastructure for cloud-based AI development and training, and the <a href="https://developer.nvidia.com/isaac">NVIDIA Isaac</a> and <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> platforms to develop tools and applications for virtual factory planning and retail configurators. Hyper, Nuro, Plus, Waabi, WeRide and XPENG are also adopting DRIVE Thor.</p>
<p>Learn more about the automotive ecosystem’s announcements at GTC:</p>
<p><iframe loading="lazy" title="Automotive Update from GTC 2024" width="500" height="281" src="https://www.youtube.com/embed/_wKNVMoMbrw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Some of the latest NVIDIA-powered vehicles displayed on the exhibition floor included:</p>
<ul>
<li>Aurora self-driving truck, already on the highways of Texas</li>
<li>Lucid Air long-range electric sedan</li>
<li>Mercedes-Benz Concept CLA Class, showcasing what’s to come</li>
<li>Nuro R3, a fully autonomous robotic delivery model</li>
<li>Polestar 3, the SUV for the electric age</li>
<li>Volvo Cars EX90, its new fully electric, flagship SUV</li>
<li>And WeRide’s Robobus, a new form of urban mobility.</li>
</ul>
<figure id="attachment_70894" aria-describedby="caption-attachment-70894" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-70894 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/AURORA-autodisplaygtc-1536x804-1-672x352.png" alt="" width="672" height="352" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/AURORA-autodisplaygtc-1536x804-1-672x352.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/AURORA-autodisplaygtc-1536x804-1-400x209.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/AURORA-autodisplaygtc-1536x804-1-768x402.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/AURORA-autodisplaygtc-1536x804-1-842x441.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/AURORA-autodisplaygtc-1536x804-1-406x213.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/AURORA-autodisplaygtc-1536x804-1-188x98.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/AURORA-autodisplaygtc-1536x804-1-1280x670.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/AURORA-autodisplaygtc-1536x804-1.png 1536w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70894" class="wp-caption-text">Aurora’s self-driving truck.</figcaption></figure>
<figure id="attachment_70897" aria-describedby="caption-attachment-70897" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-70897 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/MB-autodisplaygtc-1536x804-1-672x352.png" alt="" width="672" height="352" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/MB-autodisplaygtc-1536x804-1-672x352.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MB-autodisplaygtc-1536x804-1-400x209.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MB-autodisplaygtc-1536x804-1-768x402.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MB-autodisplaygtc-1536x804-1-842x441.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MB-autodisplaygtc-1536x804-1-406x213.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MB-autodisplaygtc-1536x804-1-188x98.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MB-autodisplaygtc-1536x804-1-1280x670.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/MB-autodisplaygtc-1536x804-1.png 1536w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70897" class="wp-caption-text">Mercedes-Benz Concept CLA Class.</figcaption></figure>
<figure id="attachment_70891" aria-describedby="caption-attachment-70891" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-70891 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/VOLVO-autodisplaygtc-1536x804-1-672x352.png" alt="" width="672" height="352" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/VOLVO-autodisplaygtc-1536x804-1-672x352.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/VOLVO-autodisplaygtc-1536x804-1-400x209.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/VOLVO-autodisplaygtc-1536x804-1-768x402.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/VOLVO-autodisplaygtc-1536x804-1-842x441.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/VOLVO-autodisplaygtc-1536x804-1-406x213.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/VOLVO-autodisplaygtc-1536x804-1-188x98.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/VOLVO-autodisplaygtc-1536x804-1-1280x670.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/VOLVO-autodisplaygtc-1536x804-1.png 1536w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70891" class="wp-caption-text">Volvo Cars EX90 fully electric, flagship SUV.</figcaption></figure>
<p>The NVIDIA auto booth highlighted the wide adoption of the <a href="https://developer.nvidia.com/drive">NVIDIA DRIVE</a> platform, with displays featuring electronic control units from a variety of partners, including Bosch, Lenovo and ZEEKR.</p>
<p><img loading="lazy" decoding="async" class="wp-image-70783 size-large aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/autodisplaygtc-672x352.png" alt="" width="672" height="352" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/autodisplaygtc-672x352.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/autodisplaygtc-400x209.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/autodisplaygtc-768x402.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/autodisplaygtc-1536x804.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/autodisplaygtc-842x441.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/autodisplaygtc-406x212.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/autodisplaygtc-188x98.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/autodisplaygtc-1280x670.png 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/autodisplaygtc.png 1999w" sizes="(max-width: 672px) 100vw, 672px" /></p>
<p>A wide range of NVIDIA automotive partners, including <a href="https://www.ansys.com/news-center/press-releases/3-18-24-ansys-and-nvidia-pioneer-next-era-of-cae">Ansys</a>, <a href="https://www.foretellix.com/end-to-end-av-development-nvidia-omniverse/">Foretellix</a>, <a href="https://www.prnewswire.com/news-releases/lenovo-vehicle-computing-and-weride-forge-a-strategic-partnership-using-nvidia-drive-thor-platform-to-accelerate-autonomous-driving-302092408.html#:~:text=Lenovo%20Vehicle%20Computing%20and%20WeRide,Platform%20to%20Accelerate%20Autonomous%20Driving">Lenovo</a>, <a href="https://corp.mediatek.com/news-events/press-releases/mediatek-brings-advanced-ai-capabilities-to-vehicles-with-new-dimensity-auto-cockpit-chipsets-enabled-by-nvidia-technology">MediaTek</a>, <a href="https://www.prweb.com/releases/nodars-advanced-stereo-vision-technology-for-long-range-object-detection-and-enhanced-autonomous-driving-safety-now-supported-on-nvidia-drive-302091117.html">NODAR</a>, <a href="https://www.ovt.com/press-releases/omnivision-announces-automotive-image-sensor-with-theiacel-technology-now-compatible-with-nvidia-omniverse-for-autonomous-driving-development/">OMNIVISION</a>, <a href="https://www.businesswire.com/news/home/20240318765820/en/Plus-Advances-the-Development-of-Next-Generation-Vision-Models-Built-on-NVIDIA-DRIVE-for-AI-Processing-in-its-Self-Driving-Software">Plus</a>, <a href="https://www.accesswire.com/843254/seyond-to-expand-lidar-solutions-for-autonomous-vehicles-with-nvidia-driveworks-and-omniverse-integration">Seyond</a>, <a href="https://www.businesswire.com/news/home/20240318067099/en/SoundHound-to-Offer-On-Chip-Voice-AI-with-NVIDIA-That-Delivers-In-Vehicle-Generative-AI-Responses-With-No-Connectivity-Required">SoundHound</a>, <a href="https://www.prnewswire.com/news-releases/voxel51-accelerates-autonomous-vehicle-development-with-nvidia-omniverse-integration-302091979.html">Voxel51</a> and <a href="https://waabi.ai/nvidia-drivethor/">Waabi</a>, all made next-generation product announcements at GTC.</p>
<p>In addition, the automotive pavilion buzzed with interest in the latest lidar advancements from Luminar and Robosense, as well as Helm.ai’s software offerings for the <a href="https://blogs.nvidia.com/blog/whats-difference-level-2-level-5-autonomy/">level 2 to level 4</a> autonomous driving stack.</p>
<p>And other partners, such as Ford, Geely, General Motors, Jaguar Land Rover and Zoox, participated in dozens of sessions and panels covering topics such as building data center applications and developing safe autonomous vehicles. Watch the sessions <a href="https://www.nvidia.com/gtc/">on demand</a>.</p>
<p><i>Learn more about the latest advancements in generative AI and automotive technology by watching </i><a href="https://www.youtube.com/watch?v=Y2F8yisiS6E&amp;list=PLZHnYvH1qtOYPPHRaHf9yPQkIcGpIUpdL"><i>Huang’s GTC keynote in replay</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/autowrapnew.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/autowrapnew-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Blackwell and Automotive Industry Innovators Dazzle at NVIDIA GTC]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI’s New Frontier: From Daydreams to Digital Deeds</title>
		<link>https://blogs.nvidia.com/blog/chat-catanzaro-qiu/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Thu, 21 Mar 2024 23:00:05 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70702</guid>

					<description><![CDATA[Imagine a world where you can whisper your digital wishes into your device, and poof, it happens. That world may be coming sooner than you think. But if you’re worried about AI doing your thinking for you, you might be waiting for a while. In a fireside chat Wednesday at NVIDIA GTC, the global AI		<a class="read-more" href="https://blogs.nvidia.com/blog/chat-catanzaro-qiu/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Imagine a world where you can whisper your digital wishes into your device, and poof, it happens.</p>
<p>That world may be coming sooner than you think. But if you’re worried about AI doing your thinking for you, you might be waiting for a while.</p>
<p>In a fireside chat Wednesday at <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>, the global AI conference, Kanjun Qiu, CEO of Imbue, and Bryan Catanzaro, vice president of applied deep learning research at NVIDIA, challenged many of the clichés that have long dominated conversations about AI.</p>
<p>Launched in October 2022, Imbue made headlines with its Series B fundraiser last year, raising over $200 million at a $1 billion valuation.</p>
<p><b>Bridging the Gap Between ‘Idea and Execution’</b><b><br />
</b><br />
The discussion highlighted not only Imbue’s approach toward building practical AI agents able to automate menial, unrewarding work, but also painted a vivid picture of what the next chapter in AI innovation might hold.</p>
<p>“Our lives are full of so much friction &#8230; every single person’s vision can come to life,” Qiu said. “The barrier between idea and execution can be much smaller.”</p>
<p>Catanzaro’s reflections on the practical difficulties of using AI for simple tasks, such as his own challenges trying to get his digital assistant to help him find his next meeting, underscored the current limitations in human-AI interaction.</p>
<p>It turns out that figuring out where and when to go to a meeting, while easy for a human assistant, isn’t easy to automate.</p>
<p>“We tend to underestimate the things that we do naturally and overestimate the things that require reasoning,” Catanzaro observed. “One of the things humans deal with well is ambiguity.”</p>
<p>This set the stage for a broader discussion of the need for AI to move beyond mere code generation and become a dynamic, intuitive interface between humans and computers.</p>
<p>Qiu said the idea that AI can be a magical assistant, one that knows everything about you “isn’t necessarily the right paradigm.”</p>
<p>That’s because delegation is hard.</p>
<p>“When I’m delegating something, even to a human, I have to think a lot about ‘okay, how can I package this up so that the person will do the right thing?’”</p>
<p>Instead, the better model might be telling your computer to do anything you want. So you’re “telling your computer to do stuff and the agent is a middle layer,” she said.</p>
<p>Such agents will need to be able to interact with people — something often described as “reasoning,” the two observed — and communicate with computers — or “code.”</p>
<p><b>A Vision for Empowerment Through Technology</b></p>
<p>Qiu and Catanzaro — who often completed each other’s sentences during the 45-minute conversation — compared AI’s potential to democratize software creation to the Industrial Revolution’s impact on manufacturing.</p>
<p>The parts needed for a steam engine, for example, once took years to create. Now they can be ordered off the shelf for a small sum.</p>
<p>Both speakers emphasized the importance of creating intuitive interfaces that allow individuals from nontechnical backgrounds to engage with computers more effectively, fostering a more inclusive digital landscape.</p>
<p>That means going beyond coding, which is done in text-heavy environments such as an Integrated Development Environment, or even using text-based chats.</p>
<p>“The interface to agents, a lot of them today, is like a chat interface. It’s not a very good interface, in a lot of ways, very restrictive. And so there are much better ways of working with these systems,” Qiu said.</p>
<p><b>The Future of Personal Computing</b></p>
<p>Qiu and Catanzaro discussed the role that virtual worlds will play in this, and how they could serve as interfaces for human-technology interaction.</p>
<p>“I think it’s pretty clear that AI is going to help build virtual worlds,” said Catanzaro. “I think the maybe more controversial part is virtual worlds are going to be necessary for humans to interact with AI.”</p>
<p>People have an almost primal fear of being displaced, Catanzaro said, but what’s much more likely is that our capabilities will be amplified as the technology fades into the background.</p>
<p>Catanzaro compared it to the adoption of electricity. A century ago, people talked a lot about electricity. Now that it’s ubiquitous, it’s no longer the focus of broader conversations, even as it makes our day-to-day lives better.</p>
<p>“I think of it as really being able to [help us] control information environments &#8230; once we have control over information environments, we’ll feel a lot more empowered,” Qiu said. “Every single person’s vision can come to life.”</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/FiresideChat-KanjunQiu-BryanCatanzaro-2603-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1365"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/FiresideChat-KanjunQiu-BryanCatanzaro-2603-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI’s New Frontier: From Daydreams to Digital Deeds]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Here Be Dragons: ‘Dragon’s Dogma 2’ Comes to GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-dragons-dogma-2/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 21 Mar 2024 13:00:58 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70674</guid>

					<description><![CDATA[Arise for a new adventure with Dragon’s Dogma 2, leading two new titles joining the GeForce NOW library this week. Set Forth, Arisen Time to go on a grand adventure, Arisen! Dragon’s Dogma 2, the long-awaited sequel to Capcom’s legendary action role-playing game, streams this week on GeForce NOW. The game challenges players to choose		<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-dragons-dogma-2/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Arise for a new adventure with <i>Dragon’s Dogma 2</i>, leading two new titles joining the <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> library this week.</p>
<h2><b>Set Forth, Arisen</b></h2>
<figure id="attachment_70678" aria-describedby="caption-attachment-70678" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-70678" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-672x378.jpg" alt="Dragon's Dogma 2" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Dragons_Dogma_2-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70678" class="wp-caption-text"><em>Fulfill a forgotten destiny in “Dragon’s Dogma 2” from Capcom.</em></figcaption></figure>
<p>Time to go on a grand adventure, Arisen!</p>
<p><i>Dragon’s Dogma 2</i>, the long-awaited sequel to Capcom’s legendary action role-playing game, streams this week on GeForce NOW.</p>
<p>The game challenges players to choose their own experience, including their Arisen’s appearance, vocation, party, approaches to different situations and more. Wield swords, bows and magick across an immersive fantasy world full of life and battle. But players won’t be alone. Recruit Pawns — mysterious otherworldly beings — to aid in battle and work with other players’ Pawns to fight the diverse monsters inhabiting the ever-changing lands.</p>
<p>Upgrade to a GeForce NOW Ultimate membership to stream <i>Dragon’s Dogma 2</i> from NVIDIA GeForce RTX 4080 servers in the cloud for the highest performance, even on low-powered devices. Ultimate members also get exclusive access to servers to get right into gaming without waiting for any downloads.</p>
<h2><b>New Games, New Challenges</b></h2>
<figure id="attachment_70681" aria-describedby="caption-attachment-70681" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-70681" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-672x336.jpg" alt="Battlefield 2042 S7 on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/03/GFN_Thursday-Battlefield_2042_S7_Turning_Point.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-70681" class="wp-caption-text"><em>No holding back.</em></figcaption></figure>
<p><i>Battlefield 2042: Season 7 </i>Turning Point is here. Do whatever it takes to battle for Earth’s most valuable resource — water — in a Chilean desert. Deploy on a new map, Haven, focused on suburban combat, and revisit a fan-favorite front: Stadium. Gear up with new hardware like the SCZ-3 SMG or the Predator SRAW, and jump into a battle for ultimate power.</p>
<p>Then, look forward to the following list of games this week:</p>
<ul>
<li><i>Alone in the Dark </i>(New release on <a href="https://store.steampowered.com/app/1310410?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, March 20)</li>
<li><i>Dragon’s Dogma 2 </i>(New release on <a href="https://store.steampowered.com/app/2054970?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, March 21)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">we got that 𝙙𝙤𝙜 in us</p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1770480417872744761?ref_src=twsrc%5Etfw">March 20, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/gfn-thursday-3-21-nv-blog-1280x680-no-copy-1-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/gfn-thursday-3-21-nv-blog-1280x680-no-copy-1-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Here Be Dragons: ‘Dragon’s Dogma 2’ Comes to GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Instant Latte: NVIDIA Gen AI Research Brews 3D Shapes in Under a Second</title>
		<link>https://blogs.nvidia.com/blog/latte-3d-generative-ai-research/</link>
		
		<dc:creator><![CDATA[Isha Salian]]></dc:creator>
		<pubDate>Thu, 21 Mar 2024 13:00:51 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[NVIDIA Research]]></category>
		<category><![CDATA[Synthetic Data Generation]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70638</guid>

					<description><![CDATA[NVIDIA researchers have pumped a double shot of acceleration into their latest text-to-3D generative AI model, dubbed LATTE3D. Like a virtual 3D printer, LATTE3D turns text prompts into 3D representations of objects and animals within a second. Crafted in a popular format used for standard rendering applications, the generated shapes can be easily served up		<a class="read-more" href="https://blogs.nvidia.com/blog/latte-3d-generative-ai-research/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>NVIDIA researchers have pumped a double shot of acceleration into their latest text-to-3D <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> model, dubbed LATTE3D.</p>
<p>Like a virtual 3D printer, <a href="https://research.nvidia.com/labs/toronto-ai/LATTE3D/">LATTE3D</a> turns text prompts into 3D representations of objects and animals within a second.</p>
<p>Crafted in a popular format used for standard rendering applications, the generated shapes can be easily served up in virtual environments for developing video games, ad campaigns, design projects or virtual training grounds for robotics.</p>
<p>“A year ago, it took an hour for AI models to generate 3D visuals of this quality — and the current state of the art is now around 10 to 12 seconds,” said Sanja Fidler, vice president of AI research at NVIDIA, whose Toronto-based AI lab team developed LATTE3D. “We can now produce results an order of magnitude faster, putting near-real-time text-to-3D generation within reach for creators across industries.”</p>
<p>This advancement means that LATTE3D can produce 3D shapes near instantly when running inference on a single GPU, such as the <a href="https://www.nvidia.com/en-us/design-visualization/rtx-a6000/">NVIDIA RTX A6000</a>, which was used for the NVIDIA Research demo.</p>
<p><iframe loading="lazy" title="LATTE3D Text to 3D Generative AI Model from NVIDIA Research" width="500" height="281" src="https://www.youtube.com/embed/yZtSS3980z4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Ideate, Generate, Iterate: Shortening the Cycle</b></h2>
<p>Instead of starting a design from scratch or combing through a 3D asset library, a creator could use LATTE3D to generate detailed objects as quickly as ideas pop into their head.</p>
<p>The model generates a few different 3D shape options based on each text prompt, giving a creator options. Selected objects can be optimized for higher quality within a few minutes. Then, users can export the shape into graphics software applications or platforms such as <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, which enables <a href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description (OpenUSD)</a>-based 3D workflows and applications.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-70649" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-scaled.jpg" alt="" width="2048" height="2048" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-400x400.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-500x500.jpg 500w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-768x768.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-1536x1536.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-450x450.jpg 450w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-215x215.jpg 215w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2024/03/latte3d-collage-1280x1280.jpg 1280w" sizes="(max-width: 2048px) 100vw, 2048px" /></p>
<p>While the researchers trained LATTE3D on two specific datasets — animals and everyday objects — developers could use the same model architecture to train the AI on other data types.</p>
<p>If trained on a dataset of 3D plants, for example, a version of LATTE3D could help a landscape designer quickly fill out a garden rendering with trees, flowering bushes and succulents while brainstorming with a client. If trained on household objects, the model could generate items to fill in 3D simulations of homes, which developers could use to train personal assistant robots before they’re tested and deployed in the real world.</p>
<p>LATTE3D was trained using <a href="https://www.nvidia.com/en-us/data-center/a100/">NVIDIA A100 Tensor Core GPUs</a>. In addition to 3D shapes, the model was trained on diverse text prompts generated using ChatGPT to improve the model’s ability to handle the various phrases a user might come up with to describe a particular 3D object — for example, understanding that prompts featuring various canine species should all generate doglike shapes.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-70646" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs.jpg" alt="" width="1999" height="426" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs.jpg 1999w, https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs-400x85.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs-672x143.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs-768x164.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs-1536x327.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs-842x179.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs-406x87.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs-188x40.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/dogs-1280x273.jpg 1280w" sizes="(max-width: 1999px) 100vw, 1999px" /></p>
<p><a href="https://www.nvidia.com/en-us/research/">NVIDIA Research</a> comprises hundreds of scientists and engineers worldwide, with teams focused on topics including AI, computer graphics, computer vision, self-driving cars and robotics.</p>
<p>Researchers shared work at <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a> this week that advances the state of the art for training diffusion models. Read more <a href="https://developer.nvidia.com/blog/rethinking-how-to-train-diffusion-models/">on the NVIDIA Technical Blog</a>, and see the full list of <a href="https://www.nvidia.com/gtc/sessions/ai-research--thought-leadership/">NVIDIA Research sessions at GTC</a>, running in San Jose, Calif., and online through March 21.</p>
<p><i>For the latest NVIDIA AI news, watch the replay of NVIDIA founder and CEO Jensen Huang’s keynote address at GTC: </i></p>
<p><iframe loading="lazy" title="GTC March 2024 Keynote with NVIDIA CEO Jensen Huang" width="500" height="281" src="https://www.youtube.com/embed/Y2F8yisiS6E?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/Latte3D_turtle_side_by_side.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/Latte3D_turtle_side_by_side-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Instant Latte: NVIDIA Gen AI Research Brews 3D Shapes in Under a Second]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>‘You Transformed the World,’ NVIDIA CEO Tells Researchers Behind Landmark AI Paper</title>
		<link>https://blogs.nvidia.com/blog/gtc-2024-transformer-ai-research-panel-jensen/</link>
		
		<dc:creator><![CDATA[Isha Salian]]></dc:creator>
		<pubDate>Thu, 21 Mar 2024 13:00:45 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70685</guid>

					<description><![CDATA[Of GTC’s 900+ sessions, the most wildly popular was a conversation hosted by NVIDIA founder and CEO Jensen Huang with seven of the authors of the legendary research paper that introduced the aptly named transformer — a neural network architecture that went on to change the deep learning landscape and enable today’s era of generative		<a class="read-more" href="https://blogs.nvidia.com/blog/gtc-2024-transformer-ai-research-panel-jensen/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Of <a href="https://www.nvidia.com/gtc/">GTC</a>’s 900+ sessions, the most wildly popular was a conversation hosted by NVIDIA founder and CEO Jensen Huang with seven of the authors of the legendary research paper that introduced the aptly named <a href="https://blogs.nvidia.com/blog/what-is-a-transformer-model/">transformer</a> — a neural network architecture that went on to change the deep learning landscape and enable today’s era of generative AI.</p>
<p>“Everything that we’re enjoying today can be traced back to that moment,” Huang said to a packed room with hundreds of attendees, who heard him speak with the authors of “<a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention Is All You Need</a>.”</p>
<p>Sharing the stage for the first time, the research luminaries reflected on the factors that led to their original paper, which has been cited more than 100,000 times since it was first published and presented at the NeurIPS AI conference. They also discussed their latest projects and offered insights into future directions for the field of generative AI.</p>
<p>While they started as Google researchers, the collaborators are now spread across the industry, most as founders of their own AI companies.</p>
<p>“We have a whole industry that is grateful for the work that you guys did,” Huang said.</p>
<figure id="attachment_70689" aria-describedby="caption-attachment-70689" style="width: 2048px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-full wp-image-70689" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-scaled.jpg" alt="" width="2048" height="1365" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5071-1280x853.jpg 1280w" sizes="(max-width: 2048px) 100vw, 2048px" /><figcaption id="caption-attachment-70689" class="wp-caption-text">From L to R: Lukasz Kaiser, Noam Shazeer, Aidan Gomez, Jensen Huang, Llion Jones, Jakob Uszkoreit, Ashish Vaswani and Illia Polosukhin.</figcaption></figure>
<h2><b>Origins of the Transformer Model</b></h2>
<p>The research team initially sought to overcome the limitations of <a href="https://blogs.nvidia.com/blog/whats-the-difference-between-a-cnn-and-an-rnn/">recurrent neural networks</a>, or RNNs, which were then the state of the art for processing language data.</p>
<p>Noam Shazeer, cofounder and CEO of Character.AI, compared RNNs to the steam engine and transformers to the improved efficiency of internal combustion.</p>
<p>“We could have done the industrial revolution on the steam engine, but it would just have been a pain,” he said. “Things went way, way better with internal combustion.”</p>
<p>“Now we’re just waiting for the fusion,” quipped Illia Polosukhin, cofounder of blockchain company NEAR Protocol.</p>
<p>The paper’s title came from a realization that attention mechanisms — an element of neural networks that enable them to determine the relationship between different parts of input data — were the most critical component of their model’s performance.</p>
<p>“We had very recently started throwing bits of the model away, just to see how much worse it would get. And to our surprise it started getting better,” said Llion Jones, cofounder and chief technology officer at Sakana AI.</p>
<p>Having a name as general as “transformers” spoke to the team’s ambitions to build AI models that could process and transform every data type — including text, images, audio, tensors and biological data.</p>
<p>“That North Star, it was there on day zero, and so it’s been really exciting and gratifying to watch that come to fruition,” said Aidan Gomez, cofounder and CEO of Cohere. “We’re actually seeing it happen now.”</p>
<figure id="attachment_70692" aria-describedby="caption-attachment-70692" style="width: 2048px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-full wp-image-70692" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-scaled.jpg" alt="" width="2048" height="1365" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-5282-1280x853.jpg 1280w" sizes="(max-width: 2048px) 100vw, 2048px" /><figcaption id="caption-attachment-70692" class="wp-caption-text">Packed house at the San Jose Convention Center.</figcaption></figure>
<h2><b>Envisioning the Road Ahead </b></h2>
<p>Adaptive computation, where a model adjusts how much computing power is used based on the complexity of a given problem, is a key factor the researchers see improving in future AI models.</p>
<p>“It’s really about spending the right amount of effort and ultimately energy on a given problem,” said Jakob Uszkoreit, cofounder and CEO of biological software company Inceptive. “You don’t want to spend too much on a problem that’s easy or too little on a problem that’s hard.”</p>
<p>A math problem like two plus two, for example, shouldn’t be run through a trillion-parameter transformer model — it should run on a basic calculator, the group agreed.</p>
<p>They’re also looking forward to the next generation of AI models.</p>
<p>“I think the world needs something better than the transformer,” said Gomez. “I think all of us here hope it gets succeeded by something that will carry us to a new plateau of performance.”</p>
<p>“You don’t want to miss these next 10 years,” Huang said. “Unbelievable new capabilities will be invented.”</p>
<p>The conversation concluded with Huang presenting each researcher with a framed cover plate of the <a href="https://www.nvidia.com/en-gb/data-center/dgx-systems/dgx-1/">NVIDIA DGX-1</a> AI supercomputer, signed with the message, “You transformed the world.”</p>
<figure id="attachment_70695" aria-describedby="caption-attachment-70695" style="width: 2048px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-70695 size-full" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-scaled.jpg" alt="" width="2048" height="1365" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-1536x1024.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-323x215.jpg 323w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6840-1280x853.jpg 1280w" sizes="(max-width: 2048px) 100vw, 2048px" /><figcaption id="caption-attachment-70695" class="wp-caption-text">Jensen presents lead author Ashish Vaswani with a signed DGX-1 cover.</figcaption></figure>
<p>There’s still time to catch the <a href="https://www.nvidia.com/gtc/session-catalog/?search=S63046&amp;tab.allsessions=1700692987788001F1cG">session replay</a> by registering for a <a href="https://www.nvidia.com/gtc/pricing/">virtual GTC pass</a> — it’s free.</p>
<p>To discover the latest in generative AI, watch Huang’s GTC keynote address:</p>
<p><iframe loading="lazy" title="GTC March 2024 Keynote with NVIDIA CEO Jensen Huang" width="500" height="281" src="https://www.youtube.com/embed/Y2F8yisiS6E?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6747_blogcrop.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/JHH-Ai-Panel-6747_blogcrop-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[‘You Transformed the World,’ NVIDIA CEO Tells Researchers Behind Landmark AI Paper]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI Decoded From GTC: The Latest Developer Tools and Apps Accelerating AI on PC and Workstation</title>
		<link>https://blogs.nvidia.com/blog/ai-decoded-gtc-chatrtx-workbench-nim/</link>
		
		<dc:creator><![CDATA[Jesse Clayton]]></dc:creator>
		<pubDate>Wed, 20 Mar 2024 13:00:02 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[AI Decoded]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[RTX Mobile Workstations]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70653</guid>

					<description><![CDATA[NVIDIA’s RTX AI platform includes tools and software development kits that help Windows developers create cutting-edge generative AI features to deliver the best performance on AI PCs and workstations.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of the </i><a href="https://blogs.nvidia.com/blog/tag/ai-decoded/"><i>AI Decoded series</i></a><i>, which demystifies AI by making the technology more accessible, and which showcases new hardware, software, tools and accelerations for RTX PC users.</i></p>
<p>NVIDIA’s RTX AI platform includes tools and software development kits that help Windows developers create cutting-edge generative AI features to deliver the best performance on AI PCs and workstations.</p>
<p>At GTC — NVIDIA’s annual technology conference — a dream team of industry luminaries, developers and researchers have come together to learn from one another, fueling what’s next in AI and accelerated computing.</p>
<p>This special edition of AI Decoded from GTC spotlights the best AI tools currently available and looks at what’s ahead for the 100 million RTX PC and workstation users and developers.</p>
<p><a href="https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/">Chat with RTX</a>, the tech demo and developer reference project that quickly and easily allows users to connect a powerful LLM to their own data, showcased new capabilities and new models in the GTC exhibit hall.</p>
<p>The winners of the <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/rtx-developer-contest/winners/">Gen AI on RTX PCs contest</a> were announced Monday. OutlookLLM, Rocket League BotChat and CLARA were highlighted in one of the AI Decoded talks in the <a href="https://www.nvidia.com/gtc/exhibits/#:~:text=Generative%20AI%20Theater">generative AI theater</a> and each are accelerated by <a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-supercharges-large-language-model-inference-on-nvidia-h100-gpus/">NVIDIA TensorRT-LLM</a>. Two other AI Decoded talks included using generative AI in content creation and a deep dive on Chat with RTX.</p>
<p>Developer frameworks and interfaces with TensorRT-LLM integration continue to grow as Jan.ai, Langchain, LlamaIndex and Oobabooga will all soon be accelerated — helping to grow the already more than 500 AI applications for RTX PCs and workstations.</p>
<p>NVIDIA NIM microservices are coming to RTX PCs and workstations. They provide pre-built containers, with industry standard APIs, enabling developers to accelerate deployment on RTX PCs and workstations. <a href="https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/workbench/">NVIDIA AI Workbench</a>, an easy-to-use developer toolkit to manage AI model customization and optimization workflows, is now generally available for RTX developers.</p>
<p>These ecosystem integrations and tools will accelerate development of new Windows apps and features. And today’s contest winners are an inspiring glimpse into what that content will look like.</p>
<h2><b>Hear More, See More, Chat More</b></h2>
<p>Chat with RTX, or ChatRTX for short, uses <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">retrieval-augmented generation</a>, NVIDIA TensorRT-LLM software and NVIDIA RTX acceleration to bring local generative AI capabilities to RTX-powered Windows systems. Users can quickly and easily connect local files as a dataset to an open large language model like Mistral or Llama 2, enabling queries for quick, contextually relevant answers.</p>
<p><iframe loading="lazy" title="Create A Personalized AI Chatbot with ChatRTX" width="500" height="281" src="https://www.youtube.com/embed/fc_NSAu41b0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Moving beyond text, ChatRTX will soon add support for voice, images and new models.</p>
<p>Users will be able to talk to ChatRTX with Whisper — an automatic speech recognition system that uses AI to process spoken language. When the feature becomes available, ChatRTX will be able to “understand” spoken language, and provide text responses.</p>
<p>A future update will also add support for photos. By integrating OpenAI’s CLIP — Contrastive Language-Image Pre-training — users will be able to search by words, terms or phrases to find photos in their private library.</p>
<p>In addition to Google’s Gemma, ChatGLM will get support in a future update.</p>
<p>Developers can start with the latest version of the <a href="https://github.com/NVIDIA/trt-llm-rag-windows">developer reference project on GitHub</a>.</p>
<h2><b>Generative AI for the Win</b></h2>
<p>The <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/rtx-developer-contest/">NVIDIA Generative AI on NVIDIA RTX developer contest</a> prompted developers to build a Windows app or plug-in.</p>
<div class="simplePullQuote right"><p>“I found that playing against bots that react to game events with in-game messages in near real time adds a new level of entertainment to the game, and I’m excited to share my approach to incorporating AI into gaming as a participant in this developer contest. The target audience for my project is anyone who plays <i>Rocket League</i> with RTX hardware.” — <a href="https://briancaffey.github.io/2024/02/17/rocket-league-botchat-nvidia-generative-ai-on-rtx-pcs-developer-contest/">Brian Caffey</a>, Rocket League BotChat developer</p>
</div>
<p>Submissions were judged on three criteria, including a short demo video posted to social media, relative impact and ease of use of the project, and how effectively NVIDIA’s technology stack was used in the project. <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/rtx-developer-contest/winners/">Each of the three winners</a> received a pass to GTC, including a spot in the NVIDIA Deep Learning Institute GenAI/LLM courses, and a GeForce RTX 4090 GPU to power future development work.</p>
<p><a href="https://github.com/fgblanch/OutlookLLM">OutlookLLM</a> gives Outlook users generative AI features — such as email composition — securely and privately in their email client on RTX PCs and workstations. It uses a local LLM served via TensorRT-LLM.</p>
<p><a href="https://github.com/briancaffey/RocketLeagueBotChat">Rocket League BotChat</a>, for the popular <i>Rocket League</i> game, is a plug-in that allows bots to send contextual in-game chat messages based on a log of game events, such as scoring a goal or making a save. Designed to be used only in offline games against bot players, the plug-in is configurable in many ways via its settings menu.</p>
<p><a href="https://github.com/0xMatthew/CLARA">CLARA</a> (short for Command Line Assistant with RTX Acceleration) is designed to enhance the command line interface of PowerShell by translating plain English instructions into actionable commands. The extension runs locally, quickly and keeps users in their PowerShell context. Once it’s enabled, users type their English instructions and press the tab button to invoke CLARA. Installation is straightforward, and there are options for both script-based and manual setup.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr"><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f389.png" alt="🎉" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Congratulations to the <a href="https://twitter.com/hashtag/GenAIonRTX?src=hash&amp;ref_src=twsrc%5Etfw">#GenAIonRTX</a> <a href="https://twitter.com/hashtag/DevContest?src=hash&amp;ref_src=twsrc%5Etfw">#DevContest</a> winners:</p>
<p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f3c6.png" alt="🏆" class="wp-smiley" style="height: 1em; max-height: 1em;" /> CLARA &#8211; Talk with computers in human language &#8211; Matthew Yaeger<br /><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f3c6.png" alt="🏆" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Rocket League BotChat &#8211; Generate in-game chat messages &#8211; Brian Caffey<br /><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f3c6.png" alt="🏆" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Outlook LLM &#8211; Compose emails securely with AI &#8211; Francisco Gonzalez Blanch</p>
<p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f447.png" alt="👇" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="https://t.co/i52w5Pn1n9">pic.twitter.com/i52w5Pn1n9</a></p>
<p>&mdash; NVIDIA AI Developer (@NVIDIAAIDev) <a href="https://twitter.com/NVIDIAAIDev/status/1770125161242493200?ref_src=twsrc%5Etfw">March 19, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<h2><b>From the Generative AI Theater</b></h2>
<p>GTC attendees can attend three AI Decoded talks on Wednesday, March 20 at the generative AI theater. These 15-minute sessions will guide the audience through ChatRTX and how developers can productize their own personalized chatbot; how each of the three contest winners’ showed some of the possibilities for generative AI apps on RTX systems; and a celebration of artists, the tools and methods they use powered by NVIDIA technology.</p>
<p>In the creator session, Lee Fraser, senior developer relations manager for generative AI media and entertainment at NVIDIA, will explore why generative AI has become so popular. He’ll show off new workflows and how creators can rapidly explore ideas. Artists to be featured include Steve Talkowski, Sophia Crespo, Lim Wenhui, Erik Paynter, Vanessa Rosa and Refik Anadol.</p>
<p>Anadol also has an installation at the show that combines data visualization and imagery based on that data.</p>
<h1><b>Ecosystem of Acceleration</b></h1>
<p>Top creative app developers, like Blackmagic Design and Topaz Labs have integrated RTX AI acceleration in their software. TensorRT doubles the speed of AI effects like rotoscoping, denoising, super-resolution and video stabilization in the DaVinci Resolve and Topaz apps.</p>
<p>“Blackmagic Design and NVIDIA’s ongoing collaborations to run AI models on RTX AI PCs will produce a new wave of groundbreaking features that give users the power to create captivating and immersive content, faster.” — Rohit Gupta, director of software development at Blackmagic Design</p>
<p><iframe loading="lazy" title="Faster Video Editing Using NVIDIA RTX GPUs &amp; AI (DaVinci Resolve)" width="500" height="281" src="https://www.youtube.com/embed/KxBXwa3rYpU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>TensorRT-LLM is being integrated with popular developer frameworks and ecosystems such as LangChain, LlamaIndex, Oobabooga and Jan.AI. Developers and enthusiasts can easily access the performance benefits of TensorRT-LLM through top LLM frameworks to build and deploy generative AI apps to both local and cloud GPUs.</p>
<p>Enthusiasts can also try out their favorite LLMs — accelerated with TensorRT-LLM on RTX systems — through the Oobabooga and Jan.AI chat interfaces.</p>
<h2><b>AI That’s NIMble, AI That’s Quick</b></h2>
<p>Developers and tinkerers can tap into NIM microservices. These pre-built AI “containers,” with industry-standard APIs, provide an optimized solution that helps to reduce deployment times from weeks to minutes. They can be used with more than two dozen popular models from NVIDIA, Getty Images, Google, Meta, Microsoft, Shutterstock and more.</p>
<p>NVIDIA AI Workbench is now generally available, helping developers quickly create, test and customize pretrained generative AI models and LLMs on RTX GPUs. It offers streamlined access to popular repositories like Hugging Face, GitHub and <a href="https://catalog.ngc.nvidia.com/">NVIDIA NGC</a>, along with a simplified user interface that enables developers to easily reproduce, collaborate on and migrate projects.</p>
<p>Projects can be easily scaled up when additional performance is needed — whether to the data center, a public cloud or <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a> — and then brought back to local RTX systems on a PC or workstation for inference and light customization. AI Workbench is a free download and provides example projects to help developers get started quickly.</p>
<p>These tools, and many others announced and shown at GTC, are helping developers drive innovative AI solutions.</p>
<p>From the Blackwell platform’s arrival, to a digital twin for Earth’s climate, it’s been a GTC to remember. For RTX PC and workstation users and developers, it was also a glimpse into what’s next for generative AI.</p>
<p><i>See </i><a href="https://www.nvidia.com/en-us/about-nvidia/legal-info/"><i>notice</i></a><i> regarding software product information.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/ai-decoded-week-3-nv-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/ai-decoded-week-3-nv-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI Decoded From GTC: The Latest Developer Tools and Apps Accelerating AI on PC and Workstation]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Secure by Design: NVIDIA AIOps Partner Ecosystem Blends AI for Businesses</title>
		<link>https://blogs.nvidia.com/blog/aiops-partners-gtc-2024/</link>
		
		<dc:creator><![CDATA[Michael Balint]]></dc:creator>
		<pubDate>Tue, 19 Mar 2024 16:33:43 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cybersecurity]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70624</guid>

					<description><![CDATA[In today’s complex business environments, IT teams face a constant flow of challenges, from simple issues like employee account lockouts to critical security threats. These situations demand both quick fixes and strategic defenses, making the job of maintaining smooth and secure operations ever tougher. That’s where AIOps comes in, blending artificial intelligence with IT operations		<a class="read-more" href="https://blogs.nvidia.com/blog/aiops-partners-gtc-2024/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>In today’s complex business environments, IT teams face a constant flow of challenges, from simple issues like employee account lockouts to critical security threats. These situations demand both quick fixes and strategic defenses, making the job of maintaining smooth and secure operations ever tougher.</p>
<p>That’s where AIOps comes in, blending artificial intelligence with IT operations to not only automate routine tasks, but also enhance security measures. This efficient approach allows teams to quickly deal with minor issues and, more importantly, to identify and respond to security threats faster and with greater accuracy than before.</p>
<p>By using machine learning, AIOps becomes a crucial tool in not just streamlining operations but also in strengthening security across the board. It’s proving to be a game-changer for businesses looking to integrate advanced AI into their teams, helping them stay a step ahead of potential security risks.</p>
<p>According to <a href="https://www.idc.com/getdoc.jsp?containerId=US51160523&amp;pageType=PRINTFRIENDLY">IDC</a>, the IT operations management software market is expected to grow at a rate of 10.3% annually, reaching a projected revenue of $28.4 billion by 2027. This growth underscores the increasing reliance on AIOps for operational efficiency and as a critical component of modern cybersecurity strategies.</p>
<p>As the rapid growth of machine learning operations continues to transform the era of generative AI, a broad ecosystem of NVIDIA partners are offering AIOps solutions that leverage NVIDIA AI to improve IT operations.</p>
<p>NVIDIA is helping a broad ecosystem of AIOps partners with accelerated compute and AI software. This includes <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a>, a cloud-native stack that can run anywhere and provides a basis for AIOps through software like NVIDIA NIM for accelerated inference of AI modes, <a href="https://developer.nvidia.com/morpheus-cybersecurity">NVIDIA Morpheus</a> for AI-based cybersecurity and <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/">NVIDIA NeMo</a> for custom generative AI. This software facilitates GenAI-based chatbot, summarization and search functionality.</p>
<p>AIOps providers using NVIDIA AI include:</p>
<ul>
<li>
<p class="x_MsoNormal"><strong>Dynatrace</strong> <a title="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.dynatrace.com%2Fplatform%2Fartificial-intelligence%2F&amp;data=05%7C02%7Ckyee%40nvidia.com%7Ce4328bc6511f4bcff98b08dc4838e462%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638464656432041971%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=YLynb7v2FCfwP3vtxEY%2BIxjt10zG8NRVjk0O617lj2U%3D&amp;reserved=0" href="https://www.dynatrace.com/platform/artificial-intelligence/" data-outlook-id="a9a7bdfc-c629-4e03-8303-21af2b8f0843">Davis hypermodal AI</a> advances AIOps by integrating causal, predictive and generative AI techniques with the addition of Davis CoPilot. This combination enhances observability and security across IT, development, security and business operations by offering precise and actionable, AI-driven answers and automation.</p>
</li>
<li><b>Elastic</b> offers <a href="https://www.elastic.co/elasticsearch/elasticsearch-relevance-engine">Elasticsearch Relevance Engine (ESRE)</a> for semantic and vector search, which integrates with popular LLMs like GPT-4 to power AI Assistants in their Observability and Security solutions. The Observability AI Assistant is a next-generation AI Ops capability that helps IT teams understand complex systems, monitor health and automate remediation of operational issues<b>.</b></li>
<li><b>New Relic</b> is advancing AIOps by leveraging its <a href="https://newrelic.com/platform/applied-intelligence">machine learning</a>,<a href="https://newrelic.com/platform/new-relic-ai"> generative AI assistant frameworks</a> and longstanding expertise in observability. Its machine learning and advanced logic helps IT teams reduce alerting noise, improve mean time to detect and mean time to repair, automate root cause analysis and generate retrospectives. Its GenAI assistant, New Relic AI, accelerates issue resolution by allowing users to identify, explain and resolve errors without switching contexts, and suggests and applies code fixes directly in a developer’s integrated development environment. It also extends incident visibility and prevention to non-technical teams by automatically producing high-level system health reports, analyzing and summarizing dashboards and answering plain-language questions about a user’s applications, infrastructure and services. New Relic also provides full-stack observability for AI-powered applications benefitting from NVIDIA GPUs.</li>
<li><b>PagerDuty</b> has introduced a new feature in <a href="https://www.pagerduty.com/platform/generative-ai/">PagerDuty Copilot</a>, integrating a generative AI assistant within Slack to offer insights from incident start to resolution, streamlining the incident lifecycle and reducing manual task loads for IT teams.</li>
<li><b>ServiceNow</b>’s <a href="https://www.servicenow.com/products/predictive-aiops.html">commitment to creating a proactive IT operations</a> encompasses automating insights for rapid incident response, optimizing service management and detecting anomalies. Now, in collaboration with NVIDIA, it is pushing into generative AI to further innovate technology service and operations.</li>
<li><b>Splunk’s</b> technology platform<a href="https://www.splunk.com/en_us/solutions/splunk-artificial-intelligence.html"> applies artificial intelligence and machine learning</a> to automate the processes of identifying, diagnosing and resolving operational issues and threats, thereby enhancing IT efficiency and security posture. Splunk<a href="https://www.splunk.com/en_us/products/it-service-intelligence.html"> IT Service Intelligence</a> serves as Splunk’s primary AIOps offering, providing embedded AI-driven incident prediction, detection and resolution all from one place.</li>
</ul>
<p>Cloud service providers including Amazon Web Services (AWS), Google Cloud and Microsoft Azure enable organizations to automate and optimize their IT operations, leveraging the scale and flexibility of cloud resources.</p>
<ul>
<li><b>AWS</b> offers a suite of services conducive to AIOps, including Amazon CloudWatch for monitoring and observability; AWS CloudTrail for tracking user activity and API usage; Amazon SageMaker for creating repeatable and responsible machine learning workflows; and AWS Lambda for serverless computing, allowing for the automation of response actions based on triggers.</li>
<li><b>Google Cloud</b> supports AIOps through services like Google Cloud Operations, which provides monitoring, logging and diagnostics across applications on the cloud and on-premises. Google Cloud’s AI and machine learning products include Vertex AI for model training and prediction and BigQuery for fast SQL queries using the processing power of Google’s infrastructure.</li>
<li><b>Microsoft Azure</b> facilitates AIOps with Azure Monitor for comprehensive monitoring of applications, services and infrastructure. Azure Monitor’s built-in AIOps capabilities help predict capacity usage, enable autoscaling, identify application performance issues and detect anomalous behaviors in virtual machines, containers and other resources. Microsoft Azure Machine Learning (AzureML) offers a cloud-based MLOps environment for training, deploying and managing machine learning models responsibly, securely and at scale.</li>
</ul>
<p>Platforms specializing in MLOps primarily focus on streamlining the lifecycle of machine learning models, from development to deployment and monitoring. While the core mission centers on making machine learning more accessible, efficient and scalable, their technologies and methodologies indirectly support AIOps by enhancing AI capabilities within IT operations: <b></b></p>
<ul>
<li><b>Anyscale’s </b>platform, based on Ray, allows for the easy scaling of AI and machine learning applications, including those used in AIOps for tasks like anomaly detection and automated remediation. By facilitating distributed computing, Anyscale helps AIOps systems process large volumes of operational data more efficiently, enabling real-time analytics and decision-making.</li>
<li><b>Dataiku</b> can be used to create models that predict IT system failures or optimize resource allocation, with features that allow IT teams to quickly deploy and iterate on these models in production environments.</li>
<li><b>Dataloop’s</b> platform delivers full data lifecycle management and a flexible way to plug in AI models for an end-to-end workflow, allowing users to develop AI applications using their data.</li>
<li><b>DataRobot</b> is a full AI lifecycle platform that enables IT operations teams to rapidly build, deploy and govern AI solutions, improving operational efficiency and performance.</li>
<li><b>Domino Data Lab’s</b> platform lets enterprises and their data scientists build, deploy and manage AI on a unified, end-to-end platform. Data, tools, compute, models and projects across all environments are centrally managed so teams can collaborate, monitor production models and standardize best practices for governed AI innovation. This approach is vital for AIOps as it balances the self-service needed by data science teams with complete reproducibility, granular cost tracking and proactive governance for IT operational needs.</li>
<li><b>Weights &amp; Biases</b> provides tools for experiment tracking, model optimization, and collaboration, crucial for developing and fine-tuning AI models used in AIOps. By offering detailed insights into model performance and facilitating collaboration across teams, Weights &amp; Biases helps ensure that AI models deployed for IT operations are both effective and transparent.</li>
</ul>
<p>Learn more about NVIDIA’s partner ecosystem and their work at <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/aiops-corp-blog-1280x680-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/aiops-corp-blog-1280x680-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Secure by Design: NVIDIA AIOps Partner Ecosystem Blends AI for Businesses]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Climate Pioneers: 3 Startups Harnessing NVIDIA’s AI and Earth-2 Platforms</title>
		<link>https://blogs.nvidia.com/blog/climate-startups-ai-earth-2/</link>
		
		<dc:creator><![CDATA[Tenika Versey Walker]]></dc:creator>
		<pubDate>Tue, 19 Mar 2024 16:00:13 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Climate]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[NVIDIA Modulus]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Scientific Visualization]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70597</guid>

					<description><![CDATA[To help mitigate climate change — one of humanity’s greatest challenges — researchers are turning to AI and sustainable computing to accelerate and operationalize their work. At this week’s NVIDIA GTC global AI conference, startups, enterprises and scientists are highlighting their environmental sustainability initiatives and latest climate innovations. Many are using NVIDIA Earth-2, a full-stack,		<a class="read-more" href="https://blogs.nvidia.com/blog/climate-startups-ai-earth-2/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>To help mitigate climate change — one of humanity’s greatest challenges — researchers are turning to AI and <a href="https://blogs.nvidia.com/blog/what-is-green-computing/" target="_blank" rel="noopener">sustainable computing</a> to accelerate and operationalize their work.</p>
<p>At this week’s <a href="https://www.nvidia.com/gtc/" target="_blank" rel="noopener">NVIDIA GTC</a> global AI conference, startups, enterprises and scientists are highlighting their environmental sustainability initiatives and latest climate innovations. Many are using <a href="https://www.nvidia.com/en-us/high-performance-computing/earth-2/" target="_blank" rel="noopener">NVIDIA Earth-2</a>, a full-stack, open platform for accelerating climate and weather simulation and predictions.</p>
<p>Earth-2 comprises GPU-accelerated numerical weather and climate prediction models, including ICON and IFS; state-of-the-art AI-driven weather models, such as FourCastNet, GraphCast and Deep Learning Weather Prediction, offered through the <a href="https://developer.nvidia.com/modulus" target="_blank" rel="noopener">NVIDIA Modulus</a> framework; and large-scale, interactive, high-resolution data visualization and simulation enabled by the <a href="https://www.nvidia.com/en-us/omniverse/" target="_blank" rel="noopener">NVIDIA Omniverse</a> platform. These capabilities are also available via cloud APIs, or application programming interfaces.</p>
<p>Various members of <a href="https://www.nvidia.com/en-us/startups/" target="_blank" rel="noopener">NVIDIA Inception</a> — a free, global program for cutting-edge startups — are pioneering climate AI advancements with Earth-2. It’s critical work, as extreme-weather events are <a href="https://authors.library.caltech.edu/records/k959a-53q45" target="_blank" rel="noopener">expected</a> to take a million lives and cost $1.7 trillion per year by 2050.</p>
<h2><b>Tomorrow.io Powers Weather Predictions of Tomorrow</b></h2>
<p><img loading="lazy" decoding="async" class="alignright size-full wp-image-70604" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/tomorrow.io_.jpeg" alt="" width="512" height="358" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/tomorrow.io_.jpeg 512w, https://blogs.nvidia.com/wp-content/uploads/2024/03/tomorrow.io_-400x280.jpeg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/tomorrow.io_-307x215.jpeg 307w, https://blogs.nvidia.com/wp-content/uploads/2024/03/tomorrow.io_-143x100.jpeg 143w" sizes="(max-width: 512px) 100vw, 512px" /></p>
<p>Boston-based <a href="http://tomorrow.io" target="_blank" rel="noopener">Tomorrow.io</a> provides actionable, weather-related insights to countries, businesses and individuals by applying advanced AI and machine learning models to a proprietary global dataset collected from satellites, radar and other sensors. Its weather intelligence and climate adaptation platform delivers high-resolution, accurate weather forecasts across time zones for both short- and long-term projections.</p>
<p>The startup is using Earth-2 to study the potential impacts of its suite of satellites on global model forecasts. By conducting observing-system simulation experiments, or OSSEs, with Earth-2 AI forecast models, Tomorrow.io can identify the optimal configurations of satellites and other instruments to improve weather-forecasting conditions. The work ultimately aims to offer users precision and simplicity, helping them easily understand complex weather situations and make the right operational decisions at the right time.</p>
<p>Learn more about Tomorrow.io’s work with Earth-2 by joining the GTC session, “<a href="https://www.nvidia.com/gtc/session-catalog/?search=tenika&amp;tab.allsessions=1700692987788001F1cG&amp;search=tenika#/session/1696445353484001C0A2" target="_blank" rel="noopener">Global Strategies: Startups, Venture Capital, and Climate Change Solutions</a>,” taking place today, March 19, at 3 p.m. PT, at the San Jose Convention Center and online.</p>
<h2><b>ClimaSens Advances Flood-Risk Management With AI</b></h2>
<p><a href="https://climasens.com/" target="_blank" rel="noopener">ClimaSens</a>, based in Melbourne, Australia, and New York, fuses historical, real-time and future climate and weather information using advanced AI models. FloodSens, its upcoming flood risk analysis model, informs clients about the probability of flooding from rainfall, offering high-resolution assessments of flash flooding, riverine flooding and all types of flooding in between.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-large wp-image-70607" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-672x210.png" alt="" width="672" height="210" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-672x210.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-400x125.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-768x240.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-1536x480.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-842x263.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-406x127.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-188x59.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/03/FloodSens-1280x400.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></p>
<p>FloodSens, now in beta, was developed using Earth-2 APIs and the FourCastNet model for high-fidelity, physically accurate representations of future weather conditions, as well as an ensemble of other models for assessing the probabilities of low-likelihood, high-impact flooding events. Through this work, the startup aims to enable a more resilient, sustainable future for communities worldwide.</p>
<h2><b>North.io Garners Ocean Insights With AI and Accelerated Modeling</b></h2>
<p><img loading="lazy" decoding="async" class="alignright size-full wp-image-70611" src="https://blogs.nvidia.com/wp-content/uploads/2024/03/north.io_.jpeg" alt="" width="512" height="288" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/03/north.io_.jpeg 512w, https://blogs.nvidia.com/wp-content/uploads/2024/03/north.io_-400x225.jpeg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/03/north.io_-382x215.jpeg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/03/north.io_-178x100.jpeg 178w" sizes="(max-width: 512px) 100vw, 512px" />Based in Kiel, Germany, <a href="http://north.io" target="_blank" rel="noopener">north.io</a> is helping to map the Earth’s largest carbon sink: oceans. Only about 25% of the ocean floor — a critical source of the world’s renewable energy and food security — has been mapped so far.</p>
<p>North.io is collecting and analyzing massive amounts of data from autonomous underwater vehicles (AUVs) and making it accessible, shareable, visualizable and understandable for users across the globe through its TrueOcean platform.</p>
<p>Using Earth-2 APIs, north.io is developing AI weather forecasts for intelligent operational planning, system management and risk assessment for its AUVs. The combination of high-precision weather modeling and the use of autonomous systems drastically reduces human safety risks in rough, offshore environments.</p>
<p><i>Learn more about the latest AI, </i><a href="https://www.nvidia.com/gtc/sessions/hpc/" target="_blank" rel="noopener"><i>high performance computing</i></a><i> and </i><a href="https://www.nvidia.com/gtc/sessions/sustainable-computing/" target="_blank" rel="noopener"><i>sustainable computing</i></a><i> advancements for climate research at GTC, running through Thursday, March 21.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/earth-2-startups-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/03/earth-2-startups-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Climate Pioneers: 3 Startups Harnessing NVIDIA’s AI and Earth-2 Platforms]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Celebrates Americas Partners Driving AI-Powered Transformation</title>
		<link>https://blogs.nvidia.com/blog/nvidia-partner-network-npn-awards-2024/</link>
		
		<dc:creator><![CDATA[Craig Weinstein]]></dc:creator>
		<pubDate>Tue, 19 Mar 2024 15:00:03 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=70621</guid>

					<description><![CDATA[NVIDIA recognized 14 partners in the Americas for their achievements in transforming businesses with AI, this week at GTC. The winners of the NVIDIA Partner Network Americas Partner of the Year awards have helped customers across industries advance their operations with the software, systems and services needed to integrate AI into their businesses. NPN awards		<a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-partner-network-npn-awards-2024/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>NVIDIA recognized 14 partners in the Americas for their achievements in transforming businesses with AI, this week at <a href="https://www.nvidia.com/gtc/">GTC</a>.</p>
<p>The winners of the <a href="https://www.nvidia.com/en-us/about-nvidia/partners/">NVIDIA Partner Network</a> Americas Partner of the Year awards have helped customers across industries advance their operations with the software, systems and services needed to integrate AI into their businesses.</p>
<p>NPN awards categories span a multitude of competencies and industries, including service delivery, data center networking, public sector, healthcare and higher education.</p>
<p>Three new categories were created this year. One recognizes a partner driving AI-powered success in the financial services industry; one celebrates a partner exhibiting overall AI excellence; and another honors a partner’s dedication to advancing NVIDIA’s full-stack portfolio across a multitude of industries.</p>
<p>All awards reflect the spirit of the NPN ecosystem in driving business success through accelerated full-stack computing and software.</p>
<p>“NVIDIA’s work driving innovation in generative AI has helped partners empower their customers with cutting-edge technology — as well reduced costs and fostered growth opportunities while solving intricate business challenges,” said Rob Enderle, president and principal analyst at the Enderle Group. “The recipients of the 2024 NPN awards embody a diverse array of AI expertise, offering rich knowledge to help customers deploy transformative solutions across industries.”</p>
<p>The 2024 NPN award winners for the Americas are:</p>
<ul>
<li><b>AI Excellence Partner of the Year </b>— <a href="https://lambdalabs.com/blog/lambda-selected-as-2024-nvidia-partner-network-ai-excellence-partner-of-the-year">Lambda</a> received this award for its dedication to providing end-to-end AI solutions featuring NVIDIA accelerated computing and <a href="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.nvidia.com%2Fen-us%2Fdata-center%2Fproducts%2Fai-enterprise%2F&amp;data=05%7C02%7Cpfox%40nvidia.com%7Ccbecb31fb679424fadac08dc396b3015%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638448379745806343%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=u%2BO8WhrVvhtQkP%2BY9RtsErHoavYXnxjUhSeV7yzwYew%3D&amp;reserved=0">NVIDIA AI Enterprise</a> across <a href="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.nvidia.com%2Fen-us%2Fdata-center%2Fdgx-platform%2F&amp;data=05%7C02%7Cpfox%40nvidia.com%7Ccbecb31fb679424fadac08dc396b3015%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638448379745822830%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=FhLA50UmnmAe758yM1opSLX3wk4ltUUWdZRNXyOu8hg%3D&amp;reserved=0">NVIDIA DGX</a> and <a href="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Flambdalabs.com%2F&amp;data=05%7C02%7Cpfox%40nvidia.com%7Ccbecb31fb679424fadac08dc396b3015%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638448379745836001%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=2whFijjHbYNxNXKKBgK%2FzW5ED0XeQIJl5XPDYkqpFzI%3D&amp;reserved=0">Lambda Cloud</a>.</li>
<li><b>Enterprise Partner of the Year </b>— <a href="https://www.wwt.com/press-release/world-wide-technology-named-ai-enterprise-partner-of-the-year">World Wide Technology</a> received this newly introduced award for its leadership, dedication and expertise in advancing the adoption of AI with NVIDIA’s portfolio of purpose-built systems, data center networking, software and accelerated computing solutions across machine learning, digital twins, <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> and visualization.</li>
<li><b>Canadian Partner of the Year </b>— <a href="https://convergetp.com/2024/03/19/converge-technology-solutions-awarded-2024-nvidia-networking-partner-of-the-year-and-canadian-partner-of-the-year/">Converge Technology Solutions</a> is recognized for its dedication and expertise in NVIDIA DGX systems and for its Canadian customer support services, leveraging training courses from NVIDIA, to further industry knowledge of the NVIDIA software stack.</li>
<li><b>Financial Services Partner of the Year</b> — <a href="https://www.cdw.com/content/cdw/en/newsroom/articles/awards/2024/03/19/cdw-named-nvidia-partner-network-financial-services-partner-of-the-year.html">CDW</a> received this newly introduced award for its ecosystem partnerships, strategic investments and targeted domain expertise serving financial customers seeking HPC solutions and customer experience solutions such as chatbots and agentless routing.</li>
<li><b>Global Consulting Partner of the Year </b>— <a href="https://www2.deloitte.com/us/en/pages/about-deloitte/articles/press-releases/deloitte-named-nvidia-partner-network-global-consulting-partner-of-the-year-for-the-fourth-consecutive-year.html">Deloitte</a> is recognized for the fourth consecutive time for its embrace of generative AI and for leveraging the capabilities of <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a>.</li>
<li><b>Healthcare Partner of the Year </b>— <a href="https://www.markiiisys.com/blog/mark-iii-recognized-as-2024-nvidia-partner-network-americas-healthcare-partner-of-the-">Mark III </a>is recognized for the second consecutive year for its utilization for the NVIDIA healthcare portfolio, which supports biopharma research, academic medical centers, research institutions, healthcare systems and life sciences organizations with NVIDIA infrastructure, software and cloud technologies.</li>
<li><b>Higher Education Partner of the Year </b>— <a href="https://www.cambridgecomputer.com/partner-of-the-year-2024/">Cambridge Computer</a> is recognized for the fourth consecutive year for its customer service and technical expertise, bringing NVIDIA AI solutions to the life sciences, education and research sectors.</li>
<li><b>Networking Partner of the Year </b>— Converge Technology Solutions is recognized for its expertise in <a href="https://www.nvidia.com/en-us/networking/">NVIDIA high-performance networking</a> solutions to support state-of-the-art accelerated computing deployments.</li>
<li><b>Public Sector Partner of the Year </b>— <a href="https://sterling.com/sterling-named-nvidia-partner-network-public-sector-partner-of-the-year">Sterling</a> is recognized for its investment and achievements in developing a robust AI practice. This includes assembling a team of dedicated AI software engineers focused on the full-stack NVIDIA platform, establishing Sterling Labs — an AI briefing center near Washington, D.C. — and collaborating with NVIDIA to launch ARC, a 5G/6G platform targeted for next-gen wireless networks.</li>
<li><b>Rising Star Partner of the Year </b>— <a href="https://www.icc-usa.com/icc-named-nvidia-partner-of-the-year-at-GTC-2024">International Computer Concepts</a> is recognized for its growth in developing AI and machine learning solutions for cloud service providers and financial services customers to power machine learning training, real-time inference and other AI workloads.</li>
<li><b>Service Delivery Partner of the Year </b>— <a href="https://quantiphi.com/press-release/quantiphi-awarded-nvidia-partner-network-ai-service-delivery-partner-of-the-year-for-third-consecutive-time/">Quantiphi</a> is recognized for the third consecutive year for its commitment to driving adoption of NVIDIA software and hardware in the enterprise. Its AI Service Delivery team has demonstrated expertise in using LLMs, information retrieval, imaging and data analytics to solve complex business problems in the telecom, life sciences, retail and energy industries for its global customers.</li>
<li><b>Distribution Partner of the Year </b>— <a href="https://news.tdsynnex.com/?p=3883">TD SYNNEX</a> is recognized for demonstrating its commitment to building its AI business on the NVIDIA AI platform, with year-over-year growth that underscores its operational excellence in distribution.</li>
<li><b>Software Partner of the Year </b>— <a href="https://investor.insight.com/news-releases/news-release-details/2024/Insight-Named-NVIDIAs-2024-Americas-Software-Partner-of-the-Year/default.aspx">Insight</a> is recognized for its leadership in NVIDIA AI Enterprise deployments, establishing cutting-edge innovation labs and certifications that cultivate expertise while seamlessly embedding generative AI into its operations.</li>
<li><b>Solution Integration Partner of the Year </b>— <a href="https://www.exxactcorp.com/News-Events/2024-NVIDIA-Partner-Network-Solution-Integration-Partner-of-the-Year">EXXACT</a> is recognized for its commitment and expertise in providing end-to-end NVIDIA AI and high performance computing solutions, including NVIDIA software and data center products across multiple industries.</li>
</ul>
<p>Learn how to <a href="https://www.nvidia.com/en-us/about-nvidia/partners/become-a-partner/">join NPN</a>, or find your local NPN partner.<br />
<b></b></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2022/01/NVIDIA-Endeavor-building-logo-1.jpg"
			type="image/jpeg"
			width="1300"
			height="868"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2022/01/NVIDIA-Endeavor-building-logo-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Celebrates Americas Partners Driving AI-Powered Transformation]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
	</channel>
</rss>
