<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Wed, 21 Feb 2024 18:40:45 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.4.3</generator>
	<item>
		<title>Shining Brighter Together: Google’s Gemma Optimized to Run on NVIDIA GPUs</title>
		<link>https://blogs.nvidia.com/blog/google-gemma-llm-rtx-ai-pc/</link>
		
		<dc:creator><![CDATA[Ankit Patel]]></dc:creator>
		<pubDate>Wed, 21 Feb 2024 13:00:31 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[TensorRT]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69874</guid>

					<description><![CDATA[NVIDIA, in collaboration with Google, today launched optimizations across all NVIDIA AI platforms for Gemma — Google’s state-of-the-art new lightweight 2 billion&#8211; and 7 billion-parameter open language models that can be run anywhere, reducing costs and speeding innovative work for domain-specific use cases. Teams from the companies worked closely together to accelerate the performance of		<a class="read-more" href="https://blogs.nvidia.com/blog/google-gemma-llm-rtx-ai-pc/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>NVIDIA, in collaboration with Google, today launched optimizations across all NVIDIA AI platforms for <a href="https://blog.google/technology/developers/gemma-open-models/">Gemma</a> — Google’s state-of-the-art new lightweight <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-foundation/models/gemma-2b">2 billion</a>&#8211; and <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-foundation/models/gemma-7b">7 billion</a>-parameter open language models that can be run anywhere, reducing costs and speeding innovative work for domain-specific use cases.</p>
<p>Teams from the companies worked closely together to accelerate the performance of Gemma — built from the same research and technology used to create the Gemini models — with <a href="https://github.com/NVIDIA/TensorRT-LLM">NVIDIA TensorRT-LLM</a>, an open-source library for optimizing large language model inference, when running on NVIDIA GPUs in the data center, in the cloud, and locally on workstations with <a href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA RTX</a> GPUs or PCs with <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/">GeForce RTX</a> GPUs.</p>
<p>This allows developers to target the installed base of over 100 million NVIDIA RTX GPUs available in high-performance AI PCs globally.</p>
<p>Developers can also run Gemma on NVIDIA GPUs in the cloud, including on Google Cloud’s A3 instances based on the H100 Tensor Core GPU and soon, NVIDIA’s <a href="https://nvidianews.nvidia.com/news/nvidia-supercharges-hopper-the-worlds-leading-ai-computing-platform">H200 Tensor Core GPUs</a> — featuring 141GB of HBM3e memory at 4.8 terabytes per second — which Google will deploy this year.</p>
<p>Enterprise developers can additionally take advantage of NVIDIA’s rich ecosystem of tools — including <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> with the <a href="https://github.com/NVIDIA/NeMo">NeMo framework</a> and <a href="https://github.com/NVIDIA/TensorRT-LLM">TensorRT-LLM</a> — to fine-tune Gemma and deploy the optimized model in their production applications.</p>
<p>Learn more about how <a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-revs-up-inference-for-google-gemma/">TensorRT-LLM is revving up inference for Gemma</a>, along with additional information for developers. This includes several model checkpoints of Gemma and the FP8-quantized version of the model, all optimized with TensorRT-LLM.</p>
<p>Experience <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-foundation/models/gemma-2b">Gemma 2B</a> and <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-foundation/models/gemma-7b">Gemma 7B</a> directly from your browser on the NVIDIA AI Playground.</p>
<h2><b>Gemma Coming to Chat With RTX</b></h2>
<p>Adding support for Gemma soon is <a href="https://blogs.nvidia.com/blog/chat-with-rtx-available-now/">Chat with RTX</a>, an NVIDIA tech demo that uses <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">retrieval-augmented generation</a> and TensorRT-LLM software to give users generative AI capabilities on their local, RTX-powered Windows PCs.</p>
<p><iframe title="Create A Personalized AI Chatbot with Chat With RTX" width="500" height="281" src="https://www.youtube.com/embed/gdsRJZT3IJw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>The Chat with RTX lets users personalize a chatbot with their own data by easily connecting local files on an RTX PC to a large language model.</p>
<p>Since the model runs locally, it provides results fast, and user data stays on the device. Rather than relying on cloud-based LLM services, Chat with RTX lets users process sensitive data on a local PC without the need to share it with a third party or have an internet connection.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/nv-google-blog-header-preview-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/nv-google-blog-header-preview-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Shining Brighter Together: Google’s Gemma Optimized to Run on NVIDIA GPUs]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI’s Hottest Ticket: NVIDIA GTC Brings Together Automotive Leaders and Visionaries Transforming the Future of Transportation</title>
		<link>https://blogs.nvidia.com/blog/gtc-2024-auto-sessions/</link>
		
		<dc:creator><![CDATA[Marie Labrie]]></dc:creator>
		<pubDate>Fri, 16 Feb 2024 19:17:57 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GTC 2024]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69865</guid>

					<description><![CDATA[Generative AI and software-defined computing are transforming the automotive landscape — making the journey behind the wheel safer, smarter and more enjoyable. Dozens of automakers and NVIDIA DRIVE ecosystem partners will be demonstrating their developments in mobility, along with showcasing their next-gen vehicles at GTC, the conference for the era of AI, running from March		<a class="read-more" href="https://blogs.nvidia.com/blog/gtc-2024-auto-sessions/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Generative AI and software-defined computing are transforming the automotive landscape — making the journey behind the wheel safer, smarter and more enjoyable.</p>
<p>Dozens of automakers and <a href="https://www.nvidia.com/en-us/self-driving-cars/">NVIDIA DRIVE</a> ecosystem <a href="https://www.nvidia.com/en-us/self-driving-cars/partners/">partners</a> will be demonstrating their developments in mobility, along with showcasing their next-gen vehicles at GTC, the conference for the era of AI, running from March 18-21 in San Jose, Calif., and online. These include the Mercedes-Benz Concept CLA Class, the new Volvo EX90, Polestar 3, WeRide Robobus, Nuro R3 autonomous delivery vehicle and more.</p>
<p>Explore myriad sessions to learn about the latest developments in mobility — from highly automated and autonomous driving, <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> and <a href="https://www.nvidia.com/en-us/glossary/large-language-models/#:~:text=Large%20language%20models%20(LLMs)%20are,content%20using%20very%20large%20datasets.">large language models</a> to simulation, safety, design and manufacturing.</p>
<p>Featured sessions include:<b><i></i></b></p>
<ul>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62464&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>How LLMs and Generative AI Will Enhance the Way We Experience Self-Driving Cars</b></a><br />
Alex Kendall, cofounder and CEO, Wayve<br />
<em>Tuesday, March 19, 9 a.m. PT</em></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=s62621&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>Accelerating the New Era of Autonomous Vehicles With Generative AI</b></a><br />
Raquel Urtasun, founder and CEO, Waabi<br />
<em>Tuesday, March 19, 10 a.m. PT</em></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62645&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>Applying AI &amp; LLMs to Transform the Luxury Automotive Experience</b></a><br />
Chrissie Kemp, chief data and digital product officer, Jaguar Land Rover<br />
<em>Tuesday, March 19, 11 a.m. PT</em></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62380&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>Generative AI and Industrial Digitalization in the Automotive Industry</b></a><br />
Alex Kendall, cofounder and CEO, Wayve<br />
Raquel Urtasun, founder and CEO, Waabi<br />
Chrissie Kemp, chief data and digital product officer, Jaguar Land Rover<br />
Norm Marks, vice president, automotive enterprise, NVIDIA<br />
<em>Tuesday, March 19, 2 p.m. PT</em></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62804&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>Accelerating Automotive Workflows With Large Language Models</b></a><br />
Bryan Goodman, director, artificial intelligence, Ford Motor Co.<br />
<em>Tuesday, March 19, 3 p.m. PT</em></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62472&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>Infusing the Car’s Cockpit With AI</b></a><br />
Dr. Ephrem Chemaly, vice president and general manager, automotive business unit, MediaTek<br />
<em>Wednesday, March 20, 9 a.m. PT</em></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=S63294&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>The Nuro Driver: An AI-First Autonomous Driving System</b></a><br />
Albert Meixner, head of Software, Nuro<br />
<em>Wednesday, March 20, 3 p.m. PT</em></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=SE63001&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>Accelerating the Shift to AI-Defined Vehicles</b></a><br />
Xinzhou Wu, vice president, automotive, NVIDIA<br />
<em>Thursday, March 21, 8 a.m. PT</em></li>
<li><a href="https://www.nvidia.com/gtc/session-catalog/?search=S62919&amp;ncid=em-prom-975499&amp;tab.allsessions=1700692987788001F1cG#/"><b>Transforming Factory Planning and Manufacturing Operations Within Digital Mega Plants</b><b><br />
</b></a>Benjamin Huber, head of advanced automation and digitalization – business area UX, Continental<br />
<em>Wednesday, March 20, 10 a.m. PT</em></li>
</ul>
<p>Rounding out the week will be <a href="https://www.nvidia.com/gtc/sessions/drive-developer-day/">DRIVE Developer Day</a> on Thursday, March 21 — featuring a series of deep-dive sessions on how to build safe and robust self-driving systems. Led by NVIDIA’s engineering experts, these talks will highlight the latest DRIVE features and developments.</p>
<p>Find additional details on <a href="https://images.nvidia.com/nvimages/gtc/pdf/GTC24_March_Automotive_Brochure.pdf">automotive-specific programming at GTC</a>.</p>
<p>Don’t stall — <a href="http://www.nvidia.com/gtc/?ncid=GTC-NVHWQQGN">register</a> today to learn how generative AI and software-defined computing are transforming the auto industry.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/autosessionsgtc24.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/autosessionsgtc24-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI’s Hottest Ticket: NVIDIA GTC Brings Together Automotive Leaders and Visionaries Transforming the Future of Transportation]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Telco GPT: Survey Shows Scale of Industry’s Enthusiasm and Adoption of Generative AI</title>
		<link>https://blogs.nvidia.com/blog/ai-telecommunications-survey/</link>
		
		<dc:creator><![CDATA[Ronnie Vasishta]]></dc:creator>
		<pubDate>Thu, 15 Feb 2024 16:37:33 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Telecommunications]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69852</guid>

					<description><![CDATA[It’s been five years since the telecommunications industry first deployed 5G networks to drive new performance levels for customers and unlock new value for telcos. But that industry milestone has been overshadowed by the emergence of generative AI and the swift pace at which telcos are embracing large language models as they seek to transform		<a class="read-more" href="https://blogs.nvidia.com/blog/ai-telecommunications-survey/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>It’s been five years since the telecommunications industry first deployed 5G networks to drive new performance levels for customers and unlock new value for telcos.</p>
<p>But that industry milestone has been overshadowed by the emergence of <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> and the swift pace at which telcos are embracing <a href="https://www.nvidia.com/en-us/glossary/large-language-models/">large language models</a> as they seek to transform all parts of their business.</p>
<p>A recent survey of more than 400 telecommunications industry professionals from around the world showed that generative AI is the breakout technology of the year and that enthusiasm and adoption for both generative AI, and AI in general, is booming. In addition, the survey showed that, among respondents, AI is improving both revenues and cost savings.</p>
<p>The generative AI insight is the main highlight in the second edition of NVIDIA’s “State of AI in Telecommunications” survey, which included questions covering a range of AI topics, including infrastructure spending, top use cases, biggest challenges and deployment models.</p>
<p>Survey respondents included C-suite leaders, managers, developers and IT architects from mobile telecoms, fixed and cable companies. The survey was conducted over eight weeks between October and December.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x.jpg"><img fetchpriority="high" decoding="async" class="aligncenter size-large wp-image-69853" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x-672x378.jpg" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/state-of-ai-report-2024-bbm-iat-p@2x.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<h2><b>Ramping Up on Generative AI</b></h2>
<p>The survey results show how generative AI went from relative obscurity in 2022 to a key solution within a year. Forty-three percent of respondents reported they were investing in it, showing clear evidence that the telecom industry is enthusiastically embracing the generative AI wave to address a wide variety of business goals.</p>
<p>More broadly, there was a marked increase in interest in adopting AI and growing expectations of success from the technology, especially among industry executives. In the survey, 53% of respondents agreed or strongly agreed that adopting AI will be a source of competitive advantage, compared to 39% who reported the same in 2022. For management respondents, the figure was 56%.</p>
<p>The primary reason for this sustained engagement is because many industry stakeholders expect AI to contribute to their company’s success. Overall, 56% of respondents agreed or strongly agreed that “AI is important to my company’s future success,” with the figure rising to 61% among decision-making management respondents. The overall figure is a 14-point boost over the 42% result from the 2022 survey.</p>
<h2><b>Customer Experience Remains Key Driver of AI Investment </b></h2>
<p>Telcos are adopting AI and generative AI to address a wide variety of business needs. Overall, 31% of respondents said they invested in at least six AI use cases in 2023, while 40% are planning to scale to six or more use cases in 2024.</p>
<p>But enhancing customer experiences remains the biggest AI opportunity for the telecom industry, with 48% of survey respondents selecting it as their main goal for using the technology. Likewise, some 35% of respondents identified customer experiences as their key AI success story.</p>
<p>For generative AI, 57% are using it to improve customer service and support, 57% to improve employee productivity, 48% for network operations and management, 40% for network planning and design, and 32% for marketing content generation.</p>
<h2><b>Early Phase of AI Investment Cycle</b></h2>
<p>The focus on customer experience is influencing investments. Investing in customer-experience optimization remains the most popular AI use case for 2023 (49% of respondents) and for generative AI investments (57% of respondents).</p>
<p>Telcos are also investing in other AI use cases: security (42%), network predictive maintenance (37%), network planning and operations (34%) and field operations (34%) are notable examples. However, using AI for fraud detection in transactions and payments had the biggest jump in popularity between 2022 and 2023, rising 14 points to 28% of respondents.</p>
<p>Overall, investments in AI are still in an early phase of the investment cycle, although growing strongly. In the survey, 43% of respondents reported an investment of over $1 million in AI in their previous year, 52% reported the same for the current year, and 66% reported their budget for AI infrastructure will increase in the next year.</p>
<p>For those who are already investing in AI, 67% reported that AI adoption has helped them increase revenues, with 19% of respondents noting that this revenue growth is more than 10% in specific business areas. Likewise, 63% reported that AI adoption has helped them reduce costs in specific business areas, with 14% noting that this cost reduction is more than 10%.</p>
<h2><b>Innovation With Partners</b></h2>
<p>While telcos are increasing their investments to improve their internal AI capabilities, partnerships remain critical for the adoption of AI solutions in the industry. This is applicable both for AI models and AI hardware infrastructure.</p>
<p>In the survey, 44% of respondents reported that co-development with partners is their company’s preferred approach to building AI solutions. Some 28% of respondents prefer to use open-source tools, while 25% take an AI-as-a-service approach. For generative AI, 29% of respondents built or customized models with a partner, an understandable conservative approach for the telecom industry with its stringent data protection rules.</p>
<p>For infrastructure, increasingly, many telcos are opting for cloud hosting, although the hybrid model still remains dominant. In the survey, 31% of respondents reported that they run most of their AI workloads in the cloud (44% for hybrid), compared to 21% of respondents in the previous survey (56% for hybrid). This is helping to fuel the growing need for more localized cloud infrastructure.</p>
<p><i>Download the “</i><a href="https://www.nvidia.com/en-us/lp/industries/telecommunications/state-of-ai-in-telecom-survey-report/?nvid=nv-int-tblg-284455-vt26"><i>State of AI in Telecommunications: 2024 Trends</i></a><i>” report for in-depth results and insights.</i></p>
<p><i>Explore how </i><a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search.industry=option_1559593261405#/"><i>AI is transforming telecommunications at NVIDIA GTC</i></a><i>, featuring industry leaders including Amdocs, Indosat, KT, Samsung Research, ServiceNow, Singtel, SoftBank, Telconet and Verizon.</i></p>
<p><i>Learn more about </i><a href="https://www.nvidia.com/en-us/industries/telecommunications/"><i>NVIDIA solutions for telecommunications</i></a><i> across customer experience, network operations, sovereign AI factories and more.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/telco-towers.jpg"
			type="image/jpeg"
			width="1200"
			height="628"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/telco-towers-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Telco GPT: Survey Shows Scale of Industry’s Enthusiasm and Adoption of Generative AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Artistry With Adobe: Creator Esteban Toro Delivers Inspirational Master Class Powered by AI and RTX</title>
		<link>https://blogs.nvidia.com/blog/studio-rtx-ai-adobe-premiere-pro-photoshop-lightroom/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Thu, 15 Feb 2024 14:00:44 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69821</guid>

					<description><![CDATA[Adobe is putting generative AI into the hands of creators with Adobe Firefly — powered by NVIDIA in the cloud — and adding to its impressive app lineup with exciting new features. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Adobe is putting generative AI into the hands of creators with <a href="https://www.adobe.com/products/firefly.html">Adobe Firefly</a> — powered by NVIDIA in the cloud — and adding to its impressive app lineup with exciting new features.</p>
<p>The AI-powered Enhance Speech tool, available soon in Adobe Premiere Pro, is accelerated by <a href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA RTX</a>. This new feature removes unwanted noise and improves the quality of dialogue clips so they sound professionally recorded.</p>
<p>Esteban Toro, senior community relationship manager at Adobe and this week’s featured <i>In the NVIDIA Studio </i>artist, expertly wields AI-powered features in Adobe Photoshop and Lightroom to create his emotionally moving <i>Cinematic Portraits </i>series.</p>
<figure id="attachment_69822" aria-describedby="caption-attachment-69822" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w.png"><img decoding="async" class="size-large wp-image-69822" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w-672x446.png" alt="" width="672" height="446" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w-672x446.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w-400x266.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w-768x510.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w-678x450.png 678w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w-324x215.png 324w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w-151x100.png 151w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-03-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69822" class="wp-caption-text">A sneak peek of Toro’s work.</figcaption></figure>
<p>Have a <a href="https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/">Chat with RTX</a> — the tech demo app that lets GeForce RTX owners personalize a generative pretrained transformer <a href="https://www.nvidia.com/en-us/glossary/large-language-models/#:~:text=Large%20language%20models%20(LLMs)%20are,content%20using%20very%20large%20datasets.">large language model</a> connected to their own content, whether in documents, notes, videos or other data formats. Since it runs locally on a Windows RTX PC or workstation, results are fast and secure. <a href="https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/">Download</a> Chat with RTX today.</p>
<p><iframe loading="lazy" title="Create A Personalized AI Chatbot with Chat With RTX" width="500" height="281" src="https://www.youtube.com/embed/gdsRJZT3IJw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Don’t forget <a href="https://www.nvidia.com/gtc/pricing/">GTC registration is open</a> for virtual or in-person attendance. Running March 18-21 in San Jose, Calif., the event delivers something for every technical level and interest area, including <a href="https://www.nvidia.com/gtc/session-catalog/">sessions</a> on how to power content creation using OpenUSD and generative AI.</p>
<p>And Omniverse OpenUSD month rolls on, spotlighting the open and extensible ecosystem for describing, composing, simulating and collaborating within 3D worlds. Follow NVIDIA Studio on <a href="https://www.instagram.com/nvidiastudio/">Instagram</a>, <a href="https://twitter.com/NVIDIAStudio">X</a> and <a href="https://www.facebook.com/NVIDIAStudio/">Facebook</a> to learn more.</p>
<h2><b>Storytelling With Adobe AI and RTX </b></h2>
<p>The talented Toro is driven by stories.</p>
<figure id="attachment_69825" aria-describedby="caption-attachment-69825" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69825" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w-672x446.png" alt="" width="672" height="446" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w-672x446.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w-400x266.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w-768x510.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w-678x450.png 678w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w-324x215.png 324w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w-151x100.png 151w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-pos-et-06-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69825" class="wp-caption-text">Stories fuel Toro’s creative process.</figcaption></figure>
<p>“Understanding how every person has a different upbringing and how the decisions they made took them to different places is absolutely inspiring,” said Toro. “When I discover a story worth telling, I just feel a necessity to tell it — and tell it right.”</p>
<p>It’s those stories that gave rise to <i>Cinematic Portraits</i>, a photo and video collection of people Toro’s befriended, such as Korean painter Kim Nam Soon, age 81, who impressively learned how to paint at 65.</p>
<div style="width: 1280px;" class="wp-video"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video class="wp-video-shortcode" id="video-69821-1" width="1280" height="720" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-kim-cinematic-1280w.mp4?_=1" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-kim-cinematic-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-kim-cinematic-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>Toro’s planning process is long and thorough — he can only retell stories by first having a conversation with each subject, making sure that they understand what the project is about and building a relationship with them so they feel comfortable enough to authentically share.</p>
<p>He captures video and photos of his subjects using Hasselblad and Sony camera gear. Then, he uses Adobe apps, accelerated by GeForce RTX and NVIDIA RTX technology, in post-production.</p>
<p>Toro deployed the Enhance Speech tool to boost the clarity and quality of voice recordings and adjusted enhancement levels with the Mix Amount setting — all powered by AI. The feature is 75% faster on a GeForce RTX 4090 laptop GPU compared with an RTX 3080 Ti.</p>
<p>“Without AI, the footage, filmed in challenging, noisy conditions, would be unusable,” he said.</p>
<p>The Text-Based Editing tool in Premiere Pro allowed Toro to use speech-to-text AI capabilities to automatically create captions, supported in 18 languages, for video footage — speeding the editing process.</p>
<figure id="attachment_69837" aria-describedby="caption-attachment-69837" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w.png"><img loading="lazy" decoding="async" class="wp-image-69837 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w-672x419.png" alt="" width="672" height="419" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w-672x419.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w-400x249.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w-768x479.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w-722x450.png 722w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w-345x215.png 345w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w-160x100.png 160w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-speech-to-text-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69837" class="wp-caption-text">The Text-Based Editing tool can create a transcription of a video sequence and add captions.</figcaption></figure>
<p>Toro also used the Filler Word Detection feature, which detects and deletes filler words and pauses, to achieve cleaner, more accurate transcripts. Filler words are language agnostic, so the feature works in all 18 languages supported in Text-Based Editing.</p>
<figure id="attachment_69840" aria-describedby="caption-attachment-69840" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69840" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w-672x446.png" alt="" width="672" height="446" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w-672x446.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w-400x266.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w-768x510.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w-678x450.png 678w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w-324x215.png 324w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w-151x100.png 151w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-wk96-esteban-at-desk-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69840" class="wp-caption-text">Adobe expert Esteban Toro hard at work.</figcaption></figure>
<p>Adobe offers a wide variety of time-saving features, such as the AI-powered Auto Reframe tool for automated editing in multiple size formats for social media with <a href="https://helpx.adobe.com/premiere-pro-next/organize-media/import-files/use-project-templates.html">project templates</a>. Toro’s <a href="https://www.nvidia.com/en-us/studio/">NVIDIA Studio laptop</a> with the <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4070-family/">GeForce RTX 4070 graphics card</a> accelerates all of these powerful tools.</p>
<p>Final file exports were achieved 4x faster than with a CPU alone thanks to the GPU-accelerated NVIDIA video encoder (<a href="https://developer.nvidia.com/video-codec-sdk">NVENC</a>). Toro quickly and easily added finishing touches in Photoshop Lightroom, using the RTX-accelerated, AI-powered Raw Details feature to refine the color detail of his high-resolution RAW images, and the Super Resolution feature to upscale images with higher quality than traditional methods.</p>
<p>“Having a dedicated GPU for video projects when filming high-quality video is almost mandatory,” said Toro. “Using NVIDIA GPUs allows me to render and process my projects faster, so the post-processing tools are serving my creative ideas, and I’m not limited by what the computer can do, but exactly what I want to create.&#8221;</p>
<figure id="attachment_69843" aria-describedby="caption-attachment-69843" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69843" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w-672x263.png" alt="" width="672" height="263" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w-672x263.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w-400x156.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w-768x300.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w-842x329.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w-406x159.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w-188x73.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-esteban-toro-wk96-artist-feature-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69843" class="wp-caption-text">Artist and Adobe expert Esteban Toro.</figcaption></figure>
<p>Follow Esteban Toro on <a href="https://www.instagram.com/estebantorom">Instagram</a>.</p>
</div>]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-esteban-toro-kim-cinematic-1280w.mp4" length="1764083" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/adobe-nv-blog-header-preview-1280x680-2.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/adobe-nv-blog-header-preview-1280x680-2-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Artistry With Adobe: Creator Esteban Toro Delivers Inspirational Master Class Powered by AI and RTX]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Eos Revealed: Peek Into Operations of a Top 10 Supercomputer</title>
		<link>https://blogs.nvidia.com/blog/eos/</link>
		
		<dc:creator><![CDATA[Charlie Boyle]]></dc:creator>
		<pubDate>Thu, 15 Feb 2024 14:00:16 +0000</pubDate>
				<category><![CDATA[Supercomputing]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69717</guid>

					<description><![CDATA[Providing a peek at the architecture powering advanced AI factories, NVIDIA Thursday released a video that offers the first public look at Eos, its latest data-center-scale supercomputer. An extremely large-scale NVIDIA DGX SuperPOD, Eos is where NVIDIA developers create their AI breakthroughs using accelerated computing infrastructure and fully optimized software. Eos is built with 576		<a class="read-more" href="https://blogs.nvidia.com/blog/eos/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Providing a peek at the architecture powering advanced AI factories, NVIDIA Thursday released a video that offers the first public look at Eos, its latest data-center-scale supercomputer.</p>
<p>An extremely large-scale <a href="https://www.nvidia.com/en-us/data-center/dgx-superpod/">NVIDIA DGX SuperPOD</a>, Eos is where NVIDIA developers create their AI breakthroughs using accelerated computing infrastructure and fully optimized software.</p>
<p>Eos is built with 576 <a href="https://www.nvidia.com/en-us/data-center/dgx-h100/">NVIDIA DGX H100</a> systems, <a href="https://www.nvidia.com/en-us/networking/quantum2/">NVIDIA Quantum-2 InfiniBand networking</a> and software, providing a total of 18.4 exaflops of FP8 AI performance. This system is a sister to a <a href="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fblogs.nvidia.com%2Fblog%2Fscaling-ai-training-mlperf%2F&amp;data=05%7C02%7Cgrainville%40nvidia.com%7Cc7f631fdf68a4870460808dc3174aac0%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638439624354202777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&amp;sdata=t8JYd63NQeTU341PEhKkonuqdW7wsCTU%2FP7Fm8AR7Jo%3D&amp;reserved=0" data-auth="NotApplicable">separate Eos DGX SuperPOD with 10,752 NVIDIA H100 GPUs</a>, used for MLPerf training in November.</p>
<p>Revealed in November at the Supercomputing 2023 trade show, Eos — named for the Greek goddess said to open the gates of dawn each day — reflects NVIDIA’s commitment to advancing AI technology.</p>
<h2>Eos Supercomputer Fuels Innovation</h2>
<p>Each DGX H100 system is equipped with eight <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100 Tensor Core GPUs</a>. Eos features a total of 4,608 H100 GPUs.</p>
<p>As a result, Eos can handle the largest AI workloads to train <a href="https://blogs.nvidia.com/blog/kt-large-language-models/">large language models</a>, recommender systems, quantum simulations and more.</p>
<p>It’s a showcase of what NVIDIA’s technologies can do, when working at scale.</p>
<p>Eos is arriving at the perfect time. People are changing the world with <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a>, from drug discovery to chatbots to autonomous machines and beyond.</p>
<p>To achieve these breakthroughs, they need more than AI expertise and development skills. They need an AI factory — a purpose-built AI engine that’s always available and can help ramp their capacity to build AI models at scale</p>
<p>Eos delivers. <a href="https://www.top500.org/lists/top500/2023/11/">Ranked No. 9 in the TOP500</a> list of the world’s fastest supercomputers, Eos pushes the boundaries of AI technology and infrastructure.</p>
<p>It includes NVIDIA’s advanced accelerated computing and networking alongside sophisticated software offerings such as <a href="https://www.nvidia.com/en-us/data-center/base-command/">NVIDIA Base Command</a> and <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a>.</p>
<p><iframe loading="lazy" title="YouTube video player" src="https://www.youtube.com/embed/J8-CgG5ewJQ?si=Ke2AmFde1VPZS2Jf" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe><i></i><br />
Eos’s architecture is optimized for AI workloads demanding ultra-low-latency and high-throughput interconnectivity across a large cluster of accelerated computing nodes, making it an ideal solution for enterprises looking to scale their AI capabilities.</p>
<p>Based on NVIDIA Quantum-2 InfiniBand with In-Network Computing technology, its network architecture supports data transfer speeds of up to 400Gb/s, facilitating the rapid movement of large datasets essential for training complex AI models.</p>
<p>At the heart of Eos lies the groundbreaking DGX SuperPOD architecture powered by NVIDIA’s DGX H100 systems.</p>
<p>The architecture is built to provide the AI and computing fields with tightly integrated full-stack systems capable of computing at an enormous scale.</p>
<p>As enterprises and developers worldwide seek to harness the power of AI, Eos stands as a pivotal resource, promising to accelerate the journey towards AI-infused applications that fuel every organization.</p>
<p><em>Editor’s note: This post was updated on Feb. 19, 2024, to clarify that there are two Eos systems.</em></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/NVIDIA-Eos-Image.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/NVIDIA-Eos-Image-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Eos Revealed: Peek Into Operations of a Top 10 Supercomputer]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>The Easiest Upgrade: Play at Ultimate Quality With GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-skull-and-bones-halo-infinite/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 15 Feb 2024 14:00:13 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69789</guid>

					<description><![CDATA[GFN Thursday keeps its fourth anniversary celebrations rolling by bringing Ubisoft’s Skull and Bones and Microsoft’s Halo Infinite to the cloud this week. They’re part of five newly supported games, and thanks to the power of the cloud, members can play them at unrivaled quality across nearly any device. The Ultimate Upgrade, Instantly When GeForce		<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-skull-and-bones-halo-infinite/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>GFN Thursday keeps its fourth anniversary celebrations rolling by bringing Ubisoft’s <i>Skull and Bones</i> and Microsoft’s <i>Halo Infinite</i> to the cloud this week.</p>
<p>They’re part of five newly supported games, and thanks to the power of the cloud, members can play them at unrivaled quality across nearly any device.</p>
<p><b>The Ultimate Upgrade, Instantly</b></p>
<p><iframe loading="lazy" title="New GeForce NOW Ultimate Membership | RTX 4080 Powered Cloud Gaming" width="500" height="281" src="https://www.youtube.com/embed/DVfWWZl1LQw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>When <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> launched in 2020, members flocked to take advantage of NVIDIA GeForce RTX 20 Series GPU-powered servers and experience real-time ray tracing on low-powered devices. For the first time, high-performance PC gaming was available to all.</p>
<p>Later, members gained access to the <a href="https://www.nvidia.com/en-us/geforce-now/memberships/">Ultimate upgrade</a>, as NVIDIA cloud gaming servers brought GeForce RTX 3080-class power to users across the globe.</p>
<p>Now, with the <a href="https://www.nvidia.com/en-us/geforce/ada-lovelace-architecture/">NVIDIA Ada Lovelace GPU architecture</a>, cloud gaming has taken another leap forward, powered by the <a href="https://blogs.nvidia.com/blog/geforce-now-thursday-jan-19/">GeForce RTX 4080 SuperPOD</a>.</p>
<figure id="attachment_69793" aria-describedby="caption-attachment-69793" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-69793" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/001-672x378.png" alt="Alan Wake 2 Performance GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/001-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/001-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/001-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/001-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/001.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/02/001-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2024/02/001-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2024/02/001-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/001-1280x720.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69793" class="wp-caption-text"><em>Oh deer, experience “Alan Wake 2” at the highest performance from the cloud.</em></figcaption></figure>
<p>That means nearly anyone can experience groundbreaking PC gaming technologies like <a href="https://www.nvidia.com/en-us/geforce/news/nvidia-dlss-3-5-ray-reconstruction/">NVIDIA DLSS 3.5</a>, with its AI-powered Frame Generation and upscaling features. Members can explore their favorite game worlds rendered with cinematic lighting and reflections thanks to <a href="https://www.nvidia.com/en-us/geforce/rtx/">RTX ON</a>, with full ray tracing supported in titles like <i>Cyberpunk 2077</i> and <i>Alan Wake 2</i>. Experience immersive gaming, even on old laptops or smartphones.</p>
<p>Enjoy the greatest PC games available at up to 4K resolution with an Ultimate membership, and explore a whole new world with support for 21:9 ultrawide resolutions.</p>
<p>Members also have the competitive edge in the cloud, thanks to support for <a href="https://www.nvidia.com/en-us/geforce/technologies/reflex/">NVIDIA Reflex</a> technology. Ultimate members can take aim and make every shot count with ultra-low latency and support for up to 240 frames per second performance — a first for cloud gaming — all made possible by GeForce NOW. Upgrade today to feel the difference.</p>
<h2><b>Shiver Me Timbers</b></h2>
<figure id="attachment_69799" aria-describedby="caption-attachment-69799" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-69799" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Skull_and_Bones-672x378.jpg" alt="Skull and Bones on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Skull_and_Bones-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Skull_and_Bones-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Skull_and_Bones-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Skull_and_Bones-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Skull_and_Bones-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Skull_and_Bones-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Skull_and_Bones-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Skull_and_Bones-1280x720.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Skull_and_Bones.jpg 1920w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69799" class="wp-caption-text"><em>Sail the seven seas in Ubisoft’s latest title.</em></figcaption></figure>
<p>Enter the perilous world of <i>Skull and Bones</i>, Ubisoft’s nautical action-packed adventure streaming now on GeForce NOW.</p>
<p>Sail the seas as a fearsome pirate kingpin, gaining infamy and gathering resources while building a smuggling empire. Engage in thrilling naval battles and risk it all for the biggest loot. Equip powerful weapons to outgun other ships and rain terror on enemy forts. Craft and sail up to 10 ships, each with unique perks, and become a force of destruction on the water.</p>
<p>Upgrade to a <a href="https://www.nvidia.com/en-us/geforce-now/memberships/">GeForce NOW Ultimate membership</a> to loot and plunder at full quality, with support for ultrawide resolutions and gameplay at up to 4K resolution and 120 fps on PCs and Macs.</p>
<h2><b>Infinite Action</b></h2>
<figure id="attachment_69796" aria-describedby="caption-attachment-69796" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-69796" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Halo_Infinite-672x378.png" alt="Halo Infinite on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Halo_Infinite-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Halo_Infinite-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Halo_Infinite-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Halo_Infinite-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Halo_Infinite.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Halo_Infinite-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Halo_Infinite-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Halo_Infinite-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Halo_Infinite-1280x720.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69796" class="wp-caption-text"><em>“I need a weapon.”</em></figcaption></figure>
<p>Step inside the armor of humanity’s greatest hero. <i>Halo Infinite</i> joins GeForce NOW this week, delivering the most expansive Master Chief campaign yet and a groundbreaking, free-to-play multiplayer experience. Plus, read this <a href="https://nvidia.custhelp.com/app/answers/detail/a_id/5462">article</a> and search for Halo Infinite for more details on how to launch the game.</p>
<p>It’s part of five new games this week:</p>
<ul>
<li><i>Banishers: Ghosts of New Eden </i>(New release on <a href="https://store.steampowered.com/app/1493640?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb. 12)</li>
<li><i>Deep Rock Galactic: Survivor</i> (New release on <a href="https://store.steampowered.com/app/2321470?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb. 14)</li>
<li><i>Goat Simulator 3</i> (New release on <a href="https://store.steampowered.com/app/850190?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb 15)</li>
<li><i>Skull and Bones </i>(New release on <a href="https://store.ubisoft.com/us/skull-and-bones/6295077a27efc536e38350a0.html#ucid=AFL-ID_152062&amp;maltcode=geforcenow_convst_AFL_geforcenow_vg__STORE____&amp;addinfo=">Ubisoft</a>, Feb. 16)</li>
<li><i>Halo Infinite </i>(<a href="https://store.steampowered.com/app/1240440?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.xbox.com/en-US/games/store/halo-infinite/9PP5G1F0C2B6/0010?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Happy Valentine&#39;s Day! <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f49a.png" alt="💚" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>Raise your hand if you&#39;re in a cirrus relationship. <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f590.png" alt="🖐" class="wp-smiley" style="height: 1em; max-height: 1em;" /><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/2601.png" alt="☁" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="https://t.co/g9bVP4BmPX">pic.twitter.com/g9bVP4BmPX</a></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1757811961146810784?ref_src=twsrc%5Etfw">February 14, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Feb_15.jpg"
			type="image/jpeg"
			width="2048"
			height="1024"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Feb_15-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[The Easiest Upgrade: Play at Ultimate Quality With GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Digitalization: A Game Changer for the Auto Industry</title>
		<link>https://blogs.nvidia.com/blog/auto-digitalization/</link>
		
		<dc:creator><![CDATA[Katie Young]]></dc:creator>
		<pubDate>Wed, 14 Feb 2024 20:28:18 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Digital Twin]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69803</guid>

					<description><![CDATA[The fusion of the physical and digital worlds is reshaping the automotive industry. NVIDIA’s automotive partners are using digitalization to transform every phase of the product lifecycle — evolving primarily physical, manual processes into software-driven, AI-enhanced digital systems. Watch the video to learn more. Digitalization: A Game Changer From End to End Kaivan Karimi, global		<a class="read-more" href="https://blogs.nvidia.com/blog/auto-digitalization/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The fusion of the physical and digital worlds is reshaping the automotive industry. NVIDIA’s automotive partners are using digitalization to transform every phase of the product lifecycle — evolving primarily physical, manual processes into software-driven, AI-enhanced digital systems.</p>
<p>Watch the video to learn more.</p>
<p><iframe loading="lazy" title="Digitalization: A Game Changer for the Auto Industry" width="500" height="281" src="https://www.youtube.com/embed/2J-o0tO7-98?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Digitalization: A Game Changer From End to End</b></h2>
<p>Kaivan Karimi, global partner strategy lead at Microsoft, observes that companies are achieving “huge” results from “digitizing the physical entity, running simulations and rendering in 3D, whether it’s factory automation or modernizing the design and development of the car.”</p>
<p>Brian Ullem, vice president of engineering at Capgemini, explains that, with “the 30,000 parts that go into a car, it takes approximately five years to develop a vehicle end to end. Instead of building 50 or 100 cars, we can use digitalization to simulate without having to build prototypes. That saves a lot of time and money in the process.”</p>
<p>Thomas Mueller, chief technology officer of engineering at Wipro, adds that with digitalization, “we are now able to run simulations at a low cost…and improve the user experience.”</p>
<h2><b>Simulation: Critical for Autonomous Driving</b></h2>
<p>“Simulation is crucial to the development of autonomous systems,” says Ziv Binyamini, CEO of Foretellix. “On one hand, you need the real world, but this is highly costly. So you have to complement it with the ability to simulate a virtual world where everything is possible. And then you can, in a very cost-effective way, iterate quickly and ensure the system operates under all of these conditions.”</p>
<p>Simulation “gives our customers the power to validate their ADAS or autonomous systems virtually — with highly accurate sensors in the camera, lidar and radar domains — without having to rely on actual physical drives,” adds Tony Karam, global sales director at Ansys.</p>
<p>Austin Russell, founder and CEO of Luminar, agrees that &#8220;simulation is absolutely critical for autonomous driving. It’s great to see the work that NVIDIA has been doing in that domain, with not just the hardware but also the software.”</p>
<h2><b>NVIDIA Omniverse: The Digital-Physical Convergence</b></h2>
<p>“Software is a new component in the value proposition,” notes Walid Negm, chief technology officer of product engineering at Deloitte. The companies that will “survive and thrive are going to have to become much more efficient using the digital-physical convergence. The Omniverse experience is going to be important for the automotive sector.”</p>
<p>Shiv Tasker, global vice president of engineering at Capgemini, adds that the “visualization and production of digital twins relies on an efficient, high-performance infrastructure as well as the platforms that make it easy for customers to adopt the technology.”</p>
<p><a href="https://www.nvidia.com/en-us/omniverse/">Omniverse</a> “will allow your worldwide team to simultaneously collaborate,” says Karimi of Microsoft. “Design engineers, migration engineers, test engineers — everybody collaborates simultaneously. That’s the power of NVIDIA Omniverse.”</p>
<p>Learn more about the <a href="https://developer.nvidia.com/drive">NVIDIA DRIVE platform</a> and how it’s helping industry leaders redefine transportation.</p>
<p><i>Join NVIDIA at </i><a href="https://www.nvidia.com/gtc/"><i>GTC</i></a><i> from March 18-21 in San Jose, Calif., to learn more about digitalization in the </i><a href="https://images.nvidia.com/nvimages/gtc/pdf/GTC24_March_Automotive_Brochure.pdf?ncid=so-yout-794329-vt03"><i>automotive industry</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/autodigitalizationblog.jpeg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/autodigitalizationblog-842x450.jpeg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Digitalization: A Game Changer for the Auto Industry]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Speak Like a Native: NVIDIA Parlays Win in Voice Challenge</title>
		<link>https://blogs.nvidia.com/blog/generative-voice-challenge/</link>
		
		<dc:creator><![CDATA[Rick Merritt]]></dc:creator>
		<pubDate>Wed, 14 Feb 2024 16:00:18 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Conversational AI]]></category>
		<category><![CDATA[generative AI]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[New GPU Uses]]></category>
		<category><![CDATA[Riva]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69734</guid>

					<description><![CDATA[Thanks to their work driving AI forward, Akshit Arora and Rafael Valle could someday speak to their spouses’ families in their native languages. Arora and Valle — along with colleagues Sungwon Kim and Rohan Badlani — won the LIMMITS ’24 challenge which asks contestants to recreate in real time a speaker’s voice in English or		<a class="read-more" href="https://blogs.nvidia.com/blog/generative-voice-challenge/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Thanks to their work driving AI forward, Akshit Arora and Rafael Valle could someday speak to their spouses’ families in their native languages.</p>
<p>Arora and Valle — along with colleagues Sungwon Kim and Rohan Badlani — won the <a href="https://sites.google.com/view/limmits24/home">LIMMITS ’24 challenge</a> which asks contestants to recreate in real time a speaker’s voice in English or any of six languages spoken in India with the appropriate accent. Their novel AI model only required a three-second speech sample.</p>
<p>The NVIDIA team advanced the state of the art in an emerging field of personalized voice interfaces for more than a billion native speakers of Bengali, Chhattisgarhi, Hindi, Kannada, Marathi and Telugu.</p>
<h2><b>Making Voice Interfaces Realistic</b></h2>
<p>The technology for personalized text-to-speech translation is a work in progress. Existing services sometimes fail to accurately reflect the accents of the target language or nuances of the speaker’s voice.</p>
<p>The challenge judged entries by listening for the naturalness of models’ resulting speech and its similarity to the original speaker’s voice.</p>
<p>The latest improvements promise personalized, realistic conversations and experiences that break language barriers. Broadcasters, telcos, universities, as well as e-commerce and online gaming services are eager to deploy such technology to create multilingual movies, lectures and virtual agents.</p>
<p>“We demonstrated we can do this at a scale not previously seen,” said Arora, who has two uses close to his heart.</p>
<h2><b>Breaking Down Linguistic Barriers</b></h2>
<p>A senior data scientist who supports one of NVIDIA’s biggest customers, Arora speaks Punjabi, while his wife and her family are native Tamil speakers.</p>
<p>It’s a gulf he’s long wanted to bridge for himself and others. “I had classmates who knew their native languages much better than the Hindi and English used in school, so they struggled to understand class material,” he said.</p>
<p>The gulf crosses continents for Valle, a native of Brazil whose wife and family speak Gujarati, a language popular in west India.</p>
<p>“It’s a problem I face every day,” said Valle, an AI researcher with degrees in computer music and machine listening and improvisation. “We’ve tried many products to help us have clearer conversations.”</p>
<p>Badlani, an AI researcher, said living in seven different Indian states, each with its own popular language, inspired him to work in the field.</p>
<h2><b>A Race to the Finish Line</b></h2>
<p>The initiative started nearly two years ago when Arora and Badlani formed the four-person team to work on the very different version of the challenge that would be held in 2023.</p>
<p>Their efforts generated a working code base for the so-called Indic languages. But getting to the win announced in January required a full-on sprint because the 2024 challenge didn’t get on the team’s radar until 15 days before the deadline.</p>
<p>Luckily, Kim, a deep learning researcher in NVIDIA’s Seoul office, had been working for some time on an AI model well suited to the challenge.</p>
<p>A specialist in text-to-speech voice synthesis, Kim was designing a so-called P-Flow model prior to starting his second internship at NVIDIA in 2023. P-Flow models borrow the technique large language models employ of using short voice samples as prompts so they can respond to new inputs without retraining.</p>
<p>“I created the model for English, but we were able to generalize it for any language,” he said.</p>
<p>“We were talking and texting about this model even before he started at NVIDIA,” said Valle, who mentored Kim in two internships before he joined full time in January.</p>
<h2><b>Giving Others a Voice</b></h2>
<p>P-Flow will soon be part of <a href="https://www.nvidia.com/en-us/ai-data-science/products/riva/">NVIDIA Riva</a>, a framework for building multilingual speech and translation AI software, included in the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> software platform.</p>
<p>The new capability will let users deploy the technology inside their data centers, on personal systems or in public or private cloud services. Today, voice translation services typically run on public cloud services.</p>
<p>“I hope our customers are inspired to try this technology,” Arora said. “I enjoy being able to showcase in challenges like this one the work we do every day.”</p>
<p>The contest is part of <a href="https://syspin.iisc.ac.in/">an initiative</a> to develop open-source datasets and AI models for nine languages most widely spoken in India.</p>
<p>Hear Arora and Badlani share their experiences in <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG&amp;search=S62517#/session/1696286805576001jEsz">a session</a> at GTC next month.</p>
<p>And listen to the results of the team’s model below, starting with a <a href="https://huggingface.co/datasets/SYSPIN/LIMMITS24_target_speaker_fewshot_samples">three-second sample</a> of a native Kannada speaker:</p>
<!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
<audio class="wp-audio-shortcode" id="audio-69734-1" preload="none" style="width: 100%;" controls="controls"><source type="audio/mpeg" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/pr_kannada_f_indictts_prompt_3s-1.mp3?_=1" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/pr_kannada_f_indictts_prompt_3s-1.mp3">https://blogs.nvidia.com/wp-content/uploads/2024/02/pr_kannada_f_indictts_prompt_3s-1.mp3</a></audio>
<p>&nbsp;</p>
<p>Here’s a similar-sounding synthesized voice reading the first sentence of this blog in Hindi:</p>
<audio class="wp-audio-shortcode" id="audio-69734-2" preload="none" style="width: 100%;" controls="controls"><source type="audio/mpeg" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/pr_kannada_f_indictts_speaking_hindi_3-2.mp3?_=2" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/pr_kannada_f_indictts_speaking_hindi_3-2.mp3">https://blogs.nvidia.com/wp-content/uploads/2024/02/pr_kannada_f_indictts_speaking_hindi_3-2.mp3</a></audio>
<p>&nbsp;</p>
<p>And then in English:</p>
<audio class="wp-audio-shortcode" id="audio-69734-3" preload="none" style="width: 100%;" controls="controls"><source type="audio/mpeg" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/pr_kannada_f_indictts_speaking_english-1.mp3?_=3" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/pr_kannada_f_indictts_speaking_english-1.mp3">https://blogs.nvidia.com/wp-content/uploads/2024/02/pr_kannada_f_indictts_speaking_english-1.mp3</a></audio>
<p><i>See </i><a href="https://www.nvidia.com/en-us/about-nvidia/legal-info/"><i>notice</i></a><i> regarding software product information.</i></p>
</div>]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/02/pr_kannada_f_indictts_prompt_3s-1.mp3" length="28510" type="audio/mpeg" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/02/pr_kannada_f_indictts_speaking_hindi_3-2.mp3" length="93931" type="audio/mpeg" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/02/pr_kannada_f_indictts_speaking_english-1.mp3" length="74733" type="audio/mpeg" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/NVIDIA-Voice-Challenge-Team-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1095"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/NVIDIA-Voice-Challenge-Team-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Speak Like a Native: NVIDIA Parlays Win in Voice Challenge]]></media:title>
			<media:description type="html">NVIDIA text-to-speech team wins LIMMITS &#039;24 Challenge</media:description>
			</media:content>
			</item>
		<item>
		<title>How the Ohio Supercomputer Center Drives the Future of Computing</title>
		<link>https://blogs.nvidia.com/blog/ohio-supercomputer-center/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Wed, 14 Feb 2024 14:00:44 +0000</pubDate>
				<category><![CDATA[The AI Podcast]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69787</guid>

					<description><![CDATA[NASCAR races are all about speed, but even the fastest cars need to factor in safety, especially as rules and tracks change. The Ohio Supercomputer Center is ready to help. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Alan Chalker, the director of strategic programs at the OSC, about all things		<a class="read-more" href="https://blogs.nvidia.com/blog/ohio-supercomputer-center/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>NASCAR races are all about speed, but even the fastest cars need to factor in safety, especially as rules and tracks change. The Ohio Supercomputer Center is ready to help. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with Alan Chalker, the director of strategic programs at the OSC, about all things supercomputing. The center’s Open OnDemand program, which takes the form of a web-based interface, empowers Ohio higher education institutions and industries with accessible, reliable and secure computational services and training and educational programs. Chalker dives into the history and evolution of the OSC, and explains how it’s working with client companies like NASCAR, which is simulating race car designs virtually. Tune in to learn more about Chalker’s outlook on the future of supercomputing and OSC’s role in realizing it.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1746649332%3Fsecret_token%3Ds-p1ZnmwGiAp3&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="How the Ohio Supercomputer Center Drives the Future of Computing - Ep. 213" href="https://soundcloud.com/theaipodcast/ai-alan-chalker/s-p1ZnmwGiAp3" target="_blank" rel="noopener">How the Ohio Supercomputer Center Drives the Future of Computing &#8211; Ep. 213</a></div>
<div>
<h2>Time Stamps:</h2>
<p>1:39: History of the Ohio Supercomputer Center<br />
3:18: What are supercomputers?<br />
5:08: How the Open OnDemand program came to be<br />
11:50 How is Open OnDemand being used across higher education, industries?<br />
22:45: OSC’s work with NASCAR<br />
26:57: What’s on the horizon for Open OnDemand?</p>
<h2>You Might Also Like…</h2>
<p><a href="https://soundcloud.com/theaipodcast/edtech">MIT’s Anant Agarwal on AI in Education &#8211; Ep. 197</a></p>
<p>AI could help students work smarter, not harder. Anant Agarwal, founder of edX and Chief Platform Officer at 2U, shares his vision for the future of online education and the impact of AI in revolutionizing the learning experience.</p>
<p><a href="https://soundcloud.com/theaipodcast/university-of-florida-ai">UF Provost Joe Glover on Building a Leading AI University &#8211; Ep. 186</a></p>
<p>Joe Glover, provost and senior vice president of academic affairs at the University of Florida, discusses the university’s efforts to implement AI across all aspects of higher education, including a public-private partnership with NVIDIA that has helped transform UF into one of the leading AI universities in the country.</p>
<p><a href="https://soundcloud.com/theaipodcast/nvidias-marc-hamilton-on-building-the-cambridge-1-supercomputer-during-a-pandemic">NVIDIA’s Marc Hamilton on Building the Cambridge-1 Supercomputer During a Pandemic &#8211; Ep. 137</a></p>
<p>Cambridge-1, U.K.’s most powerful supercomputer, ranks among the world’s top 3 most energy-efficient supercomputers and was built to help healthcare researchers make new discoveries. Marc Hamilton, vice president of solutions architecture and engineering at NVIDIA, speaks on how he remotely oversaw its construction.</p>
<h2><b>Subscribe to the AI Podcast</b></h2>
<p>Get the<a href="https://blogs.nvidia.com/ai-podcast/"> AI Podcast</a> through<a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439"> iTunes</a>,<a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjI2NDAzNDEzMy9zb3VuZHMucnNz"> Google Podcasts</a>,<a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm"> Google Play</a>, <a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">Amazon Music, </a><a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us">Castbox</a>, DoggCatcher,<a href="https://overcast.fm/itunes1186480811/the-ai-podcast"> Overcast</a>,<a href="https://player.fm/series/the-ai-podcast"> PlayerFM</a>, Pocket Casts,<a href="http://www.podbay.fm/show/1186480811"> Podbay</a>,<a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast"> PodBean</a>, PodCruncher, PodKicker,<a href="https://soundcloud.com/theaipodcast"> Soundcloud</a>,<a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L"> Spotify</a>,<a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr"> Stitcher</a> and<a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/"> TuneIn</a>.</p>
<p>Make the AI Podcast better: Have a few minutes to spare? Fill out<a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short"> this listener survey</a>.</p>
</div>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/nascar-image.png"
			type="image/png"
			width="1847"
			height="1009"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/nascar-image-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[How the Ohio Supercomputer Center Drives the Future of Computing]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Say What? Chat With RTX Brings Custom Chatbot to NVIDIA RTX AI PCs</title>
		<link>https://blogs.nvidia.com/blog/chat-with-rtx-available-now/</link>
		
		<dc:creator><![CDATA[Jesse Clayton]]></dc:creator>
		<pubDate>Tue, 13 Feb 2024 14:00:41 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69743</guid>

					<description><![CDATA[Chatbots are used by millions of people around the world every day, powered by NVIDIA GPU-based cloud servers. Now, these groundbreaking tools are coming to Windows PCs powered by NVIDIA RTX for local, fast, custom generative AI. Chat with RTX, now free to download, is a tech demo that lets users personalize a chatbot with		<a class="read-more" href="https://blogs.nvidia.com/blog/chat-with-rtx-available-now/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Chatbots are used by millions of people around the world every day, powered by NVIDIA GPU-based cloud servers. Now, these groundbreaking tools are coming to Windows PCs powered by <a href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA RTX</a> for local, fast, custom <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a>.</p>
<p><a href="https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/">Chat with RTX</a>, now free to <a href="https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/">download</a>, is a tech demo that lets users personalize a chatbot with their own content, accelerated by a local <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/">NVIDIA GeForce RTX 30 Series GPU</a> or higher with at least 8GB of video random access memory, or VRAM.</p>
<h2><b>Ask Me Anything</b></h2>
<p>Chat with RTX uses <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">retrieval-augmented generation</a> (RAG), NVIDIA <a href="https://blogs.nvidia.com/blog/ignite-rtx-ai-tensorrt-llm-chat-api/">TensorRT-LLM</a> software and NVIDIA RTX acceleration to bring generative AI capabilities to local, GeForce-powered Windows PCs. Users can quickly, easily connect local files on a PC as a dataset to an open-source <a href="https://blogs.nvidia.com/blog/what-are-large-language-models-used-for/">large language model</a> like Mistral or Llama 2, enabling queries for quick, contextually relevant answers.</p>
<p><iframe loading="lazy" title="Create A Personalized AI Chatbot with Chat With RTX" width="500" height="281" src="https://www.youtube.com/embed/gdsRJZT3IJw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Rather than searching through notes or saved content, users can simply type queries. For example, one could ask, “What was the restaurant my partner recommended while in Las Vegas?” and Chat with RTX will scan local files the user points it to and provide the answer with context.</p>
<p>The tool supports various file formats, including .txt, .pdf, .doc/.docx and .xml. Point the application at the folder containing these files, and the tool will load them into its library in just seconds.</p>
<p>Users can also include information from YouTube videos and playlists. Adding a video URL to Chat with RTX allows users to integrate this knowledge into their chatbot for contextual queries. For example, ask for travel recommendations based on content from favorite influencer videos, or get quick tutorials and how-tos based on top educational resources.</p>
<figure id="attachment_69747" aria-describedby="caption-attachment-69747" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/Chat-with-RTX-Screenshot-scaled.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-69747" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/Chat-with-RTX-Screenshot-672x378.jpg" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/Chat-with-RTX-Screenshot-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Chat-with-RTX-Screenshot-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Chat-with-RTX-Screenshot-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Chat-with-RTX-Screenshot-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Chat-with-RTX-Screenshot-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Chat-with-RTX-Screenshot-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Chat-with-RTX-Screenshot-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Chat-with-RTX-Screenshot-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Chat-with-RTX-Screenshot-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69747" class="wp-caption-text">Chat with RTX can integrate knowledge from YouTube videos into queries.</figcaption></figure>
<p>Since Chat with RTX runs locally on Windows RTX PCs and workstations, the provided results are fast — and the user’s data stays on the device. Rather than relying on cloud-based LLM services, Chat with RTX lets users process sensitive data on a local PC without the need to share it with a third party or have an internet connection.</p>
<p>In addition to a GeForce RTX 30 Series GPU or higher with a minimum 8GB of VRAM, Chat with RTX requires Windows 10 or 11, and the latest NVIDIA GPU drivers.</p>
<p><em>Editor&#8217;s note: We have identified an issue in Chat with RTX that causes installation to fail when the user selects a different installation directory. This will be fixed in a future release. For the time being, users should use the default installation directory (&#8220;C:\Users\&lt;username&gt;\AppData\Local\NVIDIA\ChatWithRTX&#8221;).</em></p>
<h2><b>Develop LLM-Based Applications With RTX</b></h2>
<p>Chat with RTX shows the potential of accelerating LLMs with RTX GPUs. The app is built from the <a href="https://github.com/NVIDIA/trt-llm-rag-windows">TensorRT-LLM RAG developer reference project, available on GitHub</a>. Developers can use the reference project to develop and deploy their own RAG-based applications for RTX, accelerated by TensorRT-LLM. Learn more about <a href="https://developer.nvidia.com/blog/get-started-with-generative-ai-development-for-windows-pcs-with-rtx-systems">building LLM-based applications</a>.</p>
<p>Enter a generative AI-powered Windows app or plug-in to the <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/rtx-developer-contest">NVIDIA Generative AI on NVIDIA RTX</a> developer contest, running through Friday, Feb. 23, for a chance to win prizes such as a GeForce RTX 4090 GPU, a full, in-person conference pass to <a href="https://www.nvidia.com/gtc/">NVIDIA GTC</a> and more.</p>
<p><i>Learn more about </i><a href="https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/"><i>Chat with RTX</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-chat-with-rtx-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-chat-with-rtx-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Say What? Chat With RTX Brings Custom Chatbot to NVIDIA RTX AI PCs]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA CEO: Every Country Needs Sovereign AI</title>
		<link>https://blogs.nvidia.com/blog/world-governments-summit/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Mon, 12 Feb 2024 16:46:48 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Generative AI]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69708</guid>

					<description><![CDATA[Every country needs to own the production of their own intelligence, NVIDIA founder and CEO Jensen Huang told attendees Monday at the World Governments Summit in Dubai. Huang, who spoke as part of a fireside chat with the UAE’s Minister of AI, His Excellency Omar Al Olama, described sovereign AI — which emphasizes a country’s		<a class="read-more" href="https://blogs.nvidia.com/blog/world-governments-summit/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Every country needs to own the production of their own intelligence, NVIDIA founder and CEO Jensen Huang told attendees Monday at the World Governments Summit in Dubai.</p>
<p>Huang, who spoke as part of a fireside chat with the UAE’s Minister of AI, His Excellency Omar Al Olama, described sovereign AI — which emphasizes a country’s ownership over its data and the intelligence it produces — as an enormous opportunity for the world’s leaders.</p>
<p>“It codifies your culture, your society’s intelligence, your common sense, your history – you own your own data,” Huang told Al Olama during their conversation, a highlight of an event attended by more than 4,000 delegates from 150 countries.</p>
<p>“We completely subscribe to that vision,” Al Olama said. “That’s why the UAE is moving aggressively on creating large language models and mobilizing compute.”</p>
<p>Huang’s appearance in the UAE comes as the Gulf State is moving rapidly to transform itself from an energy powerhouse into a global information technology hub.</p>
<p>Dubai is the latest stop for Huang in a global tour that has included meetings with leaders in Canada, France, India, Japan, Malaysia, Singapore and Vietnam over the past six months.<br />
<b><br />
</b>The Middle East is poised to reap significant benefits from AI, with PwC projecting a $320 billion boost to the region’s economy by 2030.</p>
<p>At Monday’s summit, Huang urged leaders not to be “mystified” by AI. AI’s unprecedented ability to take directions from ordinary humans makes it critical for countries to embrace AI, infusing it with local languages and expertise.</p>
<p>In response to Al Olama’s question about how he might approach AI if he were the leader of a developing nation, Huang emphasized the importance of building infrastructure.</p>
<p>“It’s not that costly, it is also not that hard,” Huang said. “The first thing that I would do, of course, is I would codify the language, the data of your culture into your own large language model.”</p>
<p>And as AI and accelerated computing has developed, NVIDIA GPUs have become a platform for one innovation after another.</p>
<p>“NVIDIA GPU is the only platform that’s available to everybody on any platform,” Huang said. “This ubiquity has not only democratized AI but facilitated a wave of innovation that spans from cloud computing to autonomous systems and beyond.</p>
<p>All of this promises to unleash new kinds of innovations that go beyond what’s traditionally been thought of as information technology.</p>
<p>Huang even countered advice offered by many visionaries over the years who urged young people to study computer science in order to compete in the information age. No longer.</p>
<p>“In fact, it’s almost exactly the opposite,” Huang said. “It is our job to create computing technologies that nobody has to program and that the programming language is human: everybody in the world is now a programmer — that is the miracle.”</p>
<p>In a move that further underscores the regional momentum behind AI, Moro Hub, a subsidiary of Digital DEWA, the digital arm of the Dubai Electricity and Water Authority, focused on providing cloud services, cybersecurity and smart city solutions, announced Monday it has agreed to build a green data center with NVIDIA.</p>
<p>In addition to the fireside chat, the summit featured panels on smart mobility, sustainable development and more, showcasing the latest in AI advancements. Later in the evening, Huang and Al Olama took the stage at the “Get Inspired” ecosystem event, organized by the UAE’s AI Office, featuring 280 attendees including developers, startups and others.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/Dubai_Jensen_Huang_Stage-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1365"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/Dubai_Jensen_Huang_Stage-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA CEO: Every Country Needs Sovereign AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA RTX 2000 Ada Generation GPU Brings Performance, Versatility for Next Era of AI-Accelerated Design and Visualization</title>
		<link>https://blogs.nvidia.com/blog/rtx-2000-ada/</link>
		
		<dc:creator><![CDATA[Stacy Ozorio]]></dc:creator>
		<pubDate>Mon, 12 Feb 2024 16:00:50 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69652</guid>

					<description><![CDATA[Generative AI is driving change across industries — and to take advantage of its benefits, businesses must select the right hardware to power their workflows. The new NVIDIA RTX 2000 Ada Generation GPU delivers the latest AI, graphics and compute technology to compact workstations, offering up to 1.5x the performance of the previous-generation RTX A2000		<a class="read-more" href="https://blogs.nvidia.com/blog/rtx-2000-ada/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><a href="https://www.nvidia.com/en-us/glossary/generative-ai/">Generative AI</a> is driving change across industries — and to take advantage of its benefits, businesses must select the right hardware to power their workflows.</p>
<p>The new <a href="https://www.nvidia.com/en-us/design-visualization/rtx-2000/">NVIDIA RTX 2000 Ada Generation GPU</a> delivers the latest AI, graphics and compute technology to compact workstations, offering up to 1.5x the performance of the previous-generation RTX A2000 12GB in professional workflows.</p>
<p>From crafting stunning 3D environments to streamlining complex design reviews to refining industrial designs, the card’s capabilities pave the way for an AI-accelerated future, empowering professionals to achieve more without compromising on performance or capabilities.</p>
<p>Modern multi-application workflows, such as AI-powered tools, multi-display setups and high-resolution content, put significant demands on GPU memory. With 16GB of memory in the RTX 2000 Ada, professionals can tap the latest technologies and tools to work faster and better with their data.</p>
<p>Powered by <a href="https://www.nvidia.com/en-us/design-visualization/rtx/">NVIDIA RTX</a> technology, the new GPU delivers impressive realism in graphics with <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">NVIDIA DLSS</a>, delivering ultra-high-quality, photorealistic ray-traced images more than 3x faster than before. In addition, the RTX 2000 Ada enables an immersive experience for enterprise virtual-reality workflows, such as for product design and engineering design reviews.</p>
<p>With its blend of performance, versatility and AI capabilities, the RTX 2000 Ada helps professionals across industries achieve efficiencies.</p>
<p>Architects and urban planners can use it to accelerate visualization workflows and structural analysis, enhancing design precision. Product designers and engineers using industrial PCs can iterate rapidly on product designs with fast, photorealistic rendering and AI-powered generative design. Content creators can edit high-resolution videos and images seamlessly, and use AI for realistic visual effects and content creation assistance.</p>
<p>And in vital embedded applications and edge computing, the RTX 2000 Ada can power real-time data processing for medical devices, optimize manufacturing processes with predictive maintenance and enable AI-driven intelligence in retail environments.</p>
<h2><b>Expanding the Reach of NVIDIA RTX</b></h2>
<p>Among the first to tap the power and performance of the RTX 2000 Ada are Dassault Systèmes for its SOLIDWORKS applications, Rob Wolkers Design and Engineering, and WSP.</p>
<p>“The new RTX 2000 Ada Generation GPU boasts impressive features compared to previous generations, with a compact design that offers exceptional performance and versatility,” said Mark Kauffman, assistant vice president and technical lead at WSP. “Its 16GB of RAM is a game-changer, enabling smooth loading of asset-heavy content, and its ability to run applications like Autodesk 3ds Max, Adobe After Effects and Unreal Engine, as well as support path tracing, expands my creative possibilities.”</p>
<p>“The new NVIDIA RTX 2000 Ada — with its higher-efficiency, next-generation architecture, low power consumption and large frame buffer — will benefit SOLIDWORKS users,” said Olivier Zegdoun, graphics applications research and development director for SOLIDWORKS at Dassault Systèmes. “It delivers excellent performance for designers and engineers to accelerate the development of innovative product experiences with full-model fidelity, even with larger datasets.”</p>
<p>“Today’s design and visualization workflows demand more advanced compute and horsepower,” said Rob Wolkers, owner and senior industrial design engineer at <a href="https://www.robwolkers.com/">Rob Wolkers Design and Engineering</a>. “Equipped with next-generation architecture and a large frame buffer, the RTX 2000 Ada Generation GPU improves productivity in my everyday industrial design and engineering workflows, allowing me to work with large datasets in full fidelity and generate renders with more lighting and reflection scenarios 3x faster.”</p>
<h2><b>Elevating Workflows With Next-Generation RTX Technology </b></h2>
<p>The NVIDIA RTX 2000 Ada features the latest technologies in the NVIDIA Ada Lovelace GPU architecture, including:</p>
<ul>
<li><b>Third-generation RT Cores: </b>Up to 1.7x faster ray-tracing performance for high-fidelity, photorealistic rendering.</li>
<li><b>Fourth-generation Tensor Cores:</b> Up to 1.8x AI throughput over the previous generation, with structured sparsity and FP8 precision to enable higher inference performance for AI-accelerated tools and applications.</li>
<li><b>CUDA cores: </b>Up to 1.5x the FP32 throughput of the previous generation for significant performance improvements in graphics and compute workloads.</li>
<li><b>Power efficiency:</b> Up to a 2x performance boost across professional graphics, rendering, AI and compute workloads, all within the same 70W of power as the previous generation.</li>
<li><b>Immersive workflows: </b>Up to 3x performance for virtual-reality workflows over the previous generation.</li>
<li><b>16GB of GPU memory:</b> An expanded canvas enables users to tackle larger projects, along with support for error correction code memory to deliver greater computing accuracy and reliability for mission-critical applications.</li>
<li><b>DLSS 3: </b>Delivers a breakthrough in AI-powered graphics, significantly boosting performance by generating additional high-quality frames.</li>
<li><b>AV1 encoder:</b> Eighth-generation NVIDIA Encoder, aka NVENC, with AV1 support is 40% more efficient than H.264, enabling new possibilities for broadcasters, streamers and video callers.</li>
</ul>
<h2><b>NVIDIA RTX Enterprise Driver Delivers New Features, Adds Support for RTX 2000 Ada</b></h2>
<p><a href="https://www.nvidia.com/download/driverResults.aspx/218117/en-us/">The latest RTX Enterprise Driver</a>, available now to download, includes a range of features that enhance graphics workflows, along with support for the RTX 2000 Ada.</p>
<p>The AI-based, standard dynamic range to high dynamic range tone-mapping feature, called Video TrueHDR, expands the color range and brightness levels when viewing content in Chrome or Edge browsers. With added support for <a href="https://blogs.nvidia.com/blog/rtx-video-super-resolution/">Video Super Resolution</a> and TrueHDR to the <a href="https://docs.nvidia.com/ngx/index.html">NVIDIA NGX</a> software development kit, video quality of low-resolution sources can be enhanced, and SDR content can easily be converted to HDR.</p>
<p><a href="https://www.nvidia.com/download/driverResults.aspx/218117/en-us/">Additional features</a> in this release include:</p>
<ul>
<li style="font-weight: 300"><a href="https://developer.nvidia.com/tensorrt">TensorRT-LLM</a>, an <a href="https://github.com/NVIDIA/TensorRT-LLM">open-source library</a> that optimizes and accelerates inference performance for the latest <a href="https://www.nvidia.com/en-us/glossary/large-language-models/">large language models</a> on NVIDIA GPUs.</li>
<li style="font-weight: 300">Video quality improvement and enhanced coding efficiency to video codecs through bit depth expansion techniques and new low-delay B frame.</li>
<li style="font-weight: 300">Ability to offload work from the CPU to the GPU with the execute indirect extension <a href="https://developer.nvidia.com/rtx/path-tracing/nvapi/get-started">NVIDIA API</a> for quicker task completion.</li>
<li style="font-weight: 300">Ability to display the GPU serial number in the NV Control Panel on desktops for easier registration to the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> and <a href="https://www.nvidia.com/en-us/omniverse/enterprise/">NVIDIA Omniverse Enterprise</a> platforms.</li>
</ul>
<h2><b>Availability</b></h2>
<p>The NVIDIA RTX 2000 Ada is available now through global distribution partners such as Arrow Electronics, Ingram Micro, Leadtek, PNY, Ryoyo Electro and TD SYNNEX, and will be available from Dell Technologies, HP and Lenovo starting in April.</p>
<h2><b>See the NVIDIA RTX 2000 Ada at Dassault Systèmes’ 3DEXPERIENCE World</b></h2>
<p>Stop by the Dell, Lenovo and Z by HP booths at <a href="https://www.3dexperienceworld.com/website/59830/home">Dassault Systèmes’ 3DEXPERIENCE World</a>, running Feb. 11-14 at the Kay Bailey Hutchison Convention Center in Dallas, to view live demos of Dassault Systèmes SOLIDWORKS applications powered by the NVIDIA RTX 2000 Ada.</p>
<p>Attend the Z by HP session on Tuesday, Feb. 13, where Wolkers will discuss the workflow used to design <a href="https://nemo-submarine.com/">NEMO</a>, the supercar of submarines.</p>
<p>Read our solution brief to discover how<a href="https://resources.nvidia.com/en-us-mfg-briefcase/proviz-print-solidworks?lx=q8vaLh"> NVIDIA RTX GPUs supercharge SOLIDWORKS workflows</a>.</p>
<p><i>Learn more about the </i><a href="https://www.nvidia.com/en-us/design-visualization/rtx-2000/"><i>NVIDIA RTX 2000 Ada Generation GPU</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/RTX-2000-GPU-Blog-Header.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/RTX-2000-GPU-Blog-Header-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA RTX 2000 Ada Generation GPU Brings Performance, Versatility for Next Era of AI-Accelerated Design and Visualization]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>National Institute of Standards and Technology Launches Artificial Intelligence Safety Institute Consortium</title>
		<link>https://blogs.nvidia.com/blog/aisic-trustworthy-ai/</link>
		
		<dc:creator><![CDATA[Ruth Berry]]></dc:creator>
		<pubDate>Thu, 08 Feb 2024 21:08:28 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cybersecurity]]></category>
		<category><![CDATA[Open Source]]></category>
		<category><![CDATA[Social Impact]]></category>
		<category><![CDATA[Trustworthy AI]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69701</guid>

					<description><![CDATA[NVIDIA has joined the National Institute of Standards and Technology’s new U.S. Artificial Intelligence Safety Institute Consortium as part of the company’s effort to advance safe, secure and trustworthy AI. AISIC will work to create tools, methodologies and standards to promote the safe and trustworthy development and deployment of AI. As a member, NVIDIA will		<a class="read-more" href="https://blogs.nvidia.com/blog/aisic-trustworthy-ai/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>NVIDIA has joined the National Institute of Standards and Technology’s <a href="https://www.commerce.gov/news/press-releases/2024/02/biden-harris-administration-announces-first-ever-consortium-dedicated">new U.S. Artificial Intelligence Safety Institute Consortium</a> as part of the company’s effort to advance safe, secure and <a href="https://www.nvidia.com/en-us/ai-data-science/trustworthy-ai/">trustworthy AI</a>.</p>
<p><a href="https://www.nist.gov/artificial-intelligence/artificial-intelligence-safety-institute">AISIC</a> will work to create tools, methodologies and standards to promote the safe and trustworthy development and deployment of AI. As a member, NVIDIA will work with <a href="https://www.nist.gov/">NIST</a> — an agency of the U.S. Department of Commerce — and fellow consortium members to advance the consortium’s mandate.</p>
<p>NVIDIA’s participation builds on a record of working with governments, researchers and industries of all sizes to help ensure AI is developed and deployed safely and responsibly.</p>
<p>Through a broad range of development initiatives, including <a href="https://blogs.nvidia.com/blog/ai-chatbot-guardrails-nemo/">NeMo Guardrails,</a> open-source software for ensuring large language model responses are accurate, appropriate, on topic and secure, NVIDIA actively works to make AI safety a reality.</p>
<p>In 2023, NVIDIA endorsed the Biden Administration’s <a href="https://blogs.nvidia.com/blog/ai-safety-washington/">voluntary AI safety</a> commitments. Last month, the company announced a $30 million contribution to the U.S. National Science Foundation’s <a href="https://blogs.nvidia.com/blog/national-ai-research-resource-pilot/">National Artificial Intelligence Research Resource pilot program</a>, which aims to broaden access to the tools needed to power responsible AI discovery and innovation.</p>
<h2><b>AISIC Research Focus</b></h2>
<p>Through the consortium, NIST aims to facilitate knowledge sharing and advance applied research and evaluation activities to accelerate innovation in trustworthy AI. AISIC members, which include more than 200 of the nation’s leading AI creators, academics, government and industry researchers, as well as civil society organizations, bring technical expertise in areas such as AI governance, systems and development, psychometrics and more.</p>
<p>In addition to participating in working groups, NVIDIA plans to leverage a range of computing resources and best practices for implementing AI risk-management frameworks and AI model transparency, as well as several NVIDIA-developed, open-source AI safety, <a href="https://blogs.nvidia.com/blog/nvidia-generative-red-team-challenge/">red-teaming</a> and security tools.</p>
<p><i>Learn more about NVIDIA’s guiding principles for </i><a href="https://www.nvidia.com/en-us/ai-data-science/trustworthy-ai/"><i>trustworthy AI</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/04/NeMo-Guardrails-KV-x1280.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/04/NeMo-Guardrails-KV-x1280-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[National Institute of Standards and Technology Launches Artificial Intelligence Safety Institute Consortium]]></media:title>
			<media:description type="html">artist&#039;s concept image of NeMo Guardrails</media:description>
			</media:content>
			</item>
		<item>
		<title>Devices for Days: With GeForce NOW, Every Device Is a Dream Gaming PC</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-four-year-anniversary-the-inquisitor/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 08 Feb 2024 14:00:38 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69663</guid>

					<description><![CDATA[The GeForce NOW anniversary celebrations continue with more games and a member-exclusive discount on the Logitech G Cloud. Among the six new titles coming to the cloud this week is The Inquisitor from Kalypso Media, which spotlights the GeForce NOW anniversary with a special shout-out. “Congrats to four years of empowering gamers to play anywhere,		<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-four-year-anniversary-the-inquisitor/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> anniversary celebrations continue with more games and a member-exclusive discount on the Logitech G Cloud.</p>
<p>Among the six new titles coming to the cloud this week is <i>The Inquisitor</i> from Kalypso Media, which spotlights the GeForce NOW anniversary with a special shout-out.</p>
<p>“Congrats to four years of empowering gamers to play anywhere, anytime,” said Marco Nier, head of marketing and public relations at Kalypso Media. “We’re thrilled to raise a glass to GeForce NOW for their four-year anniversary and commitment to bringing AAA gaming to gamers — here’s to many more chapters in this cloud-gaming adventure!”</p>
<p>Stream the dark fantasy adventure from Kalypso Media and more newly supported titles today across a variety of GeForce NOW-capable devices, whether at home, on a gaming rig, TV or Mac, or on the go with handheld streaming.</p>
<h2><b>Gadgets Galore</b></h2>
<figure id="attachment_69670" aria-describedby="caption-attachment-69670" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-69670" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Devices-672x336.jpg" alt="GeForce NOW anniversary - device ecosystem" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Devices-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Devices-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Devices-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Devices-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Devices-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Devices-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Devices-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Devices-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Devices.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69670" class="wp-caption-text"><em>Play on!</em></figcaption></figure>
<p>Gone are the days of only being able to play full PC games on a decked-out gaming rig. GeForce NOW is a cloud gaming service accessible on a range of devices, from PCs and Macs to gaming handhelds, thanks to <a href="https://www.nvidia.com/en-us/geforce/rtx/">GeForce RTX</a>-powered servers in the cloud.</p>
<p>Dive into the cloud streaming experience with the dedicated GeForce NOW app for Windows and macOS. Even on underpowered PCs, gamers can enjoy stunning visuals and buttery-smooth frame rates streaming at up to 240 frames per second or at ultrawide resolutions for Ultimate members, a cloud-gaming first.</p>
<p>Take it to the big screen and stream graphically demanding titles, from <i>The Witcher 3</i> to <i>Alan Wake 2</i>, on GeForce NOW from the comfort of the couch at up to 4K natively on Samsung and LG Smart TVs, without the need for a console. Or stream across any TV with <a href="https://www.nvidia.com/en-us/shield/">NVIDIA SHIELD TV</a> for the ultimate living room gaming experience.</p>
<p><iframe loading="lazy" title="GeForce NOW: Power The Cloud With Chromebook Plus" width="500" height="281" src="https://www.youtube.com/embed/Yf-zZWkyfLM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Gamers on the go can drop into the neon lights of <i>Cyberpunk</i> <i>2077</i> and other ray tracing-supported titles on a portable, lightweight <a href="https://www.chromebook.com/gaming">Chromebook</a> and stream up to 1600p at 120 fps. GeForce NOW members can also stream to <a href="https://blogs.nvidia.com/blog/geforce-now-thursday-android-higher-resolutions/">Android devices at new higher resolutions</a>, up to 1440p at 120 fps.</p>
<figure id="attachment_69673" aria-describedby="caption-attachment-69673" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-69673" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Logitech_G_Cloud-672x336.jpg" alt="Logitech G Cloud with GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Logitech_G_Cloud-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Logitech_G_Cloud-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Logitech_G_Cloud-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Logitech_G_Cloud-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Logitech_G_Cloud-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Logitech_G_Cloud-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Logitech_G_Cloud-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Logitech_G_Cloud-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-Logitech_G_Cloud.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69673" class="wp-caption-text"><em>Look, ma, no wires.</em></figcaption></figure>
<p>Go hands-on with any of the new handheld gaming devices supported by GeForce NOW, from the <a href="https://www.asus.com/us/site/gaming/rog/gaming-handheld/rog-ally.html">ASUS ROG Ally</a> to the <a href="https://www.logitechg.com/">Logitech G Cloud</a>. The Logitech G Cloud is an Android device with a seven-inch 1080p 16:9 touchscreen, fully customizable controls and support for GeForce NOW right out of the box.</p>
<p>The Logitech G Cloud is normally priced at $349.99, but Logitech and GeForce NOW are providing a 20% discount to the first 500 Ultimate and Priority members that grab the code from the <a href="https://www.nvidia.com/en-us/geforce-now/rewards/">GeForce NOW Rewards portal</a>, a deal available until March 8. On top of that, follow the <a href="https://www.instagram.com/nvidiagfn?utm_source=ig_web_button_share_sheet&amp;igsh=ZDNlZDc0MzIxNw==">GeForce NOW</a> and Logitech social channels for a chance to win a Logitech G Cloud during the anniversary celebrations this month.</p>
<p>Whether playing at home or on the go, members can game freely on GeForce NOW without having to worry about download times or system specs.</p>
<h2><b>Celebrate With New Games</b></h2>
<figure id="attachment_69676" aria-describedby="caption-attachment-69676" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-69676" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-The_Inquisitor-672x336.jpg" alt="The Inquisitor on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-The_Inquisitor-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-The_Inquisitor-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-The_Inquisitor-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-The_Inquisitor-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-The_Inquisitor-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-The_Inquisitor-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-The_Inquisitor-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-The_Inquisitor-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/02/GFN_Thursday-The_Inquisitor.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69676" class="wp-caption-text"><em>Jesus, take the wheel.</em></figcaption></figure>
<p>Dive into an alternate reality in the world of <i>The Inquisitor</i>, where Jesus has escaped from the cross. Play as Mordimer Madderdin, an inquisitor who investigates a mysterious murder in the town of Koenigstein. Face moral choices, visit the dangerous Unworld and fight against sinners.</p>
<p>The title leads the six new games this week. Here’s the full list:</p>
<ul>
<li><i>Stormgate </i>(Demo on <a href="https://store.steampowered.com/app/2012510?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, available Feb. 5-12 during Steam Next Fest)</li>
<li><i>The Inquisitor </i>(New release on <a href="https://store.steampowered.com/app/1880470?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Feb. 8)</li>
<li><i>Aragami 2 </i>(<a href="https://www.xbox.com/games/store/aragami-2/9PN9WG83X4XF?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>art of rally </i>(<a href="https://www.xbox.com/games/store/art-of-rally/9P6JQDDZ2MQB?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>dotAGE</i> (<a href="https://store.steampowered.com/app/638510?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Tram Simulator Urban Transit </i>(<a href="https://store.steampowered.com/app/2546690?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>The Walking Dead: The Telltale Definitive Series </i>(<a href="https://store.steampowered.com/app/1449690?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">First device you played GFN on versus your last <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f447.png" alt="👇" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>(bonus points for pictures)</p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1755275230388359517?ref_src=twsrc%5Etfw">February 7, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-thursday-date-nv-blog-1280x680-no-logos.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/gfn-thursday-date-nv-blog-1280x680-no-logos-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Devices for Days: With GeForce NOW, Every Device Is a Dream Gaming PC]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Beyond ‘Data-Driven’: How Energy-Efficient Computing for AI Is Propelling Innovation and Savings Across Industries</title>
		<link>https://blogs.nvidia.com/blog/energy-efficient-ai-industries/</link>
		
		<dc:creator><![CDATA[Shar Narasimhan]]></dc:creator>
		<pubDate>Wed, 07 Feb 2024 16:00:11 +0000</pubDate>
				<category><![CDATA[Accelerated Analytics]]></category>
		<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Networking]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[Supercomputing]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Climate]]></category>
		<category><![CDATA[Embedded Computing]]></category>
		<category><![CDATA[Energy]]></category>
		<category><![CDATA[Financial Services]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[Industrial and Manufacturing]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[Jetson]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Media and Entertainment]]></category>
		<category><![CDATA[NVIDIA BlueField]]></category>
		<category><![CDATA[RAPIDS]]></category>
		<category><![CDATA[Telecommunications]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69597</guid>

					<description><![CDATA[With advances in computing, sophisticated AI models and machine learning are having a profound impact on business and society. Industries can use AI to quickly analyze vast bodies of data, allowing them to derive meaningful insights, make predictions and automate processes for greater efficiency. In the public sector, government agencies are achieving superior disaster preparedness.		<a class="read-more" href="https://blogs.nvidia.com/blog/energy-efficient-ai-industries/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>With advances in computing, sophisticated AI models and machine learning are having a profound impact on business and society. Industries can use AI to quickly analyze vast bodies of data, allowing them to derive meaningful insights, make predictions and automate processes for greater efficiency.</p>
<p>In the public sector, government agencies are achieving superior disaster preparedness. Biomedical researchers are bringing novel drugs to market faster. Telecommunications providers are building more energy-efficient networks. Manufacturers are trimming emissions from product design, development and manufacturing processes. Hollywood studios are creating impressive visual effects at a fraction of the cost and time. Robots are being deployed on important missions to help preserve the Earth. And investment advisors are running more trade scenarios to optimize portfolios.</p>
<p><a href="https://newsroom.ibm.com/2024-01-10-Data-Suggests-Growth-in-Enterprise-Adoption-of-AI-is-Due-to-Widespread-Deployment-by-Early-Adopters#:~:text=Today%2C%C2%A042%25%C2%A0of%20IT%20professionals%20at%20large%20organizations%20report%20that%20they%20have%20actively%20deployed%20AI%20while%20an%20additional%C2%A040%25%C2%A0are%20actively%20exploring%20using%20the%20technology.%C2%A0">Eighty-two percent</a> of companies surveyed are already using or exploring AI, and <a href="https://www.wavestone.us/insights/data-and-analytics-leadership-annual-executive-survey-2023/">84%</a> report that they’re increasing investments in data and AI initiatives. Any organization that delays AI implementation risks missing out on new efficiency gains and becoming obsolete.</p>
<p>However, AI workloads are computationally demanding, and legacy computing systems are ill-equipped for the development and deployment of AI. CPU-based compute requires linear growth in power input to meet the increased processing needs of AI and data-heavy workloads. If data centers are using carbon-based energy, it’s impossible for enterprises to innovate using AI while controlling greenhouse gas emissions and meeting sustainability commitments. Plus, many countries are introducing tougher regulations to enforce data center carbon reporting.</p>
<p><a href="https://www.nvidia.com/en-us/data-center/solutions/accelerated-computing/?ncid=so-link-420754-vt21">Accelerated computing</a> — the use of GPUs and special hardware, software and parallel computing techniques — has exponentially improved the performance and <a href="https://www.nvidia.com/en-us/glossary/energy-efficiency/?ncid=so-link-787991">energy efficiency</a> of data centers.</p>
<p>Below, read more on how industries are using energy-efficient computing to scale AI, improve products and services, and reduce emissions and operational costs.</p>
<h2><strong>The Public Sector Drives Research, Delivers Improved Citizen Services </strong></h2>
<p>Data is playing an increasingly important role in government services, including for public health and disease surveillance, scientific research, social security administration, and extreme-weather monitoring and management. These operations require platforms and systems that can handle large volumes of data, provide real-time data access, and ensure data quality and accuracy.</p>
<p>But many government agencies rely on legacy systems that are difficult to maintain, don&#8217;t efficiently integrate with modern technologies and consume excessive energy. To handle increasingly demanding workloads while sticking to sustainability goals, government agencies and public organizations must adopt more efficient computing solutions.</p>
<p>The U.S. Department of Energy is making inroads in this endeavor. The department runs the National Energy Research Scientific Computing Center for open science. NERSC develops simulations, data analytics and machine learning solutions to accelerate scientific discovery through computation. Seeking new computing efficiencies, the center measured results across four of its key high performance computing and AI applications. It clocked how fast the applications ran, as well as how much energy they consumed using CPU-only versus GPU-accelerated nodes on <a href="https://blogs.nvidia.com/blog/nersc-perlmutter-ai-supercomputer/">Perlmutter</a>, one of the world’s largest supercomputers.</p>
<p>At performance parity, a GPU-accelerated cluster consumes <a href="https://resources.nvidia.com/en-us-energy-efficiency/gpu-energy-efficiency">588 less megawatt hours per month</a>, representing a 5x improvement in energy efficiency. By running the same workload on GPUs rather than CPU-only instances, researchers could save millions of dollars per month. These gains mean that the 8,000+ researchers using NERSC computing infrastructure can perform more experiments on important use cases, like studying subatomic interactions to uncover new green energy sources, developing 3D maps of the universe and bolstering a broad range of innovations in materials science and quantum physics.</p>
<p>Governments help protect citizens from adverse weather events, such as hurricanes, floods, blizzards and heat waves. With GPU deployments, climate models, like the IFS model from the European Centre for Medium-Range Weather Forecasts, can run up <a href="https://resources.nvidia.com/en-us-energy-efficiency/faster-weather-prediction">to 24x faster</a> while reducing annual energy usage by up to 127 gigawatt hours compared to CPU-only systems. As extreme-weather events occur with greater frequency and, often, with little warning, meteorology centers can use accelerated computing to generate more accurate, timely forecasts that improve readiness and response.</p>
<p>By adopting more efficient computing systems, governments can save costs while equipping researchers with the tools they need for scientific discoveries to improve climate modeling and forecasting, as well as deliver superior services in public health, disaster relief and more.</p>
<h2><strong>Drug Discovery Researchers Conduct Virtual Screenings, Generate New Proteins at Light Speed</strong></h2>
<p>Drug development has always been a time-consuming process that involves innumerable calculations and thousands of experiments to screen new compounds. To develop novel medications, the binding properties of small molecules must be tested against protein targets, a cumbersome task required for up to billions of compounds — which translates to billions of CPU hours and hundreds of millions of dollars each year.</p>
<p>Highly accurate AI models can now predict protein structures, generate small molecules, predict protein-ligand binding and perform virtual screening.</p>
<p>Researchers at <a href="https://blogs.nvidia.com/blog/covid-autodock-summit-ornl/">Oak Ridge National Laboratory</a> (ORNL) and Scripps Research have shown that screening a dataset of billions of compounds against a protein, which has traditionally taken years, can now be completed in just hours with accelerated computing. By running <a href="https://ngc.nvidia.com/catalog/containers/hpc:autodock">AutoDock</a>, a molecular-modeling simulation software, on a supercomputer with more than 27,000 NVIDIA GPUs, ORNL screened more than 25,000 molecules per second and evaluated the docking of 1 billion compounds in less than 12 hours. This is a speedup of more than 50x compared with running AutoDock on CPUs.</p>
<p><a href="https://www.iambic.ai/">Iambic</a>, an AI platform for drug discovery, has developed an approach combining quantum chemistry and AI that calculates quantum-accurate molecular-binding energies and forces at a fraction of the computational expense of traditional methods. These energies and forces can power molecular-dynamics simulations at unprecedented speed and accuracy. With its OrbNet model, Iambic uses a graph <a href="https://blogs.nvidia.com/blog/what-is-a-transformer-model/">transformer</a> to power quantum-mechanical operators that represent chemical structures. The company is using the technology to identify drug molecules that could deactivate proteins linked to certain cancer types.</p>
<p>As the number of new drug approvals declines and research and development and computing costs rise, optimizing drug discovery with accelerated computing can help control energy expenditures while creating a far-reaching impact on medical research, treatments and patient outcomes.</p>
<h2><strong>Telcos Scale Network Capacity</strong></h2>
<p>To connect their subscribers, telecommunications companies send data across sprawling networks of cell towers, fiber-optic cables and wireless signals. In the U.S., AT&amp;T’s network connects more than 100 million users from the Aleutian Islands in Alaska to the Florida Keys, processing <a href="https://www.nvidia.com/en-us/on-demand/session/gtcfall22-a41235/">500 petabytes of data per day</a>. As telcos add compute-intensive workloads like AI and user plane function (UPF) to process and route data over 5G networks, power consumption costs are skyrocketing.</p>
<p>AT&amp;T processes trillions of data rows to support field technician dispatch operations, generate performance reports and power mobile connectivity. To process data faster, <a href="https://blogs.nvidia.com/blog/att-data-science-rapids/">AT&amp;T tested the NVIDIA RAPIDS Accelerator for Apache Spark</a>. By spreading work across nodes in a cluster, the software processed 2.8 trillion rows of information — a month’s worth of mobile data — in just five hours. That’s 3.3x faster at 60% lower cost than any prior test.</p>
<p>Other telcos are saving energy by offloading networking and security tasks to <a href="https://blogs.nvidia.com/blog/what-is-a-smartnic/">SmartNICs</a> and data processing units (<a href="https://blogs.nvidia.com/blog/whats-a-dpu-data-processing-unit/">DPUs</a>) to reduce server power consumption. Ericsson, a leading telecommunications equipment manufacturer, tested a 5G UPF on servers with and without network offload to an <a href="https://resources.nvidia.com/en-us-accelerated-networking-resource-library-ms/en-us-accelerated-networking-resource-library/nvidia-dpu-power-eff">NVIDIA ConnectX-6 Dx NIC</a>. At maximum network traffic, the network offloading provided 23% power savings. The study also found that CPU micro-sleeps and frequency scaling — allowing CPUs to sleep and slow their clock frequencies during low workload levels — saved more than 10% of power per CPU.</p>
<p>Hardware-accelerated networking offloads like these allow telco operators to increase network capacity without a proportional increase in energy consumption, ensuring that networks can scale to handle increased demand and conserve energy during times of low use. By adopting energy-efficient accelerated computing, telco operators can reduce their carbon footprint, improve scalability and lower operational costs.</p>
<h2><strong>Manufacturing and Product Design Teams Achieve Faster, Cleaner Simulations</strong></h2>
<p>Many industries rely on computational fluid dynamics during design and engineering processes to model fluid flows, combustion, heat transfer and aeroacoustics. The aerospace and automotive industries use CFD to model vehicle aerodynamics, and the energy and environmental industries use it to optimize fluid-particle refining systems and model reactions, wind-farm air flow and hydro-plant water flow.</p>
<p>Traditional CFD methods are compute-intensive, using nearly 25 billion CPU core hours annually, and consume massive amounts of energy. This is a major obstacle for industrial companies looking to reduce carbon emissions and achieve net zero. Parallel computing with GPUs is making a difference.</p>
<p><a href="https://www.ansys.com/blog/unleashing-the-full-power-of-gpus-for-ansys-fluent">Ansys, an engineering simulation company, is speeding up CFD physics models</a> with GPUs to help customers drastically reduce emissions while improving the aerodynamics of vehicles. To measure computing efficiency, the company ran the benchmark DrivAer model, used for optimizing vehicle geometry, on different CPU and GPU configurations using its Fluent fluid-simulation software. Results showed that a single GPU achieved more than 5x greater performance than a cluster with 80 CPU cores. With eight GPUs, the simulation experienced more than a 30x speedup. And a server with six GPUs reduced power consumption 4x compared with a <a href="https://www.nvidia.com/en-us/glossary/high-performance-computing/">high performance computing</a> CPU cluster delivering the same performance.</p>
<p>CPFD offers <a href="https://resources.nvidia.com/en-us-isv-energy-industry/energy-solution-show-1">GPU parallelization for Barracuda Virtual Reactor</a>, a physics-based engineering software package capable of predicting fluid, particulate-solid, thermal and chemically reacting behavior in fluidized bed reactors and other fluid-particle systems.</p>
<p>Using CPFD’s Barracuda software, green energy supplier ThermoChem Recovery International (TRI) developed technology that converts municipal solid waste and woody biomass into jet fuel. Since its partnership with CPFD began 14 years ago, TRI has benefitted from 1,500x model speedups as CPFD moved its code from CPU hardware to full GPU parallelization. With these exponential speedups, models that would’ve previously taken years to run can now be completed in a day or less, saving millions of dollars in data center infrastructure and energy costs.</p>
<p>With GPU parallelization and energy-efficient architectures, industrial design processes that rely on <a href="https://resources.nvidia.com/en-us-energy-efficiency/energy-efficiency-vehicles">CFD can benefit from dramatically faster simulations</a> while achieving significant energy savings.</p>
<h2><strong>Media and Entertainment Boost Rendering</strong></h2>
<p>Rendering visual effects (VFX) and stylized animations consumes nearly 10 billion CPU core hours per year in the media and entertainment industry. A single animated film can require over 50,000 CPU cores working for more than 300 million hours. Enabling this necessitates a large space for data centers, climate control and computing — all of which result in substantial expenditures and a sizable carbon footprint.</p>
<p>Accelerated computing offers a more energy-efficient way to produce VFX and animation, enabling studios to iterate faster and compress production times.</p>
<p>Studios like Wylie Co., known for visuals in the Oscar-winning film <i>Dune</i> and in HBO and Netflix features, are adopting GPU-powered rendering to improve performance and save energy. After migrating to GPU rendering, <a href="https://resources.nvidia.com/en-us-energy-efficiency/wylie-co-gpu-renderi">Wylie Co. realized a 24x performance</a> boost over CPUs.</p>
<p>Image Engine, a VFX company involved in creating Marvel Entertainment movies and <i>Star Wars</i>-based television shows, observed a 25x performance improvement by using GPUs for rendering.</p>
<p>GPUs can increase performance up to 46x while <a href="https://resources.nvidia.com/en-us-energy-efficiency/energy-efficiency-so-1">reducing energy consumption by 10x</a> and capital expenses by 6x. With accelerated computing, the media and entertainment industry has the potential to save a staggering $900 million in hardware acquisition costs worldwide and conserve 215 gigawatt hours of energy that would have been consumed by CPU-based render farms. Such a shift would lead to substantial cost savings and significant reductions in the industry’s environmental impact.</p>
<h2><strong>Robotics Developers Extend Battery Life for Important Missions </strong></h2>
<p>With <a href="https://blogs.nvidia.com/blog/what-is-edge-computing/">edge</a> AI and supercomputing now available using compact modules, demand for robots is surging for use in factory logistics, sales showrooms, urban delivery services and even ocean exploration. Mobile robot shipments are expected to climb from 549,000 units last year to 3 million by 2030, with revenue forecast to jump from more than $24 billion to $111 billion in the same period, according to <a href="https://www.abiresearch.com/market-research/product/market-data/MD-CIROBO/">ABI Research</a>.</p>
<p>Most robots are battery-operated and rely on an array of lidar sensors and cameras for navigation. Robots communicate with edge servers or clouds for mission dispatch and require high throughput due to diverse sets of camera sensors as well as low latency for real-time decision-making. These factors necessitate energy-efficient onboard computing.</p>
<p>Accelerated edge computing can be optimized to decode images, process video and analyze lidar data to enable robot navigation of unstructured environments. This allows developers to build and deploy more energy-efficient machines that can remain in service for longer without needing to charge.</p>
<p>The Woods Hole Oceanographic Institution Autonomous Robotics and Perception Laboratory (<a href="https://warp.whoi.edu/">WARPLab</a>) and MIT are using the <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">NVIDIA Jetson Orin</a> platform for energy-efficient edge AI and robotics to power an autonomous underwater vehicle to <a href="https://blogs.nvidia.com/blog/coral-reef-decline-curee-robot-jetson-isaac-omniverse/">study coral reefs</a>.</p>
<p>The AUV, named CUREE, for Curious Underwater Robot for Ecosystem Exploration, gathers visual, audio and other environmental data to help understand the human impact on reefs and sea life. With 25% of the vehicle’s power needed for data collection, energy efficiency is a must. With Jetson Orin, CUREE constructs 3D models of reefs, tracks marine organisms and plant life, and autonomously navigates and gathers data. The AUV’s onboard energy-efficient computing also powers convolutional neural networks that enhance underwater vision by reducing backscatter and correcting colors. This enables CUREE to transmit clear images to scientists, facilitating fish detection and reef analysis.</p>
<p>Driverless smart tractors with energy-efficient edge computing are now available to help farmers with automation and data analysis. The <a href="https://blogs.nvidia.com/blog/mondavi-monarch-smart-electric-jetson-tractor/">Founder Series MK-V tractors</a>, designed by <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a> member Monarch Tractor, combine electrification, automation and data analysis to help farmers reduce their carbon footprint, improve field safety and streamline farming operations. Using onboard AI video analytics, the tractor can traverse rows of crops, enabling it to navigate even in remote areas without connectivity or GPS.</p>
<p>The MK-V tractor produces zero emissions and is estimated to save farmers $2,600 annually compared to diesel tractors. The tractor’s AI data analysis advises farmers on how to reduce the use of expensive, harmful herbicides that deplete the soil. Decreasing the volume of chemicals is a win all around, empowering farmers to protect the quality of soil, reduce herbicide expenditures and deliver more naturally cultivated produce to consumers.</p>
<p>As energy-efficient edge computing becomes more accessible to enable AI, expect to see growing use cases for mobile robots that can navigate complex environments, make split-second decisions, interact with humans and safely perform difficult tasks with precision.</p>
<h2><strong>Financial Services Use Data to Inform Investment Decisions </strong></h2>
<p>Financial services is an incredibly data-intensive industry. Bankers and asset managers pursuing the best results for investors rely on AI algorithms to churn through terabytes of unstructured data from economic indicators, earnings reports, news articles, and disparate environmental, social and governance metrics to generate market insight that inform investments. Plus, financial services companies must comb through network data and transactions to prevent fraud and protect accounts.</p>
<p>NVIDIA and Dell Technologies are optimizing computing for financial workloads to achieve higher throughput, speed and capacity with greater energy efficiency. The Strategic Technology Analysis Center, an organization dedicated to technology discovery and assessment in the finance industry, recently <a href="https://www.stacresearch.com/news/NVDA231030">tested the STAC-A2 benchmark tests</a> on several computing stacks comprising CPU-only infrastructure and GPU-based infrastructure. The STAC-A2 benchmark is designed by quants and technologists to measure the performance, scalability, quality and resource efficiency of technology stacks running market-risk analysis for derivatives.</p>
<p>When testing the STAC-A2 options pricing benchmark, the Dell PowerEdge server with NVIDIA GPUs performed 16x faster and 3x more energy efficiently than a CPU-only system for the same workload. This enables investment advisors to integrate larger bodies of data into derivatives risk-analysis calculations, enabling more data-driven decisions without increasing computing time or energy requirements.</p>
<p>PayPal, which was looking to deploy a new fraud-detection system to operate 24/7, worldwide and in real time to protect customer transactions, realized CPU-only servers couldn’t meet such computing requirements. Using NVIDIA GPUs for <a href="https://www.nvidia.com/en-us/deep-learning-ai/solutions/inference-platform/">inference</a>, PayPal improved real-time fraud detection by 10% and <a href="https://developer.nvidia.com/blog/gpu-inference-momentum-continues-to-build/">lowered server energy consumption by nearly 8x</a>.</p>
<p>With accelerated computing, financial services organizations can run more iterations of investment scenarios, improve risk assessments and make more informed decisions for better investment results. Accelerated computing is the foundation for improving data throughput, reducing latency and optimizing energy usage to lower operating costs and achieve emissions goals.</p>
<h2><strong>An AI Future With Energy-Efficient Computing</strong></h2>
<p>With energy-efficient computing, enterprises can reduce data center costs and their carbon footprint while scaling AI initiatives and data workloads to stay competitive.</p>
<p>The NVIDIA accelerated computing platform offers a comprehensive suite of energy-efficient hardware and software to help enterprises use AI to drive innovation and efficiency without the need for equivalent growth in energy consumption.</p>
<p>With more than 100 frameworks, <a href="https://blogs.nvidia.com/blog/what-is-a-pretrained-ai-model/">pretrained models</a> and development tools optimized for GPUs, <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> accelerates the entire AI journey, from data preparation and model training to inference and scalable deployment. By getting their AI into production faster, businesses can significantly reduce overall power consumption.</p>
<p>With the <a href="https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/apache-spark-3/">NVIDIA RAPIDS Accelerator for Apache Spark</a>, which is included with NVIDIA AI Enterprise, data analytics workloads can be completed 6x faster, translating to 5x savings on infrastructure and <a href="https://resources.nvidia.com/en-us-energy-efficiency/energy-efficiency-so-2">6x less power used</a> for the same amount of work. For a typical enterprise, this means 10 gigawatt hours less energy consumed compared with running jobs without GPU acceleration.</p>
<p><a href="https://www.nvidia.com/en-us/networking/products/data-processing-unit/">NVIDIA BlueField DPUs</a> bring greater energy efficiency to data centers by offloading and accelerating data processing, networking and security tasks from the main CPU infrastructure. By maximizing performance per watt, they can help enterprises <a href="https://resources.nvidia.com/en-us-accelerated-networking-resource-library/nvidia-dpu-power-eff">slash server power consumption by up to 30%</a>, saving millions in data center costs.</p>
<p>As businesses shift to a new paradigm of AI-driven results, energy-efficient accelerated computing is helping organizations deliver on the promise of AI while controlling costs, maintaining sustainable practices and ensuring they can keep up with the pace of innovation.</p>
<p><i>Learn how </i><a href="https://www.nvidia.com/en-us/data-center/solutions/accelerated-computing/"><i>accelerated computing</i></a><i> can help organizations achieve both AI goals and carbon-footprint objectives. </i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/energy-efficiency.jpeg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/energy-efficiency-842x450.jpeg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Beyond ‘Data-Driven’: How Energy-Efficient Computing for AI Is Propelling Innovation and Savings Across Industries]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Twitch Streamer Mr_Vudoo Supercharges Gaming, Entertaining and Video Editing With RTX This Week ‘In the NVIDIA Studio’</title>
		<link>https://blogs.nvidia.com/blog/studio-nvenc-geforce-rtx-twitch-davinci-resolve-adobe-photoshop/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 06 Feb 2024 14:00:36 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69625</guid>

					<description><![CDATA[Mr_Vudoo is a digital renaissance man — a livestreamer, video editor, gamer and entertainer skilled in producing an array of content for his audience. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. We’re also deep diving on new </i><a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/"><i>GeForce RTX 40 Series GPU</i></a><i> features, technologies and resources, and how they dramatically accelerate content creation.</i></p>
<p>Mr_Vudoo is a digital renaissance man — a livestreamer, video editor, gamer and entertainer skilled in producing an array of content for his audience.</p>
<p>This week’s featured artist <i>In the NVIDIA Studio</i>, he recently acquired a new GeForce RTX 4080 SUPER graphics card, which helps creators like him take their content to the next level. (Read more about the 4080 SUPER below.)</p>
<p>There’s no better place for creative types to connect with others and explore what’s next in AI and accelerated computing than GTC, which is back in-person, from March 18-21 in San Jose.</p>
<p>From the keynote by NVIDIA founder and CEO Jensen Huang to hundreds of sessions, exhibits and networking events, GTC delivers something for every technical level and interest area, including <a href="https://www.nvidia.com/gtc/session-catalog/?tab.allsessions=1700692987788001F1cG#/">sessions</a> on how to power content creation using OpenUSD and generative AI. <a href="https://www.nvidia.com/gtc/pricing/">GTC registration is open</a> for virtual or in-person attendance.</p>
<figure id="attachment_69626" aria-describedby="caption-attachment-69626" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-mr-vudoo-wk95-web-drmk-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69626" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-mr-vudoo-wk95-web-drmk-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-mr-vudoo-wk95-web-drmk-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-mr-vudoo-wk95-web-drmk-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-mr-vudoo-wk95-web-drmk-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-mr-vudoo-wk95-web-drmk-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-mr-vudoo-wk95-web-drmk-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-mr-vudoo-wk95-web-drmk-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-mr-vudoo-wk95-web-drmk-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69626" class="wp-caption-text">Join sessions like “What’s Next in Generative AI” in person or virtually.</figcaption></figure>
<p>In other NVIDIA Studio news, Topaz Labs, a company that delivers AI-powered photo and video enhancement software, recently adopted <a href="https://developer.nvidia.com/tensorrt">NVIDIA TensorRT</a> acceleration for its new Remove Tool. It uses AI to replace unwanted objects in an image with a context-aware background. The tool expedites photo editing workflows, delivering 2.4x faster processing on a GeForce RTX 4090 GPU compared with an Apple MacBook M3 Max.</p>
<div class="mceTemp"></div>
<figure id="attachment_69629" aria-describedby="caption-attachment-69629" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/topaz-labs-studio-mr-vudoo-wk95-photoshop-ai-selection-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69629" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/topaz-labs-studio-mr-vudoo-wk95-photoshop-ai-selection-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/topaz-labs-studio-mr-vudoo-wk95-photoshop-ai-selection-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/topaz-labs-studio-mr-vudoo-wk95-photoshop-ai-selection-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/topaz-labs-studio-mr-vudoo-wk95-photoshop-ai-selection-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/topaz-labs-studio-mr-vudoo-wk95-photoshop-ai-selection-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2024/02/topaz-labs-studio-mr-vudoo-wk95-photoshop-ai-selection-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2024/02/topaz-labs-studio-mr-vudoo-wk95-photoshop-ai-selection-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/02/topaz-labs-studio-mr-vudoo-wk95-photoshop-ai-selection-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69629" class="wp-caption-text">Topaz Lab’s TensorRT-powered Remove Tool removes unwanted objects with just a click.</figcaption></figure>
<h2><b>Mr_Vudoo Taps RTX for a Livestreaming Upgrade</b></h2>
<p>Mr_Vudoo’s Twitch channel is known for its variety of unique content. In his <i>Trading Card Games</i> series, Mr_Vudoo opens trading card packs and competes at one of the highest levels live on stream. In his <i>Gameplay</i> series, he goes back to his original love for gaming, streaming both multiplayer online games and third-person shooters. And in his <i>In Real Life</i> series, he breaks the norm of traditional streaming bringing his viewers outside to share his everyday life experiences.</p>
<p>It takes significant computing power to bring these series to life. Mr_Vudoo’s GeForce RTX 4080 SUPER features the eighth-generation <a href="https://developer.nvidia.com/video-codec-sdk">NVIDIA NVENC</a> — an independent component for encoding video that frees up the system to run games or tackle other compute-intensive tasks. Using it, Mr_Vudoo can achieve a more seamless streaming experience.</p>
<p>“It’s a revelation to stream with high-quality settings and get almost no performance loss in games,” he said.</p>
<p>Mr_Vudoo can also join in the new Twitch Enhanced Broadcasting beta, powered by GeForce RTX GPUs and NVENC, to broadcast up to three resolutions simultaneously at up to 1080p. This eliminates the need to trade off resolution for stream reliability.</p>
<p>In the coming months, Enhanced Broadcasting beta testers will be able to experiment with higher input bit rates, up to 4K resolutions, support for up to five concurrent streams and new codecs.</p>
<p><iframe loading="lazy" title="Twitch Enhanced Broadcasting (Multi-Encode Streaming) Powered by NVIDIA GeForce RTX GPUs" width="500" height="281" src="https://www.youtube.com/embed/gMtA3fFnXZk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Mr_Vudoo uses a number of AI-enabled features in the video and photo editing part of his creative workflow. With RTX acceleration, he can add a video camera effect with a timed zoom and a film strip transition in real time without having to render the entire project.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-69625-2" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-mr-vudoo-wk95-davinci-clip-1280w.mp4?_=2" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-mr-vudoo-wk95-davinci-clip-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-mr-vudoo-wk95-davinci-clip-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>“Adding multiple effects on a clip without affecting the preview of the video is a massive time-saver,” he said.</p>
<p>DaVinci Resolve has several RTX-accelerated AI features that can boost content creation, offering tools to smooth slow-motion effects or provide seamless video super resolution. These features are available to all RTX GPU owners.</p>
<p>“GeForce RTX graphics cards are the best GPUs for video editors to use, as they can render tasks much faster, allowing us to become more efficient with our work.” — Mr_Vudoo</p>
<p><iframe loading="lazy" title="Speed Up Your DaVinci Resolve 18 Workflow: 3 New AI Tools" width="500" height="281" src="https://www.youtube.com/embed/PeUPWEtIZc0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Mr_Vudoo can quickly export files with the RTX 4080 SUPER’s dual encoders, which work in tandem to slash export times nearly in half.</p>
<p><iframe loading="lazy" title="Faster Video Editing with GeForce RTX 40 Series GPUs &amp; DaVinci Resolve" width="500" height="281" src="https://www.youtube.com/embed/DhBFuU8Gnik?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>In post-production, Mr_Vudoo uses Adobe Photoshop’s AI-powered subject selection tool to quickly isolate objects in an image, instead of having to manually crop them out, speeding his work.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-69625-3" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-mr-vudoo-wk95-photoshop-ai-selection-1280w.mp4?_=3" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-mr-vudoo-wk95-photoshop-ai-selection-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-mr-vudoo-wk95-photoshop-ai-selection-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>Mr_Vudoo also taps the free <a href="https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/">NVIDIA Broadcast app</a> to boost his productivity.</p>
<p>“I’ve utilized the video noise removal and background replacement the most,” he said. “The eye contact feature was very interesting and quite honestly took me by surprise at how well it worked.”</p>
<p>AI has become an irreplaceable part of Mr_Vudoo’s content creation process, helping him quickly and effortlessly produce his best work. Catch him on <a href="https://www.twitch.tv/mr_vudoo">Twitch</a>.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-69625-4" width="1280" height="500" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-bozo-balov-wk86-artist-feature-1280w.mp4?_=4" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-bozo-balov-wk86-artist-feature-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-bozo-balov-wk86-artist-feature-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<h2><b>RTX 4080 SUPER Brings Super Performance</b></h2>
<p>GeForce RTX 4080 SUPER graphics cards are changing the content creation game.</p>
<p>Generative AI apps like Adobe Photoshop can take advantage of the GPU’s Tensor Cores to speed productivity and creative workflows. With the 4080 SUPER, 3D apps like Blender can run up to 70% faster than on previous-generation graphics cards. And video editing apps like Blackmagic Design’s DaVinci Resolve can accelerate AI effects over 30% faster than with the GeForce RTX 3080 Ti.</p>
<p>For gamers, the RTX 4080 SUPER enables greater immersion, with fully ray-traced visuals and the ability to run all settings at max. It delivers twice the speed of the RTX 3080 Ti, up to 836 trillion operations per second, in the most graphically intensive games with DLSS Frame Generation.</p>
<figure id="attachment_69641" aria-describedby="caption-attachment-69641" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-brandon-tieh-wk94-geforce-rtx-4080-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69641" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-brandon-tieh-wk94-geforce-rtx-4080-1280w-672x353.png" alt="" width="672" height="353" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-brandon-tieh-wk94-geforce-rtx-4080-1280w-672x353.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-brandon-tieh-wk94-geforce-rtx-4080-1280w-400x210.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-brandon-tieh-wk94-geforce-rtx-4080-1280w-768x403.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-brandon-tieh-wk94-geforce-rtx-4080-1280w-842x442.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-brandon-tieh-wk94-geforce-rtx-4080-1280w-406x213.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-brandon-tieh-wk94-geforce-rtx-4080-1280w-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-brandon-tieh-wk94-geforce-rtx-4080-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69641" class="wp-caption-text">Get creative and AI superpowers with the GeForce RTX 4080 SUPER.</figcaption></figure>
<p>Since its release, GeForce RTX 4080 SUPER Series GPUs have been put to the test in creating, gaming and other AI-powered tasks. Here’s what some reviewers had to say:</p>
<ul>
<li><em>“Jumping over to creative professionals and content creators, the 4080 Super also provides nice performance gains over the standard GeForce RTX 4080 in applications like Blender, Maya, After Effects, DaVinci Resolve and more. This means users can take full advantage of what the NVIDIA 4080 SUPER offers in much more than just gaming and can push the software they use for streaming, video creation, audio and 3D creation to get the most out of their PC.” &#8211;<a href="https://www.cgmagonline.com/review/hardware/nvidia-geforce-rtx-4080-super-gpu/"> CG Magazine</a></em></li>
<li><em>“Features like NVIDIA Broadcast and Reflex hold deep practical appeal; RTX Video Super Resolution uses AI to make ugly videos beautiful. And NVIDIA maintains a strong lead in most creative and machine learning/AI workloads if you like to put your GPU to work when you’re not playing — witness the dual AV1 encoders in the 4080 SUPER” —<a href="https://www.pcworld.com/article/2222156/nvidia-geforce-rtx-4080-super-review.html"> PC World</a>  </em></li>
<li><em>“Blender can make use of the RT cores on NVIDIA&#8217;s GPUs through the OptiX ray tracing rendering engine, and as a result, performance is much higher than any competing GPU in a similar class. The GeForce RTX 4080 SUPER notches another victory over its namesake, and dang the RTX 4090 is a beast.” &#8211; <a href="https://hothardware.com/reviews/nvidia-geforce-rtx-4080-super-review?page=2">Hot Hardware</a></em></li>
<li><em>“In terms of creative performance, the RTX 4080 SUPER walks away the winner against the RX 7900 XTX, even if you don&#8217;t factor in the fact that Blender Benchmark 4.0.0 workloads wouldn&#8217;t even run on the RX 7900 XTX (though the RX 7900 XT was able to run them, just not nearly as well).” &#8211;<a href="https://www.techradar.com/computing/gpu/nvidia-geforce-rtx-4080-super"> Tech Radar</a></em></li>
<li><em>“And when you throw in RTX technologies like DLSS into the mix, NVIDIA&#8217;s superior AV1 encoding quality, content-creator-friendly features, and performance, plus generative AI capabilities &#8211; and there&#8217;s a lot more to the story here than pure 4K gaming EXPERT-ise.” —<a href="https://www.tweaktown.com/reviews/10656/msi-geforce-rtx-4080-super-expert/index.html"> TweakTown</a></em></li>
</ul>
<p>Discover what RTX 4080 SUPER Series graphics cards and systems <a href="https://store.nvidia.com/en-us/geforce/store/?page=1&amp;limit=9&amp;locale=en-us&amp;gpu=RTX%204080%20SUPER&amp;category=GPU,DESKTOP">are available</a>.</p>
</div>]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-mr-vudoo-wk95-davinci-clip-1280w.mp4" length="1742416" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-mr-vudoo-wk95-photoshop-ai-selection-1280w.mp4" length="1303823" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/02/studio-itns-bozo-balov-wk86-artist-feature-1280w.mp4" length="1963725" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/nv-blog-header-preview-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/nv-blog-header-preview-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Twitch Streamer Mr_Vudoo Supercharges Gaming, Entertaining and Video Editing With RTX This Week ‘In the NVIDIA Studio’]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Canada Partners With NVIDIA to Supercharge Computing Power</title>
		<link>https://blogs.nvidia.com/blog/canada/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Mon, 05 Feb 2024 17:52:39 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69598</guid>

					<description><![CDATA[AI is reshaping industries, society and the “very fabric of innovation” — and Canada is poised to play a key role in this global transformation, said NVIDIA founder and CEO Jensen Huang during a fireside chat with leaders from across Canada’s thriving AI ecosystem. “Canada, as you know, even though you’re so humble, you might		<a class="read-more" href="https://blogs.nvidia.com/blog/canada/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>AI is reshaping industries, society and the “very fabric of innovation” — and Canada is poised to play a key role in this global transformation, said NVIDIA founder and CEO Jensen Huang during a fireside chat with leaders from across Canada’s thriving AI ecosystem.</p>
<p>“Canada, as you know, even though you’re so humble, you might not acknowledge it, is the epicenter of the invention of modern AI,” Huang told an audience of more than 400 from academia, industry and government gathered Thursday in Toronto.</p>
<p>In a pivotal development, Canada’s Industry Minister François-Philippe Champagne shared Friday on X, formerly known as Twitter, that <a href="https://twitter.com/FP_Champagne/status/1753500161056084102">Canada has signed a letter of intent with NVIDIA</a>.</p>
<p>Nations including Canada, France, India and Japan are discussing the importance of investing in “sovereign AI capabilities,” Huang said in an interview with Bloomberg Television in Canada.</p>
<p>Such efforts promise to enhance domestic computing capabilities, turbocharging local economies and unlocking local talent.</p>
<p>“Their natural resource, data, should be refined and produced for their country. The recognition of sovereign AI capabilities is global,” Huang told Bloomberg.</p>
<p>Huang’s conversation with the group of Canadian AI leaders, or “four heroes of mine,” as he described them — Raquel Urtasun of Waabi, Brendan Frey of Deep Genomics, University of Toronto Professor Alan Aspuru-Guzik and Aiden Gomez of Cohere — highlighted both Canada’s enormous contributions and its growing capability as a leader in AI.</p>
<p>“Each one of you,” Huang remarked, addressing the panelists and noting that every one of them is affiliated with the University of Toronto, “are doing foundational work in some of the largest industries in the world.”</p>
<p>“Let’s seize the moment,” Champagne said as he kicked off the panel discussion. “We need to move from fear to opportunity to build trust so that people understand what AI can do for them.”</p>
<p>“It’s about inspiring young researchers to continue to do research here in Canada and about creating opportunities for them after they graduate to be able to start companies here,” Huang said.</p>
<p>The panelists echoed Huang’s optimism, providing insights into how AI is reshaping industries, society and technology.</p>
<p>Gomez, reflecting on the democratization of AI, shared his optimism for the future, stating that it’s “an exciting time to explore product space,” highlighting the vast opportunities for innovation and disruption within the AI landscape.</p>
<p>Cohere&#8217;s world-class large language models help enterprises build powerful, secure applications that search, understand meaning and converse in text.</p>
<p>Gomez said the future lies in communities of researchers and entrepreneurs able to leverage AI to bridge technological divides and foster inclusivity.</p>
<p>“I owe everything to this community, the people on the stage and in this room,” he said, acknowledging the collaborative spirit that fuels innovation in AI technologies.</p>
<p>Urtasun highlighted the imperative of safety in autonomous technology as a non-negotiable standard, emphasizing its role in saving lives and shaping the future of transportation.</p>
<p>“Safety should not be proprietary. This technology is a driver, and it’s going to save so many lives,” she said.</p>
<p>Frey underscored the transformative impact of AI in RNA biology. He said that, while “it’s taken quite a bit of time,” at Deep Genomics, he and his colleagues have built the world’s first foundation model for RNA biology, envisioning a future where drug discovery is accelerated, bringing life-saving therapies to market more efficiently.</p>
<p>“If we’re highly successful, best-case scenario, it means that we will be able to design molecules that are safe, and highly efficacious, without doing any cell model studies without doing any animal studies … and getting drugs that save our loved ones rapidly and safely,” Frey said.</p>
<p>Aspuru-Guzik pointed to the fusion of AI with quantum computing and materials science as a frontier for sustainable solutions, emphasizing the importance of creating a conducive environment for innovation in Canada.</p>
<p>“We want to build it here in Canada,” he said.</p>
<p>His work exemplifies the potential of AI to accelerate the development of new materials, driving forward a sustainable future.</p>
<p>Together, these visions articulate a future where AI enhances societal well-being, drives scientific advancement and fosters an inclusive, global community of innovation.</p>
<p>“AI is about the greatest opportunity to close the technology divide and be inclusive, for everybody to enjoy the technology revolution,” Huang said.</p>
<p><i>For more on the fast-growing impact of AI across the globe, </i><a href="https://www.nvidia.com/en-us/industries/global-public-sector/"><i>visit NVIDIA’s AI nations hub</i></a><i>.  </i><i><br />
</i><i><br />
</i><i></i></p>
<p><i>Featured image credit: Christian Raul Hernandez, Creative Commons </i><a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en"><i>Attribution-Share Alike 4.0 International license</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/Toronto_Verano.jpg"
			type="image/jpeg"
			width="800"
			height="473"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/Toronto_Verano-800x450.jpg"
			width="800"
			height="450"
			/>
			<media:title type="html"><![CDATA[Canada Partners With NVIDIA to Supercharge Computing Power]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>New Study Cites AI as Strategic Tool to Combat Climate Change</title>
		<link>https://blogs.nvidia.com/blog/ai-energy-study/</link>
		
		<dc:creator><![CDATA[Dion Harris]]></dc:creator>
		<pubDate>Mon, 05 Feb 2024 16:00:17 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Climate]]></category>
		<category><![CDATA[Digital Twin]]></category>
		<category><![CDATA[Energy]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[New GPU Uses]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69550</guid>

					<description><![CDATA[A new study underscores the potential of AI and accelerated computing to deliver energy efficiency and combat climate change, efforts in which NVIDIA has long been deeply engaged. The study, called “Rethinking Concerns About AI’s Energy Use,” provides a well-researched examination into how AI can — and in many cases already does — play a		<a class="read-more" href="https://blogs.nvidia.com/blog/ai-energy-study/">
			Read Article			<span data-icon="y"></span>
		</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>A new study underscores the potential of AI and <a href="https://blogs.nvidia.com/blog/what-is-accelerated-computing/">accelerated computing</a> to deliver <a href="https://www.nvidia.com/en-us/glossary/energy-efficiency/">energy efficiency</a> and combat climate change, efforts in which NVIDIA has long been deeply engaged.</p>
<p>The <a href="https://itif.org/publications/2024/01/29/rethinking-concerns-about-ai-energy-use/">study</a>, called “Rethinking Concerns About AI’s Energy Use,” provides a well-researched examination into how AI can — and in many cases already does — play a large role in addressing these critical needs.</p>
<p>Citing dozens of sources, the study from the Information Technology and Innovation Foundation (ITIF), a Washington-based think tank focused on science and technology policy, calls for governments to accelerate adoption of AI as a significant new tool to drive energy efficiency across many industries.</p>
<p>AI can help “reduce carbon emissions, support clean energy technologies, and address climate change,” it said.</p>
<h2><b>How AI Drives Energy Efficiency</b></h2>
<p>The report documents ways machine learning is already helping many sectors reduce their impact on the environment.</p>
<p>For example, it noted:</p>
<ul>
<li>Farmers are using AI to lessen their use of fertilizer and water.</li>
<li>Utilities are adopting it to make the electric grid more efficient.</li>
<li>Logistics operations use it to optimize delivery routes, reducing the fuel consumption of their fleets.</li>
<li>Factories are deploying it to reduce waste and increase energy efficiency.</li>
</ul>
<p>In these and many other ways, the study argues that AI advances energy efficiency. So, it calls on policymakers “to ensure AI is part of the solution, not part of the problem, when it comes to the environment.”</p>
<p>It also recommends adopting AI broadly across government agencies to “help the public sector reduce carbon emissions through more efficient digital services, smart cities and buildings, intelligent transportation systems, and other AI-enabled efficiencies.”</p>
<h2><b>Reviewing the Data on AI</b></h2>
<p>The study’s author, Daniel Castro, saw in current predictions about AI a repeat of exaggerated forecasts that emerged during the rise of the internet more than two decades ago.</p>
<figure id="attachment_69584" aria-describedby="caption-attachment-69584" style="width: 150px" class="wp-caption alignleft"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/Daniel-Castro-ITIF-scaled.jpg"><img loading="lazy" decoding="async" class="size-thumbnail wp-image-69584" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/Daniel-Castro-ITIF-150x150.jpg" alt="Daniel Castro, ITIF" width="150" height="150" /></a><figcaption id="caption-attachment-69584" class="wp-caption-text">Daniel Castro</figcaption></figure>
<p>“People extrapolate from early studies, but don’t consider all the important variables including improvements you see over time in digitalization like energy efficiency,” said Castro, who leads ITIF’s Center for Data Innovation.</p>
<p>“The danger is policymakers could miss the big picture and hold back beneficial uses of AI that are having positive impacts, especially in regulated areas like healthcare,” he said.</p>
<p>“For example, we’ve had electronic health records since the 1980s, but it took focused government investments to get them deployed,” he added. “Now AI brings big opportunities for decarbonization across the government and the economy.”</p>
<h2><b>Optimizing Efficiency Across Data Centers</b></h2>
<p>Data centers of every size have a part to play in maximizing their energy efficiency with AI and accelerated computing.</p>
<p>For instance, NVIDIA’s AI-based weather-prediction model, <a href="https://arxiv.org/abs/2202.11214">FourCastNet</a>, is about 45,000x faster and consumes 12,000x less energy to produce a forecast than current techniques. That promises efficiency boosts for supercomputers around the world that run continuously to provide regional forecasts, Bjorn Stevens, director of the Max Planck Institute for Meteorology, said in <a href="https://blogs.nvidia.com/blog/ai-efficient-weather-predictions/">a blog</a>.</p>
<p>Overall, data centers could save a whopping 19 terawatt-hours of electricity a year if all AI, high performance computing and networking offloads were run on GPU and <a href="https://blogs.nvidia.com/blog/whats-a-dpu-data-processing-unit/">DPU</a> accelerators instead of CPUs, according to <a href="https://blogs.nvidia.com/blog/what-is-green-computing/">NVIDIA’s calculations</a>. That’s the equivalent of the energy consumption of 2.9 million passenger cars driven for a year.</p>
<p>Last year, the U.S. Department of Energy’s lead facility for open science documented its advances with accelerated computing.</p>
<p>Using <a href="https://www.nvidia.com/en-us/data-center/a100/">NVIDIA A100 Tensor Core GPUs</a>, energy efficiency improved 5x on average across four key scientific applications <a href="https://blogs.nvidia.com/blog/gpu-energy-efficiency-nersc/">in tests</a> at the National Energy Research Scientific Computing Center. An application for weather forecasting logged gains of nearly 10x.</p>
<figure id="attachment_69588" aria-describedby="caption-attachment-69588" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/02/Energy-efficiency-of-NVIDIA-GPUs-over-time.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-69588" src="https://blogs.nvidia.com/wp-content/uploads/2024/02/Energy-efficiency-of-NVIDIA-GPUs-over-time-672x365.jpg" alt="Chart showing the energy efficiency of GPUs has increased dramatically over time." width="672" height="365" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/02/Energy-efficiency-of-NVIDIA-GPUs-over-time-672x365.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Energy-efficiency-of-NVIDIA-GPUs-over-time-400x217.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Energy-efficiency-of-NVIDIA-GPUs-over-time-768x417.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Energy-efficiency-of-NVIDIA-GPUs-over-time-1536x834.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Energy-efficiency-of-NVIDIA-GPUs-over-time-828x450.jpg 828w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Energy-efficiency-of-NVIDIA-GPUs-over-time-396x215.jpg 396w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Energy-efficiency-of-NVIDIA-GPUs-over-time-184x100.jpg 184w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Energy-efficiency-of-NVIDIA-GPUs-over-time-1280x695.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/02/Energy-efficiency-of-NVIDIA-GPUs-over-time.jpg 1633w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69588" class="wp-caption-text">The energy efficiency of GPUs has increased dramatically over time.</figcaption></figure>
<h2><b>AI, Accelerated Computing Advance Climate Science</b></h2>
<p>The combination of accelerated computing and AI is creating new scientific instruments to help understand and combat climate change.</p>
<p>In 2021, NVIDIA <a href="https://blogs.nvidia.com/blog/earth-2-supercomputer/">announced</a> Earth-2, an initiative to build a <a href="https://www.nvidia.com/en-us/omniverse/solutions/digital-twins/">digital twin</a> of Earth on a supercomputer capable of simulating climate on a global scale. It’s among a handful of similarly <a href="https://blogs.nvidia.com/blog/digital-twins-climate-collaboration/">ambitious efforts</a> around the world.</p>
<p>An example is <a href="https://www.ecmwf.int/en/about/what-we-do/environmental-services-and-future-vision/destination-earth">Destination Earth</a>, a pan-European project to create digital twins of the planet, that’s using accelerated computing, AI and “collaboration on an unprecedented scale,” said the project’s leader, Peter Bauer, a veteran with more than 20 years at Europe’s top weather-forecasting center.</p>
<p>Experts in the utility sector agree AI is key to advancing sustainability.</p>
<p>“AI will play a crucial role maintaining stability for an electric grid that’s becoming exponentially more complex with large numbers of low-capacity, variable generation sources like wind and solar coming online, and two-way power flowing into and out of houses,” said Jeremy Renshaw, a senior program manager at the Electric Power Research Institute, an independent nonprofit that collaborates with more than 450 companies in 45 countries, in <a href="https://blogs.nvidia.com/blog/ai-energy-grids/">a blog</a>.</p>
<p>Learn more about <a href="https://www.nvidia.com/en-us/data-center/sustainable-computing/">sustainable computing</a> as well as <a href="https://images.nvidia.com/aem-dam/Solutions/documents/FY2023-NVIDIA-Corporate-Responsibility-Report-1.pdf">NVIDIA&#8217;s commitment</a> to use 100% renewable energy starting in fiscal year 2025. And watch the video below for more on how AI is accelerating efforts to combat climate change.</p>
<p><iframe loading="lazy" title="Powering the Future of Clean Energy | I AM AI" width="500" height="281" src="https://www.youtube.com/embed/zrcxLZmOyNA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/Earth-2-rbm-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1092"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/02/Earth-2-rbm-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[New Study Cites AI as Strategic Tool to Combat Climate Change]]></media:title>
			<media:description type="html">Earth-2 simulation using AI for climate science</media:description>
			</media:content>
			</item>
	</channel>
</rss>
