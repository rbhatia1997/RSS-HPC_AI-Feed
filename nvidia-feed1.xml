<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Thu, 18 Jan 2024 15:48:09 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.4.2</generator>
	<item>
		<title>Buried Treasure: Startup Mines Clean Energy’s Prospects With Digital Twins</title>
		<link>https://blogs.nvidia.com/blog/energy-storage-omniverse/</link>
		
		<dc:creator><![CDATA[Rick Merritt]]></dc:creator>
		<pubDate>Thu, 18 Jan 2024 16:00:37 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Climate]]></category>
		<category><![CDATA[Cloud Services]]></category>
		<category><![CDATA[Customer Stories]]></category>
		<category><![CDATA[Digital Twin]]></category>
		<category><![CDATA[Energy]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[New GPU Uses]]></category>
		<category><![CDATA[NVIDIA DGX]]></category>
		<category><![CDATA[NVIDIA Modulus]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Simulation and Design]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69354</guid>

					<description><![CDATA[Mark Swinnerton aims to fight climate change by transforming abandoned mines into storage tanks of renewable energy. The CEO of startup Green Gravity is prototyping his ambitious vision in a warehouse 60 miles south of Sydney, Australia, and simulating it in NVIDIA Omniverse, a platform for building 3D workflows and applications. The concept requires some <a class="read-more" href="https://blogs.nvidia.com/blog/energy-storage-omniverse/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Mark Swinnerton aims to fight climate change by transforming abandoned mines into storage tanks of renewable energy.</p>
<p>The CEO of startup Green Gravity is prototyping his ambitious vision in a warehouse 60 miles south of Sydney, Australia, and simulating it in <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, a platform for building 3D workflows and applications.</p>
<p>The concept requires some heavy lifting. Solar and wind energy will pull steel blocks weighing as much as 30 cars each up shafts taller than a New York skyscraper, storing potential energy that can turn turbines whenever needed.</p>
<h2><b>A Distributed Energy Network</b></h2>
<p>Swinnerton believes it’s the optimal way to save renewable energy because nearly a million abandoned mine shafts are scattered around the globe, many of them already connected to the grid. And his mechanical system is cheaper and greener than alternatives like massive lithium batteries better suited for electric vehicles.</p>
<figure id="attachment_69364" aria-describedby="caption-attachment-69364" style="width: 150px" class="wp-caption alignright"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/Mark-Swinnerton-Green-Gravity-CEO.jpg"><img decoding="async" class="wp-image-69364 size-thumbnail" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/Mark-Swinnerton-Green-Gravity-CEO-150x150.jpg" alt="Mark Swinnerton, CEO Green Gravity" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/Mark-Swinnerton-Green-Gravity-CEO-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Mark-Swinnerton-Green-Gravity-CEO-400x400.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Mark-Swinnerton-Green-Gravity-CEO-502x500.jpg 502w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Mark-Swinnerton-Green-Gravity-CEO-768x765.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Mark-Swinnerton-Green-Gravity-CEO-452x450.jpg 452w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Mark-Swinnerton-Green-Gravity-CEO-216x215.jpg 216w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Mark-Swinnerton-Green-Gravity-CEO-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Mark-Swinnerton-Green-Gravity-CEO-1280x1276.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Mark-Swinnerton-Green-Gravity-CEO.jpg 1430w" sizes="(max-width: 150px) 100vw, 150px" /></a><figcaption id="caption-attachment-69364" class="wp-caption-text">Mark Swinnerton</figcaption></figure>
<p>Officials in Australia, India and the U.S. are interested in the concept, and a state-owned mine operator in Romania is conducting a joint study with Green Gravity.</p>
<p>“We have a tremendous opportunity for repurposing a million mines,” said Swinnerton, who switched gears after a 20-year career at BHP Group, one of the world’s largest mining companies, determined to combat climate change.</p>
<h2><b>A Digital-First Design</b></h2>
<p>A longtime acquaintance saw an opportunity to accelerate Swinnerton’s efforts with a <a href="https://www.nvidia.com/en-us/omniverse/solutions/digital-twins/">digital twin</a>.</p>
<p>“I was fascinated by the Green Gravity idea and suggested taking a digital-first approach, using data as a differentiator,” said Daniel Keys, an IT expert and executive at <a href="https://xamplify.com.au/">xAmplify</a>, a provider of accelerated computing services.</p>
<p>AI-powered simulations could speed the design and deployment of the novel concept, said Keys, who met Swinnerton 25 years earlier at one of their first jobs, flipping burgers at a fast-food stand.</p>
<p>Today, they’ve got a digital prototype cooking on xAmplify’s Scaile computer, based on <a href="https://www.nvidia.com/en-us/data-center/dgx-platform/">NVIDIA DGX systems</a>. It’s already accelerating Green Gravity’s proof of concept.</p>
<p>“Thanks to what we inferred with a digital twin, we’ve been able to save 40% of the costs of our physical prototype by shifting from three weights to two and moving them 10 instead of 15 meters vertically,” said Swinnerton.</p>
<h2><b>Use Cases Enabled by Omniverse</b></h2>
<p>It’s the first of many use cases Green Gravity is developing in Omniverse.</p>
<p>Once the prototype is done, the simulation will help scale the design to mines as deep as 7,000 feet, or about six Empire State Buildings stacked on top of each other. Ultimately, the team will build in Omniverse a dashboard to control and monitor sensor-studded facilities without the safety hazards of sending a person into the mine.</p>
<figure id="attachment_69367" aria-describedby="caption-attachment-69367" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/Green-Gravity-test-lab.jpg"><img fetchpriority="high" decoding="async" class="size-large wp-image-69367" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/Green-Gravity-test-lab-672x367.jpg" alt="Green Gravity’s physical prototype and test lab." width="672" height="367" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/Green-Gravity-test-lab-672x367.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Green-Gravity-test-lab-400x218.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Green-Gravity-test-lab-768x419.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Green-Gravity-test-lab-1536x838.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Green-Gravity-test-lab-825x450.jpg 825w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Green-Gravity-test-lab-394x215.jpg 394w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Green-Gravity-test-lab-183x100.jpg 183w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Green-Gravity-test-lab-1280x698.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Green-Gravity-test-lab.jpg 1833w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69367" class="wp-caption-text">Green Gravity’s physical prototype and test lab.</figcaption></figure>
<p>“We expect to cut tens of millions of dollars off the estimated $100 million for the first site because we can use simulations to lower our risks with banks and insurers,” said Swinnerton. “That’s a real tantalizing opportunity.”</p>
<h2><b>Virtual Visualization Tools</b></h2>
<p>Operators will track facilities remotely using visualization systems equipped with <a href="https://www.nvidia.com/en-us/data-center/a40/">NVIDIA A40 GPUs</a> and can stream their visuals to tablets thanks to the TabletAR extension in the Omniverse Spatial Framework.</p>
<p>xAmplify’s workflow uses a number of software components such as <a href="https://developer.nvidia.com/modulus">NVIDIA Modulus</a>, a framework for physics-informed machine learning models.</p>
<p>“We also use Omniverse as a core integration fabric that lets us connect a half-dozen third-party tools operators and developers need, like Siemens PLM for sensor management and Autodesk for design,” Keys said.</p>
<p><iframe title="Green Gravity at Nvidia Day 2023 SIGGRAPH" src="https://player.vimeo.com/video/902088869?dnt=1&amp;app_id=122963" width="500" height="281" frameborder="0" allow="autoplay; fullscreen; picture-in-picture"></iframe></p>
<p>Omniverse eases the job of integrating third-party applications into one 3D workflow because it’s based on the <a href="https://blogs.nvidia.com/blog/openusd-alliance-3d-standard/">OpenUSD standard</a>.</p>
<p>Along the way, AI sifts reams of data about the thousands of available mines to select optimal sites, predicting their potential for energy storage. Machine learning will also help optimize designs for each site.</p>
<p>Taken together, it’s a digital pathway Swinnerton believes will lead to commercial operations for Green Gravity within the next couple years.</p>
<p>It’s the latest customer for xAmplify’s Canberra data center serving Australian government agencies, national defense contractors and an expanding set of enterprise users with a full stack of NVIDIA accelerated software.</p>
<p>Learn more about how AI is transforming renewables, including <a href="https://blogs.nvidia.com/blog/siemens-gamesa-wind-farms-digital-twins/">wind farm optimization</a>, <a href="https://blogs.nvidia.com/blog/ai-startup-navigates-3d-aerial-images-for-inspections/">solar energy generation</a> and <a href="https://blogs.nvidia.com/blog/ai-hpc-nuclear-fusion/">fusion energy</a>.</p>
<p><iframe loading="lazy" title="Powering the Future of Clean Energy | I AM AI" width="500" height="281" src="https://www.youtube.com/embed/zrcxLZmOyNA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/green-gravity-still-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/green-gravity-still-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Buried Treasure: Startup Mines Clean Energy’s Prospects With Digital Twins]]></media:title>
			<media:description type="html">Startup Green Gravity&#039;s concept for renewable energy storage </media:description>
			</media:content>
			</item>
		<item>
		<title>Dino-Mite: Capcom’s ‘Exoprimal’ Joins GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-exoprimal-prince-of-persia/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 18 Jan 2024 14:00:11 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69377</guid>

					<description><![CDATA[Hold on to your seats — this GFN Thursday is unleashing dinosaurs, crowns and more in the cloud. Catch it all on Capcom’s Exoprimal and Ubisoft’s Prince of Persia: The Lost Crown, leading 10 new games joining the GeForce NOW library this week. Suit Up, Adapt, Survive Don cutting-edge exosuit technology and battle ferocious dinosaurs <a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-exoprimal-prince-of-persia/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Hold on to your seats — this GFN Thursday is unleashing dinosaurs, crowns and more in the cloud.</p>
<p>Catch it all on Capcom’s <i>Exoprimal </i>and Ubisoft’s <i>Prince of Persia: The Lost Crown,</i> leading 10 new games joining the <a href="http://play.geforcenow.com">GeForce NOW library</a> this week.</p>
<h2><b>Suit Up, Adapt, Survive</b></h2>
<figure id="attachment_69381" aria-describedby="caption-attachment-69381" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-69381 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Exoprimal-672x378.jpg" alt="Exoprimal on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Exoprimal-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Exoprimal-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Exoprimal-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Exoprimal-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Exoprimal-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Exoprimal-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Exoprimal-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Exoprimal-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Exoprimal-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69381" class="wp-caption-text"><em>Life finds a way.</em></figcaption></figure>
<p>Don cutting-edge exosuit technology and battle ferocious dinosaurs on an Earth overrun with waves of prehistoric predators. Capcom’s online team-based action game <i>Exoprimal </i>is now supported in the cloud.</p>
<p>Face velociraptors, T. rex and mutated variants called Neosaurs using the exosuit’s unique weapons and abilities. Join other players in the game’s main mode, Dino Survival, to unlock snippets and special missions from the original story, piecing together the origins of the dinosaur outbreak. Change exosuits on the fly, switching between Assault, Tank and Support roles to suit the situation.</p>
<p>Catch the game in the cloud this week alongside the release of Title Update 3, which brings a new mission and special <i>Monster Hunter</i> collaboration content, a new map, new rigs, plus the start of the third season. Ultimate members can enjoy it all at up to 4K resolution and 120 frames per second, and new players can purchase the game on <a href="https://store.steampowered.com/app/1286320?utm_source=NVIDIA&amp;utm_campaign=GFN">Steam</a> at 50% off for a limited time.</p>
<h2><b>Return to the Sands of Time</b></h2>
<figure id="attachment_69384" aria-describedby="caption-attachment-69384" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-69384" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Prince_of_Persia_The_Lost_Crown-672x336.jpg" alt="Prince of Persia on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Prince_of_Persia_The_Lost_Crown-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Prince_of_Persia_The_Lost_Crown-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Prince_of_Persia_The_Lost_Crown-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Prince_of_Persia_The_Lost_Crown-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Prince_of_Persia_The_Lost_Crown-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Prince_of_Persia_The_Lost_Crown-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Prince_of_Persia_The_Lost_Crown-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Prince_of_Persia_The_Lost_Crown-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Prince_of_Persia_The_Lost_Crown.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69384" class="wp-caption-text"><em>So stylish.</em></figcaption></figure>
<p>Defy time and destiny to reclaim the crown and save a cursed world in <i>Prince of Persia: The Lost Crown</i>. It’s the newest adventure in the critically acclaimed action-adventure platformer series, available to stream in the cloud this week at the game’s PC launch.</p>
<p>Step into the shoes of Sargon, a legendary prince with extraordinary acrobatic skills and the power to manipulate time. Travel to Mount Qaf to rescue the kidnapped Prince Ghassan. Wield blades and various time-related powers to fight enemies and solve puzzles in a Persia-inspired world filled with larger-than-life landmarks.</p>
<p>Members can unleash their inner warrior with an <a href="https://www.nvidia.com/en-us/geforce-now/">Ultimate membership</a> for the highest-quality streaming. Dash into the thrilling game with support for up to 4K resolution at 120 fps on PCs and Macs, streaming from GeForce RTX 4080-powered servers in the cloud.</p>
<h2><b>Time for New Games</b></h2>
<figure id="attachment_69387" aria-describedby="caption-attachment-69387" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-69387" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Turnip_Boy_Robs_A_Bank-672x336.jpg" alt="" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Turnip_Boy_Robs_A_Bank-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Turnip_Boy_Robs_A_Bank-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Turnip_Boy_Robs_A_Bank-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Turnip_Boy_Robs_A_Bank-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Turnip_Boy_Robs_A_Bank-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Turnip_Boy_Robs_A_Bank-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Turnip_Boy_Robs_A_Bank-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Turnip_Boy_Robs_A_Bank-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Turnip_Boy_Robs_A_Bank.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69387" class="wp-caption-text"><em>Turnip Boy&#8217;s back, allright!</em></figcaption></figure>
<p>In addition, members can look for the following:</p>
<ul>
<li><i>Those Who Remain</i> (New release on <a href="https://www.xbox.com/games/store/those-who-remain/9NFC3G481KKQ?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass, Jan. 16)</li>
<li><i>Prince of Persia: The Lost Crown </i>(New release on <a href="https://store.ubi.com/6408bd687ee83d203cf3bda1.html#ucid=AFL-ID_152062&amp;maltcode=geforcenow_convst_AFL_geforcenow_vg__STORE____&amp;addinfo=">Ubisoft and Ubisoft+</a>, Jan. 18)</li>
<li><i>Turnip Boy Robs a Bank </i>(New release on <a href="https://store.steampowered.com/app/2097230?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.xbox.com/games/store/turnip-boy-robs-a-bank/9ndt1ms39fxz?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available for PC Game Pass, Jan. 18)</li>
<li><i>New Cycle</i> (New release on <a href="https://store.steampowered.com/app/2198510?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Jan. 18)</li>
<li><i>Beacon Pines </i>(<a href="https://www.xbox.com/games/store/beacon-pines/9P4R2M0NRWNK?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Exoprimal</i> (<a href="https://store.steampowered.com/app/1286320?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>FAR: Changing Tides </i>(<a href="https://www.xbox.com/games/store/far-changing-tides-windows-edition/9MT3D7Z4NWDV?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Going Under </i>(<a href="https://www.xbox.com/games/store/going-under/9nx3g3z38cv2?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>The Legend of Nayuta: Boundless Trails </i>(<a href="https://store.steampowered.com/app/1668530?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Turnip Boy Commits Tax Evasion </i>(<a href="https://www.xbox.com/games/store/turnip-boy-commits-tax-evasion/9N0T8V0R7MBC?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X </a>or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="art" dir="ltr"><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f995.png" alt="🦕" class="wp-smiley" style="height: 1em; max-height: 1em;" /> + <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/231b.png" alt="⌛" class="wp-smiley" style="height: 1em; max-height: 1em;" /> = <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1747665084292219202?ref_src=twsrc%5Etfw">January 17, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/gfn-thursday-1-18-no-copy-kv-1536x920-1.jpg"
			type="image/jpeg"
			width="1536"
			height="920"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/gfn-thursday-1-18-no-copy-kv-1536x920-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Dino-Mite: Capcom’s ‘Exoprimal’ Joins GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>From Embers to Algorithms: How DigitalPath’s AI is Revolutionizing Wildfire Detection</title>
		<link>https://blogs.nvidia.com/blog/ai-podcast-wildfires/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Wed, 17 Jan 2024 14:00:56 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69314</guid>

					<description><![CDATA[The AI Podcast · DigitalPath&#8217;s Ethan Higgins On Using AI to Fight Wildfires &#8211; Ep. 211 DigitalPath is igniting change in the Golden State — using computer vision, generative adversarial networks and a network of thousands of cameras to detect signs of fire in real time. In the latest episode of NVIDIA’s AI Podcast, host <a class="read-more" href="https://blogs.nvidia.com/blog/ai-podcast-wildfires/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1713097308%3Fsecret_token%3Ds-qw4nclf83WA&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true&amp;visual=true" width="100%" height="300" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="DigitalPath's Ethan Higgins On Using AI to Fight Wildfires - Ep. 211" href="https://soundcloud.com/theaipodcast/ai-wildfire/s-qw4nclf83WA" target="_blank" rel="noopener">DigitalPath&#8217;s Ethan Higgins On Using AI to Fight Wildfires &#8211; Ep. 211</a></div>
<p>DigitalPath is igniting change in the Golden State — using computer vision, generative adversarial networks and a network of thousands of cameras to detect signs of fire in real time.</p>
<p>In the latest episode of <a href="https://blogs.nvidia.com/ai-podcast/">NVIDIA’s AI Podcast</a>, host Noah Kravtiz spoke with DigitalPath System Architect Ethan Higgins about the company’s role in the ALERTCalifornia initiative, a collaboration between California’s wildfire fighting agency <a href="https://www.fire.ca.gov/">CAL FIRE</a> and the University of California, San Diego.</p>
<p>DigitalPath built computer vision models to process images collected from network cameras — anywhere from 8 million to 16 million a day — intelligently identifying signs of fire like smoke.</p>
<p>“One of the things we realized early on, though, is that it’s not necessarily a problem about just detecting a fire in a picture,” Higgins said. “It’s a process of making a manageable amount of data to handle.”</p>
<p>That’s because, he explained, it’s unlikely that humans will be entirely out of the loop in the detection process for the foreseeable future.</p>
<p>The company uses various AI algorithms to classify images based on whether they should be reviewed or acted upon — if so, an alert is sent out to a CAL FIRE command center.</p>
<p>One of the downsides to using computer vision to detect wildfires is that extinguishing more fires means a greater buildup of natural fuel and the potential for larger wildfires in the long term. DigitalPath and UCSD are exploring the use of high-resolution lidar data to identify where those fuels can be released in the form of prescribed burns.</p>
<p>Looking ahead, Higgins foresees the field tapping generative AI to accelerate new simulation tools and using AI models to analyze the output of other models to doubly improve wildfire prediction and detection.</p>
<p>“AI is not perfect, but when you couple multiple models together, it can get really close,” he said.</p>
<h2>You Might Also Like</h2>
<h3><a href="https://blogs.nvidia.com/blog/waabi-ai-simulation/"><b>Driver’s Ed: How Waabi Uses AI Simulation to Teach Autonomous Vehicles to Drive</b></a></h3>
<p>Teaching the AI brains of autonomous vehicles to understand the world as humans do requires billions of miles of driving experience—the road to achieving this astronomical level of driving leads to the virtual world. Learn how Waabi uses powerful high-fidelity simulations to train and develop production-level autonomous vehicles.</p>
<h3><a href="https://blogs.nvidia.com/blog/polestar/"><b>Polestar’s Dennis Nobelius on the Sustainable Performance Brand’s Plans</b></a></h3>
<p>Driving enjoyment and autonomous driving capabilities can complement one another in intelligent, sustainable vehicles. Learn about the automaker’s plans to unveil its third vehicle, the Polestar 3, the tech inside it, and what the company’s racing heritage brings to the intersection of smarts and sustainability.</p>
<h3><a href="https://soundcloud.com/theaipodcast/gantheftauto-harrison-kinsley-on-ai-generated-gaming-environments"><b>GANTheftAuto: Harrison Kinsley on AI-Generated Gaming Environments</b></a></h3>
<p>Humans playing games against machines is nothing new, but now computers can develop games for people to play. Programming enthusiast and social media influencer Harrison Kinsley created GANTheftAuto, an AI-based neural network that generates a playable chunk of the classic video game <i>Grand Theft Auto V</i>.</p>
<h2>Subscribe to the AI Podcast, Now Available on Amazon Music</h2>
<p><a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">The AI Podcast is now available through Amazon Music</a>.</p>
<p>In addition, get the<a href="https://blogs.nvidia.com/ai-podcast/"> AI Podcast</a> through<a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439"> iTunes</a>,<a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjI2NDAzNDEzMy9zb3VuZHMucnNz"> Google Podcasts</a>,<a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm"> Google Play</a>,<a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us"> Castbox</a>, DoggCatcher,<a href="https://overcast.fm/itunes1186480811/the-ai-podcast"> Overcast</a>,<a href="https://player.fm/series/the-ai-podcast"> PlayerFM</a>, Pocket Casts,<a href="http://www.podbay.fm/show/1186480811"> Podbay</a>,<a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast"> PodBean</a>, PodCruncher, PodKicker,<a href="https://soundcloud.com/theaipodcast"> Soundcloud</a>,<a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L"> Spotify</a>,<a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr"> Stitcher</a> and<a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/"> TuneIn</a>.</p>
<p>Make the AI Podcast better: Have a few minutes to spare? Fill out<a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short"> this listener survey</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/29firemain1080.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/10/29firemain1080-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[From Embers to Algorithms: How DigitalPath’s AI is Revolutionizing Wildfire Detection]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Māori Speech AI Model Helps Preserve and Promote New Zealand Indigenous Language</title>
		<link>https://blogs.nvidia.com/blog/te-hiku-media-maori-speech-ai/</link>
		
		<dc:creator><![CDATA[Angie Lee]]></dc:creator>
		<pubDate>Tue, 16 Jan 2024 16:00:13 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Conversational AI]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[Open Source]]></category>
		<category><![CDATA[Social Impact]]></category>
		<category><![CDATA[Trustworthy AI]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69344</guid>

					<description><![CDATA[Indigenous languages are under threat. Some 3,000 — three-quarters of the total — could disappear before the end of the century, or one every two weeks, according to UNESCO. As part of a movement to protect such languages, New Zealand’s Te Hiku Media, a broadcaster focused on the Māori people’s indigenous language known as te <a class="read-more" href="https://blogs.nvidia.com/blog/te-hiku-media-maori-speech-ai/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Indigenous languages are under threat. Some 3,000 — three-quarters of the total — could disappear before the end of the century, or one every two weeks, according to <a href="https://www.iesalc.unesco.org/en/2022/02/21/a-decade-to-prevent-the-disappearance-of-3000-languages/" target="_blank" rel="noopener">UNESCO</a>.</p>
<p>As part of a movement to protect such languages, New Zealand’s Te Hiku Media, a broadcaster focused on the Māori people’s indigenous language known as te reo, is using <a href="https://blogs.nvidia.com/blog/tag/trustworthy-ai/" target="_blank" rel="noopener">trustworthy AI</a> to help preserve and revitalize the tongue.</p>
<p>Using ethical, transparent methods of speech data collection and analysis to maintain data sovereignty for the Māori people, Te Hiku Media is developing <a href="https://developer.nvidia.com/blog/essential-guide-to-automatic-speech-recognition-technology/" target="_blank" rel="noopener">automatic speech recognition</a> (ASR) models for te reo, which is a Polynesian language.</p>
<p>Built using the open-source <a href="https://nvidia.github.io/NeMo/" target="_blank" rel="noopener">NVIDIA NeMo toolkit</a> for ASR and <a href="https://www.nvidia.com/en-us/data-center/a100/" target="_blank" rel="noopener">NVIDIA A100 Tensor Core GPUs</a>, the speech-to-text models transcribe te reo with 92% accuracy. It can also transcribe bilingual speech using English and te reo with 82% accuracy. They’re pivotal tools, made by and for the Māori people, that are helping preserve and amplify their stories.</p>
<p>“There’s immense value in using NVIDIA’s open-source technologies to build the tools we need to ultimately achieve our mission, which is the preservation, promotion and revitalization of te reo Māori,” said Keoni Mahelona, chief technology officer at Te Hiku Media, who leads a team of data scientists and developers, as well as Māori language experts and data curators, working on the project.</p>
<p>“We’re also helping guide the industry on ethical ways of using data and technologies to ensure they’re used for the empowerment of marginalized communities,” added Mahelona, a Native Hawaiian now living in New Zealand.</p>
<h2><b>Building a ‘House of Speech’</b></h2>
<p>Te Hiku Media began more than three decades ago as a radio station aiming to ensure te reo had space on the airwaves. Over the years, the organization incorporated television broadcasting and, with the rise of the internet, it convened a meeting in 2013 with the community’s elders to form a strategy for sharing content in the digital era.</p>
<p>“The elders agreed that we should make the stories accessible online for our community members — rather than just keeping our archives on cassettes in boxes — but once we had that objective, the challenge was how to do this correctly, in alignment with our strong roots in valuing sovereignty,” Mahelona said.</p>
<p>Instead of uploading its video and audio sources to popular, global platforms — which, in their terms and conditions of use, require signing over certain rights related to the content — Te Hiku Media decided to build its own content distribution platform.</p>
<p>Called Whare Kōrero — meaning “house of speech” — the platform now holds more than 30 years’ worth of digitized, archival material featuring about 1,000 hours of te reo native speakers, some of whom were born in the late 19th century, as well as more recent content from second-language learners and bilingual Māori people.</p>
<p>Now, around 20 Māori radio stations use and upload their content to Whare Kōrero. Community members can access the content through an app.</p>
<p>“It’s an invaluable resource of acoustic data,” Mahelona said.</p>
<h2><b>Turning to Trustworthy AI</b></h2>
<p>Such a trove held incredible value for those working to revitalize the language, the Te Hiku Media team quickly realized, but manual transcription required pulling lots of time and effort from limited resources. So began the organization’s trustworthy AI efforts, in 2016, to accelerate its work using ASR.</p>
<p>“No one would have a clue that there are eight NVIDIA A100 GPUs in our derelict, rundown, musky-smelling building in the far north of New Zealand — training and building Māori language models,” Mahelona said. “But the work has been game-changing for us.”</p>
<p>To collect speech data in a transparent, ethically compliant, community-oriented way, Te Hiku Media began by explaining its cause to elders, garnering their support and asking them to come to the station to read phrases aloud.</p>
<p>“It was really important that we had the support of the elders and that we recorded their voices, because that’s the sort of content we want to transcribe,” Mahelona said. “But eventually these efforts didn’t scale — we needed second-language learners, kids, middle-aged people and a lot more speech data in general.”</p>
<p>So, the organization ran a crowdsourcing campaign, <a href="https://koreromaori.com/" target="_blank" rel="noopener">Kōrero Māori</a>, to collect highly labeled speech samples according to the Kaitiakitanga license, which ensures Te Hiku Media uses the data only for the benefit of the Māori people.</p>
<p>In just 10 days, more than 2,500 signed up to read 200,000+ phrases, providing over 300 hours of labeled speech data, which was used to build and train the te reo Māori ASR models.</p>
<p>In addition to other open-source trustworthy AI tools, Te Hiku Media now uses the NVIDIA NeMo toolkit’s ASR module for speech AI throughout its entire pipeline. The NeMo toolkit comprises building blocks called neural modules and includes <a href="https://blogs.nvidia.com/blog/what-is-a-pretrained-ai-model/" target="_blank" rel="noopener">pretrained models</a> for language model development.</p>
<p>“It’s been absolutely amazing — NVIDIA’s open-source NeMo enabled our ASR models to be bilingual and added automatic punctuation to our transcriptions,” Mahelona said.</p>
<p>Te Hiku Media’s ASR models are the engines running behind Kaituhi, a te reo Māori transcription service now <a href="https://kaituhi.nz/" target="_blank" rel="noopener">available online</a>.</p>
<p>The efforts have spurred similar ASR projects now underway by Native Hawaiians and the Mohawk people in southeastern Canada.</p>
<p>“It’s indigenous-led work in trustworthy AI that’s inspiring other indigenous groups to think: ‘If they can do it, we can do it, too,’” Mahelona said.</p>
<p><i>Learn more about NVIDIA-powered </i><a href="https://blogs.nvidia.com/blog/tag/trustworthy-ai/" target="_blank" rel="noopener"><i>trustworthy AI</i></a><i>, the </i><a href="https://nvidia.github.io/NeMo/" target="_blank" rel="noopener"><i>NVIDIA NeMo toolkit</i></a><i> and how it enabled a </i><a href="https://blogs.nvidia.com/blog/speech-ai-telugu-language-breakthrough/" target="_blank" rel="noopener"><i>Telugu language speech AI breakthrough</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/te-hiku-media-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/te-hiku-media-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Māori Speech AI Model Helps Preserve and Promote New Zealand Indigenous Language]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Starstruck: 3D Artist Brellias Brings Curiosity to Light This Week ‘In the NVIDIA Studio’</title>
		<link>https://blogs.nvidia.com/blog/studio-brellias-blender-davinci-resolve-gpu-ai/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 16 Jan 2024 14:00:59 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69286</guid>

					<description><![CDATA[Curiosity leads the way for this week’s featured In the NVIDIA Studio 3D artist, Brellias.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. We’re also deep diving on new </i><a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/"><i>GeForce RTX 40 Series GPU</i></a><i> features, technologies and resources, and how they dramatically accelerate content creation.</i></p>
<p>Curiosity leads the way for this week’s featured <i>In the NVIDIA Studio</i> 3D artist, Brellias.</p>
<p>It’s what inspired the native Chilean’s latest artwork<i> Estrellitas</i>, which in English translates to “little stars.” The scene expresses the mixture of emotions that comes with curiosity, depicting a young girl holding little stars in her hand with a conflicted expression.</p>
<p>“She’s excited to learn about them, but she’s also a little scared,” Brellias explained.</p>
<p>The striking visual piece, rich with vibrant colors and expertly executed textures, underscores that while curiosity can invoke various emotions — both joyful and painful — it is always a source of change and growth.</p>
<h2><b>A Sky Full of Stars</b></h2>
<p>To start, Brellias first visualized and reworked an existing 3D scene of a woman in Blender. He used Blender’s built-in multi-resolution modifier for sculpting and added some shape keys to achieve the desired modifications.</p>
<p>He also created a custom shader for the character’s skin — a stylistic choice to lend its appearance a galactic hue.</p>
<figure id="attachment_69293" aria-describedby="caption-attachment-69293" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-collage-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69293" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-collage-1280w-672x441.png" alt="" width="672" height="441" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-collage-1280w-672x441.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-collage-1280w-400x263.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-collage-1280w-768x504.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-collage-1280w-686x450.png 686w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-collage-1280w-328x215.png 328w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-collage-1280w-152x100.png 152w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-collage-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69293" class="wp-caption-text">Brellias is an especially big fan of purple, blue and maroon hues.</figcaption></figure>
<p>Next, Brellias tapped Blender’s OptiX GPU-accelerated viewport denoising, powered by his GeForce RTX GPU.</p>
<p>“The technology helps reduce noise and improve the quality of the viewport image more quickly, allowing me to make decisions and iterate on the render faster,” he said.</p>
<figure id="attachment_69296" aria-describedby="caption-attachment-69296" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image4-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69296" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image4-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image4-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image4-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image4-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image4-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image4-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image4-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image4-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69296" class="wp-caption-text">Out-of-this-world levels of detail.</figcaption></figure>
<p>Next, Brellias animated the scene using a base model from Daz Studio, a free media design software developed by Daz 3D. Daz features an AI denoiser for high-performance interactive rendering that can also be accelerated by RTX GPUs.</p>
<p>In addition, rig tools in Blender made the animation process easy, eliminating the need to modify file formats.</p>
<p>To animate the character’s face, Brellias tied drivers to shape keys using empties, enabling greater fluidity and control over facial expressions.</p>
<figure id="attachment_69302" aria-describedby="caption-attachment-69302" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image2-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69302" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image2-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image2-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image2-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image2-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image2-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image2-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image2-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-brellias-wk92-image2-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69302" class="wp-caption-text">Geometry nodes bring “Estrellitas” to life.</figcaption></figure>
<p>Brellias then used geometry nodes in Blender to animate the character’s hair, giving it a magical floating effect. To light the scene, Brellias added some ambient light behind the character’s face and between its hands. His RTX GPU accelerated OptiX ray tracing in Blender’s Cycles for the fastest final-frame renders.</p>
<div style="width: 1280px;" class="wp-video"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video class="wp-video-shortcode" id="video-69286-1" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/breathe.mp4?_=1" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/breathe.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/01/breathe.mp4</a></video></div>
<p>&nbsp;</p>
<p>Finally, he moved to Blackmagic Design’s DaVinci Resolve to denoise and deflicker the scene for the smoothest-looking animation.</p>
<p>Here, Brellias’ RTX GPU accelerated the color grading, video editing and color scoping processes, dramatically speeding his creative workflow. Other RTX-accelerated AI features, including facial recognition for automatically tagging clips and the tracking of effects, were available for his use.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-69286-2" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/estrellitas.mp4?_=2" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/estrellitas.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/01/estrellitas.mp4</a></video></div>
<p>&nbsp;</p>
<p><i>Estrellitas</i> was partially inspired by Brellias’ own curiosity in exploring NVIDIA and GeForce RTX GPU technologies to power content creation workflows — a venture that provided rewarding results.</p>
<p>“Every step of my creative process involves GPU acceleration or AI in some way or another,” said Brellias. “I can’t imagine creating without a powerful GPU at my disposal.”</p>
<p>His curiosity in AI extends to productivity. He recently installed the <a href="https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/">NVIDIA Broadcast</a> app, which can transform any room into a home studio.</p>
<p><iframe loading="lazy" title="NVIDIA Broadcast 1.4 Update Featuring Eye Contact" width="500" height="281" src="https://www.youtube.com/embed/nR-vP_7XFHE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>The app has enhanced Brellias’ microphone performance by canceling external noise and echo — especially useful given his urban surroundings.</p>
<p><iframe loading="lazy" title="Half-Life 2 RTX, An RTX Remix Project - Ravenholm Trailer" width="500" height="281" src="https://www.youtube.com/embed/nIE9gQt6WXQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Download the <a href="https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/">Broadcast beta</a> and explore the rest of the <a href="https://www.nvidia.com/en-us/studio/resources/">Studio suite</a> of apps, including <a href="https://www.nvidia.com/en-us/studio/canvas/">Canvas</a>, which uses AI to turn simple brushstrokes into realistic landscape images, and <a href="https://www.nvidia.com/en-us/geforce/rtx-remix/">RTX Remix</a>, which allows modders to create AI-powered RTX remasters of classic games. The apps are all free for RTX GPU owners.</p>
<figure id="attachment_69351" aria-describedby="caption-attachment-69351" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-brellias-wk92-artist-feature-1280w-1.png"><img loading="lazy" decoding="async" class="size-large wp-image-69351" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-brellias-wk92-artist-feature-1280w-1-672x263.png" alt="" width="672" height="263" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-brellias-wk92-artist-feature-1280w-1-672x263.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-brellias-wk92-artist-feature-1280w-1-400x156.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-brellias-wk92-artist-feature-1280w-1-768x300.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-brellias-wk92-artist-feature-1280w-1-842x329.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-brellias-wk92-artist-feature-1280w-1-406x159.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-brellias-wk92-artist-feature-1280w-1-188x73.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-brellias-wk92-artist-feature-1280w-1.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69351" class="wp-caption-text">Digital 3D artist Brellias.</figcaption></figure>
<p>Check out Brellias’ portfolio on <a href="https://www.instagram.com/brellias">Instagram</a>.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>X</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/01/breathe.mp4" length="1968679" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/01/estrellitas.mp4" length="1814603" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/nv-blog-header-preview-1280x680-2.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/nv-blog-header-preview-1280x680-2-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Starstruck: 3D Artist Brellias Brings Curiosity to Light This Week ‘In the NVIDIA Studio’]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA CEO: ‘This Year, Every Industry Will Become a Technology Industry’</title>
		<link>https://blogs.nvidia.com/blog/nvidia-ceo-ai-drug-discovery-jp-morgan-healthcare-2024/</link>
		
		<dc:creator><![CDATA[Rory Kelleher]]></dc:creator>
		<pubDate>Fri, 12 Jan 2024 18:30:17 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Genomics]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[NVIDIA Clara]]></category>
		<category><![CDATA[NVIDIA DGX]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69339</guid>

					<description><![CDATA[“This year, every industry will become a technology industry,” NVIDIA founder and CEO Jensen Huang told attendees Wednesday during the annual J.P. Morgan Healthcare Conference. “You can now recognize and learn the language of almost anything with structure, and you can translate it to anything with structure — so text-protein, protein-text,” Huang said in a <a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-ceo-ai-drug-discovery-jp-morgan-healthcare-2024/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>“This year, every industry will become a technology industry,” NVIDIA founder and CEO Jensen Huang told attendees Wednesday during the annual J.P. Morgan Healthcare Conference.</p>
<p>“You can now recognize and learn the language of almost anything with structure, and you can translate it to anything with structure — so text-protein, protein-text,” Huang said in a fireside chat with Martin Chavez, partner and vice chairman of global investment firm Sixth Street Partners and board chair of Recursion, a biopharmaceutical company. “This is the generative AI revolution.”</p>
<p>The conversation, which took place at the historic San Francisco Mint, followed a <a href="https://investor.nvidia.com/events-and-presentations/events-and-presentations/event-details/2024/JP-Morgan-Healthcare-Conference-2024-KwxXOv7uMk/default.aspx">presentation at the J.P. Morgan conference</a> Monday by Kimberly Powell, NVIDIA’s VP of healthcare. In her talk, Powell announced that <a href="https://www.recursion.com/news/nothing-short-of-phenomenal-new-deep-learning-model-available-on-nvidias-bionemo-platform" target="_blank" rel="noopener">Recursion is the first hosting partner</a> to offer a foundation model through the <a href="https://www.nvidia.com/en-us/clara/bionemo/">NVIDIA BioNeMo</a> cloud service, which is <a href="https://blogs.nvidia.com/blog/drug-discovery-bionemo-generative-ai/">advancing into beta</a> this month.</p>
<p>She also said that Amgen, one of the first companies to employ BioNeMo, <a href="https://blogs.nvidia.com/blog/genomics-ai-amgen-superpod/">plans to advance drug discovery with generative AI</a> and <a href="https://www.nvidia.com/en-us/data-center/dgx-superpod/">NVIDIA DGX SuperPOD</a> — and that BioNeMo is used by a growing number of techbio companies, pharmas, AI software vendors and systems integrators. Among them are <a href="https://www.prnewswire.com/news-releases/deloitte-expands-quartz-ai-suite-with-atlas-ai-for-drug-discovery-302028784.html" target="_blank" rel="noopener">Deloitte</a>, <a href="https://innophore.com/innophore-is-folding-the-human-proteome-using-nvidia-bionemo-creating-a-fused-dataset-of-structural-models-for-machine-learning-purposes/" target="_blank" rel="noopener">Innophore</a>, <a href="https://www.linkedin.com/pulse/insilico-medicine-ai-revolution-drug-discovery-in-silico-medicine-zlwfe/" target="_blank" rel="noopener">Insilico Medicine</a>, <a href="https://www.linkedin.com/pulse/transforming-molecular-design-oneangstrom-integrates-nvidia-redon-eukpe%3FtrackingId=GwLwkk17I2oVvvfSB2KuPQ%253D%253D/?trackingId=GwLwkk17I2oVvvfSB2KuPQ%3D%3D" target="_blank" rel="noopener">OneAngstrom</a>, Recursion and <a href="https://resources.nvidia.com/en-us-dgx-cloud/terray-therapeutics-customer-success-story" target="_blank" rel="noopener">Terray Therapeutics</a>.</p>
<h2><b>From Computer-Aided Chip Design to Drug Design</b></h2>
<p>Healthcare customers and partners now consume well over a billion dollars in NVIDIA GPU computing each year — directly and indirectly through cloud partners.</p>
<p>Huang traced NVIDIA’s involvement in accelerated healthcare back to two research projects that caught his attention around 15 years ago: one at Mass General tapped <a href="https://pubmed.ncbi.nlm.nih.gov/17881799/" target="_blank" rel="noopener">NVIDIA GPUs to reconstruct CT images</a>, another at the University of Illinois Urbana-Champaign <a href="https://www.nvidia.com/es-la/data-center/gpu-accelerated-applications/namd/">applied GPU acceleration to molecular dynamics</a>.</p>
<p>“It opened my mind that we could apply the same methodology that we use in computer-aided chip design to help the world of drug discovery go from computer-aided drug discovery to computer-aided drug design,” he said, realizing that, “if we scale this up by a billion times, we could simulate biology.”</p>
<p>After 40 years of advancements in computer-aided chip design, engineers can now build complex computing systems entirely in simulation, Huang explained. Over the next decade, the same could be true for AI-accelerated drug design.</p>
<p>“Almost everything will largely start in silico, largely end in silico,” he said, using a term that refers to an experiment run on a computer.</p>
<h2><b>Collaborating on the Future of Drug Discovery and Medical Instruments</b></h2>
<p>With the progress made to date, computer-aided drug discovery is “genuinely miraculous,” Huang said.</p>
<p>NVIDIA is propelling the field forward by building state-of-the-art AI models and powerful computing platforms, and by collaborating with domain experts and investing in techbio companies.</p>
<p>“We are determined to work with you to advance this field,” Huang said, inviting healthcare innovators to reach out to NVIDIA. “We deeply believe that this is going to be the future of the way that drugs will be discovered and designed.”</p>
<p>The company’s pipelines for accelerated healthcare include algorithms for cryo-electron microscopy, X-ray crystallography, gene sequencing, amino acid structure prediction and virtual drug molecule screening. And as AI advances, these computing tools are becoming much easier to access, Huang said.</p>
<p>“Because of artificial intelligence and the groundbreaking work that our industry has done, we have closed the technology divide in a dramatic way,” he said. “Everybody is a programmer, and the programming language of the future is called ‘human.’”</p>
<p>Beyond drug development, this transformation to a software-defined, AI-driven industry will also advance medical instruments.</p>
<p>“A medical instrument is never going to be the same again. Ultrasound systems, CT scan systems, all kinds of instruments — they’re always going to be a device plus a whole bunch of AIs,” Huang said. “The value that will create, the opportunities you create, are going to be incredible.”</p>
<p>For more from NVIDIA at the J.P. Morgan Healthcare Conference, <a href="https://jpmorgan.metameetings.net/events/healthcare24/sessions/49355-nvidia-corporation/webcast/general_signin?gpu_only=true&amp;kiosk=true" target="_blank" rel="noopener">listen to the audio recording</a> and <a href="https://nvidianews.nvidia.com/multimedia/corporate#gallery-1">view the presentation deck</a> of Powell’s session.</p>
<p><i>Learn about </i><a href="https://www.nvidia.com/en-us/clara/"><i>NVIDIA’s AI platform for healthcare and life sciences</i></a><i> and subscribe to </i><a href="https://www.nvidia.com/en-us/industries/healthcare-life-sciences/healthcare-news-sign-up/"><i>NVIDIA healthcare news</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/hc-corp-jpm23-jhh-kp-jpm-3085763-1280x680-r2.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/hc-corp-jpm23-jhh-kp-jpm-3085763-1280x680-r2-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA CEO: ‘This Year, Every Industry Will Become a Technology Industry’]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI Takes Center Stage: Survey Reveals Financial Industry’s Top Trends for 2024</title>
		<link>https://blogs.nvidia.com/blog/ai-in-financial-services-survey-2024/</link>
		
		<dc:creator><![CDATA[Kevin Levitt]]></dc:creator>
		<pubDate>Thu, 11 Jan 2024 14:00:55 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cybersecurity]]></category>
		<category><![CDATA[Financial Services]]></category>
		<category><![CDATA[Generative AI]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69275</guid>

					<description><![CDATA[The financial services industry is undergoing a significant transformation with the adoption of AI technologies. NVIDIA’s fourth annual State of AI in Financial Services Report provides insights into the current landscape and emerging trends for 2024. The report reveals that an overwhelming 91% of financial services companies are either assessing AI or already using it <a class="read-more" href="https://blogs.nvidia.com/blog/ai-in-financial-services-survey-2024/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The financial services industry is undergoing a significant transformation with the adoption of AI technologies. NVIDIA’s fourth annual <a href="https://www.nvidia.com/en-us/industries/finance/ai-financial-services-report/" target="_blank" rel="noopener">State of AI in Financial Services Report</a> provides insights into the current landscape and emerging trends for 2024.</p>
<p>The report reveals that an overwhelming 91% of financial services companies are either assessing AI or already using it in production. These firms are using AI to drive innovation, improve operational efficiency and enhance customer experiences.</p>
<p>Portfolio optimization, fraud detection and risk management remain top AI use cases, while <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/" target="_blank" rel="noopener">generative AI</a> is quickly gaining popularity with organizations keen to uncover new efficiencies.</p>
<p>Below are the report’s key findings, which show how the financial services industry is evolving as advanced AI becomes more accessible.</p>
<h2><strong>Generative AI and Large Language Models Are on the Rise</strong></h2>
<p>Reflecting a macro-trend seen across industries, <a href="https://www.nvidia.com/en-us/glossary/data-science/large-language-models/" target="_blank" rel="noopener">large language models</a> (LLMs) and generative AI have emerged as significant areas of interest for financial services companies. Fifty-five percent of survey respondents reported that they were actively seeking generative AI workflows for their companies.</p>
<p>Organizations are exploring generative AI and LLMs for an array of applications ranging from marketing and sales — ad copy, email copy and content production — to <a href="https://blogs.nvidia.com/blog/what-is-synthetic-data/" target="_blank" rel="noopener">synthetic data generation</a>. Of these use cases, 37% of respondents showed interest in report generation, synthesis and investment research to cut down on repetitive manual work.</p>
<p>Customer experience and engagement was another sought-out use case, with a 34% response rate. This suggests that financial services institutions are exploring chatbots, virtual assistants and <a href="https://blogs.nvidia.com/blog/whats-a-recommender-system/" target="_blank" rel="noopener">recommendation systems</a> to enhance the customer experience.</p>
<h2><strong>AI Is Having an Impact Across Departments and Disciplines</strong></h2>
<p>With 75% of survey respondents considering their organization’s AI capabilities to be industry leading or middle of the pack, financial services organizations are becoming more confident in their ability to build, deploy and extract value from AI implementations.</p>
<p>The most popular uses for AI were in operations, risk and compliance, and marketing. To improve operational efficiency, financial organizations are using AI to automate manual processes, enhance data analysis and inform investment decisions.</p>
<p>To enhance risk and compliance, they’re deploying AI to analyze vast amounts of data to identify suspicious activities and anomalous transaction patterns. They’re also using AI to analyze customer data to predict preferences and deliver personalized marketing campaigns, educational content and targeted promotions.</p>
<p>Companies are already seeing results. Forty-three percent of financial services professionals indicated that AI had improved their operational efficiency, while 42% felt it had helped their business build a competitive advantage.</p>
<h2><strong>A Shift in the Headwinds</strong></h2>
<p>In previous years, the number one challenge respondents reported was recruiting AI experts and data scientists. A 30% increase this year in survey participants resoundingly responded that data-related challenges were the primary concern. This includes data privacy challenges, data sovereignty and data scattered around the globe governed by different oversight regulations.</p>
<p>The growing attention to these issues reflects the advancing power and complexity of AI models, which require huge, diverse datasets to train, as well as increasing regulatory scrutiny and emphasis on responsible AI.</p>
<p>Recruiting and retaining AI experts remains a challenge, as do budget concerns. But more than 60% of respondents are still planning to increase investment in computing infrastructure or optimizing AI workflows, underscoring the importance of these tools in quickly building and deploying trustworthy AI to overcome these barriers.</p>
<h2><strong>Paving the Way for Future Investments</strong></h2>
<p>By and large, the survey results paint a positive picture of AI bringing greater efficiency to operations, personalization to customer engagements, and precision to investment decisions.</p>
<p>Finance professionals agree. Eighty-six percent of respondents reported a positive impact on revenue, while 82% noted a reduction in costs. Fifty-one percent strongly agreed that AI would be important to their company’s future success, a 76% increase from last year.</p>
<p>With this positive outlook, 97% of companies plan to invest more in AI technologies in the near future. Focus areas for future investments include identifying additional AI use cases, optimizing AI workflows and increasing infrastructure spending.</p>
<p>To build and scale impactful AI across the enterprise, financial services organizations need a comprehensive AI platform that empowers data scientists, quants and developers to seamlessly collaborate while minimizing obstacles. To that end, executives are investing more in AI infrastructure and prioritizing high-yield AI use cases to improve employee productivity while delivering superior customer experiences and investment results.</p>
<p>Download the “<a href="https://www.nvidia.com/en-us/industries/finance/ai-financial-services-report/" target="_blank" rel="noopener">State of AI in Financial Services: 2024 Trends</a>” report for in-depth results and insights.</p>
<p><i>Explore NVIDIA’s AI solutions and enterprise-level AI platforms for </i><a href="https://www.nvidia.com/en-us/industries/finance/" target="_blank" rel="noopener"><i>delivering smarter, more secure financial services</i></a><i> and the </i><a href="https://www.nvidia.com/en-us/industries/finance/ai-powered-bank/" target="_blank" rel="noopener"><i>AI-powered bank</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/finance-corp-blog-state-of-ai-24-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/finance-corp-blog-state-of-ai-24-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI Takes Center Stage: Survey Reveals Financial Industry’s Top Trends for 2024]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>To the Cloud and Beyond: New Activision and Blizzard Games, Day Passes and G-SYNC Technology Coming to GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-ces-2024/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 11 Jan 2024 14:00:46 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69316</guid>

					<description><![CDATA[GFN Thursday recaps the latest cloud announcements from CES 2024 — Day Pass memberships, Cloud G-SYNC technology, expanded NVIDIA Reflex support and more. The new year brings new adventures to the cloud for members, including Diablo IV and Overwatch 2 from Blizzard, Exoprimal from Capcom, Honkai: Star Rail from HoYoverse and Pax Dei from Mainframe <a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-ces-2024/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>GFN Thursday recaps the latest cloud announcements from <a href="https://www.nvidia.com/en-us/events/ces/">CES 2024</a> — Day Pass memberships, Cloud <a href="https://www.nvidia.com/en-us/geforce/products/g-sync-monitors/">G-SYNC</a> technology, expanded <a href="https://www.nvidia.com/en-us/geforce/technologies/reflex/">NVIDIA Reflex</a> support and more.</p>
<p>The new year brings new adventures to the cloud for members, including <i>Diablo IV</i> and <i>Overwatch 2</i> from Blizzard, <i>Exoprimal</i> from Capcom, <i>Honkai: Star Rail </i>from HoYoverse and <i>Pax Dei</i> from Mainframe Industries.</p>
<p>Plus, no GFN Thursday is complete without new games. Get ready for ten new titles joining the cloud this week.</p>
<h2><b>Cloud’s-Eye View of CES</b></h2>
<p><a href="https://blogs.nvidia.com/blog/CES-2024-geforce-now-activision-blizzard-day-passes-g-sync">CES 2024</a> has come to a close, and GeForce NOW members have a lot to look forward to.</p>
<p>Coming in February, day passes for <a href="https://www.nvidia.com/en-us/geforce-now/memberships/">Ultimate and Priority memberships</a> will offer a new way for members to play at up to GeForce RTX 4080 quality for up to 24 hours. Ultimate Day Pass will be available for $7.99, and Priority Day Pass for $3.99, providing all the benefits of both memberships to gamers before they decide to commit to the better-value one-month or six-month memberships.</p>
<figure id="attachment_69329" aria-describedby="caption-attachment-69329" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Cloud_GSYNC.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-69329" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Cloud_GSYNC-672x336.jpg" alt="G-SYNC comes to GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Cloud_GSYNC-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Cloud_GSYNC-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Cloud_GSYNC-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Cloud_GSYNC-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Cloud_GSYNC-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Cloud_GSYNC-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Cloud_GSYNC-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Cloud_GSYNC-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Cloud_GSYNC.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69329" class="wp-caption-text">Nothing but a G-SYNC, baby.</figcaption></figure>
<p>Cloud G-SYNC support will match the display refresh rate of variable refresh rate monitors and <a href="https://www.nvidia.com/en-us/geforce/products/g-sync-monitors/specs/">G-SYNC-compatible monitors</a> to the streaming rate. Paired with new 60 and 120 frames per second streaming options for GeForce NOW Reflex mode, this makes cloud gaming experiences nearly indistinguishable from using a local PC.</p>
<p>Ultimate members will be able to turn their phones into portable gaming rigs with support for 1440p resolutions on compatible Android phones, as well as updated keyboard and mouse support connected through a USB hub. Thanks to the cloud, these smartphones are now capable of PC gaming at Ultimate quality.</p>
<figure id="attachment_69326" aria-describedby="caption-attachment-69326" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Worldwide_Expansion.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-69326" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Worldwide_Expansion-672x336.jpg" alt="Worldwide Expansion for GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Worldwide_Expansion-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Worldwide_Expansion-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Worldwide_Expansion-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Worldwide_Expansion-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Worldwide_Expansion-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Worldwide_Expansion-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Worldwide_Expansion-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Worldwide_Expansion-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Worldwide_Expansion.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69326" class="wp-caption-text">The cloud’s drifting into Japan.</figcaption></figure>
<p>GeForce NOW will also soon expand to Japan, operating alongside GeForce NOW Alliance partner KDDI. This will enable gamers across the country to play their favorite PC games in the cloud with Ultimate performance. <a href="https://www.nvidia.com/ja-jp/geforce-now/japan-notify-me">Learn more and sign up for notifications</a>.</p>
<h2><b>Here Comes the Blizzard</b></h2>
<p><iframe loading="lazy" title="Play Your Favorite PC Games Streaming with GeForce NOW 4080-Class Power in the Cloud" width="500" height="281" src="https://www.youtube.com/embed/35kP2TgZ5hQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>That’s not all: GeForce NOW is bringing even more top titles to the cloud from celebrated publishers.</p>
<p>Following the recent release of <a href="https://blogs.nvidia.com/blog/geforce-now-thursday-call-of-duty/"><i>Call of Duty</i></a>, the latest games from top developer Blizzard Entertainment are coming soon to GeForce NOW. Members will be able to play the Steam versions of <i>Diablo IV</i> and <i>Overwatch 2</i> on nearly any device with the power of a GeForce RTX 4080 rig in the cloud, with support for Battle.net coming soon.</p>
<figure id="attachment_69323" aria-describedby="caption-attachment-69323" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Diablo_IV-scaled.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-69323" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Diablo_IV-672x378.jpg" alt="Diablo IV on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Diablo_IV-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Diablo_IV-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Diablo_IV-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Diablo_IV-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Diablo_IV-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Diablo_IV-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Diablo_IV-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Diablo_IV-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Diablo_IV-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69323" class="wp-caption-text">Someone check the weather in hell — seems pretty cold.</figcaption></figure>
<p>Join the fight for sanctuary in <i>Diablo IV. </i>Fight the forces of hell while discovering countless abilities to master, legendary loot to gather and nightmarish dungeons full of evil enemies to vanquish. Explore a shared open world where players can form their own armies to take down World Bosses, or join the fray in player vs. player zones to test skills against others.</p>
<p>Team up and answer the call of heroes in <i>Overwatch 2</i>, a free-to-play shooter featuring 30+ epic heroes, each with game-changing abilities. Lead the charge, ambush enemies or aid allies as one of <i>Overwatch</i>’s distinct heroes. Join the battle across dozens of futuristic maps inspired by real-world locations and master unique game modes in the always-on, ever-evolving live game.</p>
<p>Members can look forward to playing the Steam version of both games from the cloud, with support for the Battle.net launcher coming soon.</p>
<figure id="attachment_69114" aria-describedby="caption-attachment-69114" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/gfn-spotlight-honkai-star-rail-tw-li-2048x1024-1.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-69114" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/gfn-spotlight-honkai-star-rail-tw-li-2048x1024-1-672x336.jpg" alt="Honkai Star Rail coming soon to GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/gfn-spotlight-honkai-star-rail-tw-li-2048x1024-1-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/gfn-spotlight-honkai-star-rail-tw-li-2048x1024-1-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/gfn-spotlight-honkai-star-rail-tw-li-2048x1024-1-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/gfn-spotlight-honkai-star-rail-tw-li-2048x1024-1-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/01/gfn-spotlight-honkai-star-rail-tw-li-2048x1024-1-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/01/gfn-spotlight-honkai-star-rail-tw-li-2048x1024-1-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/01/gfn-spotlight-honkai-star-rail-tw-li-2048x1024-1-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/01/gfn-spotlight-honkai-star-rail-tw-li-2048x1024-1-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/01/gfn-spotlight-honkai-star-rail-tw-li-2048x1024-1.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69114" class="wp-caption-text">The Astral Express is coming to GeForce NOW.</figcaption></figure>
<p>Expanding the library of hit free-to-play titles for members, <i>Honkai: Star Rail</i> from miHoYo will soon join <i>Genshin Impact</i> in the cloud. The space-fantasy role-playing game is set in a diverse universe filled with wonder, adventure and thrills. Plus, members can experience all the latest updates without worrying about download times.</p>
<p>Mainframe Industries’ <i>Pax Dei </i>is a highly anticipated social sandbox massively multiplayer online game inspired by legends of the medieval era. It’s planned to release on GeForce NOW when it launches for PC.</p>
<figure id="attachment_69320" aria-describedby="caption-attachment-69320" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Overwatch_2-scaled.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-69320" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Overwatch_2-672x378.jpg" alt="Exoprimal on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Overwatch_2-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Overwatch_2-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Overwatch_2-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Overwatch_2-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Overwatch_2-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Overwatch_2-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Overwatch_2-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Overwatch_2-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-Overwatch_2-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69320" class="wp-caption-text">Dinosaurs? Oh my.</figcaption></figure>
<p>Capcom is working with NVIDIA to bring more of its hit titles to the cloud, including <i>Exoprimal</i>, an online, team-based action game that pits humanity’s cutting-edge exosuit technology against history’s most ferocious beasts: dinosaurs. Look forward to streaming it from the cloud starting Thursday, Jan. 18.</p>
<p>Get ready to play these titles and more at high performance coming soon. Ultimate members will be able to stream at up to 4K resolution and 120 fps with support for <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/">NVIDIA DLSS</a> and <a href="https://www.nvidia.com/en-us/geforce/technologies/reflex/">Reflex</a> technology, and experience the action even on low-powered devices. Keep an eye out on <a href="https://blogs.nvidia.com/blog/author/geforcenowcommunity/">GFN Thursdays</a> for the latest on game release dates in the cloud.</p>
<h2><b>New to Play Today</b></h2>
<figure id="attachment_69317" aria-describedby="caption-attachment-69317" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-War_Hospital.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-69317" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-War_Hospital-672x336.jpg" alt="War Hospital on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-War_Hospital-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-War_Hospital-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-War_Hospital-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-War_Hospital-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-War_Hospital-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-War_Hospital-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-War_Hospital-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-War_Hospital-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/01/GFN_Thursday-War_Hospital.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69317" class="wp-caption-text">Patch the wounded, mend the broken, survive the storm.</figcaption></figure>
<p>What’s a GFN Thursday without more games? Here’s what’s coming to the GeForce NOW library this week:</p>
<ul>
<li><i>War Hospital </i>(New release Jan. 11, available on <a href="https://store.steampowered.com/app/1553000?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Assassin’s Creed: Valhalla </i>(<a href="https://gamepass.ubisoft.com/">Xbox</a>, available for PC Game Pass)</li>
<li><i>Jected &#8211; Rivals </i>(<a href="https://store.steampowered.com/app/1366850?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>RAILGRADE </i>(<a href="https://store.steampowered.com/app/1355090?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Survivalist: Invisible Strain</i> (<a href="https://store.steampowered.com/app/1054510?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>The Talos Principle 2</i> (<a href="https://www.epicgames.com/store/p/the-talos-principle-2-ab1034?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Turbo Golf Racing </i>(<a href="https://www.xbox.com/games/store/turbo-golf-racing-game-preview/9N6781PMXC02?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available for PC Game Pass)</li>
<li><i>TUNIC</i> (<a href="https://www.xbox.com/games/store/tunic/9NLRT31Z4RWM?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available for PC Game Pass)</li>
<li><i>Witch It</i> (<a href="https://store.steampowered.com/app/559650?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Zombie Army 4: Dead War</i> (<a href="https://www.xbox.com/games/store/zombie-army-4-dead-war/9PLSCHRN5715?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available for PC Game Pass)</li>
</ul>
<p>Learn more about activating and playing <a href="https://nvidia.custhelp.com/app/answers/detail/a_id/5508/~/how-do-i-play-supported-ubisoft-games-from-xbox-pc-game-pass-on-geforce-now">Ubisoft games from PC Game Pass on GeForce NOW</a>.</p>
<p>What are you playing this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/gfn-thursday-ces-ecosystem-nv-blog-1280x680-no-cta.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/gfn-thursday-ces-ecosystem-nv-blog-1280x680-no-cta-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[To the Cloud and Beyond: New Activision and Blizzard Games, Day Passes and G-SYNC Technology Coming to GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Remains Among Very Best Places to Work in US, Rising to No. 2 on Glassdoor’s Annual List</title>
		<link>https://blogs.nvidia.com/blog/nvidia-life-glassdoor-best-place-work-2024/</link>
		
		<dc:creator><![CDATA[Haley Hirai]]></dc:creator>
		<pubDate>Wed, 10 Jan 2024 16:00:54 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[NVIDIA Life]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69272</guid>

					<description><![CDATA[NVIDIA continues to be among America’s very best places to work as judged by employees themselves, rising to second place on Glassdoor’s list of best employers for 2024. This is the fourth consecutive year NVIDIA has been among the top five on the closely watched list, which is based on anonymous employee reviews about their <a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-life-glassdoor-best-place-work-2024/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>NVIDIA continues to be among America’s very best places to work as judged by employees themselves, rising to second place on <a href="https://www.glassdoor.com/Award/Best-Places-to-Work-LST_KQ0,19.htm?utm_medium=social&amp;utm_content=awards&amp;utm_campaign=BPTW23">Glassdoor’s list of best employers for 2024</a>.</p>
<p>This is the fourth consecutive year NVIDIA has been among the top five on the closely watched list, which is based on anonymous employee reviews about their job, company and work environment. Last year, NVIDIA ranked fifth.</p>
<p>Topping this year’s list is Bain &amp; Co., with ServiceNow, MathWorks and Procore Technologies rounding out the top five.</p>
<p>Employees consistently share positive feedback about NVIDIA via Glassdoor’s anonymous reviews, which capture an authentic look at what it’s like to work at more than a million companies.</p>
<p>Some 98% of NVIDIANs approve of founder and CEO Jensen Huang’s leadership and 94% would recommend working at NVIDIA to a friend.</p>
<p>Here are some typical comments submitted by employees:</p>
<ul>
<li>“NVIDIA is the best company you could possibly work for,” wrote one engineer on the site. “Employees are basically provided with every single thing they need to be able to do their life&#8217;s work at NVIDIA. I might just work here for the rest of my life and retire from here.”</li>
<li>“Truly, I have never worked at a place like NVIDIA,” another wrote. “The culture is strong, morale is high, teams are supportive of each other and employees love their work.”</li>
<li>“NVIDIA hires great people — in every discipline where we work, we have world-class experts and a deep bench. NVIDIA has a culture of help; nobody fails alone and we succeed together,” another noted.</li>
</ul>
<p><i>Learn more about </i><a href="https://www.nvidia.com/en-us/about-nvidia/careers/life-at-nvidia/"><i>NVIDIA life, culture and careers</i></a><i>. </i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/glassdoor-2023.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/glassdoor-2023-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Remains Among Very Best Places to Work in US, Rising to No. 2 on Glassdoor’s Annual List]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>How Generative AI Is Redefining the Retail Industry</title>
		<link>https://blogs.nvidia.com/blog/generative-ai-retail-industry/</link>
		
		<dc:creator><![CDATA[Azita Martin]]></dc:creator>
		<pubDate>Tue, 09 Jan 2024 16:00:45 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Retail]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69123</guid>

					<description><![CDATA[Ninety-eight percent of retailers plan to invest in generative AI in the next 18 months, according to a new survey conducted by NVIDIA. That makes retail one of the industries racing fastest to adopt generative AI to ramp up productivity, transform customer experiences and improve efficiency. Early deployments in the retail industry include personalized shopping <a class="read-more" href="https://blogs.nvidia.com/blog/generative-ai-retail-industry/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Ninety-eight percent of retailers plan to invest in <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/">generative AI</a> in the next 18 months, according to a <a href="http://www.nvidia.com/en-us/lp/industries/state-of-ai-in-retail-and-cpg/">new survey</a> conducted by NVIDIA.</p>
<p>That makes retail one of the industries racing fastest to adopt generative AI to ramp up productivity, transform customer experiences and improve efficiency.</p>
<p>Early deployments in the retail industry include personalized shopping advisors and adaptive advertising, with retailers initially testing off-the-shelf models like GPT-4 from OpenAI.</p>
<p>But many are now realizing the value in developing custom models trained on their proprietary data to achieve brand-appropriate tone and personalized results in a scalable, cost-effective way.</p>
<p>Before building them, companies must first consider a variety of questions: whether to opt for an open-source, closed-source or enterprise model; how they plan to train and deploy the models; how to host them; and, most importantly, how to ensure future innovations and new products can be easily incorporated into them.</p>
<p>New offerings like <a href="https://www.nvidia.com/en-us/ai-data-science/foundation-models/">NVIDIA AI Foundations</a>, a curated collection of optimized, enterprise-grade foundation models from NVIDIA and leading open-source pretrained models, are giving retail companies the building blocks they need to construct their custom models. With <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/">NVIDIA NeMo</a>, an end-to-end platform for large language model development, retailers can customize and deploy their models at scale using the latest state-of-the-art techniques.</p>
<h2><b>Generative AI Use Cases </b></h2>
<p>Multimodal models are leading the new frontier in the generative AI landscape. They’re capable of processing, understanding and generating content and images from multiple sources such as text, image, video and 3D rendered assets.</p>
<p>This allows retailers to create eye-catching images or videos for a brand’s marketing and advertising campaign using only a few lines of text prompts. Or they can be used to deliver  personalized shopping experiences with in-situ and try-on product image results. Yet another use case is in product description generation, where generative AI can intelligently generate detailed e-commerce product descriptions that include product attributes, using meta-tags to greatly improve SEO.</p>
<p>Many retailers are testing the generative AI waters first with internal deployments. For example, some are boosting the productivity of their engineering teams with AI-powered computer code generators that can write optimized lines of code for indicated outcomes. Others are using custom models to generate marketing copy and promotions for various audience segments, increasing click-to-conversion rates. Meanwhile, chatbots and translators are helping employees accomplish their day-to-day tasks.</p>
<p>To enhance customer experiences, retailers are deploying generative AI-powered shopping advisors that can offer personalized product recommendations ​in customer-tailored conversation styles and display images of products being recommended. It can even display those products if shoppers want to see the recommended product, for example, in their home by uploading a picture of a room. Another use case is a customer service multilingual chatbot capable of answering simple customer inquiries and routing complex ones to human agents for improved, more efficient service.</p>
<h2><b>NVIDIA at NRF</b></h2>
<p>To learn more about how generative AI is shaping the future of retail, connect with the NVIDIA team at <a href="https://nrfbigshow.nrf.com/">NRF: Retail’s Big Show</a>, the world’s largest retail expo, taking place Jan. 14-16 at the Jacob K. Javits Convention Center in New York.</p>
<p>Attend the <a href="https://nrfbigshow.nrf.com/session/how-target-and-canadian-tire-use-generative-ai-personalized-shopping-experiences-driving">Big Ideas session</a> on Jan. 14 at 2 p.m. ET to hear from Azita Martin, NVIDIA’s vice president of AI for retail, consumer packaged goods and quick-service restaurants, and others on how Target and Canadian Tire are using generative AI to deliver personalized shopping experiences and drive revenue and productivity.</p>
<p>Visit Dell’s booth on level three (4957) to meet with NVIDIA AI experts and experience NVIDIA’s <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/">generative AI</a> demos.</p>
<p><i>Download the </i><a href="https://www.nvidia.com/en-us/lp/industries/state-of-ai-in-retail-and-cpg/"><i>State of AI in Retail and CPG: 2024 Trends</i></a><i> report for in-depth results and insights.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/genairetail2.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/genairetail2-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[How Generative AI Is Redefining the Retail Industry]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Putting the AI in Retail: Survey Reveals Latest Trends Driving Technological Advancements in the Industry</title>
		<link>https://blogs.nvidia.com/blog/ai-in-retail-survey-2024/</link>
		
		<dc:creator><![CDATA[Cynthia Countouris]]></dc:creator>
		<pubDate>Tue, 09 Jan 2024 16:00:09 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Retail]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69249</guid>

					<description><![CDATA[The retail industry is in the midst of a major technology transformation, fueled by the rise in AI. With the highest potential for AI and analytics among all industries, the retail and consumer packaged goods (CPG) sectors are poised to harness the power of AI to enhance operational efficiency, elevate customer and employee experiences and <a class="read-more" href="https://blogs.nvidia.com/blog/ai-in-retail-survey-2024/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The retail industry is in the midst of a major technology transformation, fueled by the rise in AI.</p>
<p><a href="https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier#key-insights">With the highest potential for AI and analytics among all industries</a>, the retail and consumer packaged goods (CPG) sectors are poised to harness the power of AI to enhance operational efficiency, elevate customer and employee experiences and drive growth. As such, it’s crucial to stay ahead of the curve by anticipating potential trends that aim to change the retail game.</p>
<p>NVIDIA’s first annual “<a href="http://www.nvidia.com/en-us/lp/industries/state-of-ai-in-retail-and-cpg/">State of AI in Retail and CPG</a>” survey — conducted among industry professionals — provides insights into the state of AI adoption in retail, its impact on revenue and costs and the emerging trends shaping the future of the industry.</p>
<p>With more than 400 respondents globally, including C-suite leaders and other executives, general managers and individual contributors, the survey consisted of questions covering a range of AI topics, top use cases, biggest challenges, infrastructure investment initiatives and deployment models.</p>
<h2><b>Improving Operational Efficiencies Is a Top Priority</b></h2>
<p>To stay ahead in a highly dynamic market, retailers are actively considering how AI can help them meet evolving customer preferences, address labor shortages and drive sustainability efforts. AI has already proved to be a game-changer for retailers, with 69% reporting an increase in annual revenue attributed to AI adoption. Additionally, 72% of retailers using AI experienced a decrease in operating costs.</p>
<p>AI is enhancing operational efficiency, elevating customer experiences and driving growth. The top five current AI use cases were as follows:</p>
<ol>
<li>Store analytics and insights</li>
<li>Personalized customer recommendations</li>
<li>Adaptive advertising, promotions and pricing</li>
<li>Stockout and inventory management</li>
<li>Conversational AI</li>
</ol>
<p>While retailers are actively implementing AI, there are still areas they plan on exploring. These include further investing in AI infrastructure to overcome challenges related to inadequate technology and lack of AI talent, exploring the potential of the metaverse for consumer engagement and operational efficiency while also leveraging AI for brick-and-mortar stores to provide convenience and personalized customer experiences, transforming customer experiences using <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/">generative AI</a>, and ensuring data privacy and protection in generative AI adoption.</p>
<h2><b>Generative AI Is Changing Customer Experiences</b></h2>
<p>Generative AI prominently emerged in several of the top AI use cases for retail. The use cases ranged from multimodal shopping advisors for personalized product recommendations; adaptive advertising, promotions and pricing; product tagging and cataloging; identification of similar and complementary products; as well as deployment of brand avatars for automated customer service.</p>
<p>Retailers recognized the transformative potential of generative AI, with 86% expressing a desire to use it to enhance customer experiences. Respondents acknowledged that incorporating AI into business practices and solutions could revolutionize customer engagement, optimize marketing strategies and streamline operational processes.</p>
<h2><b>Staying Ahead With an Omnichannel Approach</b></h2>
<p>To stay competitive, the survey indicated the importance of an omnichannel approach that integrates numerous online and offline channels to provide consumers with a consistent experience.</p>
<p>The results showed that ecommerce was the most used channel, with 79% of retailers actively participating. Mobile applications also gained traction, with over half of retailers using them to bridge the gap between digital and physical shopping experiences.</p>
<p>Despite the rise in digital shopping, 30% of respondents say physical stores have the biggest revenue growth opportunity (ranked second behind ecommerce) and remain the channel with the most AI use cases for retailers. Given the emphasis on intelligent stores and their central role in the omnichannel experience, use cases such as store analytics and loss prevention will continue to be critical investments.</p>
<h2><b>Investing in AI Infrastructure</b></h2>
<p>While AI adoption is still in its early stages, retailers are committed to increasing their AI infrastructure investments. Over 60% of respondents plan to boost their AI investments in the next 18 months. This commitment reflects the industry’s recognition of the technology’s potential to enhance operational efficiency, reduce costs, elevate customer experiences and drive growth.</p>
<p>Download the “<a href="https://www.nvidia.com/en-us/lp/industries/state-of-ai-in-retail-and-cpg/">State of AI in Retail and CPG: 2024 Trends</a>” report for in-depth results and insights.</p>
<p><i>Explore NVIDIA’s AI solutions and enterprise-level AI platforms for retail at </i><a href="http://www.nvidia.com/retail"><i>www.nvidia.com/retail</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/retail-corp-blog-state-of-ai-23-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/retail-corp-blog-state-of-ai-23-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Putting the AI in Retail: Survey Reveals Latest Trends Driving Technological Advancements in the Industry]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA and Loss Prevention Retail Council Introduce AI Solution to Address Organized Retail Crime</title>
		<link>https://blogs.nvidia.com/blog/ai-solution-organized-retail-crime/</link>
		
		<dc:creator><![CDATA[Azita Martin]]></dc:creator>
		<pubDate>Tue, 09 Jan 2024 14:00:51 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Computer Vision]]></category>
		<category><![CDATA[Metropolis]]></category>
		<category><![CDATA[Retail]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69124</guid>

					<description><![CDATA[NVIDIA and the Loss Prevention Research Council (LPRC) are collaborating with several AI companies to showcase a real-time solution for combating and preventing organized retail crime (ORC). The integrated offering provides advance notifications of suspicious behavior inside and outside stores so that authorities can intervene early. The LPRC includes asset-protection executives from more than 85 <a class="read-more" href="https://blogs.nvidia.com/blog/ai-solution-organized-retail-crime/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>NVIDIA and the Loss Prevention Research Council (LPRC) are collaborating with several AI companies to showcase a real-time solution for combating and preventing organized retail crime (ORC).</p>
<p>The integrated offering provides advance notifications of suspicious behavior inside and outside stores so that authorities can intervene early.</p>
<p>The LPRC includes asset-protection executives from more than 85 major retail chains, with hundreds of thousands of stores worldwide, as well as law enforcement, consumer packaged goods companies and technology solutions partners. It’s focused on collaborating with the retail industry to reduce shrink — the loss of products for reasons other than sales — and increase safety and security at stores and shopping malls.</p>
<p>Flash mobs and smash-and-grab thefts are a growing concern, costing retailers billions of dollars in lost revenue and causing safety concerns among customers and employees. Crime syndicates have committed brazen, large-scale thefts, often selling stolen merchandise on the black market.</p>
<p>A <a href="https://nrf.com/media-center/press-releases/shrink-accounted-over-112-billion-industry-losses-2022-according-nrf#:~:text=According%20to%20the%20survey%2C%20the,65%25)%20of%20retailers'%20shrink.">National Retail Federation survey</a> found that shrink accounted for $112 billion in losses in 2022, with an estimated two-thirds due to theft.</p>
<p>Increasingly, this involves violence. According to the survey, 67% of respondents said they were seeing more violence and aggression associated with organized-crime theft than a year ago.</p>
<p>The AI-based solution, which helps retailers get a jump on often-evasive, fast-moving organized crime groups, uses technology from several leading AI firms that have built their high-performance AI applications on the <a href="https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/">NVIDIA Metropolis</a> application framework and microservices.</p>
<p>The solution includes product recognition and tracking, as well as anomaly detection, from AiFi, vehicle license plate and model recognition from BriefCam, and physical security management from SureView to provide advance and real-time notifications to retailer command centers.</p>
<p>The three are among over 500 software companies and startups that have developed retail, safety and security AI applications on NVIDIA Metropolis software development kits for vision AI — and that have been certified as NVIDIA Metropolis partners.</p>
<p>“The proposed AI-based ORC solution combines LPRC’s deep expertise in loss prevention from over 23 years of collaboration with asset protection executives with NVIDIA’s deep AI expertise,” said Read Hayes, who leads the LPRC and is a University of Florida research scientist and criminologist. “We believe this type of cross-industry collaboration will help retailers fight back against organized retail crime.”</p>
<h2><b>Developing Integrated AI for Securing Stores </b></h2>
<p>AiFi, based in Silicon Valley, develops <a href="https://blogs.nvidia.com/blog/what-is-computer-vision/">computer vision</a> solutions, including autonomous retail capabilities built on the NVIDIA Metropolis application framework. Its solution detects anomalies in shopper behavior, tracks items removed from shelves and notifies retailers if shoppers bypass checkout lanes.</p>
<p><a href="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fhubs.la%2FQ02fdxX00&amp;data=05%7C02%7Cobass%40nvidia.com%7C30a2729430154667d04708dc0d5a5c87%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638399929011629141%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=%2BN3Eb5BRJnJVl%2Fv3Eqyrkrb7yUGwzxywkGA3XGfh7%2Fw%3D&amp;reserved=0">BriefCam</a>, based in Newton, Mass., provides deep learning-based video analytics technology for insightful decision-making. Enabling the forensic search, alerting on and visualization of objects in video, the BriefCam Platform includes integrated license plate recognition and cross-camera object tracking, alongside other capabilities that support effective asset protection and real-time response to theft attempts.</p>
<p><a href="https://sureviewsystems.com/">SureView</a>, based in Tampa, Fla., offers a software platform for managing multiple security systems with a single view. The company’s physical security management system receives signals from the AiFi and BriefCam applications, helping teams coordinate a quick and consistent response and providing notifications to store security operations and law enforcement based on the retailer’s business rules.</p>
<p>For more information about AI solutions for mitigating organized retail crime, connect with the NVIDIA team at <a href="https://nrfbigshow.nrf.com/">NRF: Retail’s Big Show</a>, the world’s largest retail expo, taking place Jan. 14-16 at the Javits Convention Center in New York.</p>
<p>Attend the <a href="https://nrfbigshow.nrf.com/session/combatting-organized-retail-crime-ai-insights-kroger-and-jacksons-food">Big Ideas session on Organized Retail Crime</a> on Jan. 14 at 2 p.m. ET, moderated by the LPRC, to discover how Kroger and Jacksons Food are using AI in their stores to tackle crime.</p>
<p>The ORC solution will be showcased at NRF — visit NVIDIA experts in Lenovo’s booth (3665) and Dell’s booth (4957) to learn more about it from NVIDIA’s software partners.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/retail-corp-blog-nrf24-orc-adobe-stock-434996650-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/retail-corp-blog-nrf24-orc-adobe-stock-434996650-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA and Loss Prevention Retail Council Introduce AI Solution to Address Organized Retail Crime]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Amgen to Build Generative AI Models for Novel Human Data Insights and Drug Discovery</title>
		<link>https://blogs.nvidia.com/blog/genomics-ai-amgen-superpod/</link>
		
		<dc:creator><![CDATA[Rory Kelleher]]></dc:creator>
		<pubDate>Mon, 08 Jan 2024 18:00:59 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cloud Services]]></category>
		<category><![CDATA[Customer Stories]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Genomics]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[NVIDIA DGX]]></category>
		<category><![CDATA[NVIDIA Hopper Architecture]]></category>
		<category><![CDATA[Supercomputing]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69015</guid>

					<description><![CDATA[Generative AI is transforming drug research and development, enabling new discoveries faster than ever — and Amgen, one of the world’s leading biotechnology companies, is tapping the technology to power its research. Amgen will build AI models trained to analyze one of the world’s largest human datasets on an NVIDIA DGX SuperPOD, a full-stack data <a class="read-more" href="https://blogs.nvidia.com/blog/genomics-ai-amgen-superpod/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Generative AI is transforming drug research and development, enabling new discoveries faster than ever — and Amgen, one of the world’s leading biotechnology companies, is tapping the technology to power its research.</p>
<p>Amgen will build AI models trained to analyze one of the world’s largest human datasets on an <a href="https://www.nvidia.com/en-us/data-center/dgx-superpod/">NVIDIA DGX SuperPOD</a>, a full-stack data center platform, that will be installed at Amgen’s deCODE genetics’ headquarters in Reykjavik, Iceland. The system will be named Freyja in honor of the powerful, life-giving Norse goddess associated with the ability to predict the future.</p>
<p>Freyja will be used to build a human diversity atlas for drug target and disease-specific biomarker discovery, providing vital diagnostics for monitoring disease progression and regression. The system will also help develop AI-driven precision medicine models, potentially enabling individualized therapies for patients with serious diseases.</p>
<p>Amgen plans to integrate the DGX SuperPOD, which will feature 31 <a href="https://www.nvidia.com/en-us/data-center/dgx-h100/">NVIDIA DGX H100</a> nodes totaling 248 <a href="https://www.nvidia.com/en-us/data-center/h100/">H100 Tensor Core GPUs</a>, to train state-of-the-art AI models in days rather than months, enabling researchers to more efficiently analyze and learn from data in their search for novel health and therapeutics insights.</p>
<p>“For more than a decade, Amgen has been preparing for this hinge moment we are seeing in the industry, powered by the union of technology and biotechnology,” said David M. Reese, executive vice president and chief technology officer at Amgen. “We look forward to  combining the breadth and maturity of our world-class human data capabilities at Amgen with NVIDIA’s technologies.”</p>
<p>The goal of deCODE founder and CEO Kári Stefánsson in starting the company was to understand human disease by looking at the diversity of the human genome. He predicted in a recent <a href="https://tslabtalk.podbean.com/e/the-human-data-era-the-role-of-human-diversity-in-progressing-precision-medicine/">Amgen podcast</a> that within the next 10 years, doctors will routinely use genetics to explore uncommon diseases in patients.</p>
<p>“This SuperPOD has the potential to accelerate our research by training models more quickly and helping us generate questions we might not have otherwise thought to ask,” said Stefánsson.</p>
<h2><strong>Putting the Tech in Biotechnology</strong></h2>
<p>Since its founding in 1996, deCODE has curated more than 200 petabytes of de-identified human data from nearly 3 million individuals.</p>
<p>The company started by collecting de-identified data from Icelanders, who have a rich heritage in genealogies that stretch back for centuries. This population-scale data from research volunteers provides unique insights into human diversity as it applies to disease.</p>
<p>deCODE has also helped sequence more than half a million human genomes from volunteers in the <a href="https://www.ukbiobank.ac.uk/learn-more-about-uk-biobank/news/world-s-largest-genetic-project-opens-the-door-to-new-era-for-treatments-and-cures-uk-biobank-s-major-milestone">UK Biobank</a>.</p>
<p>But drawing insights from this much data requires powerful AI systems.</p>
<p>By integrating powerful new technology, Amgen has an opportunity to accelerate the discovery and development of life-changing medicines. In March 2023, NVIDIA announced that Amgen became one of the first companies <a href="https://nvidianews.nvidia.com/news/nvidia-unveils-large-language-models-and-generative-ai-services-to-advance-life-sciences-r-d">to employ NVIDIA BioNeMo</a>, which researchers have used to build generative AI models to accelerate drug discovery and development. Amgen researchers have also been accessing BioNeMo via <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a>, an AI supercomputing service.</p>
<p>“Models trained in BioNeMo can advance drug discovery on multiple fronts,” said Marti Head, executive director of computational and data sciences at Amgen. “In addition to helping develop drugs that are more effective, they can also help avoid unwanted effects like immune responses, and new biologics can be made in volume.”</p>
<p>By adopting DGX SuperPOD, Amgen is poised to gain unprecedented data insights with the potential to change the pace and scope of drug discovery.</p>
<p>“The fusion of advanced AI, groundbreaking developments in biology and molecular engineering and vast quantities of human data are not just reshaping how we discover and develop new medicines — they’re redefining medicine,” Reese said.</p>
<p>Learn about <a href="https://www.nvidia.com/en-us/clara/">NVIDIA’s AI platform for healthcare and life sciences</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/amgenblog.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/amgenblog-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Amgen to Build Generative AI Models for Novel Human Data Insights and Drug Discovery]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Generative AI Is Opening the Next Era of Drug Discovery and Design</title>
		<link>https://blogs.nvidia.com/blog/drug-discovery-bionemo-generative-ai/</link>
		
		<dc:creator><![CDATA[Kimberly Powell]]></dc:creator>
		<pubDate>Mon, 08 Jan 2024 18:00:42 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Genomics]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[NVIDIA Clara]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69016</guid>

					<description><![CDATA[In perhaps the healthcare industry’s most dramatic transformation since the advent of computing, digital biology and generative AI are helping to reinvent drug discovery, surgery, medical imaging and wearable devices. NVIDIA has been preparing for this moment for over a decade, building deep domain expertise, creating the NVIDIA Clara healthcare-specific computing platform and expanding its <a class="read-more" href="https://blogs.nvidia.com/blog/drug-discovery-bionemo-generative-ai/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>In perhaps the healthcare industry’s most dramatic transformation since the advent of computing, digital biology and generative AI are helping to reinvent drug discovery, surgery, medical imaging and wearable devices.</p>
<p>NVIDIA has been preparing for this moment for over a decade, building deep domain expertise, creating the <a href="https://www.nvidia.com/en-us/clara/">NVIDIA Clara</a> healthcare-specific computing platform and expanding its work with a rich ecosystem of partners. Healthcare customers and partners already consume well over a billion dollars in NVIDIA GPU computing each year — directly and indirectly through cloud partners.</p>
<p>In the $250 billion field of drug discovery, these efforts are meeting an inflection point: R&amp;D teams can now represent drugs inside a computer.</p>
<p>By harnessing emerging generative AI tools, drug discovery teams observe foundational building blocks of molecular sequence, structure, function and meaning — allowing them to generate or design novel molecules likely to possess desired properties. With these capabilities, researchers can curate a more precise field of drug candidates to investigate, reducing the need for expensive, time-consuming physical experiments.</p>
<p>Accelerating this shift is <a href="https://www.nvidia.com/en-gb/gpu-cloud/bionemo/">NVIDIA BioNeMo</a>, a generative AI platform that provides services to develop, customize and deploy foundation models for drug discovery.</p>
<p>Used by pharmaceutical, techbio and software companies, BioNeMo offers a new class of computational methods for drug research and development, enabling scientists to integrate generative AI to reduce experiments and, in some cases, replace them altogether.</p>
<p>In addition to developing, optimizing and hosting AI models through BioNeMo, NVIDIA has boosted the computer-aided drug discovery ecosystem with <a href="https://blogs.nvidia.com/blog/nvidia-investments/">investments in innovative techbio companies</a> — such as biopharmaceutical company Recursion, which is offering one of its foundation models for BioNeMo users, and biotech company Terray Therapeutics, which is using BioNeMo for AI model development.</p>
<h2><b>BioNeMo Brings Precision to AI-Accelerated Drug Discovery </b></h2>
<p>BioNeMo features a growing collection of pretrained biomolecular AI models for protein structure prediction, protein sequence generation, molecular optimization, generative chemistry, docking prediction and more. It also enables computer-aided drug discovery companies to make their models available to a broad audience through easy-to-access APIs for inference and customization.</p>
<p>Drug discovery teams use BioNeMo to invent or customize generative AI models with proprietary data — and drug discovery software companies, techbios and large pharmas  are integrating  BioNeMo cloud APIs, which will be released in beta this month, into platforms that deliver computer-aided drug discovery workflows.</p>
<p>The cloud APIs will now include <a href="https://blogs.nvidia.com/blog/what-are-foundation-models/">foundation models</a> from three sources: models invented by NVIDIA, such as the MolMIM generative chemistry model for small molecule generation; open-source models pioneered by global research teams, curated and optimized by NVIDIA, such as the OpenFold protein prediction AI; and proprietary models developed by NVIDIA partners, such as Recursion’s Phenom-Beta for embedding cellular microscopy images.</p>
<p>MolMIM generates small molecules while giving users finer control over the AI generation process — identifying new molecules that possess desired properties and follow constraints specified by users. For example, researchers could direct the model to generate molecules that have similar structures and properties to a given reference molecule.</p>
<h2><b>Phenomenal AI for Pharma:</b><b> Recursion </b><b>Brings Phenom-Beta Model to BioNeMo</b></h2>
<p>Recursion is the first hosting partner offering an AI model through BioNeMo cloud APIs: Phenom-Beta, a vision <a href="https://blogs.nvidia.com/blog/what-is-a-transformer-model/">transformer model</a> that extracts biologically meaningful features from cellular microscopy images.</p>
<p>This capability can provide researchers with insights about cell function and help them learn how cells respond to drug candidates or genetic engineering.</p>
<figure id="attachment_69214" aria-describedby="caption-attachment-69214" style="width: 1200px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/vit_diff_mask_ratios.gif"><img loading="lazy" decoding="async" class="wp-image-69214 size-full" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/vit_diff_mask_ratios.gif" alt="" width="1200" height="603" /></a><figcaption id="caption-attachment-69214" class="wp-caption-text">Phenom-Beta performed well on image reconstruction tasks, a training metric to evaluate model performance. Read the <a href="https://arxiv.org/abs/2309.16064" target="_blank" rel="noopener">NeurIPS workshop paper</a> to learn more.</figcaption></figure>
<p>Phenom-Beta was trained on Recursion’s publicly available <a href="https://www.rxrx.ai/rxrx3" target="_blank" rel="noopener">RxRx3 dataset</a> of biological images using the company’s BioHive-1 supercomputer, based on the <a href="https://www.nvidia.com/en-us/data-center/dgx-superpod/">NVIDIA DGX SuperPOD</a> reference architecture.</p>
<p>To further its foundation model development, Recursion is <a href="https://ir.recursion.com/news-releases/news-release-details/recursion-provides-business-updates-and-reports-third-quarter-1" target="_blank" rel="noopener">expanding its supercomputer </a>with more than 500 <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA H100 Tensor Core GPUs</a>. This will boost its computational capacity by 4x to create what’s expected to be the most powerful supercomputer owned and operated by any biopharma company.</p>
<p><iframe loading="lazy" title="Generative AI for Drug Discovery and Design" width="500" height="281" src="https://www.youtube.com/embed/Gch6bX1toB0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>How Companies Are Adopting NVIDIA BioNeMo</b></h2>
<p>A growing group of scientists, biotech and pharma companies, and AI software vendors are using NVIDIA BioNeMo to support biology, chemistry and genomics research.</p>
<p>Biotech leader <a href="https://resources.nvidia.com/en-us-dgx-cloud/terray-therapeutics-customer-success-story">Terray Therapeutics</a> is integrating BioNeMo cloud APIs into its development of a generalized, multi-target structural binding model. The company also uses <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a> to train chemistry foundation models to power generative AI for small molecule design.</p>
<p>Protein engineering and molecular design companies Innophore and Insilico Medicine are bringing BioNeMo into their computational drug discovery applications. Innophore is integrating BioNeMo cloud APIs into its Catalophore platform for protein design and drug discovery. And Insilico, a premier member of the <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a> program for startups, has adopted BioNeMo in its generative AI pipeline for early drug discovery.</p>
<p>Biotech software company OneAngstrom and systems integrator Deloitte are using BioNeMo cloud APIs to build AI solutions for their clients.</p>
<p>OneAngstrom is integrating BioNeMo cloud APIs into its SAMSON platform for molecular design used by academics, biotechs and pharmas. Deloitte is transforming scientific research by integrating BioNeMo on NVIDIA DGX Cloud with the Quartz Atlas AI platform. This combination enables biopharma researchers with unparalleled data connectivity and cutting-edge generative AI, propelling them into a new era of accelerated drug discovery.</p>
<p><i>Learn more about </i><a href="https://www.nvidia.com/en-us/clara/bionemo/"><i>NVIDIA BioNeMo</i></a><i> and subscribe to </i><a href="https://www.nvidia.com/en-us/industries/healthcare-life-sciences/healthcare-news-sign-up/"><i>NVIDIA healthcare news</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/hc-corp-jpm24-bionemo-blog-1280x680-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/hc-corp-jpm24-bionemo-blog-1280x680-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Generative AI Is Opening the Next Era of Drug Discovery and Design]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Reveals Gaming, Creating, Generative AI, Robotics Innovations at CES</title>
		<link>https://blogs.nvidia.com/blog/ces-2024/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Mon, 08 Jan 2024 17:00:40 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[CES 2024]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[Robotics]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68992</guid>

					<description><![CDATA[The AI revolution returned to where it started this week, putting powerful new tools into the hands of gamers and content creators. Generative AI models that will bring lifelike characters to games and applications and new GPUs for gamers and creators were among the highlights of a news-packed address Monday ahead of this week’s CES <a class="read-more" href="https://blogs.nvidia.com/blog/ces-2024/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>The AI revolution returned to where it started this week, putting powerful new tools into the hands of gamers and content creators.</p>
<p>Generative AI models that will bring lifelike characters to games and applications and new GPUs for gamers and creators were among the highlights of a news-packed address Monday ahead of this week’s CES trade show in Las Vegas.</p>
<p>“Today, NVIDIA is at the center of the latest technology transformation: generative AI,” said Jeff Fisher, senior vice president for GeForce at NVIDIA, who was joined by leaders across the company to introduce products and partnerships across gaming, content creation, and robotics.</p>
<p><iframe loading="lazy" title="YouTube video player" src="https://www.youtube.com/embed/-JbSg2UnK2k?si=bTsTe6wc22SGGtdw" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<h2><strong>A Launching Pad for Generative AI</strong></h2>
<p>As AI shifts into the mainstream, Fisher said NVIDIA’s RTX GPUs, with more than 100 million units shipped, are pivotal in the burgeoning field of generative AI, exemplified by innovations like ChatGPT and Stable Diffusion.</p>
<p>In October, <a href="https://developer.nvidia.com/blog/optimizing-inference-on-llms-with-tensorrt-llm-now-publicly-available/#:~:text=Today%2C%20NVIDIA%20announces%20the%20public,of%20the%20NVIDIA%20NeMo%20framework.">NVIDIA released the TensorRT-LLM library for Windows</a>, accelerating large language models, or LLMs, like Llama 2 and Mistral up to 5x on RTX PCs.</p>
<p>And with our new <a href="https://www.nvidia.com/chat-with-rtx">Chat with RTX</a> playground, releasing later this month, enthusiasts can connect an RTX-accelerated LLM to their own data, from locally stored documents to YouTube videos, using <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">retrieval-augmented generation</a>, or RAG, a technique for enhancing the accuracy and reliability of generative AI models.</p>
<p>Fisher also introduced TensorRT acceleration for Stable Diffusion XL and SDXL Turbo in the popular Automatic1111 text-to-image app, providing up to a 60% boost in performance.</p>
<h2><strong>NVIDIA Avatar Cloud Engine Microservices Debut With Generative AI Models for Digital Avatars</strong></h2>
<p><a href="https://developer.nvidia.com/ace">NVIDIA ACE</a> is a technology platform that brings digital avatars to life with generative AI. ACE AI models are designed to run in the cloud or locally on the PC.</p>
<p>In an ACE demo featuring <a href="https://www.convai.com/">Convai’s </a>new technologies, NVIDIA’s Senior Product Manager Seth Schneider showed how it works.</p>
<p>&nbsp;</p>
<p><iframe loading="lazy" title="NVIDIA ACE Brings Digital Characters to Life with Generative AI ft. Convai" width="500" height="281" src="https://www.youtube.com/embed/psrXGPh80UM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>First, a player’s voice input is passed to NVIDIA’s automatic speech recognition model, which translates speech to text. Then, the text is put into an LLM to generate the character’s response.</p>
<p>After that, the text response is vocalized using a text-to-speech model, which is passed to an animation model to create a realistic lip sync. Finally, the dynamic character is rendered into the game scene.</p>
<p>At CES, NVIDIA is announcing ACE Production Microservices for NVIDIA Audio2Face and NVIDIA Riva Automatic Speech Recognition. Available now, each model can be incorporated by developers individually into their pipelines.</p>
<p>NVIDIA is also announcing game and interactive avatar developers are pioneering ways ACE and generative AI technologies can be used to transform interactions between players and non-playable characters in games and applications. Developers embracing ACE include <a href="https://www.convai.com/">Convai</a>, <a href="https://charisma.ai/">Charisma.AI</a>, <a href="https://inworld.ai/">Inworld</a>, <a href="https://www.mihoyo.com/en/">miHoYo</a>, <a href="https://www.neteasegames.com/">NetEase Games</a>, <a href="https://youtu.be/PSg-4HmLvfI">Ourpalm</a>, <a href="https://www.tencent.com/">Tencent</a>, <a href="https://www.ubisoft.com/en-us/">Ubisoft</a> and <a href="https://www.digitalhumans.com/">UneeQ</a>.</p>
<h2><strong>Getty Images Releases Generative AI by iStock and AI Image Generation Tools Powered by NVIDIA Picasso</strong></h2>
<p>Generative AI empowers designers and marketers to create concept imagery, social media content and more. Today, iStock by Getty Images is releasing a genAI service built on NVIDIA Picasso, an AI foundry for visual design, Fisher announced.</p>
<p>The iStock service allows anyone to create 4K imagery from text using an AI model trained on Getty Images’ extensive catalog of licensed, commercially safe creative content. New editing application programming interfaces that give customers powerful control over their generated images are also coming soon.</p>
<p>The generative AI service is available today at istock.com, with advanced editing features releasing via API.</p>
<h2><strong>NVIDIA Introduces GeForce RTX 40 SUPER Series</strong></h2>
<p>Fisher announced a new series of <a href="https://nvidianews.nvidia.com/news/geforce-rtx-40-super-series">GeForce RTX 40 SUPER GPUs</a> with more gaming and generative AI performance.</p>
<p>Fisher said that the GeForce RTX 4080 SUPER can power fully ray-traced games at 4K. It’s 1.4x faster than the RTX 3080 Ti without frame gen in the most graphically intensive games. With 836 AI TOPS, NVIDIA DLSS Frame Generation delivers an extra performance boost, making the RTX 4080 SUPER twice as fast as an RTX 3080 Ti.</p>
<p>Creators can generate video with Stable Video Diffusion 1.5x faster and images with Stable Diffusion XL 1.7x faster. The RTX 4080 SUPER features more cores and faster memory, giving it a performance edge at a great new price of $999. It will be available starting Jan. 31.</p>
<p>Next up is the RTX 4070 Ti SUPER. NVIDIA has added more cores and increased the frame buffer to 16GB and the memory bus to 256 bits. It’s 1.6x faster than a 3070 Ti and 2.5x faster with DLSS 3, Fisher said. The RTX 4070 Ti SUPER will be available starting Jan. 24 for $799.</p>
<p>Fisher also introduced the RTX 4070 SUPER. NVIDIA has added 20% more cores, making it faster than the RTX 3090 while using a fraction of the power. And with DLSS 3, it’s 1.5x faster in the most demanding games. It will be available for $599 starting Jan. 17.</p>
<h2><strong>NVIDIA RTX Remix Open Beta Launches This Month</strong></h2>
<p>There are over 10 billion game mods downloaded each year. With <a href="https://www.nvidia.com/en-us/geforce/rtx-remix/">RTX Remix</a>, modders can remaster classic games with full ray tracing, DLSS, NVIDIA Reflex and generative AI texture tools that transform low-resolution textures into 4K, physically accurate materials. The RTX Remix app will be released in open beta on Jan. 22.</p>
<p>RTX Remix has already delivered stunning remasters in NVIDIA’s <a href="https://www.nvidia.com/en-us/geforce/news/portal-with-rtx-full-ray-tracing-december-8/"><i>Portal with RTX</i></a> and the modder-made <a href="https://www.nvidia.com/en-us/geforce/news/portal-prelude-rtx-available-now-for-free/"><i>Portal: Prelude RTX</i></a>. Now, Orbifold Studios is using RTX Remix to develop <a href="https://www.nvidia.com/en-us/geforce/news/half-life-2-rtx-remix-in-development/"><i>Half-Life 2 RTX: An RTX Remix Project</i></a>, a community remaster of one of the highest-rated games of all time.</p>
<p>Check out this new <i>Half-Life 2 RTX</i> gameplay trailer:</p>
<p><iframe loading="lazy" title="Half-Life 2 RTX, An RTX Remix Project - Ravenholm Trailer" width="500" height="281" src="https://www.youtube.com/embed/nIE9gQt6WXQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>&nbsp;</p>
<h2><strong>Twitch and NVIDIA to Release Multi-Encode Livestreaming</strong></h2>
<p>Twitch is one of the most popular platforms for content creators, with over 7 million streamers going live each month to 35 million daily viewers. Fisher explained that these viewers are on all kinds of devices and internet services.</p>
<p>Yet many Twitch streamers are limited to broadcasting at a single resolution and quality level. As a result, they must broadcast at lower quality to reach more viewers.</p>
<p>To address this, Twitch, OBS and NVIDIA announced Enhanced Broadcasting, supported by all RTX GPUs. This new feature allows streamers to transmit up to three concurrent streams to Twitch at different resolutions and quality so each viewer gets the optimal experience.</p>
<p>Beta signups start today and will go live later this month. Twitch will also experiment with 4K and AV1 on the GeForce RTX 40 Series GPUs to deliver even better quality and higher resolution streaming.</p>
<h2><strong>‘New Wave’ of AI-Ready RTX Laptops</strong></h2>
<p>RTX is the fastest-growing laptop platform, having grown 5x in the last four years. Over 50 million devices are enjoyed by gamers and creators across the globe.</p>
<p>More’s coming. Fisher announced “a new wave” of RTX laptops launching from every major manufacturer. “Thanks to powerful RT and Tensor Cores, every RTX laptop is AI-ready for the best gaming and AI experiences,” Fisher said.</p>
<p>With an installed base of 100 million GPUs and 500 RTX games and apps, GeForce RTX is the world’s largest platform for gamers, creators and, now, generative AI.</p>
<h2><strong>Activision and Blizzard Games Embrace RTX</strong></h2>
<p>More than 500 games and apps now take advantage of <a href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA RTX technology</a>, NVIDIA’s Senior Consumer Marketing Manager Kristina Bartz said, including <i>Alan Wake 2</i>, which won three awards at this year’s Game Awards.</p>
<figure id="attachment_69055" aria-describedby="caption-attachment-69055" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-69055 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/Kristina_Bartz_03-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/Kristina_Bartz_03-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Kristina_Bartz_03-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Kristina_Bartz_03-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Kristina_Bartz_03-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Kristina_Bartz_03.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Kristina_Bartz_03-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Kristina_Bartz_03-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Kristina_Bartz_03-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Kristina_Bartz_03-1280x720.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69055" class="wp-caption-text">NVIDIA Consumer Marketing Manager Kristina Bartz spoke about how NVIDIA technologies are being integrated into popular games.</figcaption></figure>
<p>It’s a list that keeps growing with 14 new RTX titles announced at CES.</p>
<p><a href="https://youtu.be/DEqRbxOrFAw"><i>Horizon Forbidden West</i></a>, the critically acclaimed sequel to <i>Horizon Zero Dawn</i>, will come to PC early this year with the Burning Shores expansion, accelerated by DLSS 3.</p>
<p><i>Pax Dei</i> is a social sandbox massively multiplayer online game inspired by the legends of the medieval era. Developed by Mainframe Industries with veterans from CCP Games, Blizzard and Remedy Entertainment, <i>Pax Dei </i>will launch in early access on PC with AI-accelerated DLSS 3 this spring.</p>
<p>Last summer, <i>Diablo IV</i> launched with DLSS 3 and immediately became Blizzard’s fastest-selling game. RTX ray tracing will now be coming to <i>Diablo IV</i> in March.</p>
<figure id="attachment_69058" aria-describedby="caption-attachment-69058" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-69058 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-geforce-rtx-ces-2024-announcing-new-rtx-dlss-games-672x378.jpg" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-geforce-rtx-ces-2024-announcing-new-rtx-dlss-games-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-geforce-rtx-ces-2024-announcing-new-rtx-dlss-games-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-geforce-rtx-ces-2024-announcing-new-rtx-dlss-games-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-geforce-rtx-ces-2024-announcing-new-rtx-dlss-games-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-geforce-rtx-ces-2024-announcing-new-rtx-dlss-games-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-geforce-rtx-ces-2024-announcing-new-rtx-dlss-games-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-geforce-rtx-ces-2024-announcing-new-rtx-dlss-games-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-geforce-rtx-ces-2024-announcing-new-rtx-dlss-games-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-geforce-rtx-ces-2024-announcing-new-rtx-dlss-games-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69058" class="wp-caption-text">More than 500 games and apps now take advantage of NVIDIA RTX technology, with more coming.</figcaption></figure>
<h2><strong>Day Passes and G-SYNC Technology Coming to GeForce NOW</strong></h2>
<p>NVIDIA’s partnership with Activision also extends to the cloud with <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a>, Bartz said. In November, NVIDIA welcomed the first Activation and Blizzard game, <i>Call of Duty: Modern Warfare 3</i>. <i>Diablo IV</i> and <i>Overwatch 2</i> are coming soon.</p>
<p>GeForce NOW will get Day Pass membership options starting in February. Priority and Ultimate Day Passes will give gamers a full day of gaming with the fastest access to servers, with all the same benefits as members, including NVIDIA DLSS 3.5 and NVIDIA Reflex for Ultimate Day Pass purchasers.</p>
<p>NVIDIA also announced Cloud G-SYNC technology is coming to GeForce NOW, which varies the display refresh rate to match the frame rate on G-SYNC monitors, giving members the smoothest, tear-free gaming experience from the cloud.</p>
<h2><strong>Generative AI Powers Smarter Robots With NVIDIA Isaac<br />
</strong></h2>
<figure id="attachment_69061" aria-describedby="caption-attachment-69061" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-69061 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/Deepu_040-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/Deepu_040-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Deepu_040-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Deepu_040-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Deepu_040-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Deepu_040.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Deepu_040-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Deepu_040-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Deepu_040-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Deepu_040-1280x720.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-69061" class="wp-caption-text">NVIDIA Vice President of Robotics and Edge Computing Deepu Talla addressed the intersection of AI and robotics.</figcaption></figure>
<p>Closing out the special address, NVIDIA Vice President of Robotics and Edge Computing Deepu Talla shared how the infusion of generative AI into robotics is speeding up the ability to bring robots from proof of concept to real-world deployment.</p>
<p>Talla gave a peek into the growing use of generative AI in the NVIDIA robotics ecosystem, where robotics innovators like Boston Dynamics and Collaborative Robots are changing the landscape of human-robot interaction.</p>
<p><iframe loading="lazy" title="YouTube video player" src="https://www.youtube.com/embed/-JbSg2UnK2k?si=bTsTe6wc22SGGtdw" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/Jeff_Fisher_Card_07.png"
			type="image/png"
			width="2048"
			height="1152"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/Jeff_Fisher_Card_07-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Reveals Gaming, Creating, Generative AI, Robotics Innovations at CES]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Drives AI Forward With Automotive Innovation on Display at CES</title>
		<link>https://blogs.nvidia.com/blog/ai-automotive-innovation-ces/</link>
		
		<dc:creator><![CDATA[Calisa Cole]]></dc:creator>
		<pubDate>Mon, 08 Jan 2024 16:33:26 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[CES 2024]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<category><![CDATA[Omniverse]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69186</guid>

					<description><![CDATA[Amid explosive interest in generative AI, the auto industry is racing to embrace the power of AI across a range of critical activities, from vehicle design, engineering and manufacturing, to marketing and sales. The adoption of generative AI — along with the growing importance of software-defined computing — will continue to transform the automotive market <a class="read-more" href="https://blogs.nvidia.com/blog/ai-automotive-innovation-ces/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Amid explosive interest in generative AI, the auto industry is racing to embrace the power of AI across a range of critical activities, from vehicle design, engineering and manufacturing, to marketing and sales.</p>
<p>The adoption of generative AI — along with the growing importance of software-defined computing — will continue to transform the automotive market in 2024.</p>
<p>NVIDIA today <a href="https://nvidianews.nvidia.com/news/wave-of-ev-makers-choose-nvidia-drive-for-automated-driving">announced</a> that Li Auto, a pioneer in extended-range electric vehicles (EVs), has selected the NVIDIA DRIVE Thor centralized car computer to power its next-generation fleets. Also, EV makers GWM (Great Wall Motor), ZEEKR and Xiaomi have adopted the NVIDIA DRIVE Orin platform to power their intelligent automated-driving systems.</p>
<p>In addition, a powerful lineup of technology is on display from NVIDIA’s automotive partners on the CES trade show floor in Las Vegas.</p>
<ul>
<li><b>Mercedes-Benz</b> is kicking off CES with a press conference to announce a range of exciting software-driven features and the latest developments in the Mercedes-Benz MB.OS story, each one showcased in a range of cars, including the Concept CLA Class, which is using NVIDIA DRIVE Orin for the automated driving domain. Mercedes-Benz is also using digital twins for production with help from <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, a platform for developing applications to design, collaborate, plan and operate manufacturing and assembly facilities. (West Hall &#8211; 4941)</li>
<li><b>Luminar</b> will host a fireside chat with NVIDIA on Jan. 10 at 2 p.m. PT to discuss the state of the art of sensor processing and ongoing collaborations between the companies. In addition, Luminar will showcase the work it’s doing with NVIDIA partners Volvo Cars, Polestar, Plus and Kodiak. (West Hall &#8211; 5917 and West Plaza &#8211; WP10)</li>
<li><b>Ansys</b> is demonstrating how it leverages NVIDIA Omniverse to accelerate autonomous vehicle development. Ansys AVxcelerate Sensors will be accessible within <a href="https://www.nvidia.com/en-us/self-driving-cars/simulation/">NVIDIA DRIVE Sim</a>. (West Hall &#8211; 6500)</li>
<li><b>Cerence</b> is introducing CaLLM, an automotive-specific <a href="https://www.nvidia.com/en-us/glossary/data-science/large-language-models/">large language model</a> that serves as the foundation for the company’s next-gen in-car computing platform, running on <a href="https://developer.nvidia.com/drive">NVIDIA DRIVE</a>. (West Hall &#8211; 6627)</li>
<li><b>Cipia</b> is showcasing its embedded software version of Cabin Sense, which includes both driver and occupancy monitoring and is expected to go into serial production this year. NVIDIA DRIVE is the first platform on which Cabin Sense will run commercially. (North Hall &#8211; 11022)</li>
<li><strong>EyeLights </strong>is unveiling its new cockpit vision, enabled by generative AI and accelerated compute powered by NVIDIA. The company will showcase how it’s turning the windshield into an augmented reality display. (North Hall &#8211; 10943)</li>
<li><b>Kodiak</b> is exhibiting an autonomous truck, which relies on NVIDIA GPUs for high-performance compute to process the enormous quantities of data it collects from its cameras, radar and lidar sensors. (West Plaza &#8211; WP10, with Luminar)</li>
<li><b>Lenovo</b> is displaying its vehicle computing roadmap, featuring new products based on <a href="https://nvidianews.nvidia.com/news/nvidia-unveils-drive-thor-centralized-car-computer-unifying-cluster-infotainment-automated-driving-and-parking-in-a-single-cost-saving-system">NVIDIA DRIVE Thor</a>, including: Lenovo XH1, a central compute unit for advanced driver-assistance systems and smart cockpit; Lenovo AH1, a level 2++ ADAS domain controller unit; and Lenovo AD1, a level 4 autonomous driving domain controller unit. (Estiatorio Milos, Venetian Hotel)</li>
<li><b>Pebble</b>, a recreational vehicle startup, is presenting its flagship product Pebble Flow, the electric semi-autonomous travel trailer powered by NVIDIA DRIVE Orin, with production starting before the end of 2024. (West Hall &#8211; 7023)</li>
<li><strong>Plus</strong> is showcasing its PlusDrive supervised autonomy solution on a highly automated truck, which uses NVIDIA GPUs to process the trillions of operations per second its autonomous driving system requires. (West Plaza &#8211; WP10, with Luminar)</li>
<li><b>Polestar</b> is showcasing Polestar 3, which is powered by the NVIDIA DRIVE Orin central core computer. (West Hall &#8211; 5917 with Luminar and Central Plaza &#8211; CP1 with Google)</li>
<li><b>Zoox</b> is showcasing the latest generation of its purpose-built robotaxi, which leverages NVIDIA technology, and is offering CES attendees the opportunity to join its early-bird waitlist for its autonomous ride-hailing service. (West Hall &#8211; 7228)</li>
</ul>
<h2><b>Explore to Win</b></h2>
<p><b></b>Visit select NVIDIA partner booths for a chance to win <a href="https://www.nvidia.com/gtc/">GTC 2024</a> conference passes with hotel accommodations.</p>
<h2><b>Event Lineup</b></h2>
<p><b></b>Check out <a href="https://www.nvidia.com/en-us/events/ces/">NVIDIA’s CES event page</a> for a summary of all of the company’s automotive-related events. Learn about NVIDIA’s other announcements at CES by viewing the company’s <a href="https://www.nvidia.com/en-us/events/ces/">special address</a> on demand.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/auto-ecosystem-blog-3091700-1280x680-r1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/auto-ecosystem-blog-3091700-1280x680-r1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Drives AI Forward With Automotive Innovation on Display at CES]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>The Creative AI: NVIDIA Studio Unveils New RTX- and AI-Accelerated Tools and Systems for Creators</title>
		<link>https://blogs.nvidia.com/blog/studio-rtx-hdr-video-twitch-obs-istock-getty-super-laptop-desktop/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Mon, 08 Jan 2024 16:30:41 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[CES 2024]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69135</guid>

					<description><![CDATA[NVIDIA Studio is debuting at CES powerful new software and hardware upgrades to elevate content creation. ]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. We’re also deep diving on new </i><a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/"><i>GeForce RTX 40 Series GPU</i></a> <i>features, technologies and resources, and how they dramatically accelerate content creation.</i></p>
<p><a href="https://www.nvidia.com/en-us/studio/">NVIDIA Studio</a> is debuting at CES powerful new software and hardware upgrades to elevate content creation.</p>
<p>It brings the release of powerful <a href="https://www.nvidia.com/en-us/studio/laptops-desktops/">NVIDIA Studio laptops</a> and desktops from Acer, ASUS, Dell, HP, Lenovo, MSI and Samsung, as well as the launch of the new GeForce RTX 40 SUPER Series GPUs — including the <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4080/">GeForce RTX 4080 SUPER</a>, <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4070-4070ti/">GeForce RTX 4070 Ti SUPER</a> and <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4070-4070ti/">GeForce RTX 4070 SUPER</a> — to supercharge creating, gaming and AI tasks.</p>
<p>Generative AI by iStock from Getty Images is a new generative AI tool trained by <a href="https://www.nvidia.com/en-us/gpu-cloud/picasso/">NVIDIA Picasso</a> that uses licensed artwork and the NVIDIA Edify architecture model to ensure that generated assets are commercially safe.</p>
<p>RTX Video HDR coming Jan. 24 transforms standard dynamic range video playing in internet browsers into stunning high dynamic range (HDR). By pairing it with RTX Video Super Resolution, NVIDIA RTX and GeForce RTX GPU owners can achieve dramatic video quality improvements on their HDR10 displays.</p>
<p>Twitch, OBS and NVIDIA are enhancing livestreaming technology with the new Twitch Enhanced Broadcasting beta, powered by GeForce RTX GPUs. Available later this month, the beta will enable users to stream multiple encodes concurrently, providing optimal viewing experiences for a broad range of device types and connections.</p>
<p>And <a href="https://www.nvidia.com/en-us/geforce/rtx-remix/">NVIDIA RTX Remix</a> — a free modding platform for quickly remastering classic games with RTX — releases in open beta later this month. It provides full ray tracing, NVIDIA DLSS, NVIDIA Reflex and generative AI texture tools.</p>
<p>This week’s <i>In the NVIDIA Studio</i> installment also features NVIDIA artists Ashlee Martino-Tarr, a 3D content specialist, and Daniela Flamm Jackson, a technical product marketer, who transform 2D illustrations into dynamic 3D scenes using AI and Adobe Firefly — powered by NVIDIA in the cloud and natively with GeForce RTX GPUs.</p>
<h2><b>New Year, New NVIDIA Studio Laptops</b></h2>
<p>The new NVIDIA Studio laptops and desktops level up power and efficiency with <a href="https://www.nvidia.com/en-us/studio/resources/">exclusive software</a> like Studio Drivers preinstalled — enhancing creative features, reducing time-consuming tasks and speeding workflows.</p>
<p>The <a href="https://www.acer.com/tritonneo16">Acer Predator Triton Neo 16</a> features several 16-inch screen options with up to a 3.2K resolution at a 165Hz refresh rate and 16:10 aspect ratio. It provides DCI-P3 100% color gamut and support for NVIDIA Optimus and NVIDIA G-SYNC technology for sharp color hues and tear-free frames. It’s expected to be released in March.</p>
<figure id="attachment_69222" aria-describedby="caption-attachment-69222" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-acer-predator-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69222" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-acer-predator-1280w-672x359.png" alt="" width="672" height="359" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-acer-predator-1280w-672x359.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-acer-predator-1280w-400x213.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-acer-predator-1280w-768x410.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-acer-predator-1280w-842x450.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-acer-predator-1280w-403x215.png 403w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-acer-predator-1280w-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-acer-predator-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69222" class="wp-caption-text">The Acer Predator Triton Neo 16, with up to the GeForce RTX 4070 Laptop GPU.</figcaption></figure>
<p>The <a href="https://rog.asus.com/">ASUS ROG Zephryus G14</a> features a Nebula Display with a OLED panel and a G-SYNC OLED display running at 240Hz. It’s expected to release on Feb. 6.</p>
<figure id="attachment_69142" aria-describedby="caption-attachment-69142" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-asus-rog-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69142" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-asus-rog-1280w-672x359.png" alt="" width="672" height="359" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-asus-rog-1280w-672x359.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-asus-rog-1280w-400x213.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-asus-rog-1280w-768x410.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-asus-rog-1280w-842x450.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-asus-rog-1280w-403x215.png 403w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-asus-rog-1280w-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-asus-rog-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69142" class="wp-caption-text">The ASUS ROG Zephryus G14 with up to the GeForce RTX 4070 Laptop GPU.</figcaption></figure>
<p>The <a href="https://www.dell.com/en-us/shop/dell-laptops/sr/laptops/xps-laptops">XPS 16</a> is Dell’s most powerful laptop featuring a large 16.3” InfinityEdge display, available with a 4K+ OLED touch display, true-to-life color delivering up to 80W of sustained performance, all with tone-on-tone finishes for an elegant, minimalistic design. Stay tuned for an update on release timing.</p>
<figure id="attachment_69145" aria-describedby="caption-attachment-69145" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-dell-xps-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69145" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-dell-xps-1280w-672x359.png" alt="" width="672" height="359" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-dell-xps-1280w-672x359.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-dell-xps-1280w-400x213.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-dell-xps-1280w-768x410.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-dell-xps-1280w-842x450.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-dell-xps-1280w-403x215.png 403w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-dell-xps-1280w-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-dell-xps-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69145" class="wp-caption-text">Dell’s XPS 16 with up to the GeForce RTX 4070 Laptop GPU.</figcaption></figure>
<p><a href="https://www.lenovo.com/gb/en/yoga/yoga-intel">Lenovo’s Yoga Pro 9i</a> sports a 16-inch 3.2K PureSight Pro display, delivering a grid of over 1,600 mini-LED dimming zones, expertly calibrated colors accurate to Delta E&lt; 1 and up to 165Hz. With Microsoft’s Auto Color Management feature, its display toggles automatically between 100% P3, 100% sRGB and 100% Adobe RGB color to ensure the highest-quality color. It’s expected to be released in April.</p>
<figure id="attachment_69148" aria-describedby="caption-attachment-69148" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-lenovo-yoga-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69148" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-lenovo-yoga-1280w-672x359.png" alt="" width="672" height="359" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-lenovo-yoga-1280w-672x359.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-lenovo-yoga-1280w-400x213.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-lenovo-yoga-1280w-768x410.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-lenovo-yoga-1280w-842x450.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-lenovo-yoga-1280w-403x215.png 403w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-lenovo-yoga-1280w-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-lenovo-yoga-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69148" class="wp-caption-text">Lenovo Yoga Pro 9i with up to the GeForce RTX 4070 Laptop GPU.</figcaption></figure>
<p>HP’s <a href="https://www.omen.com/us/en.html">OMEN 14 Transcend</a> features a 14-inch 4K OLED WQXGA screen, micro-edge, edge-to-edge glass and 100% DCI-P3 with a 240Hz refresh rate. NVIDIA DLSS 3 technology helps unlock more efficient content creation and gaming sessions using only one-third of the expected battery power. It’s targeting a Jan. 19 release.</p>
<figure id="attachment_69151" aria-describedby="caption-attachment-69151" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-hp-omen-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69151" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-hp-omen-1280w-672x359.png" alt="" width="672" height="359" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-hp-omen-1280w-672x359.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-hp-omen-1280w-400x213.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-hp-omen-1280w-768x410.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-hp-omen-1280w-842x450.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-hp-omen-1280w-403x215.png 403w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-hp-omen-1280w-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-hp-omen-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69151" class="wp-caption-text">HP’s OMEN 14 Transcend with up to GeForce RTX 4070 Laptop GPU.</figcaption></figure>
<p><a href="https://www.samsung.com/us/galaxybooks/">Samsung’s Galaxy Book4 Ultra</a> includes an upgraded Dynamic AMOLED 2X display for high contrast and vivid color, as well as a convenient touchscreen. Its Vision Booster feature uses an Intelligent Outdoor Algorithm to automatically enhance visibility and color reproduction in bright conditions.</p>
<figure id="attachment_69154" aria-describedby="caption-attachment-69154" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-samsung-galaxy-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69154" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-samsung-galaxy-1280w-672x359.png" alt="" width="672" height="359" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-samsung-galaxy-1280w-672x359.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-samsung-galaxy-1280w-400x213.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-samsung-galaxy-1280w-768x410.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-samsung-galaxy-1280w-842x450.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-samsung-galaxy-1280w-403x215.png 403w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-samsung-galaxy-1280w-188x100.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-samsung-galaxy-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69154" class="wp-caption-text">Samsung’s Galaxy Book4 Ultra with up to the GeForce RTX 4070 Laptop GPU.</figcaption></figure>
<p>Check back for more information on the new line of Studio systems, including updates to release dates.</p>
<h2><b>A SUPER Debut for New GeForce RTX 40 Series Graphics Cards</b></h2>
<p>The GeForce RTX 40 Series has been supercharged with the new <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4080/">GeForce RTX 4080 SUPER</a>, <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4070-4070ti/">GeForce RTX 4070 Ti SUPER</a> and <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4070-4070ti/">GeForce RTX 4070 SUPER</a> graphics cards. This trio is faster than its predecessors, with RTX platform superpowers that enhance creating, gaming and AI tasks.</p>
<p>The GeForce RTX 4080 SUPER sports more CUDA cores than the GeForce RTX 4080 and includes the world’s fastest GDDR6X video memory at 23 Gbps. In 3D apps like Blender, it can run up to 70% faster than previous generations. In generative AI apps like Stable Diffusion XL or Stable Video Diffusion, it can produce 1,024&#215;1,024 images 1.7x faster and video 1.5x faster. Or play fully ray-traced games, including <i>Alan Wake 2, Cyberpunk 2077: Phantom Liberty </i>and <i>Portal with RTX,</i> in stunning 4K. The RTX 4080 SUPER will be available Jan. 31 as a Founders Edition and as custom boards for partners starting at $999.</p>
<p>The GeForce RTX 4070 Ti SUPER is equipped with more CUDA cores than the RTX 4070, a frame buffer increased to 16GB, and a 256-bit bus. It’s suited for video editing and rendering large 3D scenes and runs up to 1.6x faster than the RTX 3070 Ti and 2.5x faster with DLSS 3 in the most graphics-intensive games. Gamers can max out high-refresh 1440p panels or even game at 4K. The RTX 4070 Ti SUPER will be available Jan. 24 from custom board partners in stock-clocked and factory-overclocked configurations starting at $799.</p>
<p>The GeForce RTX 4070 SUPER has 20% more CUDA cores than the GeForce RTX 4070 and is great for 1440p creating. With DLSS 3, it’s 1.5x faster than a GeForce RTX 3090 while using a fraction of the power.</p>
<p>Read more on the <a href="https://www.nvidia.com/en-us/geforce/news/geforce-rtx-4080-4070-ti-4070-super-gpu">GeForce article</a>.</p>
<h2><b>Creative Vision Meets Reality With Getty Images and NVIDIA</b></h2>
<p>Content creators using the new Generative AI by iStock from Getty Images tool powered by <a href="https://www.nvidia.com/en-us/gpu-cloud/picasso/">NVIDIA Picasso</a> can now safely, affordably use AI-generated images with full protection.</p>
<p>Generative AI by iStock is trained on Getty Images’ vast creative library of high-quality licensed content, including millions of exclusive photos, illustrations and videos. Users can enter prompts to generate photo-quality images at up to 4K for social media promotion, digital advertisements and more.</p>
<p><iframe loading="lazy" title="NVIDIA Picasso Powers Generative AI by iStock (Commercially Safe AI Generator by Getty Images)" width="500" height="281" src="https://www.youtube.com/embed/cv_ozHmdoms?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Getty Images is also making <a href="https://blogs.nvidia.com/blog/studio-rtx-video-hdr-twitch-obs-istock-generative-ai-super-gpu-laptop">advanced inpainting and outpainting features</a> available via application programming interfaces. Developers can seamlessly integrate the new APIs with creative applications to add people and objects to images, replace specific elements and expand images to a wide range of aspect ratios.</p>
<p>Customers can use Generative AI by iStock online today. Advanced editing features are coming soon to the iStock website.</p>
<h2><b>RTX Video HDR Brings AI Video Upgrades</b></h2>
<p>RTX Video HDR brings a new AI-enhanced feature that instantly converts any standard dynamic range video playing in internet browsers into vibrant HDR.</p>
<p>HDR delivers stunning video quality but is not widely available because of effort and hardware limitations.</p>
<p>RTX Video HDR allows NVIDIA RTX and GeForce RTX GPU owners to maximize their HDR panel’s ability to display more vivid, dynamic colors, helping preserve intricate details that may be lost in standard dynamic range.</p>
<p><iframe loading="lazy" title="AI-Enhanced Video: NVIDIA RTX Video Super Resolution Update 1.5" width="500" height="281" src="https://www.youtube.com/embed/VkKsamTPk7g?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>The feature requires an HDR10-compatible display or TV connected to a RTX-powered PC and works with Chromium-based browsers such as Google Chrome or Microsoft Edge.</p>
<p>RTX Video HDR and RTX Video Super Resolution can be used together to produce the clearest livestreamed video.</p>
<p>RTX Video HDR is coming to all NVIDIA RTX and GeForce RTX GPUs as part of a driver update later this month. Once the update goes through, navigate to the NVIDIA control panel and switch it on.</p>
<h2><b>Enhanced Broadcasting Beta Enables Multi-Encode Livestreaming</b></h2>
<p>With Twitch Enhanced Broadcasting beta, <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/">GeForce RTX GPU</a> owners will be able to broadcast up to three resolutions simultaneously at up to 1080p. In the coming months, Twitch plans to roll out support for up to five concurrent encodes to further optimize viewer experiences.</p>
<p>As part of the beta, Twitch will test higher input bit rates as well as new codecs, which are expected to further improve visual quality. The new codecs include the latest-generation AV1 for GeForce RTX 40 Series GPUs, which provides 40% more encoding efficiency than H.264, and HEVC for previous-generation GeForce GPUs.</p>
<p>To simplify the setup process, Enhanced Broadcasting will automatically configure all open broadcaster software encoder settings, including resolution, bit rate and encoding parameters.</p>
<p><iframe loading="lazy" title="Twitch Enhanced Broadcasting (Multi-Encode Streaming) Powered by NVIDIA GeForce RTX GPUs" width="500" height="281" src="https://www.youtube.com/embed/gMtA3fFnXZk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Sign up for the Twitch Enhanced Broadcasting beta today.</p>
<h2><b>A Righteous RTX Remix</b></h2>
<p>Built on <a href="https://www.nvidia.com/en-us/omniverse/creators/">NVIDIA Omniverse</a>, <a href="https://www.nvidia.com/en-us/geforce/rtx-remix/">RTX Remix</a> allows modders to easily capture game assets, automatically enhance materials with generative AI tools, reimagine assets via Omniverse-connected apps and <a href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description (OpenUSD</a>), and quickly create stunning RTX remasters of classic games with full ray tracing and NVIDIA DLSS technology.</p>
<p>The <a href="https://www.nvidia.com/en-us/geforce/news/rtx-remix-open-beta-half-life-2-rtx-trailer">RTX Remix open beta</a> releases later this month.</p>
<p>RTX Remix has already delivered stunning remasters in <a href="https://www.nvidia.com/en-us/geforce/news/portal-with-rtx-full-ray-tracing-december-8/"><i>Portal with RTX</i></a> and the modder-made <a href="https://www.nvidia.com/en-us/geforce/news/portal-prelude-rtx-available-now-for-free/"><i>Portal: Prelude RTX</i></a>. Now, Orbifold Studios is using RTX Remix to develop <a href="https://www.nvidia.com/en-us/geforce/news/half-life-2-rtx-remix-in-development/"><i>Half-Life 2 RTX: An RTX Remix Project</i></a>, a community remaster of one of the <a href="https://www.metacritic.com/browse/games/score/metascore/all/pc/filtered">highest-rated games of all time</a>. Check out the new <i>Half-Life 2 RTX</i> gameplay trailer, showcasing Orbifold Studios’ latest updates to Ravenholm:</p>
<h2><b>AI and RTX Bring Illustrations to Life</b></h2>
<p>NVIDIA artists and this week’s <i>In the NVIDIA Studio</i> features Ashlee Martino-Tarr and Daniela Flamm Jackson are passionate about illustration — whether in work or at play.</p>
<p>They used Adobe Firefly’s generative AI features, powered by NVIDIA GPUs in the cloud and accelerated with Tensor Cores in GeForce RTX GPUs, to animate a 2D illustration with special effects.</p>
<p><iframe loading="lazy" title="Bring Illustrations to Life with Adobe AI Effects power by NVIDIA GPUs on PC &amp; in the Cloud" width="500" height="281" src="https://www.youtube.com/embed/7ELrpfVY4P4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>To begin, the pair separated the 2D image into multiple layers and expanded the canvas. Firefly’s <a href="https://www.adobe.com/products/photoshop/ai.html">Generative Expand</a> feature automatically filled the added space with AI-generated content.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-69135-3" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-1.mp4?_=3" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-1.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-1.mp4</a></video></div>
<p>&nbsp;</p>
<p>Next, the team separated select elements — starting with character — and used the AI Object Select feature to automatically mask the layer. The Generative Fill feature then created new content to fill in the background, saving even more time.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-69135-4" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-2-1.mp4?_=4" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-2-1.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-2-1.mp4</a></video></div>
<p>&nbsp;</p>
<p>This process continued until all distinct layers were separated and imported into Adobe After Effects. Next, they used the Mercury 3D Engine on local RTX GPUs to accelerate playback, unlocking smoother movement in the viewport. Previews and adjustments like camera shake and depth of field were also GPU-accelerated.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-69135-5" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-3.mp4?_=5" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-3.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-3.mp4</a></video></div>
<p>&nbsp;</p>
<p>Firefly’s Style Match feature then took the existing illustration and created new imagery in its likeness — in this case, a vibrant butterfly sporting similar colors and tones. The duo also used Adobe Illustrator’s <a href="https://www.adobe.com/products/illustrator/generative-recolor.html">Generative Recolor</a> feature, which enables artists to explore a wide variety of colors and themes without having to manually recolor their work.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-69135-6" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-4.mp4?_=6" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-4.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-4.mp4</a></video></div>
<p>&nbsp;</p>
<p>Martino-Tarr and Jackson then chose their preferred assets and animated them in Adobe After Effects. Firefly’s powerful AI effects helped speed or entirely eliminate tedious tasks such as patching holes, handpainting set extensions and caching animation playbacks.</p>
<figure id="attachment_69160" aria-describedby="caption-attachment-69160" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-style-match-1280w.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-69160" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-style-match-1280w-672x359.jpg" alt="" width="672" height="359" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-style-match-1280w-672x359.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-style-match-1280w-400x213.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-style-match-1280w-768x410.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-style-match-1280w-842x450.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-style-match-1280w-403x215.jpg 403w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-style-match-1280w-188x100.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ces-wk91-style-match-1280w.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69160" class="wp-caption-text">A variety of high-quality images to choose from.</figcaption></figure>
<p>The artists concluded post-production work by putting the finishing touches on their AI animation in After Effects.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-69135-7" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-5.mp4?_=7" /><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-5.mp4">https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-5.mp4</a></video></div>
<p>&nbsp;</p>
<p>Firefly’s powerful AI capabilities were developed with the creative community in mind — guided by AI ethics principles of content and data transparency — to ensure morally responsible output. NVIDIA technology continues to power these features from the cloud for photographers, illustrators, designers, video editors, 3D artists and more.</p>
<figure id="attachment_69163" aria-describedby="caption-attachment-69163" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ashlee-daniela-wk91-featured-setup-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-69163" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ashlee-daniela-wk91-featured-setup-1280w-672x245.png" alt="" width="672" height="245" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ashlee-daniela-wk91-featured-setup-1280w-672x245.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ashlee-daniela-wk91-featured-setup-1280w-400x146.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ashlee-daniela-wk91-featured-setup-1280w-768x280.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ashlee-daniela-wk91-featured-setup-1280w-842x307.png 842w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ashlee-daniela-wk91-featured-setup-1280w-406x148.png 406w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ashlee-daniela-wk91-featured-setup-1280w-188x69.png 188w, https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-itns-ashlee-daniela-wk91-featured-setup-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69163" class="wp-caption-text">NVIDIA artists Ashlee Martino-Tarr and Daniela Flamm Jackson.</figcaption></figure>
<p>Check out Martino-Tarr’s portfolio on <a href="https://www.artstation.com/amtarr">ArtStation</a> and Jackson’s on <a href="https://www.imdb.com/name/nm5819674/">IMDb</a>.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>Twitter</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-1.mp4" length="1759008" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-2-1.mp4" length="1885203" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-3.mp4" length="1787374" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-4.mp4" length="1556887" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2024/01/nvidia-studio-itns-wk91-firefly-demo-1280w-clip-5.mp4" length="1616222" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/nv-blog-header-preview-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/nv-blog-header-preview-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[The Creative AI: NVIDIA Studio Unveils New RTX- and AI-Accelerated Tools and Systems for Creators]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Twitch, OBS and NVIDIA to Release Multi-Encode Livestreaming</title>
		<link>https://blogs.nvidia.com/blog/twitch-multiencode-av1-livestreaming/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Mon, 08 Jan 2024 16:30:34 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[CES 2024]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=69185</guid>

					<description><![CDATA[Twitch, OBS and NVIDIA are leveling up livestreaming technology with the new Twitch Enhanced Broadcasting beta, powered by GeForce RTX GPUs. Available in a few days, streamers will be able to stream multiple encodes concurrently, providing optimal viewing experiences for all viewers.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Twitch, OBS and NVIDIA are leveling up livestreaming technology with the new Twitch Enhanced Broadcasting beta, powered by <a href="https://www.nvidia.com/en-us/geforce/rtx/">GeForce RTX GPUs</a>. Available in a few days, streamers will be able to stream multiple encodes concurrently, providing optimal viewing experiences for all viewers.<i> </i></p>
<h2><b>Twitch Enhanced Broadcasting</b></h2>
<p>Today, many streamers must choose between higher resolution and reliable streaming. High-quality video provides more enjoyable viewing experiences but causes streams to buffer for viewers with low bandwidth or older viewing devices. Streaming lower-bitrate video allows more people to watch the content seamlessly, but introduces artifacts.</p>
<p>Twitch — the interactive livestreaming platform — provides server-side transcoding for top-performing channels, meaning it will create different versions of the same stream for different bandwidth levels, improving the viewing experience. But the audience of many channels are left with a single stream option.</p>
<p>Twitch, OBS and NVIDIA have collaborated on a new feature to address this — Twitch Enhanced Broadcasting, releasing in beta later this month. Using the high-quality dedicated encoder (<a href="https://developer.nvidia.com/video-codec-sdk">NVENC</a>) in modern <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/">GeForce RTX and GTX GPUs</a>, streamers will be able to broadcast up to three resolutions simultaneously at up to 1080p.</p>
<p><iframe loading="lazy" title="Twitch Enhanced Broadcasting (Multi-Encode Streaming) Powered by NVIDIA GeForce RTX GPUs" width="500" height="281" src="https://www.youtube.com/embed/gMtA3fFnXZk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>In the coming months, Enhanced Broadcasting beta testers will be able to experiment with higher-input bit rates, up to 4K resolutions, up to 5 concurrent streams, as well as new codecs. The new codecs include the latest-generation AV1 for GeForce RTX 40 Series GPUs, which provides 40% more encoding efficiency than H.264, and HEVC for previous-generation GeForce GPUs.</p>
<figure id="attachment_69243" aria-describedby="caption-attachment-69243" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2024/01/Twitch.png"><img loading="lazy" decoding="async" class="size-large wp-image-69243" src="https://blogs.nvidia.com/wp-content/uploads/2024/01/Twitch-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/01/Twitch-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Twitch-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Twitch-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Twitch-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Twitch.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Twitch-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Twitch-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Twitch-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/01/Twitch-1280x720.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-69243" class="wp-caption-text">Twitch Enhanced Broadcasting releasing in beta later this month.</figcaption></figure>
<p>To simplify set up, Enhanced Broadcasting will automatically configure all OBS encoder settings, including resolution, bit rate and encoding parameters. A server-side algorithm will return the best possible configuration for OBS Studio based on the streamer’s setup, taking the headaches out of tuning settings for the best viewer experiences.</p>
<p>Using the dedicated NVENC hardware encoder, streamers can achieve the highest quality video across streaming bitrates, with minimal impact to app and game performance.</p>
<p>Sign up for the Twitch Enhanced Broadcasting beta today at twitch.tv/broadcast. Twitch will enroll participants on a first-come, first-served basis, starting later this month. Once a creator has been enrolled in the beta, they’ll receive an email with additional instructions.</p>
<p><i>To further elevate livestreams, download the </i><a href="https://www.nvidia.com/en-in/geforce/broadcasting/broadcast-app/"><i>NVIDIA Broadcast</i></a><i> app, free for RTX GPU owners and powered by dedicated AI Tensor Cores, to augment broadcast capabilities for microphones and cameras.</i></p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>Twitter</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-ces24-twitch-multi-encode-nv-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/01/studio-ces24-twitch-multi-encode-nv-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Twitch, OBS and NVIDIA to Release Multi-Encode Livestreaming]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
	</channel>
</rss>
