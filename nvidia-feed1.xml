<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Wed, 06 Dec 2023 20:39:41 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.4.1</generator>
	<item>
		<title>Visual AI Takes Flight at Canada’s Largest, Busiest Airport</title>
		<link>https://blogs.nvidia.com/blog/zensors-visual-ai/</link>
		
		<dc:creator><![CDATA[Angie Lee]]></dc:creator>
		<pubDate>Wed, 06 Dec 2023 21:00:39 +0000</pubDate>
				<category><![CDATA[Autonomous Machines]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Computer Vision]]></category>
		<category><![CDATA[Customer Stories]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Metropolis]]></category>
		<category><![CDATA[Transportation]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68650</guid>

					<description><![CDATA[Toronto Pearson International Airport, in Ontario, Canada, is the country’s largest and busiest airport, serving some 50 million passengers each year. To enhance traveler experiences, the airport in June deployed the Zensors AI platform, which uses anonymized footage from existing security cameras to generate spatial data that helps optimize operations in real time. A member <a class="read-more" href="https://blogs.nvidia.com/blog/zensors-visual-ai/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Toronto Pearson International Airport, in Ontario, Canada, is the country’s largest and busiest airport, serving some 50 million passengers each year.</p>
<p>To enhance traveler experiences, the airport in June deployed the Zensors AI platform, which uses anonymized footage from existing security cameras to generate spatial data that helps optimize operations in real time.</p>
<p>A member of the <a href="https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/">NVIDIA Metropolis</a> vision AI partner ecosystem, <a href="https://www.zensors.com/">Zensors</a> helped the Toronto Pearson operations team significantly reduce wait times in customs lines, decreasing the average time it took passengers to go through the arrivals process from an estimated 30 minutes during peak periods in 2022 to just under six minutes last summer.</p>
<p>“Zensors is making visual AI easy for all to use,” said Anuraag Jain, the company’s cofounder and head of product and technology.</p>
<p>Scaling multimodal, transformer-based AI isn’t easy for most organizations, Jain added, so airports have often defaulted to traditional, less effective solutions based on hardware sensors, lidar or 3D stereo cameras, or look to improve their operations by renovating or building new terminals instead — which can be multibillion-dollar projects.</p>
<p>“We provide a platform that allows airports to instead think more like software companies, deploying quicker, cheaper and more accurate solutions using their existing cameras and the latest AI technologies,” Jain said.</p>
<h2><b>Speeding Airport Operations</b></h2>
<p>To meet the growing travel demands, Toronto Pearson needed a way to improve its operations in a matter of weeks, rather than the months or years it would normally take to upgrade or build new terminal infrastructure.</p>
<p>The Zensors AI platform — deployed to monitor 20+ customs lines in two of the airport’s terminals — delivered such a solution. It converts video feeds from the airport’s existing camera systems into structured data.</p>
<p>Using anonymized footage, the platform counts how many travelers are in a line, identifies congested areas and predicts passenger wait times, among other tasks — and it alerts staff in real time to speed operations.</p>
<p>The platform also offers analytical reports that enable operations teams to assess performance, plan more effectively and redeploy staff for optimal efficiency.</p>
<p>In addition to providing airport operators data-driven insights, live wait-time statistics from Zensors AI are published on Toronto Pearson’s <a href="https://www.torontopearson.com/en/airport-wait-time-dashboard">online dashboard</a>, as well as on electronic displays in the terminals. This lets passengers easily access accurate information about how long customs or security processes will take. And it increases customer satisfaction overall and reduces potential anxieties about whether they’ll be able to make connecting flights.</p>
<p>“The analyses we get from the Zensors platform are proving to be very accurate,” said Zeljko Cakic, director of airport IT planning and development at the Greater Toronto Airport Authority, Toronto Pearson’s managing company. “Our goal is to improve overall customer experience and reduce wait times, and the data gathered through the Zensors platform is one of the key contributors for decision-making to drive these results.”</p>
<h2><b>Accurate AI Powered by NVIDIA</b></h2>
<p>Zensors AI — built with vision <a href="https://blogs.nvidia.com/blog/what-is-a-transformer-model/">transformer models</a> — offers insights with an impressive accuracy of about 96% compared to when humans validate the information manually. It’s all powered by NVIDIA technology.</p>
<p>“The Zensors model development and inference run-time stack is effectively the NVIDIA AI stack,” Jain said.</p>
<p>The company uses NVIDIA GPUs and the <a href="https://developer.nvidia.com/cuda-toolkit">CUDA</a> parallel computing platform to train its AI models, along with the <a href="https://developer.nvidia.com/cudnn">cuDNN</a> accelerated library of primitives for deep neural networks and the <a href="https://developer.nvidia.com/dali">NVIDIA DALI</a> library for decoding and augmenting images and videos.</p>
<p>With checkpoints at Toronto Pearson open 24/7, Zensors AI inference runs around the clock on <a href="https://developer.nvidia.com/triton-inference-server">NVIDIA Triton Inference Server</a>, an open-source software available through the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> platform.</p>
<p>The company estimates that using NVIDIA Triton to optimize its inference run-time decreased its monthly cloud GPU spending by more than 20%. In this way, NVIDIA technology enables Zensors to provide a high-availability, production-grade, fully managed service for Toronto Pearson and other clients, Jain said.</p>
<p>“Today, lots of companies and organizations want to adopt AI, but the hard part is figuring out how to go about it,” he added. “Being a part of NVIDIA Metropolis gives us the best tools and enables more visibility for potential end users of Zensors technology, which ultimately lets users deploy AI with ease.”</p>
<p>Zensors is also a member of <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a>, a free program that nurtures cutting-edge startups.</p>
<h2><b>Visual AI for the Future of Transportation</b></h2>
<p>Among many other customers who use Zensors AI is Ireland’s Cork Airport, which uses the platform to optimize its operations from curb to gate. In June, Zensors AI was deployed across the airport in just 20 days and, in less than four months, the platform helped save about 90 hours of congestion time through proactive curbside traffic management.</p>
<p>“Aviation is just one part of mobility,” Jain said. “We’re expanding to rail, bus and multimodal transit — and we believe Zensors will provide the layer of intelligence to eventually bring AI to all types of brick-and-mortar operators.”</p>
<p>Looking forward, the company is working to incorporate <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/">generative AI</a> and <a href="https://blogs.nvidia.com/blog/what-are-large-language-models-used-for/">large language models</a> into the question-answering capabilities of its platform in a safe, reliable way.</p>
<p><i>Learn more about the </i><a href="https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/"><i>NVIDIA Metropolis</i></a><i> platform and how it’s used to build </i><a href="https://resources.nvidia.com/en-us-metropolis-software-success-stories/metropolis-and-iva-airports?xs=369940"><i>smarter, safer travel hubs</i></a><i>, including at </i><a href="https://blogs.nvidia.com/blog/bengaluru-airport-vision-ai/"><i>Bengaluru Airport</i></a><i>, one of India’s busiest airports.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/people-airport.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/people-airport-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Visual AI Takes Flight at Canada’s Largest, Busiest Airport]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>17 Predictions for 2024: From RAG to Riches to Beatlemania and National Treasures</title>
		<link>https://blogs.nvidia.com/blog/2024-ai-predictions/</link>
		
		<dc:creator><![CDATA[Cliff Edwards]]></dc:creator>
		<pubDate>Wed, 06 Dec 2023 16:00:38 +0000</pubDate>
				<category><![CDATA[Autonomous Machines]]></category>
		<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Driving]]></category>
		<category><![CDATA[Networking]]></category>
		<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[Supercomputing]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cloud Services]]></category>
		<category><![CDATA[Digital Twin]]></category>
		<category><![CDATA[Embedded Computing]]></category>
		<category><![CDATA[Energy]]></category>
		<category><![CDATA[Financial Services]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<category><![CDATA[Media and Entertainment]]></category>
		<category><![CDATA[Retail]]></category>
		<category><![CDATA[Synthetic Data Generation]]></category>
		<category><![CDATA[Telecommunications]]></category>
		<category><![CDATA[Trustworthy AI]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68592</guid>

					<description><![CDATA[Move over, Merriam-Webster: Enterprises this year found plenty of candidates to add for word of the year. “Generative AI” and “generative pretrained transformer” were followed by terms such as “large language models” and “retrieval-augmented generation” (RAG) as whole industries turned their attention to transformative new technologies. Generative AI started the year as a blip on <a class="read-more" href="https://blogs.nvidia.com/blog/2024-ai-predictions/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Move over, Merriam-Webster: Enterprises this year found plenty of candidates to add for word of the year. “Generative AI” and “generative pretrained transformer” were followed by terms such as “large language models” and “retrieval-augmented generation” (RAG) as whole industries turned their attention to transformative new technologies.</p>
<p><a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/" target="_blank" rel="noopener">Generative AI</a> started the year as a blip on the radar but ended with a splash. Many companies are sprinting to harness its ability to ingest text, voice and video to churn out new content that can revolutionize productivity, innovation and creativity.</p>
<p>Enterprises are riding the trend. Deep learning algorithms like OpenAI’s ChatGPT, further trained with corporate data, could add the equivalent of $2.6 trillion to $4.4 trillion annually across 63 business use cases, according to <a href="https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier#key-insights" target="_blank" rel="noopener">McKinsey &amp; Company</a>.</p>
<p>Yet managing massive amounts of internal data often has been cited as the biggest obstacle to scaling AI. Some NVIDIA experts in AI predict that 2024 will be all about phoning a friend — creating partnerships and collaborations with cloud service providers, data storage and analytical companies, and others with the know-how to handle, fine-tune and deploy big data efficiently.</p>
<p><a href="https://www.nvidia.com/en-us/glossary/data-science/large-language-models/" target="_blank" rel="noopener">Large language models</a> are at the center of it all. NVIDIA experts say advancements in LLM research will increasingly be applied in business and enterprise applications. AI capabilities like <a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/" target="_blank" rel="noopener">RAG</a>, autonomous intelligent agents and multimodal interactions will become more accessible and more easily deployed via virtually any platform.</p>
<p>Hear from NVIDIA experts on what to expect in the year ahead:</p>
<p><img decoding="async" class="wp-image-68619 size-thumbnail alignleft" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/manuvirdas-1-150x150.jpg" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/manuvirdas-1-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/12/manuvirdas-1-400x400.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/manuvirdas-1-500x500.jpg 500w, https://blogs.nvidia.com/wp-content/uploads/2023/12/manuvirdas-1-768x768.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/manuvirdas-1-450x450.jpg 450w, https://blogs.nvidia.com/wp-content/uploads/2023/12/manuvirdas-1-215x215.jpg 215w, https://blogs.nvidia.com/wp-content/uploads/2023/12/manuvirdas-1-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2023/12/manuvirdas-1.jpg 1080w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><strong>MANUVIR DAS<br />
</strong><strong>Vice President of Enterprise Computing</strong></p>
<p><strong>One size doesn’t fit all:</strong> Customization is coming to enterprises. Companies won’t have one or two generative AI applications — many will have hundreds of customized applications using proprietary data that is suited to various parts of their business.</p>
<p>Once running in production, these custom LLMs will feature RAG capabilities to connect data sources to generative AI models for more accurate, informed responses. Leading companies like Amdocs, Dropbox, Genentech, SAP, ServiceNow and Snowflake are already building new generative AI services built using RAG and LLMs.</p>
<p><b>Open-source software leads the charge: </b>Thanks to open-source pretrained models, generative AI applications that solve specific domain challenges will become part of businesses’ operational strategies.</p>
<p>Once companies combine these headstart models with private or real-time data, they can begin to see accelerated productivity and cost benefits across the organization. AI computing and software are set to become more accessible on virtually any platform, from cloud-based computing and AI model foundry services to the data center, edge and desktop.</p>
<p><b>Off-the-shelf AI and microservices: </b>Generative AI has spurred the adoption of application programming interface (API) endpoints, which make it easier for developers to build complex applications.</p>
<p>In 2024, software development kits and APIs will level up as developers customize off-the-shelf AI models using AI microservices such as RAG as a service. This will help enterprises harness the full potential of AI-driven productivity with intelligent assistants and summarization tools that can access up-to-date business information.</p>
<p>Developers will be able to embed these API endpoints directly into their applications without having to worry about maintaining the necessary infrastructure to support the models and frameworks. End users can in turn experience more intuitive, responsive and tailored applications that adapt to their needs.</p>
<p><img decoding="async" class="wp-image-68610 size-thumbnail alignleft" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/ianbuck-1-150x150.png" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/ianbuck-1-150x150.png 150w, https://blogs.nvidia.com/wp-content/uploads/2023/12/ianbuck-1-400x400.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/ianbuck-1-500x500.png 500w, https://blogs.nvidia.com/wp-content/uploads/2023/12/ianbuck-1-768x768.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/ianbuck-1-450x450.png 450w, https://blogs.nvidia.com/wp-content/uploads/2023/12/ianbuck-1-215x215.png 215w, https://blogs.nvidia.com/wp-content/uploads/2023/12/ianbuck-1-100x100.png 100w, https://blogs.nvidia.com/wp-content/uploads/2023/12/ianbuck-1.png 1080w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><b>IAN BUCK<br />
</b><b>Vice President of Hyperscale and HPC</b></p>
<p><b>National treasure: </b>AI is set to become the new space race, with every country looking to create its own center of excellence for driving significant advances in research and science and improving GDP.</p>
<p>With just a few hundred nodes of accelerated computing, countries will be able to quickly build highly efficient, massively performant, exascale AI supercomputers. Government-funded generative AI centers of excellence will boost countries’ economic growth by creating new jobs and building stronger university programs to create the next generation of scientists, researchers and engineers.</p>
<p><b>Quantum leaps and bounds:</b> Enterprise leaders will launch <a href="https://blogs.nvidia.com/blog/what-is-quantum-computing/" target="_blank" rel="noopener">quantum computing</a> research initiatives based on two key drivers: the ability to use traditional AI supercomputers to simulate quantum processors and the availability of an open, unified development platform for hybrid-classical quantum computing. This enables developers to use standard programming languages instead of needing custom, specialized knowledge to build quantum algorithms.</p>
<p>Once considered an obscure niche in computer science, quantum computing exploration will become more mainstream as enterprises join academia and national labs in pursuing rapid advances in materials science, pharmaceutical research, subatomic physics and logistics.</p>
<p><img decoding="async" class="wp-image-68613 size-thumbnail alignleft" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/karibriski-1-150x150.jpg" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/karibriski-1-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/12/karibriski-1-400x400.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/karibriski-1-500x500.jpg 500w, https://blogs.nvidia.com/wp-content/uploads/2023/12/karibriski-1-768x768.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/karibriski-1-450x450.jpg 450w, https://blogs.nvidia.com/wp-content/uploads/2023/12/karibriski-1-215x215.jpg 215w, https://blogs.nvidia.com/wp-content/uploads/2023/12/karibriski-1-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2023/12/karibriski-1.jpg 1080w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><b>KARI BRISKI<br />
</b><b>Vice President of AI Software</b></p>
<p><b>From RAG to riches: </b>Expect to hear a lot more about retrial-augmented generation as enterprises embrace these AI frameworks in 2024.</p>
<p>As companies train LLMs to build generative AI applications and services, RAG is widely seen as an answer to the inaccuracies or nonsensical replies that sometimes occur when the models don’t have access to enough accurate, relevant information for a given use case.</p>
<p>Using semantic retrieval, enterprises will take open-source foundation models, ingest their own data so that a user query can retrieve the relevant data from the index and then pass it to the model at run time.</p>
<p>The upshot is that enterprises can use fewer resources to achieve more accurate generative AI applications in sectors such as healthcare, finance, retail and manufacturing. End users should expect to see more sophisticated, context-sensitive and multimodal chatbots and personalized content recommendation systems that allow them to talk to their data naturally and intuitively.</p>
<p><b>Multimodality makes its mark: </b>Text-based generative AI is set to become a thing of the past. Even as generative AI remains in its infancy, expect to see many industries embrace multimodal LLMs that allow consumers to use a combination of text, speech and images to deliver more contextually relevant responses to a query about tables, charts or schematics.</p>
<p>Companies such as Meta and OpenAI will look to push the boundaries of multimodal generative AI by adding greater support for the senses, which will lead to advancements in the physical sciences, biological sciences and society at large. Enterprises will be able to understand their data not just in text format but also in PDFs, graphs, charts, slides and more.</p>
<p><img loading="lazy" decoding="async" class="wp-image-68625 size-thumbnail alignleft" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/nikkipope-1-150x150.jpg" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/nikkipope-1-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/12/nikkipope-1-400x400.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/nikkipope-1-500x500.jpg 500w, https://blogs.nvidia.com/wp-content/uploads/2023/12/nikkipope-1-768x768.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/nikkipope-1-450x450.jpg 450w, https://blogs.nvidia.com/wp-content/uploads/2023/12/nikkipope-1-215x215.jpg 215w, https://blogs.nvidia.com/wp-content/uploads/2023/12/nikkipope-1-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2023/12/nikkipope-1.jpg 1080w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><b>NIKKI POPE<br />
</b><b>Head of AI and Legal Ethics</b></p>
<p><b>Target lock on AI safety: </b>Collaboration among leading AI organizations will accelerate the research and development of robust, safe AI systems. Expect to see emerging standardized safety protocols and best practices that will be adopted across industries, ensuring a consistent and high level of safety across generative AI models.</p>
<p>Companies will heighten their focus on transparency and interpretability in AI systems — and use new tools and methodologies to shed light on the decision-making processes of complex AI models. As the generative AI ecosystem rallies around safety, anticipate AI technologies becoming more reliable, trustworthy and aligned with human values.</p>
<p><img loading="lazy" decoding="async" class="wp-image-68631 size-thumbnail alignleft" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/richardkerris-1-150x150.jpg" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/richardkerris-1-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/12/richardkerris-1-400x400.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/richardkerris-1-500x500.jpg 500w, https://blogs.nvidia.com/wp-content/uploads/2023/12/richardkerris-1-768x768.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/richardkerris-1-450x450.jpg 450w, https://blogs.nvidia.com/wp-content/uploads/2023/12/richardkerris-1-215x215.jpg 215w, https://blogs.nvidia.com/wp-content/uploads/2023/12/richardkerris-1-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2023/12/richardkerris-1.jpg 1080w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><b>RICHARD KERRIS<br />
</b><b>Vice President of Developer Relations, Head of Media and Entertainment</b></p>
<p><b>The democratization of development: </b>Virtually anyone, anywhere will soon be set to become a developer. Traditionally, one had to know and be proficient at using a specific development language to develop applications or services. As computing infrastructure becomes increasingly trained on the languages of software development, anyone will be able to prompt the machine to create applications, services, device support and more.</p>
<p>While companies will continue to hire developers to build and train AI models and other professional applications, expect to see significantly broader opportunities for anyone with the right skill set to build custom products and services. They’ll be helped by text inputs or voice prompts, making interactions with computers as simple as verbally instructing it.</p>
<p><b>“Now and Then” in film and song: </b>Just as the “new” <a href="https://www.youtube.com/watch?v=Opxhh9Oh3rg" target="_blank" rel="noopener">AI-augmented song</a> by the Fab Four spurred a fresh round of Beatlemania, the dawn of the first feature-length generative AI movie will send shockwaves through the film industry.</p>
<p>Take a filmmaker who shoots using a 35mm film camera. The same content can soon be transformed into a 70mm production using generative AI, reducing the significant costs involved in film production in the IMAX format and allowing a broader set of directors to participate.</p>
<p>Creators will transform beautiful images and videos into new types and forms of entertainment by prompting a computer with text, images or videos. Some professionals worry their craft will be replaced, but those issues will fade as generative AI gets better at being trained on specific tasks. This, in turn, will free up hands to tackle other tasks and provide new tools with artist-friendly interfaces.</p>
<p><img loading="lazy" decoding="async" class="wp-image-68640 size-thumbnail alignleft" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/image2-150x150.jpg" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/image2-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/12/image2-400x400.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/image2-451x450.jpg 451w, https://blogs.nvidia.com/wp-content/uploads/2023/12/image2-215x215.jpg 215w, https://blogs.nvidia.com/wp-content/uploads/2023/12/image2-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2023/12/image2.jpg 500w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><b>KIMBERLY POWELL<br />
</b><b>Vice President of Healthcare </b></p>
<p><b>AI surgical assistants:</b> The day has come when surgeons can use voice to augment what they see and understand inside and outside the surgical suite.</p>
<p>Combining instruments, imaging, robotics and real-time patient data with AI will lead to better surgeon training, more personalization during surgery and better safety with real-time feedback and guidance even during remote surgery. This will help close the gap on the 150 million surgeries that are needed yet <a href="https://horasis.org/global-surgery-a-vital-part-of-the-global-health-ecosystem/" target="_blank" rel="noopener">do not</a> occur, particularly in low- and middle-income countries.</p>
<p><b>Generative AI drug discovery factories: </b>A new drug discovery process is emerging, where generative AI molecule generation, property prediction and complex modeling will drive an intelligent lab-in-the-loop flywheel, shortening the time to discover and improving the quality of clinically viable drug candidates.</p>
<p>These AI drug discovery factories employ massive healthcare datasets using whole genomes, atomic-resolution instruments and robotic lab automation capable of running 24/7. For the first time, computers can learn patterns and relationships within enormous and complex datasets and generate, predict and model complex biological relationships that were only previously discoverable through time-consuming experimental observation and human synthesis.</p>
<p><img loading="lazy" decoding="async" class="wp-image-68601 size-thumbnail alignleft" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/charlieboyle-1-150x150.jpg" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/charlieboyle-1-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/12/charlieboyle-1-400x400.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/charlieboyle-1-500x500.jpg 500w, https://blogs.nvidia.com/wp-content/uploads/2023/12/charlieboyle-1-768x768.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/charlieboyle-1-450x450.jpg 450w, https://blogs.nvidia.com/wp-content/uploads/2023/12/charlieboyle-1-215x215.jpg 215w, https://blogs.nvidia.com/wp-content/uploads/2023/12/charlieboyle-1-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2023/12/charlieboyle-1.jpg 1080w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><b>CHARLIE BOYLE<br />
</b><b>Vice President of DGX Platforms</b></p>
<p><b>Enterprises lift bespoke LLMs into the cloud: </b>One thing enterprises learned from 2023 is that building LLMs from scratch isn’t easy. Companies taking this route are often daunted by the need to invest in new infrastructure and technology and they experience difficulty in figuring out how and when to prioritize other company initiatives.</p>
<p>Cloud service providers, colocation providers and other businesses that handle and process data for other businesses will help enterprises with full-stack AI supercomputing and software. This will make customizing pretrained models and deploying them easier for companies across industries.</p>
<p><b>Fishing for LLM gold in enterprise data lakes: </b>There’s no shortage of statistics on how much information the average enterprise stores — it can be anywhere in the high hundreds of petabytes for large corporations. Yet many companies <a href="https://hbr.org/2017/05/whats-your-data-strategy#:~:text=Cross%2Dindustry%20studies%20show%20that,analyzed%20or%20used%20at%20all." target="_blank" rel="noopener">report</a> that they’re mining less than half that information for actionable insights.</p>
<p>In 2024, businesses will begin using generative AI to make use of that untamed data by putting it to work building and customizing LLMs. With AI-powered supercomputing, business will begin mining their unstructured data — including chats, videos and code — to expand their generative AI development into training multimodal models. This leap beyond the ability to mine tables and other structured data will let companies deliver more specific answers to questions and find new opportunities. That includes helping detect anomalies on health scans, uncovering emerging trends in retail and making business operations safer.</p>
<p><img loading="lazy" decoding="async" class="wp-image-68595 size-thumbnail alignleft" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/azitamartin-1-150x150.jpg" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/azitamartin-1-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/12/azitamartin-1-400x400.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/azitamartin-1-500x500.jpg 500w, https://blogs.nvidia.com/wp-content/uploads/2023/12/azitamartin-1-768x768.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/azitamartin-1-450x450.jpg 450w, https://blogs.nvidia.com/wp-content/uploads/2023/12/azitamartin-1-215x215.jpg 215w, https://blogs.nvidia.com/wp-content/uploads/2023/12/azitamartin-1-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2023/12/azitamartin-1.jpg 1080w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><b>AZITA MARTIN<br />
</b><b>Vice President of Retail, Consumer-Packaged Goods and Quick-Service Restaurants </b></p>
<p><b>Generative AI shopping advisors: </b>Retailers grapple with the dual demands of connecting customers to the products they desire while delivering elevated, human-like, omnichannel shopping experiences that align with their individual needs and preferences.</p>
<p>To meet these goals, retailers are gearing up to introduce cutting-edge, generative AI-powered shopping advisors, which will undergo meticulous training on the retailers’ distinct brand, products and customer data to ensure a brand-appropriate, guided, personalized shopping journey that mimics the nuanced expertise of a human assistant. This innovative approach will help set brands apart and increase customer loyalty by providing personalized help.</p>
<p><b>Setting up for safety: </b>Retailers across the globe are facing a mounting challenge as organized retail crime grows increasingly sophisticated and coordinated. The National Retail Federation reported that retailers are experiencing a staggering <a href="https://cdn.nrf.com/sites/default/files/2022-09/National%20Retail%20Security%20Survey%20Organized%20Retail%20Crime%202022.pdf" target="_blank" rel="noopener">26.5% surge in such incidents</a> since the post-pandemic uptick in retail theft.</p>
<p>To enhance the safety and security of in-store experiences for both customers and employees, retailers will begin using computer vision and physical security information management software to collect and correlate events from disparate security systems. This will enable AI to detect weapons and unusual behavior like the large-scale grabbing of items from shelves. It will also help retailers proactively thwart criminal activities and maintain a safer shopping environment.</p>
<p><img loading="lazy" decoding="async" class="wp-image-68628 size-thumbnail alignleft" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/revlebaredian-1-150x150.jpg" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/revlebaredian-1-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/12/revlebaredian-1-400x400.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/revlebaredian-1-500x500.jpg 500w, https://blogs.nvidia.com/wp-content/uploads/2023/12/revlebaredian-1-768x768.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/revlebaredian-1-450x450.jpg 450w, https://blogs.nvidia.com/wp-content/uploads/2023/12/revlebaredian-1-215x215.jpg 215w, https://blogs.nvidia.com/wp-content/uploads/2023/12/revlebaredian-1-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2023/12/revlebaredian-1.jpg 1080w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><b>REV LEBAREDIAN<br />
</b><b>Vice President of Omniverse and Simulation Technology</b></p>
<p><b>Industrial digitalization meets generative AI: </b>The fusion of industrial digitalization with generative AI is poised to catalyze industrial transformation.Generative AI will make it easier to turn aspects of the physical world — such as geometry, light, physics, matter and behavior — into digital data. Democratizing the digitalization of the physical world will accelerate industrial enterprises, enabling them to design, optimize, manufacture and sell products more efficiently. It also enables them to more easily create virtual training grounds and synthetic data to train a new generation of AIs that will interact and operate within the physical world, such as autonomous robots and self-driving cars.</p>
<p><b>3D interoperability takes off: </b>From the drawing board to the factory floor, data for the first time will be interoperable.</p>
<p>The world’s most influential software and practitioner companies from the manufacturing, product design, retail, e-commerce and robotics industries are committing to the newly established <a href="https://aousd.org/" target="_blank" rel="noopener">Alliance for OpenUSD</a>. <a href="https://www.nvidia.com/en-us/omniverse/usd/" target="_blank" rel="noopener">OpenUSD</a>, the universal language between 3D tools and data, will break down data siloes, enabling industrial enterprises to collaborate across data lakes, tool systems and specialized teams easier and faster than ever to accelerate the digitalization of previously cumbersome, manual industrial processes.</p>
<p><img loading="lazy" decoding="async" class="wp-image-68637 size-thumbnail alignleft" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/xinzhouwu-1-150x150.png" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/xinzhouwu-1-150x150.png 150w, https://blogs.nvidia.com/wp-content/uploads/2023/12/xinzhouwu-1-400x400.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/xinzhouwu-1-500x500.png 500w, https://blogs.nvidia.com/wp-content/uploads/2023/12/xinzhouwu-1-768x768.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/xinzhouwu-1-450x450.png 450w, https://blogs.nvidia.com/wp-content/uploads/2023/12/xinzhouwu-1-215x215.png 215w, https://blogs.nvidia.com/wp-content/uploads/2023/12/xinzhouwu-1-100x100.png 100w, https://blogs.nvidia.com/wp-content/uploads/2023/12/xinzhouwu-1.png 1080w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><b>XINZHOU WU<br />
</b><b>Vice President and General Manager of Automotive</b></p>
<p><b>Modernizing the vehicle production lifecycle: </b>The automotive industry will further embrace generative AI to deliver physically accurate, photorealistic renderings that show exactly how a vehicle will look inside and out — while speeding design reviews, saving costs and improving efficiencies.</p>
<p>More automakers will embrace this technology within their smart factories, connecting design and engineering tools to build digital twins of production facilities. This will reduce costs and streamline operations without the need to shut down factory lines.</p>
<p>Generative AI will make consumer research and purchasing more interactive. From car configurators and 3D visualizations to augmented reality demonstrations and virtual test drives, consumers will be able to have a more engaging and enjoyable shopping experience.</p>
<p><b>Safety is no accident:</b> Beyond the automotive product lifecycle, generative AI will also enable breakthroughs in autonomous vehicle (AV) development, including turning recorded sensor data into fully interactive 3D simulations. These <a href="https://blogs.nvidia.com/blog/what-is-a-digital-twin/" target="_blank" rel="noopener">digital twin</a> environments, as well as <a href="https://blogs.nvidia.com/blog/what-is-synthetic-data/" target="_blank" rel="noopener">synthetic data generation</a>, will be used to safely develop, test and validate AVs at scale virtually before they’re deployed in the real world.</p>
<p>Generative AI foundational models will also support a vehicle’s AI systems to enable new personalized user experiences, capabilities and safety features inside and outside the car.</p>
<p>The behind-the-wheel experience is set to become safer, smarter and more enjoyable.</p>
<p><img loading="lazy" decoding="async" class="wp-image-68598 size-thumbnail alignleft" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/bobpette-1-150x150.jpg" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/bobpette-1-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/12/bobpette-1-400x400.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/bobpette-1-500x500.jpg 500w, https://blogs.nvidia.com/wp-content/uploads/2023/12/bobpette-1-768x768.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/bobpette-1-450x450.jpg 450w, https://blogs.nvidia.com/wp-content/uploads/2023/12/bobpette-1-215x215.jpg 215w, https://blogs.nvidia.com/wp-content/uploads/2023/12/bobpette-1-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2023/12/bobpette-1.jpg 1080w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><b>BOB PETTE<br />
</b><b>Vice President of Enterprise Platforms</b></p>
<p><b>Building anew with generative AI: </b>Generative AI will allow organizations to design cars by simply speaking to a large language model or create cities from scratch using new techniques and design principles.</p>
<p>The architecture, engineering, construction and operations (AECO) industry is building the future using generative AI as its guidepost. Hundreds of generative AI startups and customers in AECO and manufacturing will focus on creating solutions for virtually any use case, including design optimization, market intelligence, construction management and physics prediction. AI will accelerate a manufacturing evolution that promises increased efficiency, reduced waste and entirely new approaches to production and sustainability.</p>
<p>Developers and enterprises are focusing in particular on point cloud data analysis, which uses lidar to generate representations of built and natural environments with precise details. This could lead to high-fidelity insights and analysis through generative AI-accelerated workflows.</p>
<p><img loading="lazy" decoding="async" class="wp-image-68656 size-thumbnail alignleft" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/giladshainer-1-1-150x150.jpg" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/giladshainer-1-1-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/12/giladshainer-1-1-400x400.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/giladshainer-1-1-500x500.jpg 500w, https://blogs.nvidia.com/wp-content/uploads/2023/12/giladshainer-1-1-768x768.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/giladshainer-1-1-450x450.jpg 450w, https://blogs.nvidia.com/wp-content/uploads/2023/12/giladshainer-1-1-215x215.jpg 215w, https://blogs.nvidia.com/wp-content/uploads/2023/12/giladshainer-1-1-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2023/12/giladshainer-1-1.jpg 1080w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><b>GILAD SHAINER<br />
</b><b>Vice President of Networking </b></p>
<p><b>AI influx ignites connectivity demand: </b>A renewed focus on networking efficiency and performance will take off as enterprises seek the necessary network bandwidth for accelerated computing using GPUs and GPU-based systems.</p>
<p>Trillion-parameter LLMs will expose the need for faster transmission speeds and higher coverage. Enterprises that want to quickly roll out generative AI applications will need to invest in accelerated networking technology or choose a cloud service provider that does. The key to optimal connectivity is baking it into full-stack systems coupled with next-generation hardware and software.</p>
<p><b>The defining element of data center design: </b>Enterprises will learn that not all data centers need to be alike. Determining the purpose of a data center is the first step toward choosing the appropriate networking to use within it. Traditional data centers are limited in terms of bandwidth, while those capable of running large AI workloads require thousands of GPUs to work at very deterministic, low-tail latency.</p>
<p>What the network is capable of when under a full load at scale is the best determinant of performance. The future of enterprise data center connectivity requires separate management (aka north-south) and AI (aka east-west) networks, where the AI network includes in-network computing specifically designed for high performance computing, AI and hyperscale cloud infrastructures.</p>
<p><img loading="lazy" decoding="async" class="wp-image-68604 size-thumbnail alignleft" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/davidreberjr-1-150x150.jpg" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/davidreberjr-1-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/12/davidreberjr-1-400x400.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/davidreberjr-1-500x500.jpg 500w, https://blogs.nvidia.com/wp-content/uploads/2023/12/davidreberjr-1-768x768.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/davidreberjr-1-450x450.jpg 450w, https://blogs.nvidia.com/wp-content/uploads/2023/12/davidreberjr-1-215x215.jpg 215w, https://blogs.nvidia.com/wp-content/uploads/2023/12/davidreberjr-1-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2023/12/davidreberjr-1.jpg 1080w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><b>DAVID REBER JR.<br />
</b><b>Chief Security Officer</b></p>
<p><b>Clarity in adapting the security model to AI:</b> The pivot from app-centric to data-centric security is in full swing. Data is the fundamental supply chain for LLMs and the future of generative AI. Enterprises are just now seeing the problem unfold at scale. Companies will need to reevaluate people, processes and technologies to redefine the secure development lifecycle (SDLC). The industry at large will redefine its approach to trust and clarify what transparency means.</p>
<p>A new generation of cyber tools will be born. The SDLC of AI will be defined with new market leaders of tools and expectations to address the transition from the command line interface to the human language interface. The need will be especially important as more enterprises shift toward using open-source LLMs like Meta’s Llama 2 to accelerate generative AI output.</p>
<p><b>Scaling security with AI:</b> Applications of AI to the cybersecurity deficit will detect never-before-seen threats. Currently, a fraction of global data is used for cyber defense. Meanwhile, attackers continue to take advantage of every misconfiguration.</p>
<p>Experimentation will help enterprises realize the potential of AI in identifying emergent threats and risks. Cyber copilots will help enterprise users navigate phishing and configuration. For the technology to be effective, companies will need to tackle privacy issues inherent in the intersection of work and personal life to enable collective defense in data-centric environments.</p>
<p>Along with democratizing access to technology, AI will also enable a new generation of cyber defenders as threats continue to grow. As soon as companies gain clarity on each threat, AI will be used to generate massive amounts of data that train downstream detectors to defend and detect these threats.</p>
<p><img loading="lazy" decoding="async" class="wp-image-68634 size-thumbnail alignleft" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/ronnievasishta-1-150x150.jpg" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/ronnievasishta-1-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/12/ronnievasishta-1-400x400.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/ronnievasishta-1-500x500.jpg 500w, https://blogs.nvidia.com/wp-content/uploads/2023/12/ronnievasishta-1-768x768.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/ronnievasishta-1-450x450.jpg 450w, https://blogs.nvidia.com/wp-content/uploads/2023/12/ronnievasishta-1-215x215.jpg 215w, https://blogs.nvidia.com/wp-content/uploads/2023/12/ronnievasishta-1-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2023/12/ronnievasishta-1.jpg 1080w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><b>RONNIE VASISHTA<br />
</b><b>Senior Vice President of Telecoms</b></p>
<p><b>Running to or from RAN: </b>Expect to see a major reassessment of investment cases for 5G.</p>
<p>After five years of 5G, network coverage and capacity have boomed — but revenue growth is sluggish and costs for largely proprietary and inflexible infrastructure have risen. Meantime, utilization for 5G RAN is stuck below 40%.</p>
<p>The new year will be about aggressively pursuing new revenue sources on existing spectrum to uncover new monetizable applications. Telecoms also will rethink the capex structure, focusing more on a flexible, high-utilization infrastructure built on general-purpose components. And expect to see a holistic reduction of operating expenses as companies leverage AI tools to increase performance, improve efficiency and eliminate costs. The outcome of these initiatives will determine how much carriers will invest in 6G technology.</p>
<p><b>From chatbots to network management: </b>Telcos are already using generative AI for chatbots and virtual assistants to improve customer service and support. In the new year they’ll double down, ramping up their use of generative AI for operational improvements in areas such as network planning and optimization, fault and fraud detection, predictive analytics and maintenance, cybersecurity operations and energy optimization.</p>
<p>Given how pervasive and strategic generative AI is becoming, building a new type of AI factory infrastructure to support its growth also will become a key imperative. More and more telcos will build AI factories for internal use, as well as deploy these factories as a platform as a service for developers. That same infrastructure will be able to support RAN as an additional tenant.</p>
<p><img loading="lazy" decoding="async" class="wp-image-68616 size-thumbnail alignleft" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/malcolmdemayo-1-150x150.jpg" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/malcolmdemayo-1-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/12/malcolmdemayo-1-400x400.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/malcolmdemayo-1-500x500.jpg 500w, https://blogs.nvidia.com/wp-content/uploads/2023/12/malcolmdemayo-1-768x768.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/malcolmdemayo-1-450x450.jpg 450w, https://blogs.nvidia.com/wp-content/uploads/2023/12/malcolmdemayo-1-215x215.jpg 215w, https://blogs.nvidia.com/wp-content/uploads/2023/12/malcolmdemayo-1-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2023/12/malcolmdemayo-1.jpg 1080w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><b>MALCOLM DEMAYO<br />
</b><b>Vice President of Financial Services </b></p>
<p><b>AI-first financial services: </b>With AI advancements growing exponentially, financial services firms will bring the compute power to the data, rather than the other way around.</p>
<p>Firms will undergo a strategic shift toward a highly scalable, hybrid combination of on-premises infrastructure and cloud-based computing, driven by the need to mitigate concentration risk and maintain agility amid rapid technological advancements. Firms that handle their most mission-critical workloads, including AI-powered customer service assistants, fraud detection, risk management and more, will lead.</p>
<p><img loading="lazy" decoding="async" class="alignleft wp-image-56797 size-thumbnail" src="https://blogs.nvidia.com/wp-content/uploads/2022/04/Marc-Spieler-e1670963488225-150x150.jpg" alt="Marc Spieler" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2022/04/Marc-Spieler-e1670963488225-150x150.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2022/04/Marc-Spieler-e1670963488225-214x215.jpg 214w, https://blogs.nvidia.com/wp-content/uploads/2022/04/Marc-Spieler-e1670963488225-100x100.jpg 100w, https://blogs.nvidia.com/wp-content/uploads/2022/04/Marc-Spieler-e1670963488225.jpg 339w" sizes="(max-width: 150px) 100vw, 150px" /></p>
<p><b>MARC SPIELER<br />
</b><b>Senior Director of Energy</b></p>
<p><b>Physics-ML for faster simulation: </b>Energy companies will increasingly turn to physics-informed machine learning (physics-ML) to accelerate simulations, optimize industrial processes and enhance decision-making.</p>
<p>Physics-ML integrates traditional physics-based models with advanced machine learning algorithms, offering a powerful tool for the rapid, accurate simulation of complex physical phenomena. For instance, in energy exploration and production, physics-ML can quickly model subsurface geologies to aid in identification of potential exploration sites and assessment of operational and environmental risks.</p>
<p>In renewable energy sectors, such as wind and solar, physics-ML will play a crucial role in predictive maintenance, enabling energy companies to foresee equipment failures and schedule maintenance proactively to reduce downtimes and costs. As computational power and data availability continue to grow, physics-ML is poised to transform how energy companies approach simulation and modeling tasks, leading to more efficient and sustainable energy production.</p>
<p><b>LLMs — the fix for better operational outcomes: </b>Couple with physics-ML, LLMs will analyze extensive historical data and real-time sensor inputs from energy equipment to predict potential failures and maintenance needs before they occur. This proactive approach will reduce unexpected downtime and extend the lifespan of turbines, generators, solar panels and other critical infrastructure. LLMs will also help optimize maintenance schedules and resource allocation, ensuring that repairs and inspections are efficiently carried out. Ultimately, LLM use in predictive maintenance will save costs for energy companies and contribute to a more stable energy supply for consumers.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2022/12/Deepu-Talla-headshot.png"><img loading="lazy" decoding="async" class="alignleft size-thumbnail wp-image-61365" src="https://blogs.nvidia.com/wp-content/uploads/2022/12/Deepu-Talla-headshot-150x150.png" alt="" width="150" height="150" srcset="https://blogs.nvidia.com/wp-content/uploads/2022/12/Deepu-Talla-headshot-150x150.png 150w, https://blogs.nvidia.com/wp-content/uploads/2022/12/Deepu-Talla-headshot-100x100.png 100w, https://blogs.nvidia.com/wp-content/uploads/2022/12/Deepu-Talla-headshot.png 168w" sizes="(max-width: 150px) 100vw, 150px" /></a></p>
<p><b>DEEPU TALLA<br />
</b><b>Vice President of Embedded and Edge Computing</b></p>
<p><b>The rise of robotics programmers:</b> LLMs will lead to rapid improvements for robotics engineers. Generative AI will develop code for robots and create new simulations to test and train them.</p>
<p>LLMs will accelerate simulation development by automatically building 3D scenes, constructing environments and generating assets from inputs. The resulting simulation assets will be critical for workflows like synthetic data generation, robot skills training and robotics application testing.</p>
<p>In addition to helping robotics engineers, transformer AI models, the engines behind LLMs, will make robots themselves smarter so that they better understand complex environments and more effectively execute a breadth of skills within them.</p>
<p>For the robotics industry to scale, robots have to become more generalizable — that is, they need to acquire skills more quickly or bring them to new environments. Generative AI models — trained and tested in simulation — will be a key enabler in the drive toward more powerful, flexible and easier-to-use robots.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/2024predictionfeature.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/2024predictionfeature-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[17 Predictions for 2024: From RAG to Riches to Beatlemania and National Treasures]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AV 2.0, the Next Big Wayve in Self-Driving Cars</title>
		<link>https://blogs.nvidia.com/blog/av-2-0-wayve/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Wed, 06 Dec 2023 14:00:21 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[The AI Podcast]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68475</guid>

					<description><![CDATA[A new era of autonomous vehicle technology, known as AV 2.0, has emerged, marked by large, unified AI models that can control multiple parts of the vehicle stack, from perception and planning to control. Wayve, a London-based autonomous driving technology company, is leading the surf. In the latest episode of NVIDIA’s AI Podcast, host Katie <a class="read-more" href="https://blogs.nvidia.com/blog/av-2-0-wayve/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>A new era of autonomous vehicle technology, known as AV 2.0, has emerged, marked by large, unified AI models that can control multiple parts of the vehicle stack, from perception and planning to control.</p>
<p>Wayve, a London-based autonomous driving technology company, is leading the surf.</p>
<p>In the latest episode of <a href="https://blogs.nvidia.com/ai-podcast/" target="_blank" rel="noopener">NVIDIA’s AI Podcast</a>, host Katie Burke Washabaugh spoke with the company’s cofounder and CEO, Alex Kendall, about what AV 2.0 means for the future of self-driving cars.</p>
<p>Unlike AV 1.0’s focus on perfecting a vehicle’s perception capabilities using multiple deep neural networks, AV 2.0 calls for comprehensive in-vehicle intelligence to drive decision-making in real-world, dynamic environments.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1683154701%3Fsecret_token%3Ds-2gCdivuWvv1&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="Wayve CEO Alex Kendall on Making a Splash in Autonomous Vehicles - Ep. 209" href="https://soundcloud.com/theaipodcast/ai-wayve/s-2gCdivuWvv1" target="_blank" rel="noopener">Wayve CEO Alex Kendall on Making a Splash in Autonomous Vehicles &#8211; Ep. 209</a></div>
<p>Embodied AI — the concept of giving AI a physical interface to interact with the world — is the basis of this new AV wave.</p>
<p>Kendall pointed out that it’s a “hardware/software problem — you need to consider these things separately,” even as they work together. For example, a vehicle can have the highest-quality sensors, but without the right software, the system can’t use them to execute the right decisions.</p>
<p><a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/" target="_blank" rel="noopener">Generative AI</a> plays a key role, enabling <a href="https://blogs.nvidia.com/blog/what-is-synthetic-data/" target="_blank" rel="noopener">synthetic data generation</a> so AV makers can use a model’s previous experiences to create and simulate novel driving scenarios.</p>
<p>It can “take crowds of pedestrians and snow and bring them together” to “create a snowy, crowded pedestrian scene” that the vehicle has never experienced before.</p>
<p>According to Kendall, that will “play a huge role in both learning and validating the level of performance that we need to deploy these vehicles safely” — all while saving time and costs.</p>
<p>In June, Wayve unveiled GAIA-1, a generative world model for developing autonomous vehicles.</p>
<p>The company also recently announced LINGO-1, an AI model that allows passengers to use natural language to enhance the learning and explainability of AI driving models.</p>
<p>Looking ahead, the company hopes to scale and further develop its solutions, improving the safety of AVs to deliver value, build public trust and meet customer expectations. Kendall views embodied AI as playing a definitive role in the future of the AI landscape, pushing pioneers to “build better” and “build further” to achieve the “next big breakthroughs.”</p>
<h2><strong>You Might Also Like</strong></h2>
<p><a href="https://blogs.nvidia.com/blog/waabi-ai-simulation/"><b>Driver’s Ed: How Waabi Uses AI Simulation to Teach Autonomous Vehicles to Drive</b></a></p>
<p>Teaching the AI brains of autonomous vehicles to understand the world as humans do requires billions of miles of driving experience—the road to achieving this astronomical level of driving leads to the virtual world. Learn how Waabi uses powerful high-fidelity simulations to train and develop production-level autonomous vehicles.</p>
<p><a href="https://blogs.nvidia.com/blog/polestar/"><b>Polestar’s Dennis Nobelius on the Sustainable Performance Brand’s Plans</b></a></p>
<p>Driving enjoyment and autonomous driving capabilities can complement one another in intelligent, sustainable vehicles. Learn about the automaker’s plans to unveil its third vehicle, the Polestar 3, the tech inside it, and what the company’s racing heritage brings to the intersection of smarts and sustainability.</p>
<p><a href="https://soundcloud.com/theaipodcast/gantheftauto-harrison-kinsley-on-ai-generated-gaming-environments"><b>GANTheftAuto: Harrison Kinsley on AI-Generated Gaming Environments</b></a></p>
<p>Humans playing games against machines is nothing new, but now computers can develop games for people to play. Programming enthusiast and social media influencer Harrison Kinsley created GANTheftAuto, an AI-based neural network that generates a playable chunk of the classic video game <i>Grand Theft Auto V</i>.</p>
<p>SUBHEAD: Subscribe to the AI Podcast, Now Available on Amazon Music</p>
<p><a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">The AI Podcast is now available through Amazon Music</a>.</p>
<p>In addition, get the<a href="https://blogs.nvidia.com/ai-podcast/"> AI Podcast</a> through<a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439"> iTunes</a>,<a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjI2NDAzNDEzMy9zb3VuZHMucnNz"> Google Podcasts</a>,<a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm"> Google Play</a>,<a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us"> Castbox</a>, DoggCatcher,<a href="https://overcast.fm/itunes1186480811/the-ai-podcast"> Overcast</a>,<a href="https://player.fm/series/the-ai-podcast"> PlayerFM</a>, Pocket Casts,<a href="http://www.podbay.fm/show/1186480811"> Podbay</a>,<a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast"> PodBean</a>, PodCruncher, PodKicker,<a href="https://soundcloud.com/theaipodcast"> Soundcloud</a>,<a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L"> Spotify</a>,<a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr"> Stitcher</a> and<a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/"> TuneIn</a>.</p>
<p>Make the AI Podcast better: Have a few minutes to spare? Fill out<a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short"> this listener survey</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/wayve.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/wayve-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AV 2.0, the Next Big Wayve in Self-Driving Cars]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>‘Christmas Rush’ 3D Scene Brings Holiday Cheer This Week ‘In the NVIDIA Studio’</title>
		<link>https://blogs.nvidia.com/blog/studio-balov-adobe-photoshop-blender/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 05 Dec 2023 14:00:46 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68486</guid>

					<description><![CDATA[‘Tis the season for friends, family and beautifully rendered Santa animations from this week’s In the NVIDIA Studio artist, 3D expert Božo Balov.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. </i></p>
<p>‘Tis the season for friends, family and beautifully rendered Santa animations from this week’s <i>In the NVIDIA Studio </i>artist, 3D expert Božo Balov.</p>
<p>This week also marks an incredible milestone, with <a href="https://www.nvidia.com/en-us/geforce/news/rtx500-celebration-dlss-ray-tracing-new-games-win-prizes">over 500 NVIDIA RTX-powered games and creative apps</a> now available with support for ray tracing and AI-powered technologies like NVIDIA DLSS. Over 120 of the most popular apps — including the Adobe Creative Cloud suite, Autodesk Maya, Blender, Blackmagic Design’s DaVinci Resolve, OBS, Unity and more — use RTX to accelerate workflows by orders of magnitude, power new AI tools and enhancements and enable real-time, ray-traced previews.</p>
<p><iframe loading="lazy" title="500 RTX Games and Apps | RTX. It’s On." width="500" height="281" src="https://www.youtube.com/embed/YS8-smNHOhs?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>To celebrate, NVIDIA GeForce is hosting a giveaway for gift cards, rare, sought-after #RTXON keyboard keycaps and more. Follow GeForce on <a href="https://www.facebook.com/NVIDIAGeForce/">Facebook</a>, <a href="https://www.instagram.com/nvidiageforce/?hl=en">Instagram</a>, <a href="https://www.tiktok.com/@nvidiageforce?lang=en">TikTok</a> or <a href="https://twitter.com/NVIDIAGeForce">X</a> (formerly known as Twitter) for instructions on how to enter.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr"><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f49a.png" alt="💚" class="wp-smiley" style="height: 1em; max-height: 1em;" /> THANK YOU FOR 500 RTX GAMES &amp; APPS <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f49a.png" alt="💚" class="wp-smiley" style="height: 1em; max-height: 1em;" />  </p>
<p>To celebrate use <a href="https://twitter.com/hashtag/RTX500?src=hash&amp;ref_src=twsrc%5Etfw">#RTX500</a> ALL December across our social channels for a chance to win $500 gift cards courtesy of Green Man Gaming + other great prize giveaways.</p>
<p>For your first chance to win:</p>
<p><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f7e2.png" alt="🟢" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Comment <a href="https://twitter.com/hashtag/RTX500?src=hash&amp;ref_src=twsrc%5Etfw">#RTX500</a><br /><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f7e2.png" alt="🟢" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Tell us your favorite… <a href="https://t.co/l3g7kTKujD">pic.twitter.com/l3g7kTKujD</a></p>
<p>&mdash; NVIDIA GeForce (@NVIDIAGeForce) <a href="https://twitter.com/NVIDIAGeForce/status/1731726111443411452?ref_src=twsrc%5Etfw">December 4, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p>Say it ain’t snow: the NVIDIA Studio #WinterArtChallenge is back. Through the end of the year, share winter-themed art on <a href="https://www.facebook.com/NVIDIAStudios/">Facebook, </a><a href="https://www.instagram.com/nvidiastudio">Instagram</a> or <a href="https://twitter.com/NVIDIAStudio/">X</a> for a chance to be featured on NVIDIA Studio social media channels. Be sure to tag #WinterArtChallenge to join.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Winter has returned and so has our <a href="https://twitter.com/hashtag/WinterArtChallenge?src=hash&amp;ref_src=twsrc%5Etfw">#WinterArtChallenge</a>! <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/2744.png" alt="❄" class="wp-smiley" style="height: 1em; max-height: 1em;" /><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f3bf.png" alt="🎿" class="wp-smiley" style="height: 1em; max-height: 1em;" /><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/26c4.png" alt="⛄" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>Share your winter-themed art (like this incredible one created on an RTX GPU by <a href="https://twitter.com/rafianimates?ref_src=twsrc%5Etfw">@rafianimates</a>) using the hashtag for a chance to be featured on our social channels! <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f64c.png" alt="🙌" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>We can&#39;t wait to see what you create! <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/26f7.png" alt="⛷" class="wp-smiley" style="height: 1em; max-height: 1em;" /> <a href="https://t.co/Ml4cUAUgW3">pic.twitter.com/Ml4cUAUgW3</a></p>
<p>&mdash; NVIDIA Studio (@NVIDIAStudio) <a href="https://twitter.com/NVIDIAStudio/status/1731738137502556553?ref_src=twsrc%5Etfw">December 4, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p>Finally, 80 Level — the creative community for digital artists, animators and computer-generated imagery specialists — is hosting its Community Metasites Challenge. Artists can showcase their creativity by applying unique aesthetics to a simple block level via characters, game mechanics, visual effects and more — with a chance to win a new NVIDIA Studio laptop. <a href="https://t.co/OigWqOUlSD">Register</a> today.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Special Thanks to <a href="https://twitter.com/NVIDIAStudio?ref_src=twsrc%5Etfw">@NVIDIAStudio</a> who is offering this incredible prize for the first place winner of the 80 Level Community Metasites Challenge.<br />An ASUS &#8211; ProArt Studiobook 16 OLED H7600 16&quot; Laptop!</p>
<p>Register Now<a href="https://t.co/OigWqOUlSD">https://t.co/OigWqOUlSD</a><a href="https://twitter.com/hashtag/NVIDIA?src=hash&amp;ref_src=twsrc%5Etfw">#NVIDIA</a> <a href="https://twitter.com/hashtag/80levelmetasiteschallenge?src=hash&amp;ref_src=twsrc%5Etfw">#80levelmetasiteschallenge</a> <a href="https://twitter.com/hashtag/UE5?src=hash&amp;ref_src=twsrc%5Etfw">#UE5</a> <a href="https://twitter.com/hashtag/CG?src=hash&amp;ref_src=twsrc%5Etfw">#CG</a> <a href="https://t.co/atOozRqSxR">pic.twitter.com/atOozRqSxR</a></p>
<p>&mdash; 80 LEVEL (@80Level) <a href="https://twitter.com/80Level/status/1729186265336266795?ref_src=twsrc%5Etfw">November 27, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<h2><b>Wrapper’s Delight</b></h2>
<p>Balov’s <i>Christmas Rush</i> 3D animation reimagines Santa as a resident of the coastal city of Split, Croatia — but with a harsher, less jolly edge.</p>
<div style="width: 1280px;" class="wp-video"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video class="wp-video-shortcode" id="video-68486-1" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-face-closeup-1280w.mp4?_=1" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-face-closeup-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-face-closeup-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>Balov jumped straight into modeling edgy Saint Nick in the virtual-reality modeling software Quill. He deployed vertex-painting techniques and used a photogrammetry scan of a Vespa as a base, adding brushstrokes to blend it with the rest of the scene.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-68486-2" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-turntable-light-1280w.mp4?_=2" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-turntable-light-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-turntable-light-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>To achieve a flickering effect on Santa’s clothing, Balov created a custom texture with different brush strokes in Adobe Photoshop. The texture doubles as an alpha map, which intentionally clips the geometry.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-68486-3" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-solid-anim-1280w.mp4?_=3" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-solid-anim-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-solid-anim-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<div class="simplePullQuote right"><p>“When it comes to rendering 3D graphics, nothing really comes close to NVIDIA GPUs.” — Božo Balov</p>
</div>
<p>He then used Adobe Photoshop to paint monochromatic background layers. Balov’s GeForce RTX 3080 Ti GPU unlocked over 30 GPU-accelerated features, including blur gallery, liquify, smart sharpen and perspective warp.</p>
<p>Balov then converted the files to the FBX adaptable file format for 3D software before importing them into Blender, where he animated the layers to move in the opposite direction of the character to create a sense of speed. He kept the lighting fairly simple, with one light source as the base and a few supplemental ones to emphasize specific parts of the scene.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-68486-4" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-turntable-half-1280w.mp4?_=4" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-turntable-half-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-turntable-half-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>Balov prefers working in Blender’s real-time engine EEVEE to animate his scene, cutting wait times. RTX-accelerated <a href="https://developer.nvidia.com/rtx/ray-tracing/optix">OptiX</a> ray tracing in the viewport enabled greater interactivity with smoother movement, speeding his ideation and creative workflow.</p>
<figure id="attachment_68499" aria-describedby="caption-attachment-68499" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-still-face-full-render-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68499" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-still-face-full-render-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-still-face-full-render-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-still-face-full-render-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-still-face-full-render-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-still-face-full-render-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-still-face-full-render-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-still-face-full-render-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-still-face-full-render-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68499" class="wp-caption-text">Extraordinary detail.</figcaption></figure>
<p>“Rendering is a joy on NVIDIA RTX cards,” said Balov. “Since OptiX made its debut, rendering times have been cut in half or more — Blender Cycles feels like a real-time engine.”</p>
<p>When asked for advice to give aspiring artists, Balov emphasized the importance of individual passion.</p>
<p>“Pursue what matters to you,” he said. “Don’t spend time fulfilling other people’s ideas of what art should be.”</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-68486-5" width="1280" height="450" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-bozo-balov-wk86-artist-feature-1280w.mp4?_=5" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-bozo-balov-wk86-artist-feature-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-bozo-balov-wk86-artist-feature-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>Check out Balov’s art portfolio on <a href="https://www.instagram.com/bozo_balov/">Instagram</a>.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>, </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i> and </i><a href="https://twitter.com/NVIDIAStudio"><i>X</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-face-closeup-1280w.mp4" length="1833798" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-turntable-light-1280w.mp4" length="1995914" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-solid-anim-1280w.mp4" length="1906961" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-bozo-balov-wk86-turntable-half-1280w.mp4" length="1844017" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/12/studio-itns-bozo-balov-wk86-artist-feature-1280w.mp4" length="1894192" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/nv-blog-header-preview-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/nv-blog-header-preview-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[‘Christmas Rush’ 3D Scene Brings Holiday Cheer This Week ‘In the NVIDIA Studio’]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Bringing Personality to Pixels, Inworld Levels Up Game Characters Using Generative AI</title>
		<link>https://blogs.nvidia.com/blog/generative-ai-npcs/</link>
		
		<dc:creator><![CDATA[JJ Kim]]></dc:creator>
		<pubDate>Mon, 04 Dec 2023 18:00:09 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Game Development]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[NVIDIA Triton]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68477</guid>

					<description><![CDATA[To enhance the gaming experience, studios and developers spend tremendous effort creating photorealistic, immersive in-game environments. But non-playable characters (NPCs) often get left behind. Many behave in ways that lack depth and realism, making their interactions repetitive and forgettable. Inworld AI is changing the game by using generative AI to drive NPC behaviors that are <a class="read-more" href="https://blogs.nvidia.com/blog/generative-ai-npcs/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>To enhance the gaming experience, studios and developers spend tremendous effort creating photorealistic, immersive in-game environments.</p>
<p>But non-playable characters (NPCs) often get left behind. Many behave in ways that lack depth and realism, making their interactions repetitive and forgettable.</p>
<p><a href="https://inworld.ai/">Inworld AI</a> is changing the game by using <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/">generative AI</a> to drive NPC behaviors that are dynamic and responsive to player actions. The Mountain View, Calif.-based startup’s Character Engine, which can be used with any character design, is helping studios and developers enhance gameplay and improve player engagement.</p>
<h2><b>Elevate Gaming Experiences: Achievement Unlocked</b></h2>
<p>The Inworld team aims to develop AI-powered NPCs that can learn, adapt and build relationships with players while delivering high-quality performance and maintaining in-game immersion.</p>
<p>To make it easier for developers to integrate AI-based NPCs into their games, Inworld built Character Engine, which uses generative AI running on NVIDIA technology to create immersive, interactive characters. It’s built to be production-ready, scalable and optimized for real-time experiences.</p>
<p>The Character Engine comprises three layers: Character Brain, Contextual Mesh and Real-Time AI.</p>
<p><a href="https://inworld.ai/character-brain"><b>Character Brain</b></a> orchestrates a character’s performance by syncing to its multiple personality <a href="https://www.nvidia.com/en-us/glossary/data-science/machine-learning/">machine learning</a> models, such as for text-to-speech, <a href="https://developer.nvidia.com/blog/essential-guide-to-automatic-speech-recognition-technology/">automatic speech recognition</a>, emotions, gestures and animations.</p>
<p>The layer also enables AI-based NPCs to learn and adapt, navigate relationships and perform motivated actions. For example, users can create triggers using the “Goals and Action” feature to program NPCs to behave in a certain way in response to a given player input.</p>
<p><a href="https://inworld.ai/contextual-mesh"><b>Contextual Mesh</b></a> allows developers to set parameters for content and safety mechanisms, custom knowledge and narrative controls. Game developers can use the “Relationships” feature to create emergent narratives, such that an ally can turn into an enemy or vice versa based on how players treat an NPC.</p>
<p>One big challenge developers face when using generative AI is keeping NPCs in-world and on-message. Inworld’s Contextual Mesh layer helps overcome this hurdle by rendering characters within the logic and fantasy of their worlds, effectively avoiding the hallucinations that commonly appear when using <a href="https://www.nvidia.com/en-us/glossary/data-science/large-language-models/">large language models</a> (LLMs).</p>
<p>The Real-Time AI layer ensures optimal performance and scalability for real-time experiences.</p>
<p><iframe loading="lazy" title="The Developer Platform for AI Characters" width="500" height="281" src="https://www.youtube.com/embed/9UgOXaEh_f8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Powering Up AI Workflows With NVIDIA </b></h2>
<p>Inworld, a member of the <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a> program, which supports startups through every stage of their development, uses <a href="https://www.nvidia.com/en-us/data-center/a100/">NVIDIA A100 Tensor Core GPUs</a> and <a href="https://www.nvidia.com/en-us/ai-data-science/products/triton-inference-server/">NVIDIA Triton Inference Server</a> as integral parts of its generative AI training and deployment infrastructure.</p>
<p>Inworld used the open-source NVIDIA Triton Inference Server software to standardize other non-generative machine learning model deployments required to power Character Brain features, such as emotions. The startup also plans to use the open-source <a href="https://developer.nvidia.com/tensorrt#inference">NVIDIA TensorRT-LLM</a> library to optimize inference performance. Both NVIDIA Triton Inference Server and TensorRT-LLM are available with the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> software platform, which provides security, stability and support for production AI.</p>
<p>Inworld also used NVIDIA A100 GPUs within <a href="https://developer.nvidia.com/slurm">Slurm</a>-managed bare-metal machines for its production training pipelines. Similar machines wrapped in <a href="https://developer.nvidia.com/kubernetes-gpu">Kubernetes</a> help manage character interactions during gameplay. This setup delivers real-time generative AI at the lowest possible cost.</p>
<p>“We chose to use NVIDIA A100 GPUs because they provided the best, most cost-efficient option for our machine learning workloads compared to other solutions,” said Igor Poletaev, vice president of AI at Inworld.</p>
<p>“Our customers and partners are looking to find novel and innovative ways to drive player engagement metrics by integrating AI NPC functionalities into their gameplay,” said Poletaev. “There’s no way to achieve real-time performance without hardware accelerators, which is why we required GPUs to be integrated into our backend architecture from the very beginning.”</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/Inworld-AI-Copy.jpg"><img loading="lazy" decoding="async" class="aligncenter size-large wp-image-68481" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/Inworld-AI-Copy-672x357.jpg" alt="" width="672" height="357" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/Inworld-AI-Copy-672x357.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Inworld-AI-Copy-400x213.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Inworld-AI-Copy-768x408.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Inworld-AI-Copy-842x447.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Inworld-AI-Copy-406x215.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Inworld-AI-Copy-188x100.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Inworld-AI-Copy.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a></p>
<p>Inworld’s generative AI-powered NPCs have enabled dynamic, evergreen gaming experiences that keep players coming back. Developers and gamers alike have reported enhanced player engagement, satisfaction and retention.</p>
<p>Inworld has powered AI-based NPC experiences from Niantic, LG UPlus, Alpine Electronics and more. One open-world virtual reality game using the Inworld Character Engine saw a 5% increase in playtime, while a detective-themed indie game garnered over $300,000 in free publicity after some of the most popular Twitch streamers discovered it.</p>
<p>Learn more about <a href="https://inworld.ai/">Inworld AI</a> and NVIDIA technologies for <a href="https://developer.nvidia.com/industries/game-development">game developers</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/Inworld-AI-Header.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/Inworld-AI-Header-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Bringing Personality to Pixels, Inworld Levels Up Game Characters Using Generative AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Why GPUs Are Great for AI</title>
		<link>https://blogs.nvidia.com/blog/why-gpus-are-great-for-ai/</link>
		
		<dc:creator><![CDATA[Rick Merritt]]></dc:creator>
		<pubDate>Mon, 04 Dec 2023 16:00:36 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Explainer]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[CUDA]]></category>
		<category><![CDATA[Customer Stories]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[NVIDIA DGX]]></category>
		<category><![CDATA[NVIDIA Hopper Architecture]]></category>
		<category><![CDATA[NVIDIA Quantum-2]]></category>
		<category><![CDATA[NVLink]]></category>
		<category><![CDATA[Parallel Computing]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68375</guid>

					<description><![CDATA[GPUs have been called the rare Earth metals — even the gold — of artificial intelligence, because they’re foundational for today’s generative AI era. Three technical reasons, and many stories, explain why that’s so. Each reason has multiple facets well worth exploring, but at a high level: GPUs employ parallel processing. GPU systems scale up <a class="read-more" href="https://blogs.nvidia.com/blog/why-gpus-are-great-for-ai/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>GPUs have been called the rare Earth metals — even the gold — of artificial intelligence, because they’re foundational for today’s <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/">generative AI</a> era.</p>
<p>Three technical reasons, and many stories, explain why that’s so. Each reason has multiple facets well worth exploring, but at a high level:</p>
<ul>
<li>GPUs employ parallel processing.</li>
<li>GPU systems scale up to supercomputing heights.</li>
<li>The GPU software stack for AI is broad and deep.</li>
</ul>
<p>The net result is GPUs perform technical calculations faster and with greater <a href="https://www.nvidia.com/en-us/glossary/energy-efficiency/">energy efficiency</a> than CPUs. That means they deliver leading performance for AI training and inference as well as gains across a wide array of applications that use <a href="https://blogs.nvidia.com/blog/what-is-accelerated-computing/">accelerated computing</a>.</p>
<p>In its <a href="https://aiindex.stanford.edu/wp-content/uploads/2023/04/HAI_AI-Index-Report_2023.pdf">recent report</a> on AI, Stanford’s Human-Centered AI group provided some context. GPU performance “has increased roughly 7,000 times” since 2003 and price per performance is “5,600 times greater,” it reported.</p>
<figure id="attachment_68465" aria-describedby="caption-attachment-68465" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/Stanford-2023-AI-report-GPU-performance-final.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-68465" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/Stanford-2023-AI-report-GPU-performance-final-672x329.jpg" alt="Stanford report on GPU performance increases" width="672" height="329" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/Stanford-2023-AI-report-GPU-performance-final-672x329.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Stanford-2023-AI-report-GPU-performance-final-400x196.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Stanford-2023-AI-report-GPU-performance-final-768x376.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Stanford-2023-AI-report-GPU-performance-final-1536x753.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Stanford-2023-AI-report-GPU-performance-final-842x413.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Stanford-2023-AI-report-GPU-performance-final-406x199.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Stanford-2023-AI-report-GPU-performance-final-188x92.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Stanford-2023-AI-report-GPU-performance-final-1280x627.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Stanford-2023-AI-report-GPU-performance-final.jpg 1982w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68465" class="wp-caption-text">A 2023 report captured the steep rise in GPU performance and price/performance.</figcaption></figure>
<p>The report also cited analysis from Epoch, an independent research group that measures and forecasts AI advances.</p>
<p>“GPUs are the dominant computing platform for accelerating machine learning workloads, and most (if not all) of the biggest models over the last five years have been trained on GPUs … [they have] thereby centrally contributed to the recent progress in AI,” Epoch said on <a href="https://epochai.org/blog/trends-in-gpu-price-performance">its site</a>.</p>
<p>A <a href="https://cset.georgetown.edu/wp-content/uploads/AI-Chips%E2%80%94What-They-Are-and-Why-They-Matter.pdf">2020 study</a> assessing AI technology for the U.S. government drew similar conclusions.</p>
<p>“We expect [leading-edge] AI chips are one to three orders of magnitude more cost-effective than leading-node CPUs when counting production and operating costs,” it said.</p>
<p>NVIDIA GPUs have increased performance on AI inference 1,000x in the last ten years, said Bill Dally, the company’s chief scientist in a <a href="https://blogs.nvidia.com/blog/hot-chips-dally-research/">keynote</a> at Hot Chips, an annual gathering of semiconductor and systems engineers.</p>
<h2><b>ChatGPT Spread the News</b></h2>
<p>ChatGPT provided a powerful example of how GPUs are great for AI. The <a href="https://blogs.nvidia.com/blog/what-are-large-language-models-used-for/">large language model</a> (LLM), trained and run on thousands of NVIDIA GPUs, runs generative AI services used by more than 100 million people.</p>
<p>Since its 2018 launch, <a href="https://www.nvidia.com/en-us/data-center/resources/mlperf-benchmarks/">MLPerf</a>, the industry-standard benchmark for AI, has provided numbers that detail the leading performance of NVIDIA GPUs on both AI training and inference.</p>
<p>For example, <a href="https://www.nvidia.com/en-us/data-center/grace-hopper-superchip/">NVIDIA Grace Hopper Superchips</a> swept the <a href="https://blogs.nvidia.com/blog/grace-hopper-inference-mlperf/">latest round</a> of inference tests. <a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-supercharges-large-language-model-inference-on-nvidia-h100-gpus/">NVIDIA TensorRT-LLM</a>, inference software released since that test, delivers up to an 8x boost in performance and more than a 5x reduction in energy use and total cost of ownership. Indeed, NVIDIA GPUs have won every round of MLPerf training and inference tests since the benchmark was released in 2019.</p>
<p>In February, NVIDIA GPUs<a href="https://blogs.nvidia.com/blog/stac-ml-inference-gpu/"> delivered leading results</a> for inference, serving up thousands of inferences per second on the most demanding models in the STAC-ML Markets benchmark, a key technology performance gauge for the financial services industry.</p>
<p>A RedHat software engineering team put it succinctly in <a href="https://developers.redhat.com/articles/2022/11/21/why-gpus-are-essential-computing">a blog</a>: “GPUs have become the foundation of artificial intelligence.”</p>
<h2><b>AI Under the Hood</b></h2>
<p>A brief look under the hood shows why GPUs and AI make a powerful pairing.</p>
<p>An AI model, also called a neural network, is essentially a mathematical lasagna, made from layer upon layer of linear algebra equations. Each equation represents the likelihood that one piece of data is related to another.</p>
<p>For their part, GPUs pack thousands of cores, tiny calculators working in parallel to slice through the math that makes up an AI model. This, at a high level, is how <a href="https://blogs.nvidia.com/blog/what-is-ai-computing/">AI computing</a> works.</p>
<h2><b>Highly Tuned Tensor Cores</b></h2>
<p>Over time, NVIDIA’s engineers have tuned GPU cores to the evolving needs of AI models. The latest GPUs include <a href="https://www.nvidia.com/en-us/data-center/tensor-cores/">Tensor Cores</a> that are 60x more powerful than the first-generation designs for processing the matrix math neural networks use.</p>
<p>In addition, <a href="https://www.nvidia.com/en-us/data-center/h100/">NVIDIA Hopper Tensor Core GPUs</a> include a <a href="https://blogs.nvidia.com/blog/h100-transformer-engine/">Transformer Engine</a> that can automatically adjust to the optimal precision needed to process <a href="https://blogs.nvidia.com/blog/what-is-a-transformer-model/">transformer models</a>, the class of neural networks that spawned generative AI.</p>
<p>Along the way, each GPU generation has packed more memory and optimized techniques to store an entire AI model in a single GPU or set of GPUs.</p>
<h2><b>Models Grow, Systems Expand</b></h2>
<p>The complexity of AI models is expanding a whopping 10x a year.</p>
<p>The current state-of-the-art LLM, GPT4, packs more than a trillion parameters, a metric of its mathematical density. That’s up from less than 100 million parameters for a popular LLM in 2018.</p>
<figure id="attachment_68468" aria-describedby="caption-attachment-68468" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/1000x-AI-inferrence-gain-in-10-years-scaled.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-68468" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/1000x-AI-inferrence-gain-in-10-years-672x380.jpg" alt="Chart shows 1,000x performance improvement on AI inference over a decade for single GPUs" width="672" height="380" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/1000x-AI-inferrence-gain-in-10-years-672x380.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/1000x-AI-inferrence-gain-in-10-years-400x226.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/1000x-AI-inferrence-gain-in-10-years-768x434.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/1000x-AI-inferrence-gain-in-10-years-1536x868.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/12/1000x-AI-inferrence-gain-in-10-years-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/12/1000x-AI-inferrence-gain-in-10-years-797x450.jpg 797w, https://blogs.nvidia.com/wp-content/uploads/2023/12/1000x-AI-inferrence-gain-in-10-years-381x215.jpg 381w, https://blogs.nvidia.com/wp-content/uploads/2023/12/1000x-AI-inferrence-gain-in-10-years-177x100.jpg 177w, https://blogs.nvidia.com/wp-content/uploads/2023/12/1000x-AI-inferrence-gain-in-10-years-1280x723.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68468" class="wp-caption-text">In a recent talk at Hot Chips, NVIDIA Chief Scientist Bill Dally described how single-GPU performance on AI inference expanded 1,000x in the last decade.</figcaption></figure>
<p>GPU systems have kept pace by ganging up on the challenge. They scale up to supercomputers, thanks to their fast <a href="https://blogs.nvidia.com/blog/what-is-nvidia-nvlink/">NVLink</a> interconnects and <a href="https://www.nvidia.com/en-us/networking/quantum2/">NVIDIA Quantum InfiniBand networks</a>.</p>
<p>For example, the <a href="https://www.nvidia.com/en-us/data-center/dgx-gh200/">DGX GH200</a>, a large-memory AI supercomputer, combines up to 256 NVIDIA GH200 Grace Hopper Superchips into a single data-center-sized GPU with 144 terabytes of shared memory.</p>
<p>Each GH200 superchip is a single server with 72 Arm Neoverse CPU cores and four petaflops of AI performance. A new <a href="https://blogs.nvidia.com/blog/gh200-grace-hopper-superchip-powers-ai-supercomputers/">four-way Grace Hopper systems configuration</a> puts in a single compute node a whopping 288 Arm cores and 16 petaflops of AI performance with up to 2.3 terabytes of high-speed memory.</p>
<p>And <a href="https://www.nvidia.com/en-us/data-center/h200/">NVIDIA H200 Tensor Core GPUs</a> announced in November pack up to 288 gigabytes of the latest HBM3e memory technology.</p>
<h2><b>Software Covers the Waterfront</b></h2>
<p>An expanding ocean of GPU software has evolved since 2007 to enable every facet of AI, from deep-tech features to high-level applications.</p>
<p>The NVIDIA AI platform includes hundreds of software libraries and apps. The CUDA programming language and the cuDNN-X library for deep learning provide a base on top of which developers have created software like <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/">NVIDIA NeMo</a>, a framework to let users build, customize and run inference on their own generative AI models.</p>
<p>Many of these elements are available as open-source software, the grab-and-go staple of software developers. More than a hundred of them are packaged into the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> platform for companies that require full security and support. Increasingly, they’re also available from major cloud service providers as APIs and services on <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a>.</p>
<p><a href="https://blogs.nvidia.com/blog/customize-ai-models-steerlm/">SteerLM</a>, one of the latest AI software updates for NVIDIA GPUs, lets users fine tune models during inference.</p>
<h2><b>A 70x Speedup in 2008</b></h2>
<p>Success stories date back to a <a href="http://robotics.stanford.edu/~ang/papers/icml09-LargeScaleUnsupervisedDeepLearningGPU.pdf">2008 paper</a> from AI pioneer Andrew Ng, then a Stanford researcher. Using two NVIDIA GeForce GTX 280 GPUs, his three-person team achieved a 70x speedup over CPUs processing an AI model with 100 million parameters, finishing work that used to require several weeks in a single day.</p>
<p>“Modern graphics processors far surpass the computational capabilities of multicore CPUs, and have the potential to revolutionize the applicability of deep unsupervised learning methods,” they reported.</p>
<figure id="attachment_68471" aria-describedby="caption-attachment-68471" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/12/Andrew-Ng-GTC-2015-scaling-scaled.jpg"><img loading="lazy" decoding="async" class="size-large wp-image-68471" src="https://blogs.nvidia.com/wp-content/uploads/2023/12/Andrew-Ng-GTC-2015-scaling-672x266.jpg" alt="Picture of Andrew Ng showing slide in a talk on GPU performance for AI" width="672" height="266" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/12/Andrew-Ng-GTC-2015-scaling-672x266.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Andrew-Ng-GTC-2015-scaling-400x159.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Andrew-Ng-GTC-2015-scaling-768x304.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Andrew-Ng-GTC-2015-scaling-1536x609.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Andrew-Ng-GTC-2015-scaling-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Andrew-Ng-GTC-2015-scaling-842x334.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Andrew-Ng-GTC-2015-scaling-406x161.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Andrew-Ng-GTC-2015-scaling-188x75.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2023/12/Andrew-Ng-GTC-2015-scaling-1280x507.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68471" class="wp-caption-text">Andrew Ng described his experiences using GPUs for AI in a GTC 2015 talk.</figcaption></figure>
<p>In a <a href="https://video.ibm.com/recorded/60113824/highlight/619422">2015 talk</a> at NVIDIA GTC, Ng described how he continued using more GPUs to scale up his work, running larger models at Google Brain and Baidu. Later, he helped found Coursera, an online education platform where he taught hundreds of thousands of AI students.</p>
<p>Ng counts Geoff Hinton, one of the godfathers of modern AI, among the people he influenced. “I remember going to Geoff Hinton saying check out CUDA, I think it can help build bigger neural networks,” he said in the GTC talk.</p>
<p>The University of Toronto professor spread the word<b>. </b>“In 2009, I remember giving a talk at NIPS [now NeurIPS], where I told about 1,000 researchers they should all buy GPUs because GPUs are going to be the future of machine learning,” Hinton said in a <a href="https://venturebeat.com/ai/how-nvidia-dominated-ai-and-plans-to-keep-it-that-way-as-generative-ai-explodes/">press report</a>.</p>
<h2><b>Fast Forward With GPUs</b></h2>
<p>AI’s gains are expected to ripple across the global economy.</p>
<p>A <a href="https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier#key-insights">McKinsey report</a> in June estimated that generative AI could add the equivalent of $2.6 trillion to $4.4 trillion annually across the 63 use cases it analyzed in industries like banking, healthcare and retail. So, it’s no surprise Stanford’s 2023 AI report said that a majority of business leaders expect to increase their investments in AI.</p>
<p>Today, more than 40,000 companies use NVIDIA GPUs for AI and accelerated computing, attracting a global community of 4 million developers. Together they’re advancing science, healthcare, finance and virtually every industry.</p>
<p>Among the latest achievements, NVIDIA described a whopping 700,000x speedup using AI to ease climate change by keeping carbon dioxide out of the atmosphere (see video below). It’s one of many ways NVIDIA is applying the performance of GPUs to AI and beyond.</p>
<p>Learn how <a href="https://www.nvidia.com/en-us/lp/ai-data-science/how-to-get-started-with-ai-inference-series/">GPUs put AI into production</a>.</p>
<p><iframe loading="lazy" title="Accelerating Carbon Capture and Storage With Fourier Neural Operator and NVIDIA Modulus" width="500" height="281" src="https://www.youtube.com/embed/u-M5LQvx1cQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/NVIDIA-AI-platform-x1280-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1090"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/12/NVIDIA-AI-platform-x1280-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Why GPUs Are Great for AI]]></media:title>
			<media:description type="html">NVIDIA&#039;s GPU-based AI platform</media:description>
			</media:content>
			</item>
		<item>
		<title>‘Call of Duty’ Comes to GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-call-of-duty/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 30 Nov 2023 14:00:53 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68452</guid>

					<description><![CDATA[Let the games begin — this GFN Thursday brings the highly anticipated Call of Duty: Modern Warfare III to the cloud, the first Activision title on GeForce NOW as part of the NVIDIA and Microsoft partnership. It’s joined by Call of Duty: Modern Warfare II and Call of Duty: Warzone — all three titles can <a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-call-of-duty/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Let the games begin — this GFN Thursday brings the highly anticipated <i>Call of Duty: Modern Warfare III</i> to the cloud, the first Activision title on <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> as part of the <a href="https://blogs.nvidia.com/blog/geforce-now-thursday-feb-23/">NVIDIA and Microsoft partnership</a>.</p>
<p>It’s joined by <i>Call of Duty: Modern Warfare II</i> and <i>Call of Duty: Warzone</i> — all three titles can be played from one central location via the <i>Call of Duty </i>logo on GeForce NOW.</p>
<p>And it’s the most wonderful time of the year — over 65 games are joining the GeForce NOW library in December, with 15 available to stream this week.</p>
<p>Plus, stream GeForce NOW on the go and get console-quality controls by simply snapping a mobile device into a Backbone One controller. For a limited time, Backbone is offering a 30% discount for premium GeForce NOW members starting today in the <a href="https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.nvidia.com%2Fen-us%2Fgeforce-now%2Frewards%2F&amp;data=05%7C01%7Csngo%40nvidia.com%7C9a6764f3073d445e8f1708dbeb82cfb4%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638362719285332290%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=ZRfUaxP7RMBSbj95%2F2pFBldzJGUS5asGANpeyQIlmto%3D&amp;reserved=0">Rewards Portal</a>. Free-level members can claim the discount starting Dec. 7.</p>
<h2><b>The Lobby Awaits</b></h2>
<figure id="attachment_68460" aria-describedby="caption-attachment-68460" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-68460" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Call_Of_Duty_Modern_Warfare_III-672x378.jpeg" alt="Call of Duty on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Call_Of_Duty_Modern_Warfare_III-672x378.jpeg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Call_Of_Duty_Modern_Warfare_III-400x225.jpeg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Call_Of_Duty_Modern_Warfare_III-768x432.jpeg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Call_Of_Duty_Modern_Warfare_III-1536x864.jpeg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Call_Of_Duty_Modern_Warfare_III-scaled.jpeg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Call_Of_Duty_Modern_Warfare_III-800x450.jpeg 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Call_Of_Duty_Modern_Warfare_III-382x215.jpeg 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Call_Of_Duty_Modern_Warfare_III-178x100.jpeg 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Call_Of_Duty_Modern_Warfare_III-1280x720.jpeg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68460" class="wp-caption-text"><em>The war has changed.</em></figcaption></figure>
<p><i>Call of Duty: Modern Warfare III</i> returns as a direct sequel to the record-breaking <i>Call of Duty: Modern Warfare II</i> and follows the story of Task Force 141 as they face off the ultimate threat.</p>
<p>Dig into the action-packed single-player campaign or head online to defeat the undead in an exciting open-world co-op experience that takes the Zombies mode that fans know and love to the next level. Those that prefer some multiplayer action can dip into a selection of Core Multiplayer maps from the 16 iconic launch maps of 2009’s <i>Call of Duty: Modern Warfare 2</i> that are being brought over and modernized for <i>Call of Duty: Modern Warfare III</i>.</p>
<p>Plus, stay tuned to GFN Thursday for when other legacy <i>Call of Duty</i> titles will be added to the cloud. Check out <a href="https://nvidia.custhelp.com/app/answers/detail/a_id/5462">the article </a>for more details.</p>
<p>GeForce NOW <a href="http://geforcenow.com">Ultimate members</a> can get the upper hand with <a href="https://www.nvidia.com/en-us/geforce/news/dlss-3-jusant-ripout-robocop-talos-principle-2-more/">NVIDIA DLSS 3 and Reflex</a> to get the highest frame rates and lowest latencies for the smoothest gameplay by streaming from a GeForce RTX 4080 gaming rig in the cloud. Never worry about upgrading hardware or system specs again with GeForce NOW.</p>
<h2><b>Presents, Galore</b></h2>
<figure id="attachment_68457" aria-describedby="caption-attachment-68457" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-68457" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-SteamWorld_Build-672x378.jpg" alt="SteamWorld Build on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-SteamWorld_Build-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-SteamWorld_Build-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-SteamWorld_Build-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-SteamWorld_Build-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-SteamWorld_Build-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-SteamWorld_Build-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-SteamWorld_Build-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-SteamWorld_Build-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-SteamWorld_Build-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68457" class="wp-caption-text"><em>Dig, dig, dig!</em></figcaption></figure>
<p>Break ground in <i>SteamWorld Build</i> from Thunderful Publishing. Dig deep and build wide to excavate long-lost spacefaring technology while ensuring everyone has the resources needed to survive and reach the final frontier. It launches Dec. 1 on Steam and PC Game Pass — check it out with the three free months of PC Game Pass included with the purchase of a six-month Ultimate membership, part of the <a href="https://www.nvidia.com/en-us/geforce-now/holiday/">GeForce NOW holiday bundle</a><b>.</b></p>
<p>Members can start their adventures now with 15 newly supported titles in the cloud this week:</p>
<ul>
<li><i>Last Train Home </i>(New release on <a href="https://store.steampowered.com/app/1469610?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Nov. 28)</li>
<li><i>Gangs of Sherwood </i>(New release on <a href="https://store.steampowered.com/app/1351000?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Nov. 30)</li>
<li><i>SteamWorld Build </i>(New release on <a href="https://store.steampowered.com/app/2134770?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, <a href="https://www.xbox.com/games/store/steamworld-build/9MVRDC1BW8TQ?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass, Dec. 1)</li>
<li><i>Astrea: Six-Sided Oracles </i>(<a href="https://store.steampowered.com/app/1755830?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Call of Duty HQ, </i>including <i>Call of Duty: Modern Warfare III, Call of Duty: Modern Warfare II </i>and <i>Call of Duty: Warzone </i>(<a href="https://store.steampowered.com/app/1938090?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Galactic Civilizations IV </i>(<a href="https://store.steampowered.com/app/1357210?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Halls of Torment </i>(<a href="https://store.steampowered.com/app/2218750?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Kona II: Brume </i>(<a href="https://store.steampowered.com/app/1229020?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Laika: Aged Through Blood </i>(<a href="https://www.epicgames.com/store/p/laika-3293ee?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Pillars of Eternity </i>(<a href="https://www.xbox.com/games/store/pillars-of-eternity-hero-edition/9P5LZC1KB48V?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>RESEARCH and DESTROY </i>(<a href="https://www.xbox.com/games/store/research-and-destroy/9NNZJ389GSW2?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Roboquest </i>(<a href="https://www.epicgames.com/store/p/roboquest-9ad17a?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>StrangerZ</i> (<a href="https://store.steampowered.com/app/2293600?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<p>Then, check out the plentiful games for the rest of December:</p>
<ul>
<li><i>Stargate: Timekeepers </i>(New release on <a href="https://store.steampowered.com/app/1523650?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Dec. 12)</li>
<li><i>Pioneers of Pagonia </i>(New release on <a href="https://store.steampowered.com/app/2155180?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Dec. 13)</li>
<li><i>House Flipper 2 </i>(New release on <a href="https://store.steampowered.com/app/1190970?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Dec. 14)</li>
<li><i>Soulslinger: Envoy of Death </i>(New release on <a href="https://store.steampowered.com/app/2429240?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Dec. 14)</li>
<li><i>Agatha Christie &#8211; Murder on the Orient Express </i>(<a href="https://store.steampowered.com/app/1904790?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Age of Wonders 4 </i>(<a href="https://www.xbox.com/games/store/age-of-wonders-4-pc/9P0M20727BVN?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>AI: THE SOMNIUM FILES &#8211; nirvanA Initiative </i>(<a href="https://www.xbox.com/games/store/ai-the-somnium-files-nirvana-initiative/9NZPH8RG8537?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>The Anacrusis </i>(<a href="https://www.xbox.com/games/store/the-anacrusis-deluxe-edition/9N8R7XRD48F1?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>BEAST</i> (<a href="https://store.steampowered.com/app/1145630?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Before We Leave </i>(<a href="https://www.xbox.com/games/store/before-we-leave/9n360tzqz0tr?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Bloons TD Battles</i> (<a href="https://store.steampowered.com/app/444640?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Control </i>(<a href="https://www.xbox.com/games/store/control-standard-edition/9PL1J8PJKH29?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Dark Envoy </i>(<a href="https://store.steampowered.com/app/945770?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Darksiders III </i>(<a href="https://www.xbox.com/games/store/darksiders-iii/9PLPXGK1GDQ1?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>The Day Before </i>(<a href="https://store.steampowered.com/app/1372880?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Destroy All Humans! </i>(<a href="https://www.xbox.com/games/store/destroy-all-humans/9N7L81J5XW7T?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Disgaea 4 Complete+ </i>(<a href="https://www.xbox.com/games/store/disgaea-4-complete/9PFJDSL1CC7G?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Escape the Backrooms </i>(<a href="https://store.steampowered.com/app/1943950?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Europa Universalis IV (</i><a href="https://www.xbox.com/games/store/europa-universalis-iv-microsoft-store-edition/9phqjwgltzm8?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Evil Genius 2: World Domination </i>(<a href="https://www.xbox.com/games/store/evil-genius-2-world-domination-deluxe-edition/9NL75K01XDG5?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Fae Tactics </i>(<a href="https://www.xbox.com/games/store/fae-tactics/9PL4HXW1H502?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Figment 2: Creed Valley</i> (<a href="https://www.epicgames.com/store/p/figment2-creed-valley?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>The Forgotten City </i>(<a href="https://www.xbox.com/games/store/the-forgotten-city/9NJ4R763M7TH?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Human Fall Flat</i> (<a href="https://www.xbox.com/games/store/human-fall-flat/BSMZH25V6V46?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Ikonei Island: An Earthlock Adventure </i>(<a href="https://store.steampowered.com/app/1550730?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Immortal Realms: Vampire Wars </i>(<a href="https://www.xbox.com/games/store/immortal-realms-vampire-wars/9P2XMXXFQV5G?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Lethal League Blaze </i>(<a href="https://www.xbox.com/games/store/lethal-league-blaze/9NHPR05080C6?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Loddlenaut </i>(<a href="https://store.steampowered.com/app/1644940?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Matchpoint &#8211; Tennis Championships </i>(<a href="https://www.xbox.com/games/store/matchpoint---tennis-championships-win/9P8X0RH2WV5J?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Maneater </i>(<a href="https://www.xbox.com/games/store/maneater/9P5B81KVDGP1?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>The Medium </i>(<a href="https://www.xbox.com/games/store/the-medium/9NFSR96G6K4N?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Metro Exodus</i> (<a href="https://www.xbox.com/games/store/metro-exodus-windows/9P60KL3MHCNH?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Mortal Shell </i>(<a href="https://www.xbox.com/games/store/mortal-shell-enhanced-edition/9PC2BJDXR2LK?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>MotoGP 20 </i>(<a href="https://www.xbox.com/en-us/games/store/motogp20-windows-edition/9N88HSBP6RJ8?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Moving Out</i> (<a href="https://www.xbox.com/games/store/moving-out/9N9H593X8SVP?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>MUSYNX </i>(<a href="https://www.xbox.com/games/store/the-musynx/9NQ18G93XQWK?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Nova-Life: Amboise </i>(<a href="https://store.steampowered.com/app/885570?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Observer System Redux </i>(<a href="https://www.xbox.com/games/store/observer-system-redux/9PB3TP3MT2Q0?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Pathologic 2</i> (<a href="https://www.xbox.com/games/store/pathologic-2/9PHS5Q7KQMJM?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>The Pedestrian </i>(<a href="https://www.xbox.com/games/store/the-pedestrian/9NTX07HR22TG?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Primal Carnage Extinction </i>(<a href="https://store.steampowered.com/app/321360?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Recompile </i>(<a href="https://www.xbox.com/games/store/recompile/9PDRJWHBSK88?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>RESEARCH and DESTROY </i>(<a href="https://www.xbox.com/games/store/research-and-destroy/9NNZJ389GSW2?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>RIDE 5 </i>(<a href="https://www.epicgames.com/store/p/ride-5?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Sable </i>(<a href="https://www.xbox.com/games/store/sable/9MZ4V4RG0W81?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>The Smurfs 2 &#8211; The Prisoner of the Green Stone </i>(<a href="https://store.steampowered.com/app/2397500?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>SpellForce 3: Soul Harvest </i>(<a href="https://www.xbox.com/games/store/spellforce-3-soul-harvest/9PC58LJXK3RM?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Tainted Grail: Conquest </i>(<a href="https://www.xbox.com/games/store/tainted-grail-conquest/9MZGGWHPKQ4C?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Terminator: Dark Fate &#8211; Defiance </i>(<a href="https://store.steampowered.com/app/1839950?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Tintin Reporter &#8211; Cigars of the Pharaoh </i>(<a href="https://store.steampowered.com/app/2125090?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Universe Sandbox </i>(<a href="https://store.steampowered.com/app/230290?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Warhammer 40,000: Rogue Trader </i>(<a href="https://store.steampowered.com/app/2186680?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>World War Z: Aftermath </i>(<a href="https://www.xbox.com/games/store/world-war-z/9N015DFDMVK6?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Worms Rumble </i>(<a href="https://www.xbox.com/games/store/worms-rumble/9pcpd8cgkr4l?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
<li><i>Worms W.M.D </i>(<a href="https://www.xbox.com/games/store/worms-wmd/9NVRZZJ4NG99?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on the Microsoft Store)</li>
</ul>
<h2><b>Nicely Done in November</b></h2>
<p>On top of the 54 games announced in October, an additional 23 joined the cloud last month, including this week’s additions: <i>Astrea: Six-Sided Oracles, Galactic Civilizations IV, Halls of Torment, Kona II: Brume, Laika: Aged Through Blood (Epic Games Store), Pillars of Eternity</i> and <i>SteamWorld Build.</i></p>
<ul>
<li><i>Car Mechanic Simulator 2021 </i>(<a href="https://www.xbox.com/games/store/car-mechanic-simulator-2021/9NH019ZFFHTV?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Chivalry 2 </i>(<a href="https://www.xbox.com/games/store/chivalry-2/9N7CJX93ZGWN?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Disney Dreamlight Valley</i> (<a href="https://www.xbox.com/games/store/disney-dreamlight-valley/9NSF0BGH8D86?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Dungeons 4</i> (<a href="https://www.epicgames.com/store/p/dungeons-4-595454?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Hello Neighbor 2</i> (<a href="https://www.xbox.com/games/store/hello-neighbor-2/9N961B11FJ4W?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>The Invincible </i>(<a href="https://www.epicgames.com/store/p/the-invincible?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>KarmaZoo </i>(New release on <a href="https://store.steampowered.com/app/1661630?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, Nov. 14)</li>
<li><i>Planet of Lana </i>(<a href="https://www.xbox.com/games/store/planet-of-lana/9MXK2RSQJQND?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Q.U.B.E. 10th Anniversary </i>(<a href="https://www.epicgames.com/store/p/qube-10th-anniversary-59e999?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>RoboCop: Rogue City </i>(New release on <a href="https://www.epicgames.com/store/p/robocop-rogue-city?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Roboquest </i>(<a href="https://www.xbox.com/games/store/roboquest-game-preview/9p47s7njgwzl?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Rune Factory 4 Special </i>(<a href="https://www.xbox.com/games/store/rune-factory-4-special---windows-edition/9N73PLHJN878?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a> and available on PC Game Pass)</li>
<li><i>Saints Row IV: Re-Elected </i>(<a href="https://www.xbox.com/games/store/saints-row-iv-re-elected/9NFVLZQDZHKW?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>State of Decay: Year-One Survival Edition</i> (<a href="https://store.steampowered.com/app/329430?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Supraland: Six Inches Under </i>(<a href="https://www.xbox.com/games/store/supraland-six-inches-under/9P5RS5065835?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Turnip Boy Commits Tax Evasion </i>(<a href="https://www.xbox.com/games/store/turnip-boy-commits-tax-evasion/9N0T8V0R7MBC?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
</ul>
<p><i>Veiled Experts</i> will no longer be coming to the service due to the closure of its live services, and <i>Spirttea </i>(PC Game Pass) didn’t make it to GeForce NOW in November due to technical issues. Stay tuned to GFN Thursday for future updates.</p>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">Twitter</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">[𝘐𝘕𝘊𝘖𝘔𝘐𝘕𝘎 𝘊𝘈𝘓𝘓] <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f4f1.png" alt="📱" class="wp-smiley" style="height: 1em; max-height: 1em;" /><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f440.png" alt="👀" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1729908078911320204?ref_src=twsrc%5Etfw">November 29, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Nov_30.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Nov_30-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[‘Call of Duty’ Comes to GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Embracing Transformation: AWS and NVIDIA Forge Ahead in Generative AI and Cloud Innovation</title>
		<link>https://blogs.nvidia.com/blog/aws-nvidia/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Tue, 28 Nov 2023 19:28:06 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[Supercomputing]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68436</guid>

					<description><![CDATA[Amazon Web Services and NVIDIA will bring the latest generative AI technologies to enterprises worldwide. Combining AI and cloud computing, NVIDIA founder and CEO Jensen Huang joined AWS CEO Adam Selipsky Tuesday on stage at AWS re:Invent 2023 at the Venetian Expo Center in Las Vegas. Selipsky said he was “thrilled” to announce the expansion <a class="read-more" href="https://blogs.nvidia.com/blog/aws-nvidia/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Amazon Web Services and NVIDIA will bring the latest generative AI technologies to enterprises worldwide.</p>
<p>Combining AI and cloud computing, NVIDIA founder and CEO Jensen Huang joined AWS CEO Adam Selipsky Tuesday on stage at AWS re:Invent 2023 at the Venetian Expo Center in Las Vegas.</p>
<p>Selipsky said he was “thrilled” to announce the expansion of the partnership between AWS and NVIDIA with more offerings that will deliver advanced graphics, machine learning and generative AI infrastructure.</p>
<p>The two announced that AWS will be the first cloud provider to adopt the latest <a href="https://developer.nvidia.com/blog/one-giant-superchip-for-llms-recommenders-and-gnns-introducing-nvidia-gh200-nvl32/">NVIDIA GH200 NVL32 Grace Hopper Superchip</a> with new multi-node NVLink technology, that AWS is bringing <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a> to AWS, and that AWS has integrated some of NVIDIA’s most popular software libraries.</p>
<p>Huang started the conversation by highlighting the integration of key NVIDIA libraries with AWS, encompassing a range from <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> to <a href="https://developer.nvidia.com/cuquantum-sdk">cuQuantum</a> to <a href="https://blogs.nvidia.com/blog/bionemo-on-aws-generative-ai-drug-discovery/">BioNeMo</a>, catering to domains like data processing, quantum computing and digital biology.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-68437" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide1.png" alt="" width="2048" height="1152" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide1.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide1-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide1-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide1-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide1-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide1-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide1-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide1-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide1-1280x720.png 1280w" sizes="(max-width: 2048px) 100vw, 2048px" /></p>
<p>The partnership opens AWS to millions of developers and the nearly 40,000 companies who are using these libraries, Huang said, adding that it’s great to see AWS expand its cloud instance offerings to include NVIDIA’s new L4, L40S and, soon, H200 GPUs.</p>
<p>Selipsky then introduced the AWS debut of the NVIDIA GH200 Grace Hopper Superchip, a significant advancement in cloud computing, and prompted Huang for further details.</p>
<p>“Grace Hopper, which is GH200, connects two revolutionary processors together in a really unique way,” Huang said. He explained that the GH200 connects NVIDIA’s Grace Arm CPU with its H200 GPU using a chip-to-chip interconnect called NVLink, at an astonishing one terabyte per second.</p>
<p>Each processor has direct access to the high-performance HBM and efficient LPDDR5X memory. This configuration results in 4 petaflops of processing power and 600GB of memory for each superchip.</p>
<p>AWS and NVIDIA connect 32 Grace Hopper Superchips in each rack using a new NVLink switch. Each 32 GH200 NVLink-connected node can be a single Amazon EC2 instance. When these are integrated with AWS Nitro and EFA networking, customers can connect GH200 NVL32 instances to scale to thousands of GH200 Superchips</p>
<p>“With AWS Nitro, that becomes basically one giant virtual GPU instance,” Huang said.</p>
<p>The combination of AWS expertise in highly scalable cloud computing plus NVIDIA innovation with Grace Hopper will make this an amazing platform that delivers the highest performance for complex generative AI workloads, Huang said.</p>
<p>&#8220;It&#8217;s great to see the infrastructure, but it extends to the software, the services and all the other workflows that they have,&#8221; Selipsky said, introducing NVIDIA DGX Cloud on AWS.</p>
<p>This partnership will bring about the first DGX Cloud AI supercomputer powered by the GH200 Superchips, demonstrating the power of AWS’s cloud infrastructure and NVIDIA’s AI expertise.</p>
<p>Following up, Huang announced that this new DGX Cloud supercomputer design in AWS, codenamed Project Ceiba, will serve as NVIDIA’s newest AI supercomputer as well, for its own AI research and development.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-68440" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide2.png" alt="" width="3840" height="2160" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide2.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide2-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide2-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide2-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide2-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide2-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide2-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide2-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Slide2-1280x720.png 1280w" sizes="(max-width: 3840px) 100vw, 3840px" /><br />
Named after the majestic Amazonian Ceiba tree, the Project Ceiba DGX Cloud cluster incorporates 16,384 GH200 Superchips to achieve 65 exaflops of AI processing power, Huang said.</p>
<p>Ceiba will be the world’s first GH200 NVL32 AI supercomputer built and the newest AI supercomputer in NVIDIA DGX Cloud, Huang said.</p>
<p>Huang described Project Ceiba AI supercomputer as “utterly incredible,” saying it will be able to reduce the training time of the largest language models by half.</p>
<p>NVIDIA’s AI engineering teams will use this new supercomputer in DGX Cloud to advance AI for graphics, LLMs, image/video/3D generation, digital biology, robotics, self-driving cars, <a href="https://www.nvidia.com/en-us/high-performance-computing/earth-2/">Earth-2 climate prediction</a> and more, Huang said.</p>
<p>“DGX is NVIDIA’s cloud AI factory,” Huang said, noting that AI is now key to doing NVIDIA’s own work in everything from computer graphics to creating digital biology models to robotics to climate simulation and modeling.</p>
<p>“DGX Cloud is also our AI factory to work with enterprise customers to build custom AI models,” Huang said. “They bring data and domain expertise; we bring AI technology and infrastructure.”</p>
<p>In addition, Huang also announced that AWS will be bringing four Amazon EC2 instances based on the NVIDIA GH200 NVL, H200, L40S, L4 GPUs, coming to market early next year.</p>
<p>Selipsky wrapped up the conversation by announcing that GH200-based instances and DGX Cloud will be available on AWS in the coming year.<br />
<b><br />
</b><i>You can catch the discussion and Selipsky’s entire keynote on AWS’s YouTube channel. </i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/AWS-NVIDIA.jpg"
			type="image/jpeg"
			width="1920"
			height="1098"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/AWS-NVIDIA-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Embracing Transformation: AWS and NVIDIA Forge Ahead in Generative AI and Cloud Innovation]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA BioNeMo Enables Generative AI for Drug Discovery on AWS</title>
		<link>https://blogs.nvidia.com/blog/bionemo-on-aws-generative-ai-drug-discovery/</link>
		
		<dc:creator><![CDATA[Kimberly Powell]]></dc:creator>
		<pubDate>Tue, 28 Nov 2023 17:21:33 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Genomics]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[NVIDIA Clara]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68361</guid>

					<description><![CDATA[Researchers and developers at leading pharmaceutical and techbio companies can now easily deploy NVIDIA Clara software and services for accelerated healthcare through Amazon Web Services. Announced today at AWS re:Invent, the initiative gives healthcare and life sciences developers using AWS cloud resources the flexibility to integrate NVIDIA-accelerated offerings such as NVIDIA BioNeMo — a generative <a class="read-more" href="https://blogs.nvidia.com/blog/bionemo-on-aws-generative-ai-drug-discovery/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Researchers and developers at leading pharmaceutical and techbio companies can now easily deploy <a href="https://aws.amazon.com/nvidia/hcls/" target="_blank" rel="noopener">NVIDIA Clara software and services</a> for accelerated healthcare through Amazon Web Services.</p>
<p><a href="https://nvidianews.nvidia.com/news/aws-nvidia-strategic-collaboration-for-generative-ai">Announced today at AWS re:Invent</a>, the initiative gives healthcare and life sciences developers using AWS cloud resources the flexibility to integrate NVIDIA-accelerated offerings such as <a href="https://www.nvidia.com/en-gb/clara/bionemo/">NVIDIA BioNeMo</a> — a generative AI platform for drug discovery — coming to <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a> on AWS, and currently available via the AWS ParallelCluster cluster management tool for high performance computing and the Amazon SageMaker machine learning service.</p>
<p>Thousands of healthcare and life sciences companies globally use AWS. They will now be able to access BioNeMo to build or customize digital biology foundation models with proprietary data, scaling up model training and deployment using NVIDIA GPU-accelerated cloud servers on AWS.</p>
<p>Techbio innovators including <a href="https://www.alchemab.com/" target="_blank" rel="noopener">Alchemab Therapeutics</a>, <a href="https://www.basecamp-research.com/" target="_blank" rel="noopener">Basecamp Research</a>, <a href="https://www.characterbio.com/" target="_blank" rel="noopener">Character Biosciences</a>, <a href="https://www.evozyne.com/" target="_blank" rel="noopener">Evozyne</a>, <a href="https://www.etcembly.com/" target="_blank" rel="noopener">Etcembly</a> and <a href="https://labgeni.us/" target="_blank" rel="noopener">LabGenius</a> are among the AWS users already using BioNeMo for generative AI-accelerated drug discovery and development. This collaboration gives them more ways to rapidly scale up cloud computing resources for developing generative AI models trained on biomolecular data.</p>
<p>This announcement extends NVIDIA’s existing healthcare-focused offerings available on AWS — <a href="https://www.nvidia.com/en-us/clara/monai/">NVIDIA MONAI</a> for medical imaging workflows and <a href="https://www.nvidia.com/en-us/clara/parabricks/">NVIDIA Parabricks</a> for accelerated genomics.</p>
<h2><b>New to AWS: NVIDIA BioNeMo Advances Generative AI for Drug Discovery</b></h2>
<p><a href="https://www.nvidia.com/en-gb/gpu-cloud/bionemo/">BioNeMo</a> is a domain-specific framework for digital biology generative AI, including pretrained large language models (LLMs), data loaders and optimized training recipes that can help advance computer-aided drug discovery by speeding target identification, protein structure prediction and drug candidate screening.</p>
<p>Drug discovery teams can use their proprietary data to build or optimize models with BioNeMo and run them on cloud-based high performance computing clusters.</p>
<p>One of these models, ESM-2 — a powerful LLM that supports protein structure prediction —  achieves almost linear scaling on 256 NVIDIA H100 Tensor Core GPUs. Researchers can scale to 512 H100 GPUs to complete training in a few days instead of a month, the training time published in the original paper.</p>
<p>Developers can train ESM-2 at scale using checkpoints of 650 million or 3 billion parameters. Additional AI models supported in the BioNeMo training framework include small-molecule generative model MegaMolBART and protein sequence generation model ProtT5.</p>
<p>BioNeMo’s pretrained models and optimized training recipes — which are available using self-managed services like AWS ParallelCluster and Amazon ECS as well as integrated, managed services through NVIDIA DGX Cloud and Amazon SageMaker — can help R&amp;D teams build foundation models that can explore more drug candidates, optimize wet lab experimentation and find promising clinical candidates faster.</p>
<h2><b>Also Available on AWS: NVIDIA Clara for Medical Imaging and Genomics</b></h2>
<p>Project MONAI, cofounded and <a href="https://www.nvidia.com/en-us/clara/monai/">enterprise-supported by NVIDIA</a> to support medical imaging workflows, has been downloaded more than 1.8 million times and is available for deployment on AWS. Developers can harness their proprietary healthcare datasets already stored on AWS cloud resources to rapidly annotate and build AI models for medical imaging.</p>
<p>These models, trained on NVIDIA GPU-powered <a href="https://aws.amazon.com/ec2/pricing/" target="_blank" rel="noopener">Amazon EC2 instances</a>, can be used for interactive annotation and fine-tuning for segmentation, classification, registration and detection tasks in medical imaging. Developers can also harness MRI image synthesis models available in MONAI to augment training datasets.</p>
<p>To accelerate genomics pipelines, <a href="https://aws.amazon.com/marketplace/pp/prodview-apbngojlskcyq" target="_blank" rel="noopener">Parabricks</a> enables variant calling on a whole human genome in around 15 minutes, compared to a day on a CPU-only system. <a href="https://aws.amazon.com/blogs/hpc/getting-started-with-nvidia-parabricks-on-aws-batch-using-aws-cloudformation/" target="_blank" rel="noopener">On AWS</a>, developers can quickly scale up to process large amounts of genomic data across multiple GPU nodes.</p>
<p>More than a dozen <a href="https://aws.amazon.com/blogs/industries/easily-run-nvidia-parabricks-ready2run-workflows-on-amazon-omics/" target="_blank" rel="noopener">Parabricks workflows are available on</a> AWS HealthOmics as Ready2Run workflows, which enable customers to easily run pre-built pipelines.</p>
<p>Get started with <a href="https://aws.amazon.com/nvidia/hcls/" target="_blank" rel="noopener">NVIDIA Clara on AWS</a> to accelerate AI workflows for drug discovery, genomics and medical imaging.</p>
<p><i>Subscribe to </i><a href="https://www.nvidia.com/en-us/industries/healthcare-life-sciences/healthcare-news-sign-up/"><i>NVIDIA healthcare news</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/hc-corp-blog-aws23-bionemo-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/hc-corp-blog-aws23-bionemo-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA BioNeMo Enables Generative AI for Drug Discovery on AWS]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA GPUs on AWS to Offer 2x Simulation Leap in Omniverse Isaac Sim, Accelerating Smarter Robots</title>
		<link>https://blogs.nvidia.com/blog/gpu-aws-omniverse-isaac-sim-robots/</link>
		
		<dc:creator><![CDATA[Gerard Andrews]]></dc:creator>
		<pubDate>Tue, 28 Nov 2023 17:20:12 +0000</pubDate>
				<category><![CDATA[Autonomous Machines]]></category>
		<category><![CDATA[Corporate]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[NVIDIA Isaac Sim]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Synthetic Data Generation]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68341</guid>

					<description><![CDATA[Developing more intelligent robots in the cloud is about to get a speed multiplier. NVIDIA Isaac Sim and NVIDIA L40S GPUs are coming to Amazon Web Services, enabling developers to build and deploy accelerated robotics applications in the cloud. Isaac Sim, an extensible simulator for AI-enabled robots, is built on the NVIDIA Omniverse development platform <a class="read-more" href="https://blogs.nvidia.com/blog/gpu-aws-omniverse-isaac-sim-robots/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Developing more intelligent robots in the cloud is about to get a speed multiplier.</p>
<p><a href="https://developer.nvidia.com/isaac-sim">NVIDIA Isaac Sim</a> and <a href="https://www.nvidia.com/en-us/data-center/l40s/">NVIDIA L40S GPUs</a> are coming to Amazon Web Services, enabling developers to build and deploy accelerated robotics applications in the cloud. Isaac Sim, an extensible simulator for AI-enabled robots, is built on the <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> development platform for building and connecting <a href="https://www.nvidia.com/en-us/omniverse/usd/">OpenUSD</a> applications.</p>
<p>Combining powerful AI compute with graphics and media acceleration, the L40S GPU is built to power the next generation of data center workloads. Based on the Ada Lovelace architecture, the L40S enables ultrafast real-time rendering delivering up to a 3.8x performance leap for Omniverse compared with the previous generation, boosting engineering and robotics teams.</p>
<p>The generational leap in acceleration results in 2x faster performance than the A40 GPU across a broad set of robotic simulations tasks when using Isaac Sim.</p>
<p>L40S GPUs can also be harnessed for generative AI workloads, from fine-tuning large language models within a matter of hours, to real-time inferencing for text-to-image and chat applications.</p>
<p>New Amazon Machine Images (AMIs) on the NVIDIA L40S in AWS Marketplace will enable roboticists to easily access preconfigured virtual machines to operate Isaac Sim workloads.</p>
<p>Robotics development in simulation is speeding the process of deploying applications, turbocharging industries such as <a href="https://blogs.nvidia.com/blog/isaac-jetson-robotics/">retail</a>, <a href="https://blogs.nvidia.com/blog/isaac-soft-robotics-simulation/">food processing</a>, <a href="https://blogs.nvidia.com/blog/bmw-group-nvidia-omniverse/">manufacturing</a>, logistics and more.</p>
<p>Revenue from mobile robots in warehouses worldwide is expected to explode, more than tripling from $11.6 billion in 2023 to $42.2 billion by 2030, according to ABI Research.</p>
<p>Robotics systems have played an important role across fulfillment centers to help meet the demands of online shoppers and provide a better workplace for employees. Amazon Robotics has deployed more than 750,000 robots in its warehouses around the world to improve the experience for employees supporting package fulfillment and its customers.</p>
<p>“Simulation technology plays a critical role in how we develop, test and deploy our robots.” said Brian Basile, head of virtual systems at Amazon Robotics. “At Amazon Robotics we continue to increase the scale and complexity of our simulations. With the new AWS L40S offering we will push the boundaries of simulation, rendering and model training even further.”</p>
<h2><b>Accelerated Robotics Development With Isaac Sim</b></h2>
<p>Robotics systems can demand large datasets for precision operation in deployed applications. Gathering these datasets and testing them in the real world is time-consuming, costly and impractical.</p>
<p><a href="https://blogs.nvidia.com/blog/what-is-robotics-simulation/">Robotics simulation</a> drives the training and testing of AI-based robotic applications. With <a href="https://blogs.nvidia.com/blog/what-is-synthetic-data/">synthetic data</a>, simulations are enabling virtual advances like never before. Simulations can help verify, validate and optimize robot designs, systems and their algorithms before operation. It can also be used to optimize facility designs before construction or remodeling starts for maximum efficiencies, reducing costly manufacturing change orders.</p>
<p>Isaac Sim offers access to the latest robotics simulation tools and capabilities as well as cloud access, enabling teams to collaborate more effectively. Access to the <a href="https://developer.nvidia.com/omniverse/replicator">Omniverse Replicator</a> synthetic data generation engine in Isaac Sim allows machine learning engineers to build production-ready synthetic datasets for training robust deep learning perception models.</p>
<h2><b>Customer Adoption of Isaac Sim on AWS</b></h2>
<p>AWS early adopters tapping into the Isaac Sim platform include <a href="https://blogs.nvidia.com/blog/isaac-jetson-robotics/">Amazon Robotics</a>, <a href="https://blogs.nvidia.com/blog/isaac-soft-robotics-simulation/">Soft Robotics</a> and <a href="https://www.theorystudios.com/synthetic-data">Theory Studios</a>.</p>
<p>Amazon Robotics has begun using Omniverse to build digital twins for automating, optimizing and planning its autonomous warehouses in virtual environments before deploying them into the real world.</p>
<p>Using Isaac Sim for sensor emulation, Amazon Robotics will accelerate development of its <a href="https://www.youtube.com/watch?v=LUnZXBL_lqA">Proteus autonomous mobile robot</a>, improving it to help the online retail giant efficiently manage fulfillment.</p>
<p><i>Learn more about </i><a href="https://developer.nvidia.com/isaac-sim"><i>Isaac Sim</i></a><i>, powered by </i><a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>.</p>
<p>&nbsp;</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/AWS-reinvent-robotics-blog-key-visual.png"
			type="image/png"
			width="2048"
			height="1062"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/AWS-reinvent-robotics-blog-key-visual-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA GPUs on AWS to Offer 2x Simulation Leap in Omniverse Isaac Sim, Accelerating Smarter Robots]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Powers Training for Some of the Largest Amazon Titan Foundation Models</title>
		<link>https://blogs.nvidia.com/blog/nemo-amazon-titan/</link>
		
		<dc:creator><![CDATA[Nirmalya De]]></dc:creator>
		<pubDate>Tue, 28 Nov 2023 17:19:07 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cloud Services]]></category>
		<category><![CDATA[Customer Stories]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Parallel Computing]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68363</guid>

					<description><![CDATA[Everything about large language models is big — giant models train on massive datasets across thousands of NVIDIA GPUs. That can pose a lot of big challenges for companies pursuing generative AI. NVIDIA NeMo, a framework for building, customizing and running LLMs, helps overcome these challenges. A team of experienced scientists and developers at Amazon <a class="read-more" href="https://blogs.nvidia.com/blog/nemo-amazon-titan/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Everything about large language models is big — giant models train on massive datasets across thousands of NVIDIA GPUs.</p>
<p>That can pose a lot of big challenges for companies pursuing generative AI. <a href="https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/">NVIDIA NeMo</a>, a framework for building, customizing and running <a href="https://www.nvidia.com/en-us/glossary/data-science/large-language-models/">LLMs</a>, helps overcome these challenges.</p>
<p>A team of experienced scientists and developers at Amazon Web Services creating <a href="https://aws.amazon.com/bedrock/titan/">Amazon Titan</a> <a href="https://blogs.nvidia.com/blog/what-are-foundation-models/">foundation models</a> for <a href="https://aws.amazon.com/bedrock/">Amazon Bedrock</a>, a generative AI service for foundation models, has been using NVIDIA NeMo for over the past several months.</p>
<p>“One key reason for us to work with NeMo is that it is extensible, comes with optimizations that allow us to run with high GPU utilization while also enabling us to scale to larger clusters so we can train and deliver models to our customers faster,” said Leonard Lausen, a senior applied scientist at AWS.</p>
<p style="margin: 12.0pt 0in 12.0pt 0in;"><b>Think Big, Really Big</b></p>
<p>Parallelism techniques in NeMo enable efficient LLM training at scale. When coupled with the Elastic Fabric Adapter from AWS, it allowed the team to spread its LLM across many GPUs to accelerate training.</p>
<p>EFA provides AWS customers with an UltraCluster Networking infrastructure that can directly connect more than 10,000 GPUs and bypass the operating system and CPU using <a href="https://developer.nvidia.com/gpudirect">NVIDIA GPUDirect</a>.</p>
<p>The combination allowed the AWS scientists to deliver excellent model quality — something that’s not possible at scale when relying solely on data parallelism approaches.</p>
<h2><b>Framework Fits All Sizes</b></h2>
<p>“The flexibility of NeMo,” Lausen said, “allowed AWS to tailor the training software for the specifics of the new Titan model, datasets and infrastructure.”</p>
<p>AWS’s innovations include efficient streaming from Amazon Simple Storage Service (Amazon S3) to the GPU cluster. “It was easy to incorporate these improvements because NeMo builds upon popular libraries like PyTorch Lightning that standardize LLM training pipeline components,” Lausen said.</p>
<p>AWS and NVIDIA aim to infuse products like NVIDIA NeMo and services like Amazon Titan with lessons learned from their collaboration for the benefit of customers.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/Amazon-Titan-logo-KV.jpg"
			type="image/jpeg"
			width="1280"
			height="683"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/Amazon-Titan-logo-KV-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Powers Training for Some of the Largest Amazon Titan Foundation Models]]></media:title>
			<media:description type="html">Amazon Titan logo, a foundation model trained with NVIDIA NeMo</media:description>
			</media:content>
			</item>
		<item>
		<title>3D Artist Nourhan Ismail Brings Isometric Innovation ‘In the NVIDIA Studio’ With Adobe After Effects and Blender</title>
		<link>https://blogs.nvidia.com/blog/ismail-adobe-after-effects-blender/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 28 Nov 2023 14:00:44 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68394</guid>

					<description><![CDATA[This week’s talented In the NVIDIA Studio artist, Nourhan Ismail, created a literal NVIDIA studio.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. </i></p>
<p>This week’s talented <i>In the NVIDIA Studio</i> artist, Nourhan Ismail, created a literal NVIDIA studio.</p>
<p>Her piece, called <i>Creator by Day, Gamer by Night</i>, was crafted with the isometric art style and impressive graphical fidelity Ismail’s known for, rich with vibrant colors and playful details. It also captures her “work hard, play hard” mentality as a 3D artist, interior designer and game level designer.</p>
<p>The same art style is featured in the NVIDIA Studio Sessions YouTube miniseries led by Ismail, which provides step-by-step tutorials on how to create a low-poly bedroom, from inception to final render.</p>
<p><iframe loading="lazy" title="Creating Low Poly Bedroom in Blender w/ Nourhan Ismail" width="500" height="281" src="https://www.youtube.com/embed/videoseries?list=PL4w6jm6S2lzso-UjuP-cB0Nsv9NloOThB" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Facial Animations Made Easier</b></h2>
<p>Reallusion is the maker of <a href="https://www.reallusion.com/iclone/default.html">Reallusion iClone</a>, real-time 3D animation software built to produce professional animations for films and video games.</p>
<p>To expedite character animation workflows, the company recently launched its <a href="https://mocap.reallusion.com/iclone-motion-live-mocap/accuface.html?_gl=1*1qxpyqc*_ga*MzYwNDE5ODQ4LjE3MDA2MDg2MDk.*_ga_Q3FS71VPKC*MTcwMDYwODYwOC4xLjEuMTcwMDYxMTQzNS40Mi4wLjA.">AccuFACE plug-in</a>, which accurately captures facial expressions from webcams and conventional video files, without the need for expensive, specialized equipment.</p>
<p><iframe loading="lazy" title="AccuFACE - Video-based AI Facial Mocap | Live from Webcam or Recorded Video | iClone 8" width="500" height="281" src="https://www.youtube.com/embed/WCzHLSss_xU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>The <a href="https://developer.nvidia.com/maxine">NVIDIA Maxine</a> software development platform, the foundational technology behind the revolutionary <a href="https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/">NVIDIA Broadcast app</a>, powers this incredible capability by weighing output and analyzing facial expressions and blendshapes to predict facial mesh animations.</p>
<p>From there, the AccuFACE plug-in converts this data into facial mesh assets for creators to apply seamlessly. It also fine-tunes lip and tongue articulation using proprietary AccuLIPS technology.</p>
<p><iframe loading="lazy" title="Advanced Facial Animations With OpenUSD and AI" width="500" height="281" src="https://www.youtube.com/embed/XwtzEU91oAI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Download the <a href="https://mocap.reallusion.com/iclone-motion-live-mocap/accuface.html">plug-in</a> today, available to creators with <a href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA RTX</a> GPUs.</p>
<h2><b>Turning Pain Into Beauty</b></h2>
<p>Ismail’s creative journey began at age four as a form of escape from the armed conflict occurring in Syria, her homeland. During that time, Ismail’s family faced many difficulties, including the loss of their home.</p>
<p>In the aftermath, she looked to her father, an accomplished artist and fashion designer, as a source of inspiration.</p>
<p>“His encouragement propelled me to showcase the pinnacle of my abilities, reminding me that art has the power to transform pain into beauty,” she said.</p>
<p>That encouragement has guided and fueled Ismail’s creative journey, eventually giving rise to her signature, single-room isometric style, an homage to the power of resilience and finding beauty in adversity.</p>
<figure id="attachment_68401" aria-describedby="caption-attachment-68401" style="width: 500px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68401" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w-500x500.png" alt="" width="500" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w-500x500.png 500w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w-400x400.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w-150x150.png 150w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w-768x768.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w-450x450.png 450w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w-215x215.png 215w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w-100x100.png 100w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-living-room-1280w.png 1280w" sizes="(max-width: 500px) 100vw, 500px" /></a><figcaption id="caption-attachment-68401" class="wp-caption-text">Warm and homey.</figcaption></figure>
<p>“Starting with a single room, I delve into interior design, crafting spaces that reflect the comfort and joy I yearned for during challenging times,” she said. “To me, overcoming adversity proves that even from the harshest circumstances, beauty can emerge.”</p>
<p>Ismail started as a self-taught 3D artist, driven by a passion to learn the intricacies of creating digital masterpieces.</p>
<p>“Posting my works became a personal gauge of improvement — not for validation, but as a record of my learning curve,” she said.</p>
<figure id="attachment_68404" aria-describedby="caption-attachment-68404" style="width: 500px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68404" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w-500x500.png" alt="" width="500" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w-500x500.png 500w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w-400x400.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w-150x150.png 150w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w-768x768.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w-450x450.png 450w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w-215x215.png 215w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w-100x100.png 100w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-bathroom-1280w.png 1280w" sizes="(max-width: 500px) 100vw, 500px" /></a><figcaption id="caption-attachment-68404" class="wp-caption-text">Beautifully conceived, masterfully executed.</figcaption></figure>
<p>Each of Ismail’s pieces is a testament to her evolving skills, dedication and love for sharing her craft, especially with her father.</p>
<p>In fact, she dedicated her first isometric house to her father. “That was the happiest moment, to create something inspiring and make someone happy,” she said.</p>
<h2><b>Isometric Art</b></h2>
<p>Ismail first collects reference material on Adobe Behance to gain inspiration on ways to mix different art styles.</p>
<p>She then opens Blender and starts sketching in 3D. Blender Cycles’ RTX-accelerated OptiX ray tracing, powered by her <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3080-3080ti/">GeForce RTX 3080 Ti GPU</a>, ensured smooth viewport movement.</p>
<figure id="attachment_68422" aria-describedby="caption-attachment-68422" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-scaled.jpg"><img loading="lazy" decoding="async" class="wp-image-68422 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-672x378.jpg" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-light-mode-1280w-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68422" class="wp-caption-text">A gorgeous work in progress.</figcaption></figure>
<p>While the models are still fairly rudimentary, Ismail calculates the angles that light should be coming in from.</p>
<p>“Lighting is an emotional element,” she said. “The lighting of each piece evokes different emotions and a certain idiosyncratic introspectiveness, making the experience unique to each person.”</p>
<figure id="attachment_68407" aria-describedby="caption-attachment-68407" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68407" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-studio-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68407" class="wp-caption-text">The NVIDIA Studio has NVIDIA Canvas!</figcaption></figure>
<p>Her trick is to regularly switch between rich, colorful scenes and plain color models to measure the emotional weight and visual impact. She either creates the custom textures herself or downloads premade ones online when on a time crunch.</p>
<figure id="attachment_68410" aria-describedby="caption-attachment-68410" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68410" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-desk-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68410" class="wp-caption-text">Ismail’s incredible detail on full display.</figcaption></figure>
<p>Then, she plays with camera angles to analyze depth shadows and lighting, setting up animations and sequence shots in Blender. There, Blender Cycles’ RTX-accelerated OptiX ray tracing delivered seamless viewport movement.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-68394-6" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-nvidia-camera-animation-1280w.mp4?_=6" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-nvidia-camera-animation-1280w.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-nvidia-camera-animation-1280w.mp4</a></video></div>
<p>&nbsp;</p>
<p>Final touch-ups are done in post-production in Adobe After Effects. Over 30 GPU-accelerated effects sped the process, allowed Ismail to complete the project with time to spare.</p>
<figure id="attachment_68416" aria-describedby="caption-attachment-68416" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68416" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-dark-mode-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68416" class="wp-caption-text">“Creator by Day, Gamer by Night” in dark mode.</figcaption></figure>
<p>“There will always be hard times, so never give up and keep believing in yourself,” Ismail encourages content creators.</p>
<figure id="attachment_68419" aria-describedby="caption-attachment-68419" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68419" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w-672x252.png" alt="" width="672" height="252" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w-672x252.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w-400x150.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w-768x288.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w-842x316.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w-406x152.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w-188x71.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-nourhan-ismail-wk85-artist-feature-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68419" class="wp-caption-text">Digital 3D artist Nourhan Ismail.</figcaption></figure>
<p>Check out Ismail’s <a href="https://www.instagram.com/noah.pabllooll/">Instagram</a> for more spectacular isometric art.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>Twitter</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-nourhan-ismail-wk85-nvidia-camera-animation-1280w.mp4" length="1210576" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/nv-blog-header-preview-1280x680-3.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/nv-blog-header-preview-1280x680-3-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[3D Artist Nourhan Ismail Brings Isometric Innovation ‘In the NVIDIA Studio’ With Adobe After Effects and Blender]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Medical Imaging AI Made Easier: NVIDIA Offers MONAI as Hosted Cloud Service</title>
		<link>https://blogs.nvidia.com/blog/monai-cloud-apis-rsna/</link>
		
		<dc:creator><![CDATA[Prerna Dogra]]></dc:creator>
		<pubDate>Sun, 26 Nov 2023 14:00:26 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Cloud Services]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68260</guid>

					<description><![CDATA[NVIDIA today launched a cloud service for medical imaging AI to further streamline and accelerate the creation of ground-truth data and training of specialized AI models through fully managed, cloud-based application programming interfaces. NVIDIA MONAI cloud APIs — announced at the annual meeting of RSNA, the Radiological Society of North America, taking place this week <a class="read-more" href="https://blogs.nvidia.com/blog/monai-cloud-apis-rsna/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>NVIDIA today launched a cloud service for medical imaging AI to further streamline and accelerate the creation of ground-truth data and training of specialized AI models through fully managed, cloud-based application programming interfaces.</p>
<p><a href="https://www.nvidia.com/en-us/clara/monai/">NVIDIA MONAI</a> cloud APIs — announced at the annual meeting of RSNA, the Radiological Society of North America, taking place this week in Chicago — provide an expedited path for developers and platform providers to integrate AI into their medical imaging offerings using pretrained foundation models and AI workflows for enterprises. The APIs are built on the open-source MONAI project founded by NVIDIA and King’s College London.</p>
<p>Medical imaging is critical across healthcare, making up approximately <a href="https://arxiv.org/pdf/2008.09104.pdf" target="_blank" rel="noopener">90% of healthcare data</a>. It’s used by radiologists and clinicians to do screening, diagnosis and intervention, by biopharma researchers to evaluate how clinical trial patients respond to new drugs and by medical device makers to provide real-time decision support.</p>
<p>The scale of work across each of these areas requires a medical imaging-specific AI factory — an enterprise-grade platform that delivers large-scale data management, creates ground-truth annotations, accelerates model development and establishes seamless AI application deployment.</p>
<p>With NVIDIA MONAI cloud APIs, solution providers can more easily integrate AI into their medical imaging platforms, enabling them to provide supercharged tools for radiologists, researchers and clinical trial teams to build domain-specialized AI factories. The APIs are <a href="https://developer.nvidia.com/nvidia-monai-cloud-api-early-access-program">available in early access</a> through the <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a> AI supercomputing service.</p>
<p>The NVIDIA MONAI cloud API is integrated into Flywheel, a leading medical imaging data and AI platform that supports end-to-end workflows for AI development. Developers at medical image annotation companies including <a href="https://redbrickai.com/" target="_blank" rel="noopener">RedBrick AI</a> and at machine learning operations (MLOps) platform providers including <a href="https://www.dataiku.com/" target="_blank" rel="noopener">Dataiku</a> are poised to integrate NVIDIA MONAI cloud APIs into their offerings.</p>
<h2><b>Easy-to-Deploy Annotation and Training for Medical Imaging</b></h2>
<p>Building efficient and cost-effective AI solutions requires a robust, domain-specialized development foundation that includes full-stack optimizations for software, scalable multi-node systems and state-of-the-art research. It also requires high-quality ground-truth data — which can be arduous and time-consuming to gather, particularly for 3D medical images that require a high level of expertise to annotate.</p>
<p>NVIDIA MONAI cloud APIs feature interactive annotation powered by the VISTA-3D (Vision Imaging Segmentation and Annotation) foundation model. It’s purpose-built for continuous learning, a capability that improves AI model performance based on user feedback and new data.</p>
<p>Trained on a dataset of annotated images from 3D CT scans from more than 4,000 patients, spanning various diseases and parts of the body, VISTA-3D accelerates the creation of 3D segmentation masks for medical image analysis. With continuous learning, the AI model’s annotation quality improves over time.</p>
<p>To further accelerate AI training, this release includes APIs that make it seamless to build custom models based on MONAI pretrained models. NVIDIA MONAI cloud APIs also include Auto3DSeg, which automates hyperparameter tuning and AI model selection for a given 3D segmentation task, simplifying the model development process.</p>
<p>NVIDIA researchers recently won four challenges at the MICCAI medical imaging conference using Auto3DSeg. These included AI models to analyze 3D CT scans of the kidneys and heart, brain MRIs and 3D ultrasounds of the heart.</p>
<h2><b>Solutions Providers, Platform Builders Embrace NVIDIA MONAI Cloud APIs</b></h2>
<p>Medical imaging solution providers and machine learning platforms are using NVIDIA MONAI cloud APIs to deliver critically valuable AI insights to accelerate their customers’ work.</p>
<p>Flywheel has integrated MONAI through <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> and is now offering NVIDIA MONAI cloud APIs to accelerate medical image curation, labeling analysis and training. The Minneapolis-based company’s centralized, cloud-based platform powers biopharma companies, life science organizations, healthcare providers and academic medical centers to identify, curate and train medical imaging data for the development of trustworthy AI.</p>
<p>“NVIDIA MONAI cloud APIs lower the cost of building high-quality AI models for radiology, disease research and the evaluation of clinical trial data,” said Dan Marcus, chief scientific officer at Flywheel. “With the addition of cloud APIs for interactive annotation and automated segmentation, customers of our medical imaging AI platform can accelerate AI model development to more quickly deliver innovative solutions.”</p>
<p>Annotation and viewer solution providers, including Redbrick AI, <a href="https://radicalimaging.com/" target="_blank" rel="noopener">Radical Imaging</a> and <a href="https://www.v7labs.com/" target="_blank" rel="noopener">V7 Labs</a> will use NVIDIA MONAI cloud APIs to bring AI-assisted annotation and training capabilities to market faster, without having to host and manage the AI infrastructure on their own. Medical data labeling company <a href="https://centaurlabs.com/" target="_blank" rel="noopener">Centaur Labs</a> is also exploring MONAI cloud APIs to accelerate medical image annotation.</p>
<p>RedBrick AI is integrating the VISTA-3D model available through NVIDIA MONAI cloud APIs to deliver interactive cloud annotation for its medical device customers that support distributed teams of clinicians.</p>
<p>“VISTA-3D allows our clients to rapidly build models across different modalities and conditions,” said Shivam Sharma, CEO of RedBrick AI. “The foundation model is generalizable, making it easy to fine-tune for various clinical applications with accurate, reliable segmentation results.”</p>
<p>To streamline enterprise AI model development, MLOps platform builders including Dataiku, ClearML and Weight &amp; Biases are also investigating the use of NVIDIA MONAI cloud APIs.</p>
<p>Dataiku plans to integrate NVIDIA MONAI cloud APIs to further simplify AI model creation for medical imaging applications.</p>
<p>“With NVIDIA MONAI cloud APIs, Dataiku users would be able to easily use Auto3DSeg, a low-code option to accelerate the development of state-of-the-art segmentation models, through Dataiku’s web interface connected to an NVIDIA-hosted, GPU-accelerated service,” said Kelci Miclaus, global head of AI health and life sciences solutions at Dataiku. “This democratizes AI in biomedical imaging by extending the power to create and apply AI-driven workflows to both data and domain experts.”</p>
<p>Join the medical imaging innovators accelerating AI development with NVIDIA MONAI cloud APIs by signing up for <a href="https://developer.nvidia.com/nvidia-monai-cloud-api-early-access-program/join">early access</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/hc-corp-blog-monai-services-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/hc-corp-blog-monai-services-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Medical Imaging AI Made Easier: NVIDIA Offers MONAI as Hosted Cloud Service]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Hungry for Gaming: 18 New Games to Join GeForce NOW</title>
		<link>https://blogs.nvidia.com/blog/hungry-for-gaming-18-new-games-to-join-geforce-now/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 23 Nov 2023 14:00:44 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68348</guid>

					<description><![CDATA[GeForce NOW is bringing 18 new games to the cloud this week, part of a gratitude-filled GFN Thursday. A collaboration between Chromebook Plus, CD PROJEKT RED and GeForce NOW brought an immersive 3D activation to Times Square over the weekend, containing a hidden Easter egg for Cyberpunk 2077 players. Plus, this holiday season, give the <a class="read-more" href="https://blogs.nvidia.com/blog/hungry-for-gaming-18-new-games-to-join-geforce-now/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> is bringing 18 new games to the cloud this week, part of a gratitude-filled GFN Thursday.</p>
<p>A collaboration between Chromebook Plus, CD PROJEKT RED and GeForce NOW brought an immersive 3D activation to Times Square over the weekend, containing a hidden Easter egg for <i>Cyberpunk 2077</i> players.</p>
<p>Plus, this holiday season, give the gift of high-performance cloud gaming with <a href="https://blogs.nvidia.com/blog/geforce-now-thursday-nov-16/">a free, three-month PC Game Pass subscription</a> included with a six-month GeForce NOW <a href="https://www.nvidia.com/en-us/geforce-now/memberships/">Ultimate membership</a>.</p>
<h2><b>Eye Spy</b></h2>
<figure id="attachment_68356" aria-describedby="caption-attachment-68356" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-68356" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-672x378.png" alt="Chromebook Plus activation with GeForce NOW and Cyberpunk, Times Square" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chromebook_Plus_GeForceNOW_Time_Square_Cyberpunk2077-1280x720.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68356" class="wp-caption-text"><em>Crack the code now with Chromebook Plus, GeForce NOW and “Cyberpunk 2077.”</em></figcaption></figure>
<p>Times Square was transformed into a futuristic dystopia last weekend by a stunning 3D <i>Cyberpunk 2077</i> activation. The immersive display showcased the power of GeForce NOW on a Chromebook Plus, enabling gamers to stream thousands of titles from popular digital gaming stores from the cloud, right out of the box.</p>
<p><iframe loading="lazy" title="Chromebook Plus presents Cyberpunk 2077 x GeForce NOW" width="500" height="281" src="https://www.youtube.com/embed/G_oqD3ytjVU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Long-time <i>Cyberpunk 2077 </i>fans were also challenged to try their hand at spotting a code hidden in the activation — the latest hint in a long line of clues needed to solve a riddle that has had players guessing for the past three years.</p>
<p>Chromebook owners with an <a href="http://geforcenow.com">Ultimate or Priority membership</a> can explore <i>Cyberpunk 2077</i>’s Night City with <a href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA RTX ON</a> for the most immersive gaming experience, including the “Phantom Liberty” expansion and 2.0 update. Google and NVIDIA are offering all Chromebook owners <a href="https://www.google.com/intl/en_us/chromebook/perks/">three free months of a GeForce NOW Priority membership</a> to get gamers started.</p>
<p>And those interested in leveling up to the highest-performing tier can get three free months of a GeForce NOW Ultimate membership with the purchase of a Cloud Gaming Chromebook. Find more details on how to redeem the offer on the <a href="https://www.google.com/intl/en_us/chromebook/perks/">Chromebook Perks page</a>.</p>
<h2><b>Grateful for Great Games</b></h2>
<figure id="attachment_68353" aria-describedby="caption-attachment-68353" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-68353" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-672x378.jpg" alt="Chivalry 2 on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/GFN_Thursday-Chivalry_2-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68353" class="wp-caption-text"><em>That’s one way to carve a turkey.</em></figcaption></figure>
<p>Get the weekend started with the new weekly games list:<i></i></p>
<ul>
<li><i>Breathedge</i> (<a href="https://www.xbox.com/games/store/breathedge/9PHJSGJNX37S?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Bridge Constructor: The Walking Dead </i>(<a href="https://www.xbox.com/games/store/bridge-constructor-the-walking-dead/9P1LWFXNQVQ0?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Bus Simulator 21 </i>(<a href="https://www.xbox.com/games/store/bus-simulator-21-next-stop-gold-edition/9PFBJC0VVTMB?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Chivalry 2 </i>(<a href="https://www.xbox.com/games/store/chivalry-2/9N7CJX93ZGWN?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Dungeons 4</i> (<a href="https://www.epicgames.com/store/p/dungeons-4-595454?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Hexarchy</i> (<a href="https://store.steampowered.com/app/1356810?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Hearts of Iron IV</i> (<a href="https://www.xbox.com/games/store/hearts-of-iron-iv/9NF6WPNS1S73?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>I Am Future </i>(<a href="https://www.epicgames.com/store/p/i-am-future-cozy-apocalypse-survival-6b452c?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Imagine Earth </i>(<a href="https://www.xbox.com/games/store/imagine-earth/9NPLW3TFSVH0?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>The Invincible </i>(<a href="https://www.epicgames.com/store/p/the-invincible?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
<li><i>Land of the Vikings </i>(<a href="https://store.steampowered.com/app/1981570?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Saints Row IV: Re-Elected </i>(<a href="https://www.xbox.com/games/store/saints-row-iv-re-elected/9NFVLZQDZHKW?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>SHENZHEN I/O </i>(<a href="https://www.xbox.com/games/store/shenzhen-io/9P1JHJ127HR4?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Supraland: Six Inches Under </i>(<a href="https://www.xbox.com/games/store/supraland-six-inches-under/9P5RS5065835?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>The Surge 2</i> (<a href="https://www.xbox.com/games/store/the-surge-2-premium-edition/9NK73WHQZKDS?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Thymesia </i>(<a href="https://www.xbox.com/games/store/thymesia/9N68F8TM7TKW?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>Tropico 6</i> (<a href="https://www.xbox.com/games/store/tropico-6/9N2VDJVMFKQ9?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
<li><i>West of Dead</i> (<a href="https://www.xbox.com/games/store/west-of-dead-path-of-the-crow-edition/9NSXQS17N797?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on Microsoft Store)</li>
</ul>
<p>What are you looking forward to streaming? Let us know on <a href="https://www.twitter.com/nvidiagfn">Twitter</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">tell us a device you have that you&#39;re grateful for <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/2601.png" alt="☁" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>bonus points for pictures</p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1727371365789934020?ref_src=twsrc%5Etfw">November 22, 2023</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/gfn-thursday-11-23-nv-blog-1280x680-no-cta.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/gfn-thursday-11-23-nv-blog-1280x680-no-cta-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Hungry for Gaming: 18 New Games to Join GeForce NOW]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Teenage Dream: Aspiring Computer Science Major Experiences NVIDIA Life With Make-A-Wish Visit</title>
		<link>https://blogs.nvidia.com/blog/nvidia-life-make-a-wish/</link>
		
		<dc:creator><![CDATA[Samantha Zee]]></dc:creator>
		<pubDate>Wed, 22 Nov 2023 16:00:26 +0000</pubDate>
				<category><![CDATA[NVIDIA Life]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68301</guid>

					<description><![CDATA[A calendar packed with meetings, calls and lab visits may sound like a typical workday for many — but for Luca Lofranco, whose greatest wish was to experience what it’s like to work at NVIDIA, it was a dream come true. Eighteen-year-old Lofranco recently traveled from his hometown near Toronto, Canada, to spend the day <a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-life-make-a-wish/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>A calendar packed with meetings, calls and lab visits may sound like a typical workday for many — but for Luca Lofranco, whose greatest wish was to experience what it’s like to work at NVIDIA, it was a dream come true.</p>
<p>Eighteen-year-old Lofranco recently traveled from his hometown near Toronto, Canada, to spend the day at our Santa Clara campus, supported by Make-A-Wish, a nonprofit that grants life-changing wishes for children with critical illnesses. The wish from Lofranco, who has Hodgkin’s lymphoma, was the fifth NVIDIA has been a part of in the last decade.</p>
<p>The NVIDIA team kept the day’s agenda a secret — surprising Lofranco with tours of the demo room and robotics lab, a chat with the University Recruiting team, a ride in a self-driving car and a video call with NVIDIA founder and CEO Jensen Huang. An aspiring computer science major, Lofranco was stoked for it all because, as his mom Cassandra shared, “NVIDIA is his Disneyland.”</p>
<figure id="attachment_68318" aria-describedby="caption-attachment-68318" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-68318 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-1536x1025.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-322x215.jpg 322w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08869-crop-1280x854.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68318" class="wp-caption-text">NVIDIA’s auto garage</figcaption></figure>
<h2><b>A Long-Time NVIDIA Fan </b></h2>
<p>After attending his first computer science summer camp when he was eight, Lofranco learned 3D modeling in Autodesk Maya, programming in Python, as well as 3D printing. His budding interest in tech grew and, soon enough, he was building his own gaming rigs.</p>
<p>NVIDIA quickly became Lofranco’s favorite tech company, he said, so much so that he carved the company logo out of a piece of wood using a computer numerical control machine.</p>
<p>For gaming, he enjoys using NVIDIA GeForce RTX 3070 and GeForce GTX 1080 Ti GPUs. But Lofranco’s ultimate draw to NVIDIA wasn’t its products but its culture.</p>
<p>“Everyone is driven to see the same outcome and comes together to make it happen,” he said. “Everything is designed for collaboration.”</p>
<figure id="attachment_68324" aria-describedby="caption-attachment-68324" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-68324 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-672x409.jpg" alt="" width="672" height="409" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-672x409.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-400x244.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-768x468.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-1536x935.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-739x450.jpg 739w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-353x215.jpg 353w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-164x100.jpg 164w, https://blogs.nvidia.com/wp-content/uploads/2023/11/Luca_crop1-1280x779.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68324" class="wp-caption-text">Lofranco in NVIDIA gear</figcaption></figure>
<h2><b>A VIP Experience</b></h2>
<p>Ahead of Lofranco’s visit, the NVIDIA team sent him a box of swag — including a hoodie, a hat and a custom NVIDIA badge.</p>
<p>Once he arrived on campus, NVIDIA volunteers welcomed and whisked Lofranco off on a campus tour, followed by a meeting with the solutions architect team, which includes NVIDIANs focused on healthcare, auto, AI, cloud service providers and <a href="https://blogs.nvidia.com/blog/what-are-large-language-models-used-for/">large language models</a>.</p>
<p><img loading="lazy" decoding="async" class="aligncenter wp-image-68327 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-667x500.jpg" alt="" width="667" height="500" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-667x500.jpg 667w, https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-400x300.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-768x576.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-1536x1152.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-600x450.jpg 600w, https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-287x215.jpg 287w, https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-133x100.jpg 133w, https://blogs.nvidia.com/wp-content/uploads/2023/11/NVIDIA_swag-1280x960.jpg 1280w" sizes="(max-width: 667px) 100vw, 667px" /></p>
<p>Next, a visit to the robotics lab helped satisfy Lofranco’s “maker” curiosity. He saw an <a href="https://www.nvidia.com/en-sg/data-center/dgx-platform/">NVIDIA DGX Station</a> as well as test robots for developing the <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/">NVIDIA Jetson</a> edge AI platform, and was soon directing a robot arm to stack colored blocks.</p>
<p>After learning that Lofranco’s favorite foods include lobster, tiramisu and Kit Kat candy bars, the café team prepared a special menu for him and all employees in the office that day. Everyone enjoyed a lobster roll pop-up station in the campus park and tiramisu-flavored ice cream with assorted toppings, including Kit Kat pieces.</p>
<figure id="attachment_68330" aria-describedby="caption-attachment-68330" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-68330 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-1536x1025.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-322x215.jpg 322w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08511-2-1280x854.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68330" class="wp-caption-text">Lofranco checks out NVIDIA GPUs in the company’s demo room</figcaption></figure>
<h2><b>Innovators</b></h2>
<p>On a visit to the demo room at NVIDIA’s Santa Clara site, Lofranco and his father revealed that they tinker with innovations themselves. They programmed their water heater in the family hot tub to maintain a comfortable temperature and decrease the time needed to warm it — all thanks to Python code and Raspberry Pi experimentation.</p>
<p>With so much to soak in, Lofranco described his wish day at NVIDIA as “unfathomable” — and that was before his video call with Huang, which stretched from a planned quarter hour to 45 minutes.</p>
<p>After a conversation that spanned NVIDIA’s origins, many near failures and innovation, Huang gifted Lofranco a <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4090/">GeForce RTX 4090</a> Founders Edition GPU and shared some sound advice: “Keep playing video games — but make sure to prioritize your homework.”</p>
<figure id="attachment_68333" aria-describedby="caption-attachment-68333" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="wp-image-68333 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-1536x1025.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-322x215.jpg 322w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08733-1280x854.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-68333" class="wp-caption-text">Lofranco with the surprise gift from Huang following their chat</figcaption></figure>
<p>Capping a packed day of fun-filled support from nearly 50 NVIDIANs was a visit to the auto lab and a spin in one of NVIDIA’s self-driving test cars.</p>
<p>How was it all? “Breathtaking,” said Lofranco, who learned firsthand from Huang that while NVIDIA has evolved from being the underdog to a leading tech company, it still feels “like a family.”</p>
<p><i>Learn more about </i><a href="https://www.nvidia.com/en-us/about-nvidia/careers/life-at-nvidia/"><i>NVIDIA life, culture and careers</i></a><i>. </i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08087-Edit-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1366"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/DSC08087-Edit-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Teenage Dream: Aspiring Computer Science Major Experiences NVIDIA Life With Make-A-Wish Visit]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>AI-Powered Tech Company Helps Grocers Start Afresh in Supply Chain Management</title>
		<link>https://blogs.nvidia.com/blog/ai-afresh-grocer/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Wed, 22 Nov 2023 14:00:29 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[The AI Podcast]]></category>
		<category><![CDATA[Agriculture and Food]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Climate]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68338</guid>

					<description><![CDATA[Talk about going after low-hanging fruit. Afresh is an AI startup that helps grocery stores and retailers reduce food waste by making supply chains more efficient. In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with the company’s cofounder and president, Nathan Fenner, about its mission, offerings and the greater challenge of <a class="read-more" href="https://blogs.nvidia.com/blog/ai-afresh-grocer/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Talk about going after low-hanging fruit. Afresh is an AI startup that helps grocery stores and retailers reduce food waste by making supply chains more efficient.</p>
<p>In the latest episode of NVIDIA’s <a href="https://blogs.nvidia.com/ai-podcast/">AI Podcast</a>, host Noah Kravitz spoke with the company’s cofounder and president, Nathan Fenner, about its mission, offerings and the greater challenge of eliminating food waste.</p>
<p>Most supply chain and inventory management offerings targeting grocers and retailers are outdated. Fenner and his team noticed those solutions, built for the nonperishable side of the business, didn’t work as well on the fresh side — creating enormous amounts of food waste and causing billions in lost profits.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1671268662%3Fsecret_token%3Ds-75QpZNVnAWT&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="AI-Powered Tech Company Helps Grocers Start Afresh in Supply Chain Management" href="https://soundcloud.com/theaipodcast/nathan-fenner-afresh/s-75QpZNVnAWT" target="_blank" rel="noopener">AI-Powered Tech Company Helps Grocers Start Afresh in Supply Chain Management</a></div>
<p>The team first sought to solve the store-replenishment challenge by developing a platform to help grocers decide how much fresh produce to order to optimize costs while meeting demand.</p>
<p>They created machine learning and AI models that could effectively use the data generated by fresh produce, which is messier than data generated by nonperishable goods because of factors like time to decay, greater demand fluctuation and unreliability caused by lack of barcodes, leading to incorrect scans at self-checkout registers.</p>
<p>The result was a fully integrated, machine learning-based platform that helps grocers make informed decisions at each node of the operations process.</p>
<p>The company also recently launched inventory management software that allows grocers to save time and increase data accuracy by intelligently tracking inventory. That information can be inputted back into the platform’s ordering solution, further refining the accuracy of inventory data.</p>
<p>It’s all part of Afresh’s greater mission to tackle climate change.</p>
<p>“The most impactful thing we can do is reduce food waste to mitigate climate change,” Fenner said. “It’s really one of the key things that brought me into the business: I think I’ve always had a keen eye to work in the climate space. It’s really motivating for a lot of our team, and it’s a key part of our mission.”</p>
<h2><b>Subscribe to the AI Podcast: Now Available on Amazon Music</b></h2>
<p><a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">The AI Podcast is now available through Amazon Music</a>.</p>
<p>In addition, get the <a href="https://blogs.nvidia.com/ai-podcast/">AI Podcast</a> through <a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439">iTunes</a>, <a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjI2NDAzNDEzMy9zb3VuZHMucnNz">Google Podcasts</a>, <a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm">Google Play</a>, <a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us">Castbox</a>, DoggCatcher, <a href="https://overcast.fm/itunes1186480811/the-ai-podcast">Overcast</a>, <a href="https://player.fm/series/the-ai-podcast">PlayerFM</a>, Pocket Casts, <a href="http://www.podbay.fm/show/1186480811">Podbay</a>, <a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast">PodBean</a>, PodCruncher, PodKicker, <a href="https://soundcloud.com/theaipodcast">Soundcloud</a>, <a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L">Spotify</a>, <a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr">Stitcher</a> and <a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/">TuneIn</a>.</p>
<p>Make the AI Podcast better. Have a few minutes to spare? Fill out <a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short">this listener survey</a>.</p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast.jpg"
			type="image/jpeg"
			width="1400"
			height="931"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[AI-Powered Tech Company Helps Grocers Start Afresh in Supply Chain Management]]></media:title>
			<media:description type="html">NVIDIA AI Podcast</media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Collaborates With Genentech to Accelerate Drug Discovery Using Generative AI</title>
		<link>https://blogs.nvidia.com/blog/genentech-drug-discovery-bionemo/</link>
		
		<dc:creator><![CDATA[Rory Kelleher]]></dc:creator>
		<pubDate>Tue, 21 Nov 2023 14:00:25 +0000</pubDate>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[Science]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68193</guid>

					<description><![CDATA[Genentech, a member of the Roche Group, is pioneering the use of generative AI to discover and develop new therapeutics and deliver treatments to patients more efficiently. A new collaboration between Genentech, the biotechnology pioneer, and NVIDIA aims to transform the discovery and development of new medicines by bringing together experts from each company to <a class="read-more" href="https://blogs.nvidia.com/blog/genentech-drug-discovery-bionemo/">Read article &#62;</a>]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p>Genentech, a member of the Roche Group, is pioneering the use of <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/">generative AI</a> to discover and develop new therapeutics and deliver treatments to patients more efficiently.</p>
<p>A new <a href="https://www.gene.com/media/press-releases/15010/2023-11-21/genentech-and-nvidia-enter-into-strategi" target="_blank" rel="noopener">collaboration between Genentech</a>, the biotechnology pioneer, and NVIDIA aims to transform the discovery and development of new medicines by bringing together experts from each company to optimize and accelerate Genentech’s proprietary algorithms.</p>
<p>NVIDIA will work with Genentech to accelerate these models on <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a>, which provides dedicated instances of AI supercomputing and software hosted by NVIDIA cloud service provider partners.</p>
<p>Genentech plans to use <a href="https://www.nvidia.com/en-us/gpu-cloud/bionemo/">NVIDIA BioNeMo</a>, which enables biotech companies to customize models at scale, and integrate BioNeMo cloud application programming interfaces directly into computational drug discovery workflows.</p>
<p>BioNeMo, now generally available as a training service, is a domain-specific platform that simplifies, accelerates and scales generative AI applications for computational drug discovery. It allows researchers to <a href="https://blogs.nvidia.com/blog/what-is-a-pretrained-ai-model/">pretrain</a> or fine-tune state-of-the-art models on DGX Cloud.</p>
<p>The collaboration will initially focus on optimizing Genentech’s drug discovery AI models in its “lab in a loop” framework. The goal: To allow its researchers to understand complex biomolecular patterns and relationships to truly disrupt drug development and improve the success rate of R&amp;D, and to empower scientists to deliver multiplicative, rather than linear or additive, benefits for patients and the broader healthcare ecosystem.</p>
<p>“Our collaboration with NVIDIA builds on our long history of successfully inventing and deploying technology in ways that were not initially apparent to others,” said Aviv Regev, executive vice president and head of Genentech Research &amp; Early Development (gRED). “We were the first biotech company to leverage molecular biology for drug discovery and development, which changed the world. We pioneered antibody therapeutics that became the paradigm of treatment. And now, we have brought AI, the lab and the clinic together to uncover otherwise inaccessible patterns in vast quantities of data, and to design experiments to test those patterns. Collaborating with NVIDIA, and introducing generative AI, has the power to turbocharge the discovery and design of therapeutics that will improve the lives of patients across the world.”</p>
<p><iframe loading="lazy" title="Genentech and NVIDIA Revolutionize Drug Discovery with Generative AI in Lab in the Loop" width="500" height="281" src="https://www.youtube.com/embed/-Ijg2g8AsjE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<h2><b>Streamlining Drug Discovery With Computation  </b></h2>
<p>Drug discovery and development is currently a lengthy, complicated and costly process. Drug targets for novel medicines are difficult to predict, as is successfully developing a molecule as a potential therapeutic. AI can play a transformational role because generative and other AI models can help scientists rapidly identify potential drug molecules and interactions by training on large-scale datasets.</p>
<p>For Genentech, using AI helps bridge the gap between lab experiments and computational algorithms.</p>
<p>The company’s R&amp;D group, gRED, has already done significant work using AI — across multiple modalities — to discover and develop novel therapeutics while learning more about the building blocks of biology and diseases.</p>
<p>Teams from Genentech and NVIDIA will now work together to optimize Genentech’s custom-developed models to shorten this time-consuming process of drug discovery and development and lead to greater success.</p>
<h2><b>Putting AI in a Loop</b></h2>
<p>Genentech’s “lab in a loop” is an iterative framework for generating and exploring molecular designs with predicted properties. It aims to use experimental data to inform generative computational models and better optimize future molecular designs. NVIDIA will help Genentech optimize its framework by accelerating training and inference of Genentech’s drug discovery models.</p>
<p>Through this collaboration, NVIDIA AI experts will gain insights into AI-related challenges in drug discovery and development. NVIDIA plans to use these insights to improve its BioNeMo platform and others to further accommodate the requirements of models used by the biotech industry.</p>
<p>“AI can play a transformational role in accelerating drug discovery and development — as it has across many parts of healthcare and life sciences,” said Kimberly Powell, vice president of healthcare at NVIDIA. “Together, NVIDIA and Genentech are unlocking scientific innovation by developing and implementing AI models and algorithms that enable us to rapidly iterate and unearth insights.”</p>
<p><a href="https://www.nvidia.com/en-us/industries/healthcare-life-sciences/healthcare-news-sign-up/"><i>Subscribe to NVIDIA healthcare news</i></a><i>.</i></p>
</div>]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/hc-corp-blog-genentech-1280x680-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/hc-corp-blog-genentech-1280x680-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Collaborates With Genentech to Accelerate Drug Discovery Using Generative AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>3D Artist Cooks Up Stunningly Photorealistic Food Renders This Week ‘In the NVIDIA Studio’</title>
		<link>https://blogs.nvidia.com/blog/carpenen-adobe-substance-3d-painter-lightroom-blender/</link>
		
		<dc:creator><![CDATA[Gerardo Delgado]]></dc:creator>
		<pubDate>Tue, 21 Nov 2023 14:00:04 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Art]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Creators]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[In the NVIDIA Studio]]></category>
		<category><![CDATA[NVIDIA Studio]]></category>
		<category><![CDATA[Rendering]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=68261</guid>

					<description><![CDATA[It’s the season of gratitude: that time of year to give thanks for the people and small moments that make life so special.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"><p><i>Editor’s note: This post is part of our weekly </i><a href="https://blogs.nvidia.com/blog/tag/in-the-nvidia-studio/"><i>In the NVIDIA Studio</i></a><i> series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how </i><a href="https://www.nvidia.com/en-us/studio/"><i>NVIDIA Studio</i></a><i> technology improves creative workflows. </i></p>
<p>It’s the season of gratitude: that time of year to give thanks for the people and small moments that make life so special.</p>
<p>This week’s featured <i>In the NVIDIA Studio</i> artist, Ravissen Carpenen, is serving up a feast of mouthwateringly photorealistic 3D food renders to the dinner table.</p>
<p>His delectable time-lapse videos are featured on his YouTube channel, <a href="https://www.youtube.com/channel/UC9Vs9hDHCD1pD85uCehjlAg">CG Realism</a> — presented with a side of upbeat music and a pinch of style.</p>
<p>Carpenen was one of several contributors to the food-themed Studio Standout video contest, alongside Roger Roque (<a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbFhGU0p5aEVnT2VHSU5IaHhuWDB3YURySWhtQXxBQ3Jtc0tsT196Ui14MWhNeHpTTmRzX2pNTFRWdlRld1VOVDNVaTQzbTljUV9xV1lWWXZDcW5kMVctcC1wWW9PVkloNjVpMXBLTHloUHVIa1FIZzZvNmZPbkdXWV9YVVFBUXExYXBWNU5yS0Y0aUNCeWFKREw5RQ&amp;q=https%3A%2F%2Fwww.instagram.com%2Frogerroqueid%2F&amp;v=P1BIBbjntsM">@rogerroqueid</a>), Nicole Morena (<a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbmtuWHZKam1CUHB1VUd3aHBBZzRwZnhRTHZrQXxBQ3Jtc0tuX1NHQ3ZwZGpVcVZiS1RfMjRzR3VBd3Z5OTZIWnJPOVVKcS1UWTBLUFBtcENxYmdURy1QcjUzNU92aEFlMTJlZExuNjJINzBOaDJsNXZOLVB6cWt3OGpjRlNaQUZ5eDZHSnVxQjVjbEJUeXp1N0RyWQ&amp;q=https%3A%2F%2Fwww.instagram.com%2Fnicky.blender%2F&amp;v=P1BIBbjntsM">@nicky.blender</a>), Heloise Cart (<a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqa0l4ajNyVDBqV0Fta0xOOGhmXzZyNXJaM204Z3xBQ3Jtc0tsdUl4ZW5pZEdNMTUtblhkdW5QcjZpOTZvQkszMGVDdWlGM3Jva2p1eTlERkw5V0p2VjJBREVaSkRJVS1DQ1dWZ1o5Z0JyM3NZbFotUUFnRV9iYjZqYlhXR29zX0F5b3VQUHhJdzdQM25WQ1M0S2EzSQ&amp;q=https%3A%2F%2Fwww.instagram.com%2Fisoheell%2F&amp;v=P1BIBbjntsM">@isoheell</a>) and Kris Theroin (<a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbnRlYnpmR2pIY0pXQXp4Q2hieERxZm90dldyUXxBQ3Jtc0ttODhUdFRJRkJUOUVxRzE5SHE4cGM4dTVRa1FCX1JhYktoaUp6NGxwdE55QWc0MEpyQUdzbVFIN2lMX215WEdacEZ3OUphRDVJSkdpMmNjZlNGT3JEMC12MGJwZ3lyR0ptSFFOUXVOQ016M2NCbHlBYw&amp;q=https%3A%2F%2Fwww.instagram.com%2Fkristheorin%2F&amp;v=P1BIBbjntsM">@kristheorin</a>).</p>
<p><iframe loading="lazy" title="Try Not To Get Hungry Challenge | NVIDIA Studio Standouts" width="500" height="281" src="https://www.youtube.com/embed/P1BIBbjntsM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Finally, livestreamers using OBS Studio — a free, open-source software for video recording and livestreaming — can download the latest update with HDR10 capture support, WHIP and WebRTC output and more. Learn more <a href="https://github.com/obsproject/obs-studio/releases">details</a>.</p>
<h2><b>All About That Baste</b></h2>
<p>Carpenen’s wife, a pastry chef, inspired his photorealistic, food-centered works.</p>
<p>“My aim, one day, is to be able to create ultra-realistic renders that will be used in film and movies,” he said.</p>
<p><iframe loading="lazy" title="Happy Meal - Blender Timelapse" width="500" height="281" src="https://www.youtube.com/embed/vwA5CaYVPQQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>His projects begin with online research and reference gathering, mainly on Pinterest and Behance, which he then compiles into mood boards using the stand-alone image tracking program PureRef.</p>
<p>Before any modeling takes place, Carpenen lights the scene — but without textures.</p>
<p>“This is to tell the story of the artwork, as light intends to give artwork an emotional flow, alongside as well as color and materials,” he said.</p>
<p>Carpenen initially sculpts his models in ZBrush using customizable brushes to shape, texture and paint his virtual clay in a real-time environment with instant feedback.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-68261-7" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/Turkey-Blender-Timelapse-video.mp4?_=7" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/Turkey-Blender-Timelapse-video.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/11/Turkey-Blender-Timelapse-video.mp4</a></video></div>
<p>&nbsp;</p>
<p>He then browses the Quixel Megascans library for models that can further add realism, such as garlic cloves and rosemary garnishes for his turkey project.</p>
<h2><b>Rare-in for More</b></h2>
<p>Carpenen uses Marmoset Toolbag’s ambient occlusion, curvature, normal and thickness features to bake the ZBrush meshes from high-poly to low-poly models as 32-bit textures.</p>
<p><iframe loading="lazy" title="Medium Cooked Steak - 3D Timelapse" width="500" height="281" src="https://www.youtube.com/embed/c2NOK9eDRDA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>The process saves memory space, minimizing lag time while allowing greater flexibility in the modeling stage.</p>
<figure id="attachment_68271" aria-describedby="caption-attachment-68271" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68271" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w-672x372.png" alt="" width="672" height="372" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w-672x372.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w-400x221.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w-768x425.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w-814x450.png 814w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w-389x215.png 389w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w-181x100.png 181w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-medium-cooked-steak-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68271" class="wp-caption-text">Bake ZBrush meshes from high-poly to low-poly models as 32-bit textures in Marmoset Toolbag.</figcaption></figure>
<p>Carpenen’s GeForce RTX 3070 GPU-powered system with RTX acceleration instantly optimized his meshes. RTX-accelerated ray tracing and OptiX AI-powered denoising also enabled smoother viewport movement.</p>
<h2><b>Baking a Berry Good Pie</b></h2>
<p>Once the renders are ready, Carpenen imports them into Adobe Substance 3D Painter to apply custom colors and textures.</p>
<p><iframe loading="lazy" title="Blackberry Pie - Blender Timelapse" width="500" height="281" src="https://www.youtube.com/embed/xPA6-ZW293Q?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>There, Carpenen uses RTX-accelerated light and ambient occlusion baking — though not in the oven — to optimize his assets, such as this berry pie, in mere seconds.</p>
<div style="width: 1280px;" class="wp-video"><video class="wp-video-shortcode" id="video-68261-8" width="1280" height="720" loop="1" autoplay="1" preload="metadata" controls="controls"><source type="video/mp4" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/Blackberry-Pie-Blender-Timelapse-video.mp4?_=8" /><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/Blackberry-Pie-Blender-Timelapse-video.mp4">https://blogs.nvidia.com/wp-content/uploads/2023/11/Blackberry-Pie-Blender-Timelapse-video.mp4</a></video></div>
<p>&nbsp;</p>
<p>He also had the option to set up a <a href="https://www.nvidia.com/en-us/omniverse/ecosystem/">live link</a> connection between 3D Painter and <a href="https://www.nvidia.com/en-us/omniverse/creators/">NVIDIA Omniverse</a>, a development platform for connecting and building <a href="https://www.nvidia.com/en-us/omniverse/usd/">Universal Scene Description (OpenUSD)</a>-based tools and applications, via the <a href="https://www.nvidia.com/en-us/omniverse/apps/usd-composer/">USD Composer foundation app</a>.</p>
<p><iframe loading="lazy" title="Adobe Substance 3D Painter Connector Overview with Omniverse USD Composer" width="500" height="281" src="https://www.youtube.com/embed/_XRN2qAWJN0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>The connection would allow Carpenen’s texture work in Substance 3D Painter to directly translate to USD Composer — eliminating the need for numerous file imports, exports and reformatting.</p>
<h2><b>Donut Hole in One</b></h2>
<p>Carpenen uses Blender to bring his scenes together with advanced model sculpting, animations and further lighting refinement.</p>
<p><iframe loading="lazy" title="Donut Fever - Blender Timelapse" width="500" height="281" src="https://www.youtube.com/embed/LESrdWIZgv0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>RTX GPUs allow smoother movement in the viewport thanks to Blender Cycles’ RTX-accelerated OptiX ray tracing.</p>
<figure id="attachment_68277" aria-describedby="caption-attachment-68277" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68277" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-opengl-render-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68277" class="wp-caption-text">Beautifully rendered donuts make us go nuts.</figcaption></figure>
<p>And for exporting final files, RTX-accelerated OptiX ray tracing in Blender Cycles delivers the fastest final-frame render.</p>
<figure id="attachment_68280" aria-describedby="caption-attachment-68280" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68280" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w-672x378.png" alt="" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-ravissen-carpenen-wk84-raw-image-edit-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68280" class="wp-caption-text">It doesn’t get any sweeter than this.</figcaption></figure>
<h2><b>Thanks to AI, This Work Is Toast</b></h2>
<p>Carpenen uses Adobe Photoshop Lightroom to put the finishing touches on his food scenes.</p>
<p>GPU-accelerated image processing enables dramatically more responsive adjustments on his 4K-resolution display.</p>
<p><iframe loading="lazy" title="Blender 2.92 - Toasty Morning" width="500" height="281" src="https://www.youtube.com/embed/bHmrGJhm8-4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
<p>Carpenen had even more RTX-accelerated AI tools at his disposal in Lightroom. The “Raw Details” feature refines the fine color details of high-resolution RAW images. And “Super Resolution” uses AI to upscale images with higher quality than traditional methods.</p>
<p>According to Carpenen, putting in the work is key.</p>
<p>“It’s equivalent to practicing football — if you don’t get enough time daily to practice, you can’t hone skills,” he said. “It’s important to know how to tackle obstacles — and that knowledge can only be gained by experience.”</p>
<figure id="attachment_68283" aria-describedby="caption-attachment-68283" style="width: 672px" class="wp-caption aligncenter"><a href="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w.png"><img loading="lazy" decoding="async" class="size-large wp-image-68283" src="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w-672x252.png" alt="" width="672" height="252" srcset="https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w-672x252.png 672w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w-400x150.png 400w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w-768x288.png 768w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w-842x316.png 842w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w-406x152.png 406w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w-188x71.png 188w, https://blogs.nvidia.com/wp-content/uploads/2023/11/studio-itns-ravissen-carpenen-wk84-artist-feature-1280w.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /></a><figcaption id="caption-attachment-68283" class="wp-caption-text">Digital 3D artist Ravissen Carpenen’s logo and signature work.</figcaption></figure>
<p>Check out Carpenen’s YouTube <a href="https://www.youtube.com/channel/UC9Vs9hDHCD1pD85uCehjlAg">channel</a>, CG Realism, and <a href="https://www.artstation.com/rcarts">ArtStation</a> to check out more food projects.</p>
<p><i>Follow NVIDIA Studio on </i><a href="https://www.instagram.com/nvidiastudio/"><i>Instagram</i></a><i>, </i><a href="https://twitter.com/NVIDIAStudio"><i>Twitter</i></a><i> and </i><a href="https://www.facebook.com/NVIDIAStudio/"><i>Facebook</i></a><i>. Access tutorials on the </i><a href="https://www.youtube.com/channel/UCDeQdW6Lt6nhq3mLM4oLGWw"><i>Studio YouTube channel</i></a><i> and get updates directly in your inbox by subscribing to the </i><a href="https://www.nvidia.com/en-us/studio/?nvmid=subscribe-creators-mail-icon"><i>Studio newsletter</i></a><i>.</i><b> </b></p>
</div>]]></content:encoded>
					
		
		<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/11/Turkey-Blender-Timelapse-video.mp4" length="1998359" type="video/mp4" />
<enclosure url="https://blogs.nvidia.com/wp-content/uploads/2023/11/Blackberry-Pie-Blender-Timelapse-video.mp4" length="1265816" type="video/mp4" />

		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/nv-blog-header-preview-1280x680-1-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2023/11/nv-blog-header-preview-1280x680-1-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[3D Artist Cooks Up Stunningly Photorealistic Food Renders This Week ‘In the NVIDIA Studio’]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
	</channel>
</rss>
