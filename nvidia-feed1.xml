<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>NVIDIA Blog</title>
	<atom:link href="https://blogs.nvidia.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://blogs.nvidia.com/</link>
	<description></description>
	<lastBuildDate>Mon, 03 Jun 2024 17:16:05 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.5.3</generator>
	<item>
		<title>Digital Bank Debunks Financial Fraud With Generative AI</title>
		<link>https://blogs.nvidia.com/blog/bunq-financial-services-generative-ai/</link>
		
		<dc:creator><![CDATA[Angie Lee]]></dc:creator>
		<pubDate>Mon, 03 Jun 2024 07:00:28 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Customer Stories]]></category>
		<category><![CDATA[Data Science]]></category>
		<category><![CDATA[Financial Services]]></category>
		<category><![CDATA[GPU]]></category>
		<category><![CDATA[NVIDIA NIM]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71798</guid>

					<description><![CDATA[European neobank bunq is debunking financial fraudsters with the help of NVIDIA accelerated computing and AI. Dubbed “the bank of the free,” bunq offers online banking anytime, anywhere. Through the bunq app, users can handle all their financial needs exclusively online, without needing to visit a physical bank. With more than 12 million customers and	<a class="read-more" href="https://blogs.nvidia.com/blog/bunq-financial-services-generative-ai/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>European neobank <a href="https://www.bunq.com/about" target="_blank" rel="noopener">bunq</a> is debunking financial fraudsters with the help of NVIDIA accelerated computing and AI.</p>
<p>Dubbed “the bank of the free,” bunq offers online banking anytime, anywhere. Through the bunq app, users can handle all their financial needs exclusively online, without needing to visit a physical bank.</p>
<p>With more than 12 million customers and 8 billion euros’ worth of deposits made to date, bunq has become one of the largest neobanks in the European Union. Founded in 2012, it was the first bank to obtain a European banking license in over three decades.</p>
<p>To meet growing customer needs, bunq turned to <a href="https://www.nvidia.com/en-us/glossary/generative-ai/" target="_blank" rel="noopener">generative AI</a> to help <a href="https://blogs.nvidia.com/blog/ai-fraud-detection-rapids-triton-tensorrt-nemo/" target="_blank" rel="noopener">detect fraud and money laundering</a>. Its automated transaction-monitoring system, powered by NVIDIA accelerated computing, greatly improved its training speed.</p>
<p>“AI has enormous potential to help humanity in so many ways, and this is a great example of how human intelligence can be coupled with AI,” said Ali el Hassouni, head of data and AI at bunq.</p>
<h2><b>Faster Fraud Detection</b></h2>
<p>Financial fraud is more prevalent than ever, el Hassouni said in a recent <a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62593/" target="_blank" rel="noopener">talk at NVIDIA GTC</a>.</p>
<p>Traditional transaction-monitoring systems are rules based, meaning algorithms flag suspicious transactions according to a set of criteria that determine if an activity presents risk of fraud or money laundering. These criteria must be manually set, resulting in high false-positive rates and making such systems labor intensive and difficult to scale.</p>
<p>Instead, using <a href="https://blogs.nvidia.com/blog/supervised-unsupervised-learning/" target="_blank" rel="noopener">supervised and unsupervised learning</a>, bunq’s AI-powered transaction-monitoring system is completely automated and easily scalable.</p>
<p>Bunq achieved this using NVIDIA GPUs, which accelerated its data processing pipeline more than 5x.</p>
<p>In addition, compared with previous methods, bunq trained its fraud-detection model nearly 100x faster using the open-source <a href="https://developer.nvidia.com/rapids" target="_blank" rel="noopener">NVIDIA RAPIDS</a> suite of GPU-accelerated data science libraries.</p>
<p>RAPIDS is part of the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/" target="_blank" rel="noopener">NVIDIA AI Enterprise</a> software platform, which accelerates data science pipelines and streamlines the development and deployment of production-grade generative AI applications.</p>
<p>“We chose NVIDIA’s advanced, GPU-optimized software, as it enables us to use larger datasets and speed the training of new models — sometimes by an order of magnitude — resulting in improved model accuracy and reduced false positives,” said el Hassouni.</p>
<h2><b>AI Across the Bank</b></h2>
<p>Bunq is seeking to tap AI’s potential across its operations.</p>
<p>“We’re constantly looking for new ways to apply AI for the benefit of our users,” el Hassouni said. “More than half of our user tickets are handled automatically. We also use AI to spot fake IDs when onboarding new users, automate our marketing efforts and much more.”</p>
<p>Finn, a personal AI assistant available to bunq customers, is powered by the company’s proprietary <a href="https://www.nvidia.com/en-us/glossary/large-language-models/" target="_blank" rel="noopener">large language model</a> and generative AI. It can answer user questions like, “How much did I spend on groceries last month?” and “What’s the name of the Indian restaurant I ate at last week?”</p>
<p>The company is exploring <a href="https://developer.nvidia.com/blog/translate-your-enterprise-data-into-actionable-insights-with-nvidia-nemo-retriever/" target="_blank" rel="noopener">NVIDIA NeMo Retriever</a>, a collection of generative AI microservices available in <a href="https://developer.nvidia.com/nemo-microservices" target="_blank" rel="noopener">early access</a>, to further improve Finn’s accuracy. NeMo Retriever is a part of <a href="https://www.nvidia.com/en-us/ai/" target="_blank" rel="noopener">NVIDIA NIM</a> inference microservices, which provide models as optimized containers, available with NVIDIA AI Enterprise.</p>
<p>“Our initial testing of NeMo Retriever embedding NIM has been extremely positive, and our collaboration with NVIDIA on LLMs is poised to help us to take Finn to the next level and enhance customer experience,” el Hassouni said.</p>
<p>Plus, for the digital bank’s marketing efforts, AI helps analyze consumer engagement metrics to inform future campaigns.</p>
<p>“We’re creating a borderless banking experience for our users, always keeping them at the heart of everything we do,” el Hassouni said.</p>
<p><i>Watch bunq’s </i><a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62593/" target="_blank" rel="noopener"><i>NVIDIA GTC session on demand</i></a><i> and </i><i>subscribe to </i><a href="https://www.nvidia.com/en-us/industries/finance/?nvmid=subscribe" target="_blank" rel="noopener"><i>NVIDIA financial services news</i></a><i>. </i></p>
<p><i>Learn more about AI and financial services at </i><a href="https://europe.money2020.com/" target="_blank" rel="noopener"><i>Money20/20 Europe</i></a><i>, a fintech conference running June 4-6 in Amsterdam, where NVIDIA will host an AI Summit in collaboration with AWS, and where bunq will present on a panel about AI for fraud detection.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/bunq-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/bunq-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Digital Bank Debunks Financial Fraud With Generative AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>‘Accelerate Everything,’ NVIDIA CEO Says Ahead of COMPUTEX</title>
		<link>https://blogs.nvidia.com/blog/computex-2024-jensen-huang/</link>
		
		<dc:creator><![CDATA[Brian Caulfield]]></dc:creator>
		<pubDate>Sun, 02 Jun 2024 14:12:31 +0000</pubDate>
				<category><![CDATA[Corporate]]></category>
		<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Driving]]></category>
		<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[COMPUTEX 2024]]></category>
		<category><![CDATA[NVIDIA NIM]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71820</guid>

					<description><![CDATA[“Generative AI is reshaping industries and opening new opportunities for innovation and growth,” NVIDIA founder and CEO Jensen Huang said in an address ahead of this week’s COMPUTEX technology conference in Taipei. “Today, we’re at the cusp of a major shift in computing,” Huang told the audience, clad in his trademark black leather jacket. “The	<a class="read-more" href="https://blogs.nvidia.com/blog/computex-2024-jensen-huang/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>“Generative AI is reshaping industries and opening new opportunities for innovation and growth,” NVIDIA founder and CEO Jensen Huang said in an address ahead of this week’s COMPUTEX technology conference in Taipei.</p>
<p>“Today, we’re at the cusp of a major shift in computing,” Huang told the audience, clad in his trademark black leather jacket. “The intersection of AI and accelerated computing is set to redefine the future.”</p>
<p>Huang spoke ahead of one of the world’s premier technology conferences to an audience of more than 6,500 industry leaders, press, entrepreneurs, gamers, creators and AI enthusiasts gathered at the glass-domed National Taiwan University Sports Center set in the verdant heart of Taipei.</p>
<p><img fetchpriority="high" decoding="async" class="aligncenter size-large wp-image-71980" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/crowd-computex-2024-672x464.jpg" alt="" width="672" height="464" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/crowd-computex-2024-672x464.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/crowd-computex-2024-400x276.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/crowd-computex-2024-768x530.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/crowd-computex-2024-1536x1060.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/crowd-computex-2024-652x450.jpg 652w, https://blogs.nvidia.com/wp-content/uploads/2024/06/crowd-computex-2024-312x215.jpg 312w, https://blogs.nvidia.com/wp-content/uploads/2024/06/crowd-computex-2024-145x100.jpg 145w, https://blogs.nvidia.com/wp-content/uploads/2024/06/crowd-computex-2024-1280x883.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/06/crowd-computex-2024.jpg 1980w" sizes="(max-width: 672px) 100vw, 672px" /></p>
<p>The theme: NVIDIA accelerated platforms are in full production, whether through AI PCs and consumer devices featuring a host of NVIDIA RTX-powered capabilities or enterprises building and deploying AI factories with NVIDIA’s full-stack computing platform.</p>
<p>“The future of computing is accelerated,” Huang said. “With our innovations in AI and accelerated computing, we’re pushing the boundaries of what’s possible and driving the next wave of technological advancement.”<br />
<iframe title="YouTube video player" src="https://www.youtube.com/embed/pKXDVsWZmUU?si=bYffxIwUxYMev6hK" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe><strong> </strong></p>
<h2>‘One-Year Rhythm’</h2>
<p>More’s coming, with Huang revealing a roadmap for new semiconductors that will arrive on a one-year rhythm. Revealed for the first time, the Rubin platform will succeed the upcoming Blackwell platform, featuring new GPUs, a new Arm-based CPU — Vera — and advanced networking with NVLink 6, CX9 SuperNIC and the X1600 converged InfiniBand/Ethernet switch.</p>
<p>“Our company has a one-year rhythm. Our basic philosophy is very simple: build the entire data center scale, disaggregate and sell to you parts on a one-year rhythm, and push everything to technology limits,” Huang explained.</p>
<p>NVIDIA’s creative team used AI tools from members of the <a href="https://www.nvidia.com/en-us/startups/">NVIDIA Inception</a> startup program, built on <a href="https://www.nvidia.com/en-us/ai/">NVIDIA NIM</a> and NVIDIA’s accelerated computing, to create the COMPUTEX keynote. Packed with demos, this showcase highlighted these innovative tools and the transformative impact of NVIDIA’s technology.</p>
<h2>‘Accelerated Computing Is Sustainable Computing’</h2>
<p>NVIDIA is driving down the cost of turning data into intelligence, Huang explained as he began his talk.</p>
<p>“Accelerated computing is sustainable computing,” he emphasized, outlining how the combination of GPUs and CPUs can deliver up to a 100x speedup while only increasing power consumption by a factor of three, achieving 25x more performance per Watt over CPUs alone.</p>
<p>“The more you buy, the more you save,” Huang noted, highlighting this approach’s significant cost and energy savings.</p>
<h2>Industry Joins NVIDIA to Build AI Factories to Power New Industrial Revolution</h2>
<p>Leading computer manufacturers, particularly from Taiwan, the global IT hub, have embraced NVIDIA GPUs and networking solutions. Top companies include <a href="https://www.asrockrack.com/general/news.asp?id=239">ASRock Rack</a>, <a href="https://servers.asus.com/NEWS/ASUS-Presents-ESC-AI-POD-with-NVIDIA-GB200-NVL72-at-Computex-2024">ASUS</a>, <a href="https://www.gigabyte.com/Press/News/2168">GIGABYTE</a>, Ingrasys, Inventec, <a href="https://svr.pegatroncorp.com/News/6">Pegatron</a>, QCT, Supermicro, Wistron and Wiwynn, which are creating cloud, on-premises and edge AI systems.</p>
<p>The NVIDIA MGX modular reference design platform now supports Blackwell, including the GB200 NVL2 platform, designed for optimal performance in large language model inference, retrieval-augmented generation and data processing.</p>
<p>AMD and Intel are supporting the MGX architecture with plans to deliver, for the first time, their own CPU host processor module designs. Any server system builder can use these reference designs to save development time while ensuring consistency in design and performance.</p>
<h2>Next-Generation Networking with Spectrum-X</h2>
<p>In networking, Huang unveiled plans for the <a href="https://nvidianews.nvidia.com/news/nvidia-supercharges-ethernet-networking-for-generative-ai">annual release of Spectrum-X products</a> to cater to the growing demand for high-performance Ethernet networking for AI.</p>
<p>NVIDIA Spectrum-X, the first Ethernet fabric built for AI, enhances network performance by 1.6x more than traditional Ethernet fabrics. It accelerates the processing, analysis and execution of AI workloads and, in turn, the development and deployment of AI solutions.</p>
<p>CoreWeave, GMO Internet Group, Lambda, Scaleway, STPX Global and Yotta are among the first AI cloud service providers embracing Spectrum-X to bring extreme networking performance to their AI infrastructures.</p>
<h2>NVIDIA NIM to Transform Millions Into Gen AI Developers</h2>
<p>With <a href="https://nvidianews.nvidia.com/news/nvidia-nim-model-deployment-generative-ai-developers">NVIDIA NIM</a>, the world’s 28 million developers can now easily create generative AI applications. NIM — inference microservices that provide models as optimized containers — can be deployed on clouds, data centers or workstations.</p>
<p>NIM also enables enterprises to maximize their infrastructure investments. For example, running Meta Llama 3-8B in a NIM produces up to 3x more generative AI tokens on accelerated infrastructure than without NIM.</p>
<p><img decoding="async" class="aligncenter size-large wp-image-71989" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4248-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4248-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4248-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4248-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4248-1536x1025.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4248-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4248-322x215.jpg 322w, https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4248-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4248-1280x854.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4248.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><br />
Nearly <a href="https://nvidianews.nvidia.com/news/nvidia-nim-model-deployment-generative-ai-developers">200 technology partners</a> — including Cadence, Cloudera, <a href="https://www.cohesity.com/press/unlock-gen-ai-capabilities-via-nvidia-collaboration/">Cohesity</a>, <a href="https://www.datastax.com/press-release/datastax-to-deliver-high-performance-rag-solution-with-20x-faster-embeddings-and-indexing-at-80-lower-cost-using-nvidia-microservices">DataStax</a>, <a href="https://www.netapp.com/newsroom/press-releases/news-rel-20240514-813887/">NetApp</a>, Scale AI, and <a href="https://news.synopsys.com/2024-03-18-Synopsys-Showcases-EDA-Performance-and-Next-Gen-Capabilities-with-NVIDIA-Accelerated-Computing,-Generative-AI-and-Omniverse">Synopsys </a>— are integrating NIM into their platforms to speed generative AI deployments for domain-specific applications, such as copilots, code assistants, digital human avatars and more. <a href="https://huggingface.co/blog/train-dgx-cloud">Hugging Face</a> is now offering NIM — starting with <a href="https://ai.meta.com/blog/meta-llama-3/">Meta Llama 3</a>.</p>
<p>&#8220;Today we just posted up in Hugging Face the Llama 3 fully optimized, it&#8217;s available there for you to try. You can even take it with you,&#8221; Huang said. &#8220;So you could run it in the cloud, run it in any cloud, download this container, put it into your own data center, and you can host it to make it available for your customers.&#8221;</p>
<h2>NVIDIA Brings AI Assistants to Life With GeForce RTX AI PCs</h2>
<p><a href="https://www.nvidia.com/en-us/geforce/news/computex-2024-nvidia-geforce-announcements">NVIDIA’s RTX AI PCs</a>, powered by RTX technologies, are set to revolutionize consumer experiences with over 200 RTX AI laptops and more than 500 AI-powered apps and games.</p>
<p>The <a href="https://developer.nvidia.com/blog/streamline-ai-powered-app-development-with-nvidia-rtx-ai-toolkit-for-windows-rtx-pcs/">RTX AI Toolkit</a> and newly available PC-based NIM inference microservices for the <a href="https://nvidianews.nvidia.com/news/digital-humans-ace-generative-ai-microservices">NVIDIA ACE digital human platform</a> underscore NVIDIA’s commitment to AI accessibility.</p>
<p><a href="https://www.nvidia.com/en-us/geforce/news/g-assist-ai-assistant">Project G-Assist, an RTX-powered AI assistant technology demo</a>, was also announced, showcasing context-aware assistance for PC games and apps.</p>
<p>And Microsoft and NVIDIA are collaborating to help developers bring new generative AI capabilities to their Windows native and web apps with easy API access to RTX-accelerated SLMs that enable RAG capabilities that run on-device as part of Windows Copilot Runtime.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-large wp-image-71968" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4569-672x448.jpg" alt="" width="672" height="448" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4569-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4569-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4569-768x512.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4569-1536x1025.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4569-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4569-322x215.jpg 322w, https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4569-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4569-1280x854.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/06/2G8A4569.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /></p>
<h2>NVIDIA Robotics Adopted by Industry Leaders</h2>
<p>NVIDIA is spearheading the $50 trillion industrial digitization shift, with sectors embracing autonomous operations and digital twins — virtual models that enhance efficiency and cut costs. Through its Developer Program, NVIDIA offers access to NIM, fostering AI innovation.</p>
<p>Taiwanese manufacturers are transforming their factories using NVIDIA’s technology, with Huang showcasing Foxconn’s use of NVIDIA Omniverse, Isaac and Metropolis to create digital twins, combining vision AI and robot development tools for enhanced robotic facilities.</p>
<p>“The next wave of AI is physical AI. AI that understands the laws of physics, AI that can work among us,” Huang said, emphasizing the importance of robotics and AI in future developments.</p>
<p>The <a href="https://www.nvidia.com/en-us/industries/robotics/">NVIDIA Isaac platform</a> provides a robust toolkit for developers to build AI robots, including AMRs, industrial arms and humanoids, powered by AI models and supercomputers like Jetson Orin and Thor.</p>
<p>“Robotics is here. Physical AI is here. This is not science fiction, and it’s being used all over Taiwan. It’s just really, really exciting,” Huang added.</p>
<p><img loading="lazy" decoding="async" class="aligncenter wp-image-71986 size-large" src="https://blogs.nvidia.com/wp-content/uploads/2024/06/robots-computex-2024-672x449.jpg" alt="" width="672" height="449" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/06/robots-computex-2024-672x449.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/06/robots-computex-2024-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/06/robots-computex-2024-768x513.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/06/robots-computex-2024-1536x1026.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/06/robots-computex-2024-674x450.jpg 674w, https://blogs.nvidia.com/wp-content/uploads/2024/06/robots-computex-2024-322x215.jpg 322w, https://blogs.nvidia.com/wp-content/uploads/2024/06/robots-computex-2024-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/06/robots-computex-2024-1280x855.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/06/robots-computex-2024.jpg 2045w" sizes="(max-width: 672px) 100vw, 672px" /></p>
<p>Global electronics giants are integrating NVIDIA’s autonomous robotics into their factories, leveraging simulation in Omniverse to test and validate this new wave of AI for the physical world. This includes over 5 million preprogrammed robots worldwide.</p>
<p>“All the factories will be robotic. The factories will orchestrate robots, and those robots will be building products that are robotic,” Huang explained.</p>
<p>Huang emphasized NVIDIA Isaac’s role in boosting factory and warehouse efficiency, with global leaders like BYD Electronics, Siemens, Teradyne Robotics and Intrinsic adopting its advanced libraries and AI models.</p>
<p><a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> on the IGX platform, with partners like ADLINK, Advantech and ONYX, delivers edge AI solutions meeting strict regulatory standards, essential for medical technology and other industries.</p>
<p>Huang ended his keynote on the same note he began it on, paying tribute to Taiwan and NVIDIA’s many partners there. “Thank you,” Huang said. “I love you guys.”</p>
<p><iframe title="YouTube video player" src="https://www.youtube.com/embed/pKXDVsWZmUU?si=bYffxIwUxYMev6hK" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/earth-computex-2024-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1366"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/earth-computex-2024-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[‘Accelerate Everything,’ NVIDIA CEO Says Ahead of COMPUTEX]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>KServe Providers Dish Up NIMble Inference in Clouds and Data Centers</title>
		<link>https://blogs.nvidia.com/blog/kserve-nim-inference/</link>
		
		<dc:creator><![CDATA[Adam Tetelman]]></dc:creator>
		<pubDate>Sun, 02 Jun 2024 13:14:59 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[COMPUTEX 2024]]></category>
		<category><![CDATA[NVIDIA NIM]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71902</guid>

					<description><![CDATA[Deploying generative AI in the enterprise is about to get easier than ever. NVIDIA NIM, a set of generative AI inference microservices, works with KServe, open-source software that automates putting AI models to work at the scale of a cloud computing application. The combination ensures generative AI can be deployed like any other large enterprise	<a class="read-more" href="https://blogs.nvidia.com/blog/kserve-nim-inference/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Deploying generative AI in the enterprise is about to get easier than ever.</p>
<p><a href="https://www.nvidia.com/en-us/ai/" target="_blank" rel="noopener">NVIDIA NIM</a>, a set of generative AI inference microservices, works with <a href="https://kserve.github.io/website/latest/" target="_blank" rel="noopener">KServe</a>, open-source software that automates putting AI models to work at the scale of a cloud computing application.</p>
<p>The combination ensures <a href="https://www.nvidia.com/en-us/glossary/generative-ai/" target="_blank" rel="noopener">generative AI</a> can be deployed like any other large enterprise application. It also makes NIM widely available through platforms from dozens of companies, such as Canonical, Nutanix and Red Hat.</p>
<p>The integration of NIM on KServe extends NVIDIA’s technologies to the open-source community, ecosystem partners and customers. Through NIM, they can all access the performance, support and security of the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/" target="_blank" rel="noopener">NVIDIA AI Enterprise</a> software platform with an API call — the push-button of modern programming.</p>
<h2><b>Serving AI on Kubernetes</b></h2>
<p>KServe got its start as part of Kubeflow, a machine learning toolkit based on Kubernetes, the open-source system for deploying and managing software containers that hold all the components of large distributed applications.</p>
<p>As Kubeflow expanded its work on AI inference, what became KServe was born and ultimately evolved into its own open-source project.</p>
<p>Many companies have contributed to and adopted the KServe software that runs today at companies including AWS, Bloomberg, Canonical, Cisco, Hewlett Packard Enterprise, IBM, Red Hat, Zillow and NVIDIA.</p>
<h2><b>Under the Hood With KServe</b></h2>
<p>KServe is essentially an extension of Kubernetes that runs AI inference like a powerful cloud application. It uses a standard protocol, runs with optimized performance and supports PyTorch, Scikit-learn, TensorFlow and XGBoost without users needing to know the details of those AI frameworks.</p>
<p>The software is especially useful these days, when new large language models (<a href="https://www.nvidia.com/en-us/glossary/large-language-models/" target="_blank" rel="noopener">LLMs</a>) are emerging rapidly.</p>
<p>KServe lets users easily go back and forth from one model to another, testing which one best suits their needs. And when an updated version of a model gets released, a KServe feature called “canary rollouts” automates the job of carefully validating and gradually deploying it into production.</p>
<p>Another feature, GPU autoscaling, efficiently manages how models are deployed as demand for a service ebbs and flows, so customers and service providers have the best possible experience.</p>
<h2><b>An API Call to Generative AI</b></h2>
<p>The goodness of KServe is now available with the ease of NVIDIA NIM.</p>
<p>With NIM, a simple API call takes care of all the complexities. Enterprise IT admins get the metrics they need to ensure their application is running with optimal performance and efficiency, whether it’s in their data center or on a remote cloud service — even if they change the AI models they’re using.</p>
<p>NIM lets IT professionals become generative AI pros, transforming their company’s operations. That’s why a host of enterprises such as Foxconn and ServiceNow are <a href="https://nvidianews.nvidia.com/news/nvidia-nim-model-deployment-generative-ai-developers" target="_blank" rel="noopener">deploying NIM microservices</a>.</p>
<h2><b>NIM Rides Dozens of Kubernetes Platforms</b></h2>
<p>Thanks to its integration with KServe, users will be able access NIM on dozens of enterprise platforms such as Canonical’s Charmed KubeFlow and Charmed Kubernetes, <a href="https://ir.nutanix.com/news-releases/news-release-details/nutanix-and-nvidia-collaborate-accelerate-enterprise-ai-adoption" target="_blank" rel="noopener">Nutanix GPT-in-a-Box 2.0</a>, <a href="https://developers.redhat.com/articles/2024/03/15/empower-conversational-ai-scale-kserve" target="_blank" rel="noopener">Red Hat’s OpenShift AI</a> and many others.</p>
<p>“Red Hat has been working with NVIDIA to make it easier than ever for enterprises to deploy AI using open source technologies,” said KServe contributor Yuan Tang, a principal software engineer at Red Hat. “By enhancing KServe and adding support for NIM in Red Hat OpenShift AI, we’re able to provide streamlined access to NVIDIA’s generative AI platform for Red Hat customers.”</p>
<p>“Through the integration of NVIDIA NIM inference microservices with Nutanix GPT-in-a-Box 2.0, customers will be able to build scalable, secure, high-performance generative AI applications in a consistent way, from the cloud to the edge,” said the vice president of engineering at Nutanix, Debojyoti Dutta, whose team contributes to KServe and Kubeflow.</p>
<p>“As a company that also contributes significantly to KServe, we’re pleased to offer NIM through Charmed Kubernetes and Charmed Kubeflow,” said Andreea Munteanu, MLOps product manager at Canonical. “Users will be able to access the full power of generative AI, with the highest performance, efficiency and ease thanks to the combination of our efforts.”</p>
<p>Dozens of other software providers can feel the benefits of NIM simply because they include KServe in their offerings.</p>
<h2><b>Serving the Open-Source Community</b></h2>
<p>NVIDIA has a long track record on the KServe project. As noted in a <a href="https://developers.redhat.com/articles/2024/03/15/empower-conversational-ai-scale-kserve?extIdCarryOver=true&amp;sc_cid=701f2000001OH6fAAG" target="_blank" rel="noopener">recent technical blog</a>, KServe’s Open Inference Protocol is used in <a href="https://developer.nvidia.com/triton-inference-server" target="_blank" rel="noopener">NVIDIA Triton Inference Server</a>, which helps users run many AI models simultaneously across many GPUs, frameworks and operating modes.</p>
<p>With KServe, NVIDIA focuses on use cases that involve running one AI model at a time across many GPUs.</p>
<p>As part of the NIM integration, NVIDIA plans to be an active contributor to KServe, building on its portfolio of contributions to open-source software that includes Triton and <a href="https://github.com/NVIDIA/TensorRT-LLM" target="_blank" rel="noopener">TensorRT-LLM</a>. NVIDIA is also an active member of the <a href="https://www.cncf.io/" target="_blank" rel="noopener">Cloud Native Computing Foundation</a>, which supports open-source code for generative AI and other projects.</p>
<p>Try the NIM API on the <a href="https://www.nvidia.com/en-us/ai/" target="_blank" rel="noopener">NVIDIA API Catalog</a> using the <a href="https://build.nvidia.com/meta/llama3-8b" target="_blank" rel="noopener">Llama 3 8B</a> or <a href="https://build.nvidia.com/meta/llama3-70b" target="_blank" rel="noopener">Llama 3 70B</a> LLM models today. Hundreds of NVIDIA partners worldwide are using NIM to deploy generative AI.</p>
<p>Watch NVIDIA founder and CEO Jensen Huang’s <a href="https://www.nvidia.com/en-us/events/computex/" target="_blank" rel="noopener">COMPUTEX keynote</a> to get the latest on AI and more.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/NIM-Kubernetes-logos-1.jpg"
			type="image/jpeg"
			width="1409"
			height="749"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/NIM-Kubernetes-logos-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[KServe Providers Dish Up NIMble Inference in Clouds and Data Centers]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Taiwan Electronics Giants Drive Industrial Automation With NVIDIA Metropolis and NIM</title>
		<link>https://blogs.nvidia.com/blog/computex-metropolis-nim/</link>
		
		<dc:creator><![CDATA[Adam Scraba]]></dc:creator>
		<pubDate>Sun, 02 Jun 2024 13:12:33 +0000</pubDate>
				<category><![CDATA[Robotics]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[COMPUTEX 2024]]></category>
		<category><![CDATA[Industrial and Manufacturing]]></category>
		<category><![CDATA[Metropolis]]></category>
		<category><![CDATA[NVIDIA NIM]]></category>
		<category><![CDATA[Omniverse]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71878</guid>

					<description><![CDATA[Taiwan’s leading consumer electronics giants are making advances with AI automation for manufacturing, as fleets of robots and millions of cameras and sensors drive efficiencies across the smart factories of the future. Dozens of electronics manufacturing and automation specialists — including Foxconn, Pegatron and Wistron — are showcasing their use of the NVIDIA software at	<a class="read-more" href="https://blogs.nvidia.com/blog/computex-metropolis-nim/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Taiwan’s leading consumer electronics giants are making advances with AI automation for manufacturing, as fleets of robots and millions of cameras and sensors drive efficiencies across the smart factories of the future.</p>
<p>Dozens of electronics manufacturing and automation specialists — including Foxconn, Pegatron and Wistron — are showcasing their use of the NVIDIA software at COMPUTEX, in Taipei, and are called out in NVIDIA founder and CEO <a href="https://www.nvidia.com/en-us/events/computex/">Jensen Huang’s keynote address</a>.</p>
<p>Companies displayed the latest in computer vision and generative AI using <a href="https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/">NVIDIA Metropolis</a> for everything from automating product manufacturing to improving worker safety and device performance.</p>
<h2><b>Creating Factory Autonomy</b></h2>
<p>With increasing production challenges, manufacturers are seeing a need to turn factories into autonomous machines, with generative AI and digital twins as a foundation. AI agents — driven by large language models (LLMs) — are being built that can talk and assist on warehouse floors to boost productivity and increase safety. And digital twins are helping manufacturers simulate and develop factories and AI-powered automation before being deployed in real factories.</p>
<p>Foxconn and its Ingrasys subsidiary use <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> and Metropolis to build digital twins for factories, planning efficiency optimizations and worker safety improvement at a number of manufacturing sites. At COMPUTEX, Foxconn is showing how it uses digital twins to plan placements of many video cameras in factories to optimize its data capture for collecting key insights.</p>
<h2><b>Bringing Generative AI to the Factory Floor</b></h2>
<p>Generative AI is creating productivity leaps across industries. Researcher McKinsey forecasts that generative AI will deliver as much as $290 billion in value for the advanced manufacturing industry, while bringing $4.4 trillion annually to the global economy.</p>
<p>At GTC in March, NVIDIA launched <a href="https://www.nvidia.com/en-us/ai/">NVIDIA NIM</a>, a set of microservices designed to speed up generative AI deployment in enterprises. Supporting a wide range of AI models, it ensures seamless, scalable AI inferencing, on premises or in the cloud, using industry-standard application programming interfaces.</p>
<p>Billions of IoT devices worldwide can tap into Metropolis and NVIDIA NIM for improvements in AI perception to enhance their capabilities.</p>
<h2><b>Advancing Manufacturing With NVIDIA NIM</b></h2>
<p>Linker Vision, an AI vision insights specialist, is adopting NVIDIA NIM to assist factories in deploying AI agents that can respond to natural language queries.</p>
<p>The Taipei company uses <a href="https://www.nvidia.com/en-us/solutions/robotics-and-edge-computing/vision-ai/visual-insight-agent/">NVIDIA Visual Insight Agent</a> (VIA) in manufacturing environments for always-on video feed monitoring of factory floors. With user prompts, these ChatGPT-like systems can enable operators to ask for video of factory floors to be monitored for insights and safety alerts, like when workers are not wearing hardhats.</p>
<p>Operators can ask questions and receive instant, context-aware responses from AI agents, which can tap into organizational knowledge via <a href="https://www.nvidia.com/en-us/ai-data-science/ai-workflows/generative-ai-chatbots/">retrieval-augmented generation</a>, an integration of AI that can enhance operational efficiency.</p>
<p>Leading manufacturer Pegatron has factories that span more than 20 million square feet and the facilities process and build more than 15 million assemblies per month, while deploying more than 3,500 robots across factory floors. It has announced efforts based on NVIDIA NIM and is using <a href="https://developer.nvidia.com/blog/optimize-processes-for-large-spaces-with-a-multi-camera-tracking-workflow/">Metropolis multi-camera tracking reference workflows</a> to help with worker safety and productivity on factory lines. Pegatron’s workflow fuses digital twins in Omniverse and Metropolis real-time AI to better monitor and optimize operations.</p>
<h2><b>Boosting Automated Visual Inspections</b></h2>
<p>Adoption of NVIDIA Metropolis is helping Taiwan’s largest electronics manufacturers streamline operations and reduce cost as they build and inspect some of the world’s most complex and high-volume products.</p>
<p>Quality control with manual inspections in manufacturing is a multitrillion-dollar challenge. While automated optical inspection systems have been relied upon for some time, legacy AOI systems have high false detection rates, requiring costly secondary manual inspections for verification.</p>
<p><a href="https://developer.nvidia.com/metropolis-for-factories">NVIDIA Metropolis for Factories</a> offers a state-of-the-art AI reference workflow for bringing sophisticated and accurate AOI inspection applications to production faster.</p>
<p>TRI, Taiwan’s leading AOI equipment maker, has announced integrating NVIDIA Metropolis for Factories workflow and capabilities into its latest AOI systems and is also planning to use NVIDIA NIM to further optimize system performance.</p>
<p>Wistron is expanding its <a href="https://youtu.be/XlJMZ1rqSco">OneAI platform</a> for visual inspection and AOI with Metropolis. OneAI has been deployed in more than 10 Wistron factories globally, spanning hundreds of inspection points.</p>
<p><i>Learn about </i><a href="https://developer.nvidia.com/metropolis-for-factories"><i>NVIDIA Metropolis for Factories</i></a>,<i> </i><a href="https://www.nvidia.com/en-us/ai/"><i>NVIDIA NIM</i></a><i> and the </i><a href="https://developer.nvidia.com/blog/optimize-processes-for-large-spaces-with-a-multi-camera-tracking-workflow/"><i>NVIDIA Metropolis multi-camera tracking workflow</i></a>,<i> which developers can use to build state-of-the-art real-time locating services and worker safety into their factory or warehouse operations. </i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/isaac-robotics-computex24-blog-3261843-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/isaac-robotics-computex24-blog-3261843-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Taiwan Electronics Giants Drive Industrial Automation With NVIDIA Metropolis and NIM]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Foxconn Trains Robots, Streamlines Assembly With NVIDIA AI and Omniverse</title>
		<link>https://blogs.nvidia.com/blog/foxconn-digital-twin-ai/</link>
		
		<dc:creator><![CDATA[Madison Huang]]></dc:creator>
		<pubDate>Sun, 02 Jun 2024 13:02:56 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Robotics]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[COMPUTEX 2024]]></category>
		<category><![CDATA[Industrial and Manufacturing]]></category>
		<category><![CDATA[Isaac]]></category>
		<category><![CDATA[Omniverse]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71911</guid>

					<description><![CDATA[Foxconn operates more than 170 factories around the world — the latest one a virtual plant pushing the state of the art in industrial automation. It’s the digital twin of a new factory in Guadalajara, hub of Mexico’s electronics industry. Foxconn’s engineers are defining processes and training robots in this virtual environment, so the physical	<a class="read-more" href="https://blogs.nvidia.com/blog/foxconn-digital-twin-ai/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Foxconn operates more than 170 factories around the world — the latest one a virtual plant pushing the state of the art in industrial automation.</p>
<p>It’s the digital twin of a new factory in Guadalajara, hub of Mexico’s electronics industry. Foxconn’s engineers are defining processes and training robots in this virtual environment, so the physical plant can produce at high efficiency the next engine of accelerated computing, <a href="https://www.nvidia.com/en-us/data-center/hgx/">NVIDIA Blackwell HGX systems</a>.</p>
<p>To design an optimal assembly line, factory engineers need to find the best placement for dozens of robotic arms, each weighing hundreds of pounds. To accurately monitor the overall process, they situate thousands of sensors, including many networked video cameras in a matrix to show plant operators all the right details.</p>
<h2><b>Virtual Factories Create Real Savings</b></h2>
<p>Such challenges are why companies like Foxconn are increasingly creating <a href="https://blogs.nvidia.com/blog/virtual-factories-industrial-digitalization/">virtual factories</a> for simulation and testing.</p>
<p>“Our digital twin will guide us to new levels of automation and industrial efficiency, saving time, cost and energy,” said Young Liu, chairman of the company that last year had revenues of nearly $200 billion.</p>
<p>Based on its efforts so far, the company anticipates that it can increase the manufacturing efficiency of complex servers using the simulated plant, leading to significant cost savings and reducing kilowatt-hour usage by over 30% annually.</p>
<h2><b>Foxconn Teams With NVIDIA, Siemens</b></h2>
<p>Foxconn is building its digital twin with software from the Siemens Xcelerator portfolio including Teamcenter and <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a>, a platform for developing 3D workflows and applications based on <a href="https://www.nvidia.com/en-us/omniverse/usd/">OpenUSD</a>.</p>
<p>NVIDIA and Siemens <a href="https://blogs.nvidia.com/blog/siemens-immersive-visualization-generative-ai/">announced</a> in March that they will connect Siemens Xcelerator applications to <a href="https://www.nvidia.com/en-us/omniverse/cloud/">NVIDIA Omniverse Cloud</a> API microservices. Foxconn will be among the first to employ the combined services, so its digital twin is physically accurate and visually realistic.</p>
<p>Engineers will employ Teamcenter with Omniverse APIs to design robot work cells and assembly lines. Then they’ll use Omniverse to pull all the 3D CAD elements into one virtual factory where their robots will be trained with <a href="https://developer.nvidia.com/isaac/sim">NVIDIA Isaac Sim</a>.</p>
<h2><b>Robots Attend a Virtual School</b></h2>
<p>A growing set of manufacturers is building digital twins to streamline factory processes. Foxconn is among the first to take the next step in automation — training their AI robots in the digital twin.</p>
<p>Inside the Foxconn virtual factory, robot arms from manufacturers such as Epson can learn how to see, grasp and move objects with <a href="https://developer.nvidia.com/isaac/manipulator">NVIDIA Isaac Manipulator</a>, a collection of NVIDIA-accelerated libraries and AI foundation models for robot arms.</p>
<p>For example, the robot arms may learn how to pick up a Blackwell server and place it on an <a href="https://blogs.nvidia.com/blog/isaac-amr-nova-orin-autonomous-mobile-robots/">autonomous mobile robot</a> (AMR). The arms can use Isaac Manipulator&#8217;s cuMotion to find inspection paths for products, even when objects are placed in the way.</p>
<p>Foxconn’s AMRs, from Taiwan’s FARobot, will learn how to see and navigate the factory floor using <a href="https://developer.nvidia.com/isaac/perceptor">NVIDIA Perceptor</a>, software that helps them build a real-time 3D map that indicates any obstacles. The robot’s routes are generated and optimized by <a href="https://www.nvidia.com/en-us/ai-data-science/products/cuopt/">NVIDIA cuOpt</a>, a world-record holding route optimization microservice.</p>
<p>Unlike many transport robots that need to stick to carefully drawn lines on the factory floor, these smart AMRs will navigate around obstacles to get wherever they need to go.</p>
<p><iframe loading="lazy" title="Building Digital Twins of Foxconn’s Robotic Factories" width="500" height="281" src="https://www.youtube.com/embed/HjpwGgmt57U?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<h2><b>A Global Trend to Industrial Digitization</b></h2>
<p>The Guadalajara factory is just the beginning. Foxconn is starting to design digital twins of factories around the world, including one in Taiwan where it will manufacture electric buses.</p>
<p>Foxconn is also deploying <a href="https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/">NVIDIA Metropolis</a>, an application framework for smart cities and spaces, to give cameras on the shop floor AI-powered vision. That gives plant managers deeper insights into daily operations and opportunities to further streamline operations and improve worker safety.</p>
<p>With an estimated 10 million factories worldwide, the $46 trillion manufacturing sector is a rich field for industrial digitalization.</p>
<p>Delta Electronics, MediaTek, MSI and Pegatron are among other top <a href="https://nvidianews.nvidia.com/news/robotic-factories-industrial-digitalization-electronic-makers-ai-omniverse">electronics makers revealed at COMPUTEX</a> this week how they’re using NVIDIA AI and Omniverse to build digital twins of their factories.</p>
<p>Like Foxconn, they’re racing to make their factories more agile, autonomous and sustainable to serve the demand for more than a billion smartphones, PCs and servers a year.</p>
<p>A <a href="https://resources.nvidia.com/en-us-digital-twin-reference-architecture/ov-factory-digital-twin-reference-architecture">reference architecture</a> shows how to develop factory digital twins  with the NVIDIA AI and Omniverse platforms. And learn about <a href="https://resources.nvidia.com/en-us-digital-twins-article/omniverse-enterprise-2">the experiences</a> of five companies doing this work.</p>
<p><em>Watch NVIDIA founder and CEO Jensen Huang’s <a href="https://www.nvidia.com/en-us/events/computex/">COMPUTEX keynote</a> to get the latest on AI and more.</em></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/robotic-factory.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/robotic-factory-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Foxconn Trains Robots, Streamlines Assembly With NVIDIA AI and Omniverse]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Gen AI Healthcare Accelerated: Dozens of Companies Adopt Meta Llama 3 NIM</title>
		<link>https://blogs.nvidia.com/blog/llama-3-nim-healthcare-generative-ai/</link>
		
		<dc:creator><![CDATA[Brad Genereaux]]></dc:creator>
		<pubDate>Sun, 02 Jun 2024 12:30:52 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[COMPUTEX 2024]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[Inference]]></category>
		<category><![CDATA[NVIDIA NIM]]></category>
		<category><![CDATA[Social Impact]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71886</guid>

					<description><![CDATA[Meta Llama 3, Meta’s openly available state-of-the-art large language model — trained and optimized using NVIDIA accelerated computing — is dramatically boosting healthcare and life sciences workflows, helping deliver applications that aim to improve patients’ lives. Now available as a downloadable NVIDIA NIM inference microservice at ai.nvidia.com, Llama 3 is equipping healthcare developers, researchers and	<a class="read-more" href="https://blogs.nvidia.com/blog/llama-3-nim-healthcare-generative-ai/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Meta Llama 3, Meta’s openly available state-of-the-art large language model — trained and optimized using NVIDIA <a href="https://blogs.nvidia.com/blog/what-is-accelerated-computing/" target="_blank" rel="noopener">accelerated computing</a> — is dramatically boosting healthcare and life sciences workflows, helping deliver applications that aim to improve patients’ lives.</p>
<p>Now available as a downloadable <a href="https://www.nvidia.com/en-us/ai/" target="_blank" rel="noopener">NVIDIA NIM</a> inference microservice at <a href="http://ai.nvidia.com" target="_blank" rel="noopener">ai.nvidia.com</a>, Llama 3 is equipping healthcare developers, researchers and companies to innovate responsibly across a wide variety of applications. The NIM comes with a standard application programming interface that can be deployed anywhere.</p>
<p>For use cases spanning surgical planning and digital assistants to drug discovery and clinical trial optimization, developers can use Llama 3 to easily deploy optimized <a href="https://www.nvidia.com/en-us/glossary/generative-ai/" target="_blank" rel="noopener">generative AI</a> models for copilots, chatbots and more.</p>
<p>At <a href="https://www.nvidia.com/en-us/events/computex/" target="_blank" rel="noopener">COMPUTEX</a>, one of the world’s premier technology events, NVIDIA today announced that hundreds of AI ecosystem partners are embedding NIM into their solutions.</p>
<p>More than 40 of these adopters are healthcare and life sciences startups and enterprises using the Llama 3 NIM to build and run applications that accelerate digital biology, digital surgery and digital health.</p>
<h2><b>Advancing Digital Biology</b></h2>
<p>Techbio and pharmaceutical companies, along with life sciences platform providers, use NVIDIA NIM for generative biology, chemistry and molecular prediction. With the Llama 3 NIM for intelligent assistants and <a href="https://www.nvidia.com/en-us/clara/bionemo/" target="_blank" rel="noopener">NVIDIA BioNeMo</a> NIM microservices for digital biology, researchers can build and scale end-to-end workflows for drug discovery and clinical trials.</p>
<p><a href="https://www2.deloitte.com/us/en/pages/consulting/solutions/deloitte-nvidia-atlas-ai-for-drug-discovery.html" target="_blank" rel="nofollow noopener">Deloitte</a> is driving efficiency for garnering data-based insights from gene to function for research copilots, scientific research mining, chemical property prediction and drug repurposing with its Atlas AI drug discovery accelerator, powered by the NVIDIA BioNeMo, NeMo and Llama 3 NIM microservices.</p>
<p><a href="https://www.transcriptabio.com/" target="_blank" rel="nofollow noopener">Transcripta Bio</a> harnesses Llama 3 and BioNeMo for accelerated intelligent drug discovery. Its proprietary artificial intelligence modeling suite, Conductor AI, uses its Drug-Gene Atlas to help discover and predict the effects of new drugs at <a href="https://www.genome.gov/about-genomics/fact-sheets/Transcriptome-Fact-Sheet" target="_blank" rel="nofollow noopener">transcriptome</a> scale.</p>
<h2><b>Bolstering Clinical Trials</b></h2>
<p><a href="https://quantiphi.com/" target="_blank" rel="nofollow noopener">Quantiphi</a> — an AI-first digital engineering company and an Elite Service Delivery Partner in the <a href="https://www.nvidia.com/en-us/about-nvidia/partners/" target="_blank" rel="noopener">NVIDIA Partner Network</a> — is using NVIDIA NIM to develop generative AI solutions for clinical research and development, diagnostics and patient care. These innovations are enabling organizations to save substantial cost, enhance workforce productivity and improve patient outcomes.</p>
<p><a href="https://www.concertai.com/" target="_blank" rel="nofollow noopener">ConcertAI </a>is advancing a broad set of translational and clinical development solutions within its CARA AI platform. The company has integrated the Llama 3 NIM to support population-scale patient matching to clinical trials, study automation and research site copilots with real-time insights and model management for large-scale AI applications.</p>
<p><a href="https://www.mendel.ai/" target="_blank" rel="nofollow noopener">Mendel AI</a> is developing clinically focused AI solutions that can understand nuances in medical data at scale to provide actionable insights, with applications across clinical research, real-world evidence generation and cohort selection. It has deployed a fine-tuned Llama 3 NIM for its Hypercube copilot, offering a 36% performance improvement. Mendel is also exploring potential use cases with Llama 3 NIM to extract clinical information from patient records and to translate natural language into clinical queries.</p>
<h2><b>Improving Digital Surgery</b></h2>
<p>The operating room is bolstered by AI and the latest digital technologies, too.</p>
<p><a href="https://www.activsurgical.com/" target="_blank" rel="noopener">Activ Surgical</a> is using Llama 3 to accelerate development of its AI copilot and augmented-reality solution for real-time surgical guidance. The company’s ActivSight technology, which allows surgeons to view critical physiological structures and functions, aims to reduce surgical complication rates, improving patient care and safety.</p>
<h2><b>Enhancing Digital Health</b></h2>
<p>Generative AI-powered digital health applications enhance patient-doctor interactions, helping to improve patient outcomes and deliver more efficient healthcare.</p>
<p>Precision medicine company <a href="https://simbiosys.com/" target="_blank" rel="nofollow noopener">SimBioSys</a> recently downloaded the Llama 3 NIM to help analyze a breast cancer patient’s diagnosis and tailor guidance for the physician regarding the patient’s unique characteristics.</p>
<p><a href="https://artisight.com/" target="_blank" rel="nofollow noopener">Artisight</a>, a startup focused on smart hospital transformation, uses Llama 3 to automate documentation and care coordination in all its clinical locations with ambient voice and vision systems.</p>
<p><a href="https://www.linkedin.com/pulse/aitem-nvidia-nim-revolutionizing-veterinary-care-laika-y4eve/?trackingId=nH4tgIRb5LbQJxCwBCX%2F3A%3D%3D" target="_blank" rel="nofollow noopener">AITEM</a>, which offers medical and veterinary AI diagnostic solutions, is building healthcare-specific chatbots with the model.</p>
<p>And <a href="https://www.abridge.com/" target="_blank" rel="nofollow noopener">Abridge</a>, which offers a generative AI platform for clinical conversations, is using the NIM to build a physician-patient encounter summarization solution.</p>
<p>Transcripta Bio, Activ Surgical, SimBioSys, Artisight, AITEM and Abridge are all members of <a href="https://www.nvidia.com/startups/?nvid=nv-int-tblg-295718-vt33" target="_blank" rel="noopener">NVIDIA Inception</a>, a free program that helps startups evolve faster through cutting-edge technology, opportunities to connect with venture capitalists and access to the latest technical resources from NVIDIA.</p>
<p>The NVIDIA NIM collection of inference microservices is available with <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/" target="_blank" rel="noopener">NVIDIA AI Enterprise</a>, a software platform that streamlines development and deployment of production-grade copilots and other generative AI applications.</p>
<p><a href="http://ai.nvidia.com" target="_blank" rel="noopener"><i>Download the Meta Llama 3 NIM</i></a><i> now and learn more about how generative AI is reshaping healthcare and other industries by joining </i><a href="https://www.nvidia.com/en-us/events/computex/" target="_blank" rel="noopener"><i>NVIDIA at COMPUTEX</i></a><i>, running through June 7 in Taipei, Taiwan.</i></p>
<p><i><span>Watch NVIDIA founder and CEO Jensen Huang’s </span></i><a href="https://www.youtube.com/live/pKXDVsWZmUU?si=sYFHqkbGiiJZ8FXg"><i><span>COMPUTEX keynote</span></i></a><i><span> in replay:</span></i></p>
<p><iframe loading="lazy" title="NVIDIA CEO Jensen Huang Keynote at COMPUTEX 2024" width="500" height="281" src="https://www.youtube.com/embed/pKXDVsWZmUU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/healthcare-llama-3-nim-computex-1280x680-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/healthcare-llama-3-nim-computex-1280x680-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Gen AI Healthcare Accelerated: Dozens of Companies Adopt Meta Llama 3 NIM]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Putting More Tech to the Test, NVIDIA Certifies New Categories of Gen AI-Ready Systems</title>
		<link>https://blogs.nvidia.com/blog/nvidia-certified-systems-spectrum-x-igx/</link>
		
		<dc:creator><![CDATA[Anthony Larijani]]></dc:creator>
		<pubDate>Sun, 02 Jun 2024 12:30:41 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[COMPUTEX 2024]]></category>
		<category><![CDATA[Embedded Computing]]></category>
		<category><![CDATA[Hardware]]></category>
		<category><![CDATA[Industrial and Manufacturing]]></category>
		<category><![CDATA[NVIDIA NIM]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71870</guid>

					<description><![CDATA[Fueled by generative AI, enterprises globally are creating “AI factories,” where data comes in and intelligence comes out. Critical to this movement are validated systems and reference architectures that reduce the risk and time involved in deploying specialized infrastructure that can support complex, computationally intensive generative AI workloads. At the COMPUTEX trade show, NVIDIA today	<a class="read-more" href="https://blogs.nvidia.com/blog/nvidia-certified-systems-spectrum-x-igx/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Fueled by <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a>, enterprises globally are creating “AI factories,” where data comes in and intelligence comes out.</p>
<p>Critical to this movement are validated systems and reference architectures that reduce the risk and time involved in deploying specialized infrastructure that can support complex, computationally intensive generative AI workloads.</p>
<p>At the <a href="https://www.nvidia.com/en-us/events/computex/">COMPUTEX</a> trade show, NVIDIA today announced the expansion of its <a href="https://www.nvidia.com/en-us/data-center/products/certified-systems/">NVIDIA-Certified Systems</a> program, which designates leading partner systems as suited for AI and accelerated computing, so customers can confidently deploy these platforms from the data center to the edge.</p>
<p>Two new certification types are now included: NVIDIA-Certified <a href="https://www.nvidia.com/en-us/networking/spectrumx/">Spectrum-X</a> Ready systems for AI in the data center and NVIDIA-Certified <a href="https://www.nvidia.com/en-us/edge-computing/products/igx/">IGX</a> systems for AI at the edge.</p>
<p>Each NVIDIA-Certified System undergoes rigorous testing and is validated to provide enterprise-grade performance, manageability, security and scalability for <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> software workloads, including generative AI applications built with <a href="https://www.nvidia.com/en-us/ai/">NVIDIA NIM</a> inference microservices. The systems provide a trusted pathway to design and implement efficient, reliable infrastructure.</p>
<h2><b>NVIDIA-Certified Spectrum-X Ready Systems</b></h2>
<p>The world’s first Ethernet fabric built for AI, the NVIDIA Spectrum-X AI Ethernet platform combines the <a href="https://www.nvidia.com/en-us/networking/ethernet-switching/">NVIDIA Spectrum-4</a> SN5000 Ethernet switch series, <a href="https://www.nvidia.com/en-us/networking/products/data-processing-unit/">NVIDIA BlueField-3 SuperNICs</a> and <a href="https://www.nvidia.com/en-us/networking/ethernet-switching/">networking acceleration software</a> to deliver 1.6x AI networking performance over traditional Ethernet fabrics.</p>
<p>NVIDIA-Certified Spectrum-X Ready servers will act as building blocks for high-performance AI computing clusters and support powerful <a href="https://www.nvidia.com/en-us/data-center/technologies/hopper-architecture/" target="_blank" rel="noopener">NVIDIA Hopper architecture</a> and <a href="https://www.nvidia.com/en-us/data-center/l40s/" target="_blank" rel="noopener">NVIDIA L40S</a> GPUs.</p>
<h2><b>NVIDIA-Certified IGX Systems</b></h2>
<p><a href="https://www.nvidia.com/en-us/edge-computing/products/igx/" target="_blank" rel="noopener">NVIDIA IGX Orin</a> is an enterprise-ready AI platform for the industrial edge and medical applications that features industrial-grade hardware, a production-grade software stack and long-term enterprise support. It includes the latest technologies in device security, remote provisioning and management, along with built-in extensions, to deliver high-performance AI and proactive safety for low-latency, real-time applications in such areas as medical diagnostics, manufacturing, industrial robotics, agriculture and more.</p>
<h2><b>Expanding Partner Portfolio</b></h2>
<p>Top NVIDIA ecosystem partners are set to achieve the new certifications.</p>
<p>ASUS, Dell Technologies, GIGABYTE, Hewlett Packard Enterprise, Ingrasys, Lenovo, QCT and Supermicro will soon offer NVIDIA-Certified Spectrum-X Ready systems.</p>
<p>And NVIDIA-Certified IGX systems will soon be available from ADLINK, Advantech, Aetina, Ahead, Cosmo Intelligent Medical Devices (a division of Cosmo Pharmaceuticals), Dedicated Computing, Leadtek, Onyx and YUAN.</p>
<p><i>Learn more about </i><a href="https://www.nvidia.com/en-us/data-center/products/certified-systems/" target="_blank" rel="noopener"><i>NVIDIA-Certified Systems</i></a><i> and the latest generative AI technologies by joining </i><a href="https://www.nvidia.com/en-us/events/computex/" target="_blank" rel="noopener"><i>NVIDIA at COMPUTEX</i></a><i>.</i></p>
<p><i><span>Watch NVIDIA founder and CEO Jensen Huang’s </span></i><i><span>COMPUTEX keynote</span></i><i><span> in replay:</span></i></p>
<p><iframe loading="lazy" title="NVIDIA CEO Jensen Huang Keynote at COMPUTEX 2024" width="500" height="281" src="https://www.youtube.com/embed/pKXDVsWZmUU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/nv-certified-computex-1280x680-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/nv-certified-computex-1280x680-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Putting More Tech to the Test, NVIDIA Certifies New Categories of Gen AI-Ready Systems]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Leading Medical Centers in Taiwan Adopt NVIDIA Accelerated Computing to Advance Biomedical Research</title>
		<link>https://blogs.nvidia.com/blog/medical-taiwan/</link>
		
		<dc:creator><![CDATA[Kimberly Powell]]></dc:creator>
		<pubDate>Sun, 02 Jun 2024 12:30:28 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[COMPUTEX 2024]]></category>
		<category><![CDATA[Healthcare and Life Sciences]]></category>
		<category><![CDATA[NVIDIA DGX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71922</guid>

					<description><![CDATA[Taiwan’s leading medical centers — the National Health Research Institute (NHRI) and Chang Gung Memorial Hospital (CGMH) — are set to advance biomedical research and healthcare for patients. The centers are embracing accelerated computing and generative AI for everything from imaging to enhancing patient care, from streamlining clinical workflows to drug discovery research. “The use	<a class="read-more" href="https://blogs.nvidia.com/blog/medical-taiwan/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Taiwan’s leading medical centers — the National Health Research Institute (NHRI) and Chang Gung Memorial Hospital (CGMH) — are set to advance biomedical research and healthcare for patients.</p>
<p>The centers are embracing accelerated computing and generative AI for everything from imaging to enhancing patient care, from streamlining clinical workflows to drug discovery research.</p>
<p>“The use of AI in healthcare will fundamentally change the way we approach disease prevention and treatment,” said Dr. Hung-Yi Chiou, director of the Institute of Population Health Sciences (IPHS) at NHRI. “With AI’s ability to analyze vast amounts of data quickly and accurately, we can develop personalized medicine strategies and early intervention methods that were previously unattainable.”</p>
<p>“The future of AI in healthcare is incredibly promising,” said Dr. Wen-Jin Cherng at CGMH.</p>
<p>With the assistance of AI in smart healthcare, future diagnoses will become more accurate, treatment plans will have better predictions and patients will experience faster recovery, Dr. Cherng explained. And in complex analytical processes, AI can enable more efficient and cost-effective decision-making in healthcare, he added.</p>
<p>“The transformative potential of the NVIDIA Blackwell platform allows us to integrate advanced AI capabilities into our medical practices, enhancing patient care and streamlining clinical workflows like never before,” he said.</p>
<p>NHRI, the leading medical research institution in Taiwan, plays a crucial role in advancing public health through biomedical research and innovation. The integration of NVIDIA accelerated computing into its IT infrastructure marks a significant leap forward in the realm of AI-driven healthcare.</p>
<p>NHRI’s collaboration with NVIDIA also extends to the development of large language models tailored specifically for Taiwan’s healthcare needs.</p>
<p>“Traditional Chinese medical records and genomic data present unique challenges that require localized solutions,” said Dr. Feng-Chi Chen, deputy director of IPHS at the NHRI.</p>
<p>These challenges include the complexity of language variations and the need for precise genomic interpretations specific to Taiwan’s population, Dr. Chen explained.</p>
<p>“NVIDIA accelerated computing enables us to create these solutions, ensuring that our healthcare system remains at the cutting edge of medical research,” he said.</p>
<p>CGMH, one of the largest healthcare systems in Taiwan, operates a network of 10 hospitals with a combined inpatient capacity of over 11,000 beds. It also serves millions of people in outpatient services. It’s a cornerstone of Taiwan’s healthcare system, which is one of the most advanced in the world.</p>
<p>“With the computational power of Blackwell, we can expand our language model services to all hospitals under our umbrella, enhancing professional support, patient care and streamlining clinical workflows,” said Dr. Chang-Fu Kuo, director of the AI center at CGMH. “It addresses the needs of various medical disciplines and diverse patient populations, enabling healthcare professionals to focus on critical clinical tasks and ultimately improve patient outcomes.”</p>
<h2>NHRI, CGMH Pioneering Medical AI</h2>
<p>NHRI currently uses six <a href="https://www.nvidia.com/en-us/data-center/dgx-platform">NVIDIA DGX A100 systems</a> for cloud and data center services, focusing on biomedical model training and genomic analysis.</p>
<p>By harnessing the power of NVIDIA accelerated computing, NHRI is also tackling pressing public health issues. One of its key projects involves using AI to predict the risk of chronic diseases such as diabetes and cardiovascular conditions by analyzing a multitude of genetic and environmental parameters.</p>
<p>“This level of analysis was previously unattainable due to computational constraints,” said Dr. Chen. “Now, with the power of NVIDIA accelerated computing, we will be able to offer more accurate risk assessments and preventative strategies.”</p>
<p>CGMH also has a diverse array of NVIDIA hardware, including NVIDIA H100, A100, and other Tensor Core GPUs, which it uses for medical imaging development and deployment. The foundation serves 46 models daily and intends to use Blackwell for LLM training and the deployment of service robots in hospitals.</p>
<p>Running these systems on premises and keeping the data within the hospital’s infrastructure are key to ensuring patient data privacy as well as faster data processing and reduced latency, said Dr. Chihung Lin, deputy director of the CGMH AI center.</p>
<p>These technologies may be used in various medical applications, including:</p>
<ul>
<li><b>Clinical Decision Support System:</b> Developed on premises to ensure patient data confidentiality and privacy, this system assists clinicians by providing access to up-to-date data and guidelines and using models to answer questions and prepare medical decisions.</li>
<li><b>Patient Interaction System:</b> Allows patients to interact with a robot to get answers about their medication and medical conditions, reducing the burden on medical staff. Medical staff review the robot’s responses to ensure accuracy.</li>
<li><b>Medical Imaging:</b> Enhances radiology and other imaging tasks using AI. This project is one of the most mature AI technologies in CGMH’s healthcare system.</li>
<li><b>Precision Medicine:</b> Handles large-scale genomic data and transforms sequences into readable medical reports for doctors. Focused on building computational facilities to support whole genome and exome sequencing.</li>
<li><b>Expansion of AI Services:</b> Aims to extend the language model services to all hospitals under CGMH’s umbrella, leveraging the computational capacity from the Blackwell platform to support this expansion.</li>
</ul>
<p>Other applications include early detection of colorectal cancer via endoscopy, autoimmune disease screening through microscope images and kidney disease prediction using general imaging techniques.</p>
<p>NHRI and CGMH’s adoption of accelerated computing underscores the growing importance of AI and advanced computing in medical research and healthcare delivery.</p>
<p>With these tools, Taiwan is poised to make strides in improving patient outcomes and advancing biomedical science.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/ngc-press-nvidia-gemma-1920x1080-1-1.jpg"
			type="image/jpeg"
			width="1920"
			height="1080"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/ngc-press-nvidia-gemma-1920x1080-1-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Leading Medical Centers in Taiwan Adopt NVIDIA Accelerated Computing to Advance Biomedical Research]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Power Tool: Generative AI Tracks Typhoons, Tames Energy Use</title>
		<link>https://blogs.nvidia.com/blog/weather-forecast-corrdiff/</link>
		
		<dc:creator><![CDATA[Dion Harris]]></dc:creator>
		<pubDate>Sun, 02 Jun 2024 11:43:30 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Software]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Climate]]></category>
		<category><![CDATA[COMPUTEX 2024]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71915</guid>

					<description><![CDATA[Weather forecasters in Taiwan had their hair blown back when they saw a typhoon up close, created on a computer that slashed the time and energy needed for the job. It’s a reaction that users in many fields are feeling as generative AI shows them how new levels of performance contribute to reductions in total	<a class="read-more" href="https://blogs.nvidia.com/blog/weather-forecast-corrdiff/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Weather forecasters in Taiwan had their hair blown back when they saw a typhoon up close, created on a computer that slashed the time and energy needed for the job.</p>
<p>It’s a reaction that users in many fields are feeling as <a href="https://www.nvidia.com/en-us/glossary/generative-ai/" target="_blank" rel="noopener">generative AI</a> shows them how new levels of performance contribute to reductions in total cost of ownership.</p>
<h2><b>Inside the AI of the Storm</b></h2>
<p>Tracking a typhoon provided a great test case of generative AI’s prowess. The work traditionally begins with clusters of CPUs cranking on complex algorithms to create atmospheric models with a 25-kilometer resolution.</p>
<p>Enter <a href="https://arxiv.org/abs/2309.15214" target="_blank" rel="noopener">CorrDiff</a>, a generative AI model that’s part of <a href="https://www.nvidia.com/en-us/high-performance-computing/earth-2/" target="_blank" rel="noopener">NVIDIA Earth-2</a>, a set of services and software for weather and climate research.</p>
<p>Using a class of diffusion models that power today’s text-to-image services, CorrDiff resolved the <a href="https://resources.nvidia.com/en-us-energy-efficiency/energy-efficiency-solution-brief-weather-prediction">25-km models to two kilometers 1,000x faster, using 3<b>,</b>000x less energy</a> for a single inference than traditional methods.</p>
<h2><b>CorrDiff Cuts Costs 50x, Energy Use 25x</b></h2>
<p>CorrDiff shines on the NVIDIA AI platform, even when retraining the model once a year and using statistical groups of a thousand forecasts to boost the accuracy of predictions. Compared to traditional methods under these conditions, it slashes cost by 50x cost and energy use by 25x a year.</p>
<p>That means work that used to require nearly $3 million for a cluster of CPUs and the energy to run them can be done for about $60,000 on a single system with an <a href="https://www.nvidia.com/en-us/data-center/h100/" target="_blank" rel="noopener">NVIDIA H100 Tensor Core GPU</a>. It’s a massive reduction that shows how generative AI and <a href="https://blogs.nvidia.com/blog/what-is-accelerated-computing/" target="_blank" rel="noopener">accelerated computing</a> increases energy efficiency and lowers total cost of ownership.</p>
<p>The technology also helps forecasters see more precisely where a typhoon will land, potentially saving lives.</p>
<p>“NVIDIA’s CorrDiff generative AI model opens the door to the use of AI-generated kilometer-scale weather forecasts, enabling Taiwan to prepare better for typhoons,” said Hongey Chen, a director of Taiwan’s National Science and Technology Center for Disaster Reduction.</p>
<p>The Taiwan forecasters could save nearly a gigawatt-hour a year, using CorrDiff. Energy savings could balloon if the nearly 200 regional weather data centers around the world adopt the technology for more <a href="https://www.nvidia.com/en-us/data-center/sustainable-computing/" target="_blank" rel="noopener">sustainable computing</a>.</p>
<p>Companies that sell commercial forecasts are <a href="https://blogs.nvidia.com/blog/generative-ai-science-isc/" target="_blank" rel="noopener">also adopting CorrDiff</a>, attracted by its speed and savings.</p>
<h2><b>Broad Horizons for Energy Efficiency</b></h2>
<p>NVIDIA Earth-2 takes these capabilities to a planetary scale. It fuses AI, physics simulations and observed data to help countries and companies respond to global issues like climate change. That will help address the impacts of climate change, which is expected to cost a million lives and $1.7 trillion per year by 2050.</p>
<p>Accelerated computing and generative AI are bringing new levels of performance and energy efficiency to many applications. Explainers on <a href="https://blogs.nvidia.com/blog/what-is-green-computing/" target="_blank" rel="noopener">green computing</a> and why <a href="https://blogs.nvidia.com/blog/why-gpus-are-great-for-ai/" target="_blank" rel="noopener">GPUs are great for AI</a> provide more context and some examples.</p>
<p>Compare the costs and energy consumption of popular workloads running on an x86 CPU-based server versus an NVIDIA GPU server with <a href="https://www.nvidia.com/en-us/data-center/sustainable-computing/energy-efficiency-calculator/" target="_blank" rel="noopener">this simple calculator</a>. And watch Huang’s <a href="https://www.nvidia.com/en-us/events/computex/" target="_blank" rel="noopener">keynote address</a> at COMPUTEX to get the big picture.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/taiwan-typhoon-corrdiff.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/06/taiwan-typhoon-corrdiff-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Power Tool: Generative AI Tracks Typhoons, Tames Energy Use]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Grace Hopper Superchip Accelerates Murex MX.3 Analytics Performance, Reduces Power Consumption</title>
		<link>https://blogs.nvidia.com/blog/grace-hopper-murex-mx-3/</link>
		
		<dc:creator><![CDATA[Prabhu Ramamoorthy]]></dc:creator>
		<pubDate>Fri, 31 May 2024 15:00:58 +0000</pubDate>
				<category><![CDATA[Accelerated Analytics]]></category>
		<category><![CDATA[GPU Computing]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71839</guid>

					<description><![CDATA[After the 2008 financial crisis and increased risk-management regulations that followed, Pierre Spatz anticipated banks would focus on reducing computing expenses. As head of quantitative research at Murex, a trading and risk management software company based in Paris, Spatz adopted NVIDIA’s CUDA and GPU-accelerated computing, aiming for top performance and energy efficiency. Always seeking the	<a class="read-more" href="https://blogs.nvidia.com/blog/grace-hopper-murex-mx-3/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>After the 2008 financial crisis and increased risk-management regulations that followed, Pierre Spatz anticipated banks would focus on reducing computing expenses.</p>
<p>As head of quantitative research at Murex, a trading and risk management software company based in Paris, Spatz adopted NVIDIA’s CUDA and GPU-accelerated computing, aiming for top performance and energy efficiency.</p>
<p>Always seeking the latest technologies, the company’s quants team has begun trials of the <a href="https://www.nvidia.com/en-us/data-center/grace-hopper-superchip/">NVIDIA Grace Hopper Superchip</a>. The effort is focused on helping customers better price and manage credit and market risk exposures of derivatives contracts.</p>
<p>More than 60,000 daily users in 65 countries rely on the Murex MX.3 platform. MX.3 assists banks, asset managers, pension funds and other financial institutions with their trading, risk and operations across asset classes.</p>
<h2><b>Managing Risk With MX.3 Driven by Grace Hopper</b></h2>
<p>Financial institutions need high-performance computing infrastructure to run risk models on vast amounts of data for pricing and risk calculations, and to deliver real-time decision-making capabilities.</p>
<p>MX.3 coverage includes both credit and market risk, BASEL capital standards, fundamental review of the trading book and x-valuation adjustment (XVA). XVA is used for different types of valuation adjustments related to derivative contracts, such as the credit value adjustment (CVA), the margin value adjustment and the funding valuation adjustment.</p>
<p>Murex is testing Grace Hopper on the MX.3 platform for XVA calculations, as well as for market risk calibration, pricing evaluation, sensitivity, and profit and loss calculations on various asset classes.</p>
<p>Grace Hopper offers faster calculation as well as power savings to the Murex platform.</p>
<p>“On counterparty credit risk workloads such as CVA, Grace Hopper is the perfect fit, leveraging a heterogeneous architecture with a unique mix of CPU and GPU computations,” Spatz said. “On risk calculations, Grace is not only the fastest processor, but also far more power-efficient, making green IT a reality in the trading world.”</p>
<p>When running XVA workloads in MX.3, the Murex research and development lab has noticed Grace Hopper can offer a 4x reduction in energy consumption and a 7x performance improvement compared with CPU-based systems.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-1-002.jpg"><img loading="lazy" decoding="async" class="aligncenter wp-image-71879" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-1-002-400x270.jpg" alt="" width="400" height="270" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-1-002-400x270.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-1-002-672x454.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-1-002-768x519.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-1-002-666x450.jpg 666w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-1-002-318x215.jpg 318w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-1-002-148x100.jpg 148w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-1-002.jpg 1027w" sizes="(max-width: 400px) 100vw, 400px" /></a></p>
<h2><b>Pricing FX Barrier Options in MX.3 With Grace Hopper </b></h2>
<p>To price foreign exchange (FX) barrier options, Murex has used its flagship and latest stochastic local volatility model and also noticed impressive performance improvements when running on Grace Hopper. A barrier option is a derivative with a payoff that relies on whether its underlying asset price reaches or crosses a specified threshold during the span of the option contract.</p>
<p>The pricing evaluation is done with a 2D partial differential equation, which is more cost-effective on the Arm-based NVIDIA Grace CPU in GH200. Pricing this derivative with MX.3 on Grace Hopper goes 2.3x faster compared with Intel Xeon Gold 6148.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-2-002.jpg"><img loading="lazy" decoding="async" class="aligncenter wp-image-71883" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-2-002-400x253.jpg" alt="" width="400" height="253" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-2-002-400x253.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-2-002-672x424.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-2-002-768x485.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-2-002-712x450.jpg 712w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-2-002-340x215.jpg 340w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-2-002-158x100.jpg 158w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-2-002.jpg 904w" sizes="(max-width: 400px) 100vw, 400px" /></a></p>
<p>The NVIDIA Grace CPU also offers significant power efficiencies for FX barrier calculations on a watts-per-server basis, and it’s 5x better.</p>
<p><a href="https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-3-002.jpg"><img loading="lazy" decoding="async" class="aligncenter wp-image-71887" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-3-002-400x267.jpg" alt="" width="400" height="267" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-3-002-400x267.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-3-002-672x448.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-3-002-675x450.jpg 675w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-3-002-322x215.jpg 322w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-3-002-150x100.jpg 150w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Murex-Blog_Figure-3-002.jpg 760w" sizes="(max-width: 400px) 100vw, 400px" /></a></p>
<p>NVIDIA’s next-generation accelerated computing platform is driving energy efficiency and cost-saving for high-performance computing for quantitative analytics in capital markets, says Murex, pointing to the results above.</p>
<p><i>Learn about NVIDIA AI solutions for </i><a href="https://www.nvidia.com/en-us/industries/finance/"><i>financial services</i></a><i>. </i></p>
<p>&nbsp;</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/finance-tech-blog-murex-1920x1080-1.jpg"
			type="image/jpeg"
			width="1920"
			height="1080"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/finance-tech-blog-murex-1920x1080-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Grace Hopper Superchip Accelerates Murex MX.3 Analytics Performance, Reduces Power Consumption]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Elevate Your Expertise: NVIDIA Introduces AI Infrastructure and Operations Training and Certification</title>
		<link>https://blogs.nvidia.com/blog/ai-infrastructure-operations-training-certification/</link>
		
		<dc:creator><![CDATA[Ann Sheridan]]></dc:creator>
		<pubDate>Thu, 30 May 2024 15:00:23 +0000</pubDate>
				<category><![CDATA[Deep Learning]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Education]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71841</guid>

					<description><![CDATA[NVIDIA has introduced a self-paced course, called AI Infrastructure and Operations Fundamentals, to provide enterprise professionals with essential training on the infrastructure and operational aspects of AI and accelerated computing.  From enhancing speech recognition systems to powering self-driving cars, AI is transforming everyday life. The new course explains how to deploy and manage scalable infrastructure	<a class="read-more" href="https://blogs.nvidia.com/blog/ai-infrastructure-operations-training-certification/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><span data-contrast="auto">NVIDIA has introduced a self-paced course</span><span data-contrast="auto">,</span><span data-contrast="auto"> called </span><a href="https://academy.nvidia.com/en/course/ai-infrastructure-operations-fundamentals/?cm=64727&amp;nvid=nv-int-tblg-131693" target="_blank" rel="noopener"><i><span data-contrast="none">AI Infrastructure and Operations Fundamentals</span></i></a><i><span data-contrast="auto">,</span></i><span data-contrast="auto"> to provide enterprise professionals with essential training on the infrastructure and operational aspects of AI and accelerated computing.</span><span data-ccp-props="{}"> </span></p>
<p><span data-contrast="auto">From enhancing speech recognition systems to powering self-driving cars, AI is transforming everyday life. The new course explains how to deploy and manage scalable infrastructure to support AI-based solutions, helping IT pros realize AI’s potential and stay competitive in the rapidly changing technological landscape.</span><span data-ccp-props="{}"> </span></p>
<h2><b><span data-contrast="auto">Course Overview </span></b><span data-ccp-props="{}"> </span></h2>
<p><span data-contrast="auto">The course is ideal for anyone seeking to expand their knowledge of AI and its applications. It was created and taught by NVIDIA experts with real-world experience and deep technical domain expertise.</span></p>
<p><span data-contrast="auto">The course is divided into three modules. The first, </span><i><span data-contrast="auto">Introduction to AI</span></i><span data-contrast="none">, </span><span data-contrast="auto">covers foundational AI concepts and principles. Learners will:  </span><span data-ccp-props="{}"> </span></p>
<ul>
<li data-leveltext="o" data-font="Courier New" data-listid="1" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:1490,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Courier New&quot;,&quot;469769242&quot;:[9675],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;o&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="1" data-aria-level="2"><span data-contrast="auto">Discover how AI is being applied in various sectors</span><span data-contrast="auto">,</span><span data-contrast="auto"> to drive innovation and efficiency </span><span data-ccp-props="{&quot;335559685&quot;:630,&quot;335559991&quot;:270}"> </span></li>
<li data-leveltext="o" data-font="Courier New" data-listid="1" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:1490,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Courier New&quot;,&quot;469769242&quot;:[9675],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;o&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="1" data-aria-level="2"><span data-contrast="auto">Trace the progression of AI from basic machine learning to advanced deep learning to generative AI — and learn how each phase unlocked new capabilities </span><span data-ccp-props="{&quot;335559685&quot;:630,&quot;335559991&quot;:270}"> </span></li>
<li data-leveltext="o" data-font="Courier New" data-listid="1" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:1490,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Courier New&quot;,&quot;469769242&quot;:[9675],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;o&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="3" data-aria-level="2"><span data-contrast="auto">Explore how GPUs revolutionized AI, providing the computational power necessary for complex AI tasks </span><span data-ccp-props="{&quot;335559685&quot;:630,&quot;335559991&quot;:270}"> </span></li>
<li data-leveltext="o" data-font="Courier New" data-listid="1" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:1490,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Courier New&quot;,&quot;469769242&quot;:[9675],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;o&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="4" data-aria-level="2"><span data-contrast="auto">Understand the importance of a robust software stack in ensuring optimal performance and efficiency </span><span data-ccp-props="{&quot;335559685&quot;:630,&quot;335559991&quot;:270}"> </span></li>
<li data-leveltext="o" data-font="Courier New" data-listid="1" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:1490,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Courier New&quot;,&quot;469769242&quot;:[9675],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;o&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="5" data-aria-level="2"><span data-contrast="auto">Delve into the environments where AI workloads operate, whether on premises or in the cloud </span><span data-ccp-props="{&quot;335559685&quot;:630,&quot;335559991&quot;:270}"> </span></li>
</ul>
<p><i><span data-contrast="auto">AI Infrastructure</span></i><span data-contrast="none">, </span><span data-contrast="auto">the second module</span><span data-contrast="auto">,</span><span data-contrast="auto"> dives into the critical infrastructure components that support AI operations. Learners will: </span><span data-ccp-props="{}"> </span></p>
<ul>
<li data-leveltext="o" data-font="Courier New" data-listid="1" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:1490,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Courier New&quot;,&quot;469769242&quot;:[9675],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;o&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="6" data-aria-level="2"><span data-contrast="auto">Gain knowledge about the hardware that powers AI, including the latest advancements in compute platforms, networking and storage  </span><span data-ccp-props="{&quot;335559685&quot;:630,&quot;335559991&quot;:270}"> </span></li>
<li data-leveltext="o" data-font="Courier New" data-listid="1" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:1490,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Courier New&quot;,&quot;469769242&quot;:[9675],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;o&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="7" data-aria-level="2"><span data-contrast="auto">Explore practices that reduce data center carbon footprints and energy usage</span><span data-ccp-props="{&quot;335559685&quot;:630,&quot;335559991&quot;:270}"> </span></li>
<li data-leveltext="o" data-font="Courier New" data-listid="1" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:1490,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Courier New&quot;,&quot;469769242&quot;:[9675],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;o&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="8" data-aria-level="2"><span data-contrast="auto">Discover how reference architectures can serve as a foundation for building the most effective AI designs </span><span data-ccp-props="{&quot;335559685&quot;:630,&quot;335559991&quot;:270}"> </span></li>
<li data-leveltext="o" data-font="Courier New" data-listid="1" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:1490,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Courier New&quot;,&quot;469769242&quot;:[9675],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;o&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="9" data-aria-level="2"><span data-contrast="auto">Evaluate the benefits of transitioning from on-premises data centers to cloud-based solutions </span><span data-ccp-props="{&quot;335559685&quot;:630,&quot;335559991&quot;:270}"> </span></li>
</ul>
<p><i><span data-contrast="auto">AI Operations</span></i><span data-contrast="auto">, </span><span data-contrast="auto">the final module</span><span data-contrast="auto">,</span><span data-contrast="auto"> focuses on the practical aspect of managing AI infrastructure. Learners will: </span><span data-ccp-props="{}"> </span></p>
<ul>
<li data-leveltext="o" data-font="Courier New" data-listid="1" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:1490,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Courier New&quot;,&quot;469769242&quot;:[9675],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;o&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="1" data-aria-level="2"><span data-contrast="auto">Gain insights into the tools and techniques that enable effective infrastructure management and monitoring </span><span data-ccp-props="{&quot;335559685&quot;:630,&quot;335559991&quot;:270}"> </span></li>
<li data-leveltext="o" data-font="Courier New" data-listid="1" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:1490,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Courier New&quot;,&quot;469769242&quot;:[9675],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;o&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="2" data-aria-level="2"><span data-contrast="auto">Learn about orchestrating AI clusters and scheduling tasks to maximize performance and resource efficiency </span><span data-ccp-props="{&quot;335559685&quot;:630,&quot;335559991&quot;:270}"> </span></li>
</ul>
<h2><b><span data-contrast="auto">Certification: AI Infrastructure and Operations Associate </span></b><span data-ccp-props="{}"> </span></h2>
<p><span data-contrast="auto">Alongside the course, NVIDIA offers a new </span><a href="https://www.nvidia.com/en-us/learn/certification/ai-infrastructure-operations-associate/?nvid=nv-int-tblg-138971" target="_blank" rel="noopener"><span data-contrast="none">AI Infrastructure and Operations associate certification</span></a><span data-contrast="none">.</span><span data-contrast="auto"> This entry-level credential validates knowledge of the foundational con</span><span data-contrast="none">cept</span><span data-contrast="auto">s of adopting AI computing with NVIDIA solutions. Topics covered in this exam include:</span><span data-ccp-props="{}"> </span></p>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="1" data-aria-level="1"><span data-contrast="auto">Accelerated computing use cases</span><span data-ccp-props="{}"> </span></li>
<li data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="2" data-aria-level="1"><span data-contrast="auto">AI, machine learning and deep learning</span><span data-ccp-props="{}"> </span></li>
<li data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="3" data-aria-level="1"><span data-contrast="auto">GPU architecture</span><span data-ccp-props="{}"> </span></li>
<li data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="4" data-aria-level="1"><span data-contrast="auto">NVIDIA’s software suite</span><span data-ccp-props="{}"> </span></li>
<li data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" data-aria-posinset="5" data-aria-level="1"><span data-contrast="auto">Infrastructure and operation considerations for adopting NVIDIA solutions</span><span data-ccp-props="{}"> </span></li>
</ul>
<p><span data-contrast="auto">Whether attendees want to enhance existing skills, support projects, advance career paths</span><span data-contrast="auto">,</span><span data-contrast="auto"> or embark on a new professional trajectory, this AI course and certification will further the knowledge and skills needed to excel in using AI.</span><span data-ccp-props="{}"> </span></p>
<p><span data-contrast="auto">Learn more about this </span><a href="https://www.nvidia.com/en-us/learn/learning-path/dgx-data-center/?nvid=nv-int-tblg-390056" target="_blank" rel="noopener"><span data-contrast="none">training and certification</span></a><span data-contrast="none">.</span><span data-contrast="auto"> </span><span data-ccp-props="{}"> </span></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/nvt-blog-nca-aiio-exam-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/nvt-blog-nca-aiio-exam-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Elevate Your Expertise: NVIDIA Introduces AI Infrastructure and Operations Training and Certification]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>GeForce NOW Brings the Heat With ‘World of Warcraft’</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-world-of-warcraft/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 30 May 2024 13:00:17 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71843</guid>

					<description><![CDATA[World of Warcraft comes to the cloud this week, part of the 17 games joining the GeForce NOW library, with seven available to stream this week. Plus, it’s time to get rewarded. Get a free in-game mount in Elder Scrolls Online starting today by opting into GeForce NOW’s Rewards program. Heroes Rise to the Cloud	<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-world-of-warcraft/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><i>World of Warcraft </i>comes to the cloud this week, part of the 17 games joining the <a href="http://play.geforcenow.com">GeForce NOW library</a>, with seven available to stream this week.</p>
<p>Plus, it’s time to get rewarded. Get a free in-game mount in <i>Elder Scrolls Online</i> starting today by opting into <a href="https://www.nvidia.com/en-us/geforce-now/rewards/">GeForce NOW’s Rewards program</a>.</p>
<h2><b>Heroes Rise to the Cloud</b></h2>
<p>Dive into the immersive realms of <i>World of Warcraft, </i>including the latest expansion<i> Dragonflight, </i>the nostalgic journey of <i>World of Warcraft Classic</i> and the recently launched <i>World of Warcraft Cataclysm Classic</i>. These popular, massively multiplayer, online role-playing experiences from Blizzard Entertainment immerse players in legendary battles.</p>
<figure id="attachment_71862" aria-describedby="caption-attachment-71862" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71862" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/image-34-672x378.png" alt="World of Warcraft: Dragonflight on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/image-34-672x378.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/image-34-400x225.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/image-34-768x432.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/image-34-1536x864.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/image-34.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/05/image-34-800x450.png 800w, https://blogs.nvidia.com/wp-content/uploads/2024/05/image-34-382x215.png 382w, https://blogs.nvidia.com/wp-content/uploads/2024/05/image-34-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/05/image-34-1280x720.png 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71862" class="wp-caption-text"><em>Dragonriders fly best in the cloud.</em></figcaption></figure>
<p>Embark on a journey of endless adventure in the rich and dynamic universe of Azeroth in the latest modern expansion, <i>World of Warcraft: Dragonflight</i>. The expansive landscapes of the Dragon Isles are available to explore — even on the back of a fearsome dragon. The newly awakened Dracthyr Evokers are also available, <i>World of Warcraft</i>’s first-ever playable race-and-class combo. GeForce NOW Priority and Ultimate members can get immersed in the cinematic gameplay with support for RTX ON.</p>
<figure id="attachment_71859" aria-describedby="caption-attachment-71859" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71859" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Cataclysm_Classic_Azeroth_Aflame_Key_Art-672x415.jpg" alt="World of Warcraft Cataclysm Classic on GeForce NOW" width="672" height="415" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/Cataclysm_Classic_Azeroth_Aflame_Key_Art-672x415.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Cataclysm_Classic_Azeroth_Aflame_Key_Art-400x247.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Cataclysm_Classic_Azeroth_Aflame_Key_Art-768x474.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Cataclysm_Classic_Azeroth_Aflame_Key_Art-1536x948.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Cataclysm_Classic_Azeroth_Aflame_Key_Art-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Cataclysm_Classic_Azeroth_Aflame_Key_Art-729x450.jpg 729w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Cataclysm_Classic_Azeroth_Aflame_Key_Art-348x215.jpg 348w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Cataclysm_Classic_Azeroth_Aflame_Key_Art-162x100.jpg 162w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Cataclysm_Classic_Azeroth_Aflame_Key_Art-1280x790.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71859" class="wp-caption-text"><em>Witness the return of Deathwing.</em></figcaption></figure>
<p>Face the return of Deathwing the Destroyer, whose violent emergence shatters and reshapes the continent of Azeroth. Journey into an era of fire and destruction in <i>World of Warcraft Cataclysm Classic</i> and usher in a new era for Azeroth. The updated game brings new dungeons and raids, fresh race and class combinations, and more.</p>
<figure id="attachment_71856" aria-describedby="caption-attachment-71856" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71856" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/WoW_Classic_Molten_Core_3840x2160-1-672x378.jpg" alt="World of Warcraft Classic on GeForce NOW" width="672" height="378" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/WoW_Classic_Molten_Core_3840x2160-1-672x378.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/WoW_Classic_Molten_Core_3840x2160-1-400x225.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/WoW_Classic_Molten_Core_3840x2160-1-768x432.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/WoW_Classic_Molten_Core_3840x2160-1-1536x864.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/WoW_Classic_Molten_Core_3840x2160-1-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/05/WoW_Classic_Molten_Core_3840x2160-1-800x450.jpg 800w, https://blogs.nvidia.com/wp-content/uploads/2024/05/WoW_Classic_Molten_Core_3840x2160-1-382x215.jpg 382w, https://blogs.nvidia.com/wp-content/uploads/2024/05/WoW_Classic_Molten_Core_3840x2160-1-178x100.jpg 178w, https://blogs.nvidia.com/wp-content/uploads/2024/05/WoW_Classic_Molten_Core_3840x2160-1-1280x720.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71856" class="wp-caption-text"><em>Azeroth awaits.</em></figcaption></figure>
<p>Whether a seasoned adventurer or a newcomer to the game, head to the Azeroth of yesteryear in <i>World of Warcraft Classic</i> and relive the experience of the game as it was upon its initial launch, with a few new upgrades. Explore the Eastern Kingdoms and Kalimdor, venture into iconic dungeons or engage in legendary player-vs-player battles.</p>
<p>Experience it all with a <a href="http://geforcenow.com">GeForce NOW membership</a>, which means no waiting for downloads or games to update, even for the upcoming <i>World of Warcraft</i> expansion <i>The War Within</i>.</p>
<h2><b>Mount Up</b></h2>
<p>GeForce NOW members get access to rewards that enhance the gaming experience. This week <a href="https://blogs.nvidia.com/blog/geforce-now-thursday-elder-scrolls-online-japan-expansion-april-games-list/"><i>The Elder Scrolls Online</i></a> 10-year celebration continues with an in-game reward for GeForce NOW members.</p>
<figure id="attachment_71853" aria-describedby="caption-attachment-71853" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71853" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-eso-reward-tw-li-2048x1024-1-672x336.jpg" alt="New member reward on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-eso-reward-tw-li-2048x1024-1-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-eso-reward-tw-li-2048x1024-1-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-eso-reward-tw-li-2048x1024-1-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-eso-reward-tw-li-2048x1024-1-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-eso-reward-tw-li-2048x1024-1-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-eso-reward-tw-li-2048x1024-1-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-eso-reward-tw-li-2048x1024-1-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-eso-reward-tw-li-2048x1024-1-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-eso-reward-tw-li-2048x1024-1.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71853" class="wp-caption-text"><em>Manes flow freely in the cloud.</em></figcaption></figure>
<p>Mounts offer a great way to travel the world and provide a completely different experience to traveling on foot. This new free reward provides members with a trusty companion beyond the starter option. The mount has a sunny disposition, matching its vibrant, multihued coat. It’s an excellent horse for a new rider or one who regularly ventures into treacherous situations.</p>
<p>Members can claim their free mount starting today by opting into rewards and checking their email for instructions on how to redeem. Ultimate and Priority members can redeem starting today, while free members will be able to claim it starting May 31. It’s available until June 30, first come first served.</p>
<h2><b>New Games, Assemble!</b></h2>
<figure id="attachment_71850" aria-describedby="caption-attachment-71850" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71850" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-capes-tw-li-2048x1024-1-672x336.jpg" alt="Capes on GeForce NOW" width="672" height="336" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-capes-tw-li-2048x1024-1-672x336.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-capes-tw-li-2048x1024-1-400x200.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-capes-tw-li-2048x1024-1-768x384.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-capes-tw-li-2048x1024-1-1536x768.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-capes-tw-li-2048x1024-1-842x421.jpg 842w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-capes-tw-li-2048x1024-1-406x203.jpg 406w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-capes-tw-li-2048x1024-1-188x94.jpg 188w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-capes-tw-li-2048x1024-1-1280x640.jpg 1280w, https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-spotlight-capes-tw-li-2048x1024-1.jpg 2048w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71850" class="wp-caption-text"><em>Turn-based strategy with a superhero twist.</em></figcaption></figure>
<p>Build a team of heroes and fight to take back the city in <i>Capes</i>, a turn-based strategy game from Daedlic Entertainment. Recruit, train and deploy a team to take back the city from the villains that hold it hostage. Level up heroes to gain access to new abilities and powerful upgrades — plus, each hero gains a unique team-up ability from each of their allies.</p>
<p>Check out the full list of new games this week:</p>
<ul>
<li><i>The Rogue Prince of Persia</i> (New release on <a href="https://store.steampowered.com/app/2717880?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 27)</li>
<li><i>Capes </i>(New release on <a href="https://store.steampowered.com/app/2081080?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 29)</li>
<li><i>Lords of the Fallen </i>(New release on Xbox, available on PC Game Pass, May 30)</li>
<li><i>Soulmask </i>(New release on <a href="https://store.steampowered.com/app/2646460?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 31)</li>
<li><i>World of Warcraft: Dragonflight</i> (<a href="https://shop.battle.net/family/world-of-warcraft?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
<li><i>World of Warcraft Classic </i>(<a href="https://us.shop.battle.net/en-us/family/world-of-warcraft-classic?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
<li><i>World of Warcraft Cataclysm Classic </i>(<a href="https://us.shop.battle.net/en-us/family/world-of-warcraft-classic?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now">Battle.net</a>)</li>
</ul>
<p>And members can look for the following later this month:<i></i></p>
<ul>
<li><i>Autopsy Simulator </i>(New release on <a href="https://store.steampowered.com/app/1283230?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, June 6)</li>
<li><i>Chornobyl Liquidators</i> (New release on <a href="https://store.steampowered.com/app/1113010?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, June 6)</li>
<li><i>SunnySide </i>(New release on <a href="https://store.steampowered.com/app/1746930?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, June 14)</li>
<li><i>Still Wakes the Deep </i>(New release on <a href="https://store.steampowered.com/app/1622910?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.xbox.com/games/store/1622910?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass, June 18)</li>
<li><i>Disney Speedstorm </i>(<a href="https://store.steampowered.com/app/1537830?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.xbox.com/games/store/disney-speedstorm/9pmr3t9nsf8w?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
<li><i>Farm Together 2 </i>(<a href="https://store.steampowered.com/app/2418520?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Resident Evil Village </i>(<a href="https://store.steampowered.com/app/1196590?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Star Traders: Frontiers </i>(<a href="https://store.steampowered.com/app/335620?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Street Fighter 6</i> (<a href="https://store.steampowered.com/app/1364780?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Torque Drift 2 </i>(<a href="https://www.epicgames.com/store/p/torque-drift-2-b08765?utm_source=nvidia&amp;utm_campaign=geforce_now">Epic Games Store</a>)</li>
</ul>
<h2><b>More to May</b></h2>
<p>In addition to the 24 games announced last month, four more joined the <a href="http://play.geforcenow.com">GeForce NOW library</a>:<i></i></p>
<ul>
<li><i>Senua’s Saga: Hellblade II</i> (New release on <a href="https://store.steampowered.com/app/2461850?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.xbox.com/games/store/senuas-saga-hellblade-ii/9pmbb7nghv95?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass, May 21)</li>
<li><i>Serum</i> (New release on <a href="https://store.steampowered.com/app/1610520?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 23)</li>
<li><i>Palworld </i>(<a href="https://store.steampowered.com/app/1623730?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, and <a href="https://www.xbox.com/en-us/games/store/palworld-game-preview/9nkv34xdw014">Xbox</a>, available on PC Game Pass)</li>
<li><i>Tomb Raider: Definitive Edition</i> (<a href="https://www.xbox.com/games/store/tomb-raider-definitive-edition/bqxts0sx4w0n?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass)</li>
</ul>
<p><i>Gestalt</i>, <i>Norland</i> and <i>Sunnyside</i> have delayed their launch dates to later this year. Stay tuned to GFN Thursday for updates.</p>
<p>From Tamriel to Teyvet, Night City to Sanctuary, GeForce NOW brings the world of PC gaming to nearly any device. Share your favorite gaming destinations all month long using #GreetingsFromGFN for a chance to be featured on the @NVIDIAGFN channels.</p>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below.</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">What’s an MMO that has taken over your life at one point in time? <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/2694.png" alt="⚔" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1795847572793274591?ref_src=twsrc%5Etfw">May 29, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-thursday-5-30-nv-blog-1280x680-no-cta.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-thursday-5-30-nv-blog-1280x680-no-cta-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[GeForce NOW Brings the Heat With ‘World of Warcraft’]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Riding the Wayve of AV 2.0, Driven by Generative AI</title>
		<link>https://blogs.nvidia.com/blog/wayve-generative-ai/</link>
		
		<dc:creator><![CDATA[Norm Marks]]></dc:creator>
		<pubDate>Wed, 29 May 2024 16:24:31 +0000</pubDate>
				<category><![CDATA[Driving]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Inception]]></category>
		<category><![CDATA[NVIDIA DRIVE]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71805</guid>

					<description><![CDATA[Generative AI is propelling AV 2.0, a new era in autonomous vehicle technology characterized by large, unified, end-to-end AI models capable of managing various aspects of the vehicle stack, including perception, planning and control. London-based startup Wayve is pioneering this new era, developing autonomous driving technologies that can be built on NVIDIA DRIVE Orin and	<a class="read-more" href="https://blogs.nvidia.com/blog/wayve-generative-ai/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Generative AI is propelling AV 2.0, a new era in autonomous vehicle technology characterized by large, unified, end-to-end AI models capable of managing various aspects of the vehicle stack, including perception, planning and control.</p>
<p>London-based startup Wayve is pioneering this new era, developing autonomous driving technologies that can be built on <a href="https://www.nvidia.com/en-us/self-driving-cars/in-vehicle-computing/" target="_blank" rel="noopener">NVIDIA DRIVE Orin</a> and its successor NVIDIA DRIVE Thor, which uses the <a href="https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/" target="_blank" rel="noopener">NVIDIA Blackwell GPU architecture</a> designed for <a href="https://blogs.nvidia.com/blog/what-is-a-transformer-model/" target="_blank" rel="noopener">transformer</a>, <a href="https://www.nvidia.com/en-us/glossary/large-language-models/" target="_blank" rel="noopener">large language model</a> (LLM) and <a href="https://www.nvidia.com/en-us/glossary/data-science/generative-ai/" target="_blank" rel="noopener">generative AI</a> workloads.</p>
<p>In contrast to AV 1.0’s focus on refining a vehicle’s perception capabilities using multiple deep neural networks, AV 2.0 calls for comprehensive in-vehicle intelligence to drive decision-making in dynamic, real-world environments.</p>
<p><iframe loading="lazy" title="Wayve and NVIDIA: Developing AI Foundation Models for Autonomous Driving" width="500" height="281" src="https://www.youtube.com/embed/kx-JJhrs3sU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Wayve, a member of the <a href="https://www.nvidia.com/startups/?nvid=nv-int-tblg-295718-vt33" target="_blank" rel="noopener">NVIDIA Inception</a> program for cutting-edge startups, specializes in developing AI foundation models for autonomous driving, equipping vehicles with a “robot brain” that can learn from and interact with their surroundings.</p>
<p>“NVIDIA has been the oxygen of everything that allows us to train AI,” said Alex Kendall, cofounder and CEO of Wayve. “We train on NVIDIA GPUs, and the software ecosystem NVIDIA provides allows us to iterate quickly — this is what enables us to build billion-parameter models trained on petabytes of data.”</p>
<p>Generative AI also plays a key role in Wayve’s development process, enabling <a href="https://blogs.nvidia.com/blog/what-is-synthetic-data/" target="_blank" rel="noopener">synthetic data generation</a> so AV makers can use a model’s previous experiences to create and simulate novel driving scenarios.</p>
<p>The company is building embodied AI, a set of technologies that integrate advanced AI into vehicles and robots to transform how they respond to and learn from human behavior, enhancing safety.</p>
<p>Wayve recently announced its Series C investment round — with participation from NVIDIA — that will support the development and launch of the first embodied AI products for production vehicles. As Wayve’s core AI model advances, these products will enable manufacturers to efficiently upgrade cars to higher levels of driving automation, from <a href="https://blogs.nvidia.com/blog/whats-difference-level-2-level-5-autonomy/" target="_blank" rel="noopener">L2+ assisted driving to L4 automated driving</a>.</p>
<p>As part of its embodied AI development, Wayve launched GAIA-1, a generative AI model for autonomy that creates realistic driving videos using video, text and action inputs. It also launched LINGO-2, a driving model that links vision, language and action inputs to explain and determine driving behavior.</p>
<p>“One of the neat things about generative AI is that it allows you to combine different modes of data seamlessly,” Kendall said. “You can bring in the knowledge of all the texts, the general purpose reasoning and capabilities that we get from LLMs and apply that reasoning to driving — this is one of the more promising approaches that we know of to be able to get to true generalized autonomy and eventually L5 capabilities on the road.”</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/wayve.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/wayve-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Riding the Wayve of AV 2.0, Driven by Generative AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Decoding How NVIDIA RTX AI PCs and Workstations Tap the Cloud to Supercharge Generative AI</title>
		<link>https://blogs.nvidia.com/blog/ai-decoded-rtx-pc-hybrid/</link>
		
		<dc:creator><![CDATA[Jesse Clayton]]></dc:creator>
		<pubDate>Wed, 29 May 2024 13:00:53 +0000</pubDate>
				<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[AI Decoded]]></category>
		<category><![CDATA[Artficial Intelligence]]></category>
		<category><![CDATA[GeForce]]></category>
		<category><![CDATA[NVIDIA NIM]]></category>
		<category><![CDATA[NVIDIA RTX]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71827</guid>

					<description><![CDATA[Generative AI is enabling new capabilities for Windows applications and games. It’s powering unscripted, dynamic NPCs, it’s enabling creators to generate novel works of art, and it’s helping gamers boost frame rates by up to 4x.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><i>Editor’s note: This post is part of the </i><a href="https://blogs.nvidia.com/blog/tag/ai-decoded/"><i>AI Decoded series</i></a><i>, which demystifies AI by making the technology more accessible, and showcases new hardware, software, tools and accelerations for GeForce RTX PC and RTX workstation users.</i></p>
<p><a href="https://www.nvidia.com/en-us/glossary/generative-ai/">Generative AI</a> is enabling new capabilities for Windows applications and games. It’s powering unscripted, dynamic NPCs, it’s enabling creators to generate novel works of art, and it’s helping gamers boost frame rates by up to 4x. But this is just the beginning.</p>
<p>As the capabilities and use cases for generative AI continue to grow, so does the demand for compute to support it.</p>
<p>Hybrid AI combines the onboard AI acceleration of <a href="https://www.nvidia.com/en-us/design-visualization/technologies/rtx/">NVIDIA RTX</a> with scalable, cloud-based GPUs to effectively and efficiently meet the demands of AI workloads.</p>
<h2><b>Hybrid AI, a Love Story</b></h2>
<p>With growing AI adoption, app developers are looking for deployment options: AI running locally on RTX GPUs delivers high performance and low latency, and is always available — even when not connected to the internet. On the other hand, AI running in the cloud can run larger models and scale across many GPUs, serving multiple clients simultaneously. In many cases, a single application will use both.</p>
<p>Hybrid AI is a kind of matchmaker that harmonizes local PC and workstation compute with cloud scalability. It provides the flexibility to optimize AI workloads based on specific use cases, cost and performance. It helps developers ensure that AI tasks run where it makes the most sense for their specific applications.</p>
<p>Whether the AI is running locally or in the cloud it gets accelerated by NVIDIA GPUs and NVIDIA’s AI stack, including TensorRT and TensorRT-LLM. That means less time staring at pinwheels of death and more opportunity to deliver cutting-edge, AI powered features to users.</p>
<p>A range of NVIDIA tools and technologies support hybrid AI workflows for creators, gamers, and developers.</p>
<h2><b>Dream in the Cloud, Bring to Life on RTX</b></h2>
<p>Generative AI has demonstrated its ability to help artists ideate, prototype and brainstorm new creations. One such solution, the cloud-based <a href="https://www.istockphoto.com/ai">Generative AI by iStock</a> — powered by <a href="https://www.nvidia.com/en-us/gpu-cloud/picasso/">NVIDIA Edify</a> — is a generative photography service that was built for and with artists, training only on licensed content and with compensation for artist contributors.</p>
<p>Generative AI by iStock goes beyond image generation, providing artists with extensive tools to explore styles, variations, modify parts of an image or expand the canvas. With all these tools, artists can ideate numerous times and still bring ideas to life quickly.</p>
<p>Once the creative concept is ready, artists can bring it back to their local systems. RTX-powered PCs and workstations offer artists AI acceleration in more than 125 of the top creative apps to realize the full vision — whether it’s creating an amazing piece of artwork in Photoshop with local AI tools, animating the image with a parallax effect in DaVinci Resolve, or building a 3D scene with the reference image in Blender with ray tracing acceleration, and AI denoising in Optix.</p>
<h2><b>Hybrid ACE Brings NPCs to Life</b></h2>
<p>Hybrid AI is also enabling a <a href="https://blogs.nvidia.com/blog/ai-decoded-ace-microservices-digital-humans/">new realm of interactive PC gaming</a> with <a href="https://developer.nvidia.com/ace">NVIDIA ACE</a>, allowing game developers and digital creators to integrate state-of-the-art generative AI models into digital avatars on RTX AI PCs.</p>
<p><iframe loading="lazy" title="NVIDIA ACE | NVIDIA x Inworld AI - Pushing the Boundaries of Game Characters in Covert Protocol" width="500" height="281" src="https://www.youtube.com/embed/uryeFhnNzEs?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Powered by AI neural networks, <a href="https://developer.nvidia.com/ace">NVIDIA ACE</a> lets developers and designers create non-playable characters (NPCs) that can understand and respond to human player text and speech. It leverages AI models, including speech-to-text models to handle natural language spoken aloud, to generate NPCs’ responses in real time.</p>
<h2><b>A Hybrid Developer Tool That Runs Anywhere</b></h2>
<p>Hybrid also helps developers build and tune new AI models. <a href="https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/workbench/">NVIDIA AI Workbench</a> helps developers quickly create, test and customize pretrained generative AI models and LLMs on RTX GPUs. It offers streamlined access to popular repositories like Hugging Face, GitHub and <a href="https://catalog.ngc.nvidia.com/?filters=&amp;orderBy=weightPopularDESC&amp;query=&amp;page=&amp;pageSize=">NVIDIA NGC</a>, along with a simplified user interface that enables data scientists and developers to easily reproduce, collaborate on and migrate projects.</p>
<p><iframe loading="lazy" title="NVIDIA AI Workbench | Fine Tuning Generative AI" width="500" height="281" src="https://www.youtube.com/embed/ntMRzPzSvM4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>Projects can be easily scaled up when additional performance is needed — whether to the data center, a public cloud or <a href="https://www.nvidia.com/en-us/data-center/dgx-cloud/">NVIDIA DGX Cloud</a> — and then brought back to local RTX systems on a PC or workstation for inference and light customization. Data scientists and developers can leverage pre-built Workbench projects to chat with documents using retrieval-augmented generation (<a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/">RAG</a>), customize LLMs using fine-tuning, accelerate data science workloads with seamless CPU-to-GPU transitions and more.</p>
<p>The <a href="https://github.com/NVIDIA/workbench-example-hybrid-rag">Hybrid RAG Workbench project</a> provides a customizable RAG application that developers can run and adapt themselves. They can embed their documents locally and run inference either on a local RTX system, a cloud endpoint hosted on <a href="http://ai.nvidia.com">NVIDIA’s API catalog</a> or using <a href="http://ai.nvidia.com">NVIDIA NIM</a> microservices. The project can be adapted to use various models, endpoints and containers, and provides the ability for developers to quantize models to run on their GPU of choice.</p>
<p>NVIDIA GPUs power remarkable AI solutions locally on <a href="https://www.nvidia.com/en-us/geforce/rtx/">NVIDIA GeForce RTX</a> PCs and RTX workstations and in the cloud. Creators, gamers and developers can get the best of both worlds with growing hybrid AI workflows.</p>
<p><i>Generative AI is transforming gaming, videoconferencing and interactive experiences of all kinds. Make sense of what’s new and what’s next by subscribing to the </i><a href="https://www.nvidia.com/en-us/ai-on-rtx/?modal=subscribe-ai"><i>AI Decoded newsletter</i></a><i>.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/hybrid-nv-blog-1280x680-1.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/hybrid-nv-blog-1280x680-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Decoding How NVIDIA RTX AI PCs and Workstations Tap the Cloud to Supercharge Generative AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Tidy Tech: How Two Stanford Students Are Building Robots for Handling Household Chores</title>
		<link>https://blogs.nvidia.com/blog/stanford-students-robots-household-chores/</link>
		
		<dc:creator><![CDATA[Kristen Yee]]></dc:creator>
		<pubDate>Wed, 29 May 2024 13:00:16 +0000</pubDate>
				<category><![CDATA[Robotics]]></category>
		<category><![CDATA[The AI Podcast]]></category>
		<category><![CDATA[Omniverse]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71821</guid>

					<description><![CDATA[Imagine having a robot that could help you clean up after a party — or fold heaps of laundry. Chengshu Eric Li and Josiah David Wong, two Stanford University Ph.D. students advised by renowned American computer scientist Professor Fei-Fei Li, are making that a ‌dream come true. In this episode of the AI Podcast, host	<a class="read-more" href="https://blogs.nvidia.com/blog/stanford-students-robots-household-chores/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Imagine having a robot that could help you clean up after a party — or fold heaps of laundry. Chengshu Eric Li and Josiah David Wong, two Stanford University Ph.D. students advised by renowned American computer scientist Professor Fei-Fei Li, are making that a ‌dream come true. In this episode of the <a href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">AI Podcast</a>, host Noah Kravitz spoke with the two about their project, BEHAVIOR-1K, which aims to enable robots to perform 1,000 household chores, including picking up fallen objects or cooking. To train the robots, they’re using the <a href="https://www.nvidia.com/en-us/omniverse/" target="_blank" rel="noopener">NVIDIA Omniverse platform</a>, as well as reinforcement and imitation learning techniques. Listen to hear more about the breakthroughs and challenges Li and Wong experienced along the way.</p>
<p><iframe loading="lazy" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1832461098%3Fsecret_token%3Ds-syNAqY6PTo6&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true" width="100%" height="166" frameborder="no" scrolling="no"></iframe></p>
<div style="font-size: 10px; color: #cccccc; line-break: anywhere; word-break: normal; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif; font-weight: 100;"><a style="color: #cccccc; text-decoration: none;" title="The AI Podcast" href="https://soundcloud.com/theaipodcast" target="_blank" rel="noopener">The AI Podcast</a> · <a style="color: #cccccc; text-decoration: none;" title="How Two Stanford Students Are Building Robots for Handling Household Chores - Ep. 219" href="https://soundcloud.com/theaipodcast/household-robots/s-syNAqY6PTo6" target="_blank" rel="noopener">How Two Stanford Students Are Building Robots for Handling Household Chores &#8211; Ep. 219</a></div>
<p>Stay tuned for more AI Podcast episodes recorded live from GTC.</p>
<h2><b>Time Stamps</b></h2>
<p><span>3:33: Background on the BEHAVIOR-1K project</span></p>
<p><span>5:00: Why use a simulated environment to train robots? </span></p>
<p><span>6:48: Why build a new simulation engine instead of using an existing one? </span></p>
<p><span>10:48: The process of training the robots to perform household chores</span></p>
<p><span>14:04: Some of the most complex tasks taught to the robots</span></p>
<p><span>19:07: How are large language models and large vision models affecting the progress of robotics?</span></p>
<p><span>24:09: What’s next for the project?  </span></p>
<h2>You Might Also Like…</h2>
<p><a href="https://soundcloud.com/theaipodcast/ai-llm" target="_blank" rel="noopener"><b>NVIDIA’s Annalamai Chockalingam on the Rise of LLMs &#8211; Ep. 206</b></a></p>
<p>Generative AI and large language models (LLMs) are stirring change across industries — but according to NVIDIA Senior Product Manager of Developer Marketing Annamalai Chockalingam, “we’re still in the early innings.” In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Chockalingam about LLMs: what they are, their current state and their future potential.</p>
<p><a href="https://soundcloud.com/theaipodcast/ai-stroller" target="_blank" rel="noopener"><b>How GluxKind Created Ella, the AI-Powered Smart Stroller &#8211; Ep. 193</b><b><br />
</b><br />
</a>Imagine a stroller that can drive itself, help users up hills, brake on slopes and provide alerts of potential hazards. That’s what GlüxKind has done with Ella, an award-winning smart stroller that uses the NVIDIA Jetson edge AI and robotics platform to power its AI features.</p>
<p><a href="https://soundcloud.com/theaipodcast/gantheftauto-harrison-kinsley-on-ai-generated-gaming-environments" target="_blank" rel="noopener"><b>GANTheftAuto: Harrison Kinsley on AI-Generated Gaming Environments &#8211; Ep. 151</b></a></p>
<p>Machines have long played games &#8211; think of Deep Blue or AlphaGo. Now they&#8217;re building them. GANTheftAuto creator Harrison Kinsley talks about his creation on the latest episode of the AI Podcast.</p>
<p><a href="https://soundcloud.com/theaipodcast/nvidia-liila-torabi" target="_blank" rel="noopener"><b>NVIDIA’s Liila Torabi Talks the New Era of Robotics Through Isaac Sim &#8211; Ep. 147</b></a></p>
<p>Robots are not just limited to the assembly line. At NVIDIA, Liila Torabi works on making the next generation of robotics possible. Torabi is the senior product manager for Isaac Sim, a robotics and AI simulation platform powered by NVIDIA Omniverse. Torabi spoke with NVIDIA AI Podcast host Noah Kravitz about the new era of robotics, one driven by making robots smarter through AI.</p>
<h2>Subscribe to the AI Podcast</h2>
<p>Get the <a href="https://blogs.nvidia.com/ai-podcast/">AI Podcast</a> through <a href="https://itunes.apple.com/us/podcast/the-ai-podcast/id1186480811?mt=2&amp;adbsc=social_20161220_68874946&amp;adbid=811257941365882882&amp;adbpl=tw&amp;adbpr=61559439">iTunes</a>, <a href="https://play.google.com/music/listen?u=0#/ps/I4kyn74qfrsdhrm35mcrf3igxzm">Google Play</a>, <a href="https://music.amazon.com/podcasts/956857d0-9461-4496-a07e-24be0539ee82/the-ai-podcast">Amazon Music,</a> <a href="https://castbox.fm/channel/The-AI-Podcast-id433488?country=us">Castbox</a>, DoggCatcher, <a href="https://overcast.fm/itunes1186480811/the-ai-podcast">Overcast</a>, <a href="https://player.fm/series/the-ai-podcast">PlayerFM</a>, Pocket Casts, <a href="http://www.podbay.fm/show/1186480811">Podbay</a>,<a href="https://www.podbean.com/podcast-detail/cjgnp-4a6e0/The-AI-Podcast"> PodBean</a>, PodCruncher, PodKicker, <a href="https://soundcloud.com/theaipodcast">Soundcloud</a>, <a href="https://open.spotify.com/show/4TB4pnynaiZ6YHoKmyVN0L">Spotify</a>, <a href="http://www.stitcher.com/s?fid=130629&amp;refid=stpr">Stitcher</a> and <a href="https://tunein.com/podcasts/Technology-Podcasts/The-AI-Podcast-p940829/">TuneIn</a>.</p>
<p>Make the AI Podcast better: Have a few minutes to spare? Fill out <a href="http://survey.podtrac.com/start-survey.aspx?pubid=I5V0tOQFNS8j&amp;ver=short">this listener survey</a>.</p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2021/08/ai-podcast-2600x1472_-1-scaled.jpg"
			type="image/jpeg"
			width="2048"
			height="1159"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2021/08/ai-podcast-2600x1472_-1-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Tidy Tech: How Two Stanford Students Are Building Robots for Handling Household Chores]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>NVIDIA Scoops Up Wins at COMPUTEX Best Choice Awards</title>
		<link>https://blogs.nvidia.com/blog/computex-best-choice-awards-2024/</link>
		
		<dc:creator><![CDATA[Melody Tu]]></dc:creator>
		<pubDate>Tue, 28 May 2024 03:00:53 +0000</pubDate>
				<category><![CDATA[Data Center]]></category>
		<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Generative AI]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[COMPUTEX 2024]]></category>
		<category><![CDATA[Data Science]]></category>
		<category><![CDATA[Events]]></category>
		<category><![CDATA[High Performance Computing]]></category>
		<category><![CDATA[NVIDIA BlueField]]></category>
		<category><![CDATA[NVIDIA Hopper Architecture]]></category>
		<category><![CDATA[NVIDIA NIM]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71806</guid>

					<description><![CDATA[Building on more than a dozen years of stacking wins at the COMPUTEX trade show’s annual Best Choice Awards, NVIDIA was today honored with BCAs for its latest technologies. The NVIDIA GH200 Grace Hopper Superchip won the Computer and System Category Award; the NVIDIA Spectrum-X AI Ethernet networking platform won the Networking and Communication Category	<a class="read-more" href="https://blogs.nvidia.com/blog/computex-best-choice-awards-2024/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Building on more than a dozen years of stacking wins at the <a href="https://www.nvidia.com/en-us/events/computex/" target="_blank" rel="noopener">COMPUTEX</a> trade show’s annual <a href="https://bcaward.computex.biz/default.aspx" target="_blank" rel="noopener">Best Choice Awards</a>, NVIDIA was today honored with BCAs for its latest technologies.</p>
<p>The <a href="https://www.nvidia.com/en-us/data-center/grace-hopper-superchip/" target="_blank" rel="noopener">NVIDIA GH200 Grace Hopper Superchip</a> won the Computer and System Category Award; the <a href="https://www.nvidia.com/en-us/networking/spectrumx/" target="_blank" rel="noopener">NVIDIA Spectrum-X</a> AI Ethernet networking platform won the Networking and Communication Category Award; and the <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/" target="_blank" rel="noopener">NVIDIA AI Enterprise</a> software platform won a Golden Award.</p>
<p>The awards — judged on the functionality, innovation and market potential of products exhibited at the leading computer and technology expo — were announced ahead of the show, which runs from June 4-7, in Taipei.</p>
<p>NVIDIA founder and CEO Jensen Huang will deliver a COMPUTEX <a href="https://events.nvidia.com/jensen-huang-taipei-keynote-2024" target="_blank" rel="noopener">keynote address</a> on Sunday, June 2, at 7 p.m. Taiwan time, at the NTU Sports Center and online.</p>
<h2><b>NVIDIA AI Enterprise Takes Gold</b></h2>
<p>NVIDIA AI Enterprise — a cloud-native software platform that streamlines the development and deployment of copilots and other <a href="https://www.nvidia.com/en-us/glossary/generative-ai/" target="_blank" rel="noopener">generative AI</a> applications — won a Golden Award.</p>
<p>The platform lifts the burden of maintaining and securing complex AI software, so businesses can focus on building and harnessing the technology’s game-changing insights.</p>
<p>Microservices that come with NVIDIA AI Enterprise — including <a href="https://www.nvidia.com/en-us/ai/" target="_blank" rel="noopener">NVIDIA NIM</a> and <a href="https://www.nvidia.com/en-us/technologies/cuda-x/" target="_blank" rel="noopener">NVIDIA CUDA-X</a> — optimize model performance and run anywhere with enterprise-grade security, support and stability, offering users a smooth transition from prototype to production.</p>
<p>Plus, the platform’s ability to improve AI performance results in better overall utilization of computing resources. This means companies using NVIDIA AI Enterprise need fewer servers to support the same workloads, greatly reducing their energy costs and data center footprint.</p>
<h2><b>More BCA Wins for NVIDIA Technologies</b></h2>
<p>NVIDIA GH200 and Spectrum-X were named best in their respective categories.</p>
<p>The NVIDIA GH200 Grace Hopper Superchip is the world’s first truly heterogeneous accelerated platform for AI and high-performance computing workloads. It combines the power-efficient <a href="https://www.nvidia.com/en-us/data-center/grace-cpu/" target="_blank" rel="noopener">NVIDIA Grace CPU</a> with an <a href="https://www.nvidia.com/en-us/data-center/technologies/hopper-architecture/" target="_blank" rel="noopener">NVIDIA Hopper architecture-based GPU</a> over a high-bandwidth 900GB/s coherent <a href="https://www.nvidia.com/en-us/data-center/nvlink-c2c/" target="_blank" rel="noopener">NVIDIA NVLink </a>chip-to-chip interconnect.</p>
<p>The superchip — shipping worldwide and <a href="https://blogs.nvidia.com/blog/gh200-grace-hopper-superchip-powers-ai-supercomputers/" target="_blank" rel="noopener">powering more than 40 AI supercomputers</a> across global research centers, system makers and cloud providers — <a href="https://nvidianews.nvidia.com/news/nvidia-grace-hopper-ignites-new-era-of-ai-supercomputing" target="_blank" rel="noopener">supercharges scientific innovation</a> with accelerated computing and scale-out solutions for AI inference, <a href="https://www.nvidia.com/en-us/glossary/large-language-models/" target="_blank" rel="noopener">large language models</a>, recommenders, vector databases, HPC applications and more.</p>
<p>The Spectrum-X platform, featuring <a href="https://www.nvidia.com/en-us/networking/spectrumx/" target="_blank" rel="noopener">NVIDIA Spectrum SN5600 switches</a> and <a href="https://www.nvidia.com/en-us/networking/products/data-processing-unit/" target="_blank" rel="noopener">NVIDIA BlueField-3 SuperNICs</a>, is the world’s first Ethernet fabric built for AI, accelerating generative AI network performance 1.6x over traditional Ethernet fabrics.</p>
<p>It can serve as the backend AI fabric for any AI cloud or large enterprise deployment, and is available from major server manufacturers as part of the full NVIDIA AI stack.</p>
<h2><b>NVIDIA Partners Recognized</b></h2>
<p>Other BCA winners include NVIDIA partners Acer, ASUS, MSI and YUAN, which were given Golden Awards for their respective laptops, gaming motherboards and smart-city applications — all powered by NVIDIA technologies, such as <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4090/" target="_blank" rel="noopener">NVIDIA GeForce RTX 4090 GPUs</a>, the <a href="https://www.nvidia.com/en-us/studio/" target="_blank" rel="noopener">NVIDIA Studio platform</a> for creative workflows and the <a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/" target="_blank" rel="noopener">NVIDIA Jetson platform</a> for edge AI and robotics.</p>
<p>ASUS also won a Computer and System Category Award, while MSI won a Gaming and Entertainment Category Award.</p>
<p><i>Learn more about the latest generative AI, HPC and networking technologies by joining </i><a href="https://www.nvidia.com/en-us/events/computex/" target="_blank" rel="noopener"><i>NVIDIA at COMPUTEX</i></a><i>.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/computex-bca-gh200-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/computex-bca-gh200-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[NVIDIA Scoops Up Wins at COMPUTEX Best Choice Awards]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Into the Omniverse: SoftServe and Continental Drive Digitalization With OpenUSD and Generative AI</title>
		<link>https://blogs.nvidia.com/blog/softserve-and-continental-drive-digitalization-with-openusd-and-generative-ai/</link>
		
		<dc:creator><![CDATA[James McKenna]]></dc:creator>
		<pubDate>Thu, 23 May 2024 13:00:08 +0000</pubDate>
				<category><![CDATA[Pro Graphics]]></category>
		<category><![CDATA[3D]]></category>
		<category><![CDATA[Into the Omniverse]]></category>
		<category><![CDATA[NVIDIA NIM]]></category>
		<category><![CDATA[Omniverse]]></category>
		<category><![CDATA[Universal Scene Description]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71772</guid>

					<description><![CDATA[Leading German automotive technology company enhances manufacturing workflows with OpenUSD-powered virtual factory solutions.]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p><i>Editor’s note: This post is part of </i><a href="https://www.nvidia.com/en-us/omniverse/news/"><i>Into the Omniverse</i></a><i>, a series focused on how artists, developers and enterprises can transform their workflows using the latest advances in </i><a href="https://www.nvidia.com/en-us/omniverse/usd/"><i>OpenUSD</i></a><i> and </i><a href="https://www.nvidia.com/en-us/omniverse/usd/"><i>NVIDIA Omniverse</i></a><i>.</i></p>
<p>Industrial digitalization is driving automotive innovation.</p>
<p>In response to the industry’s growing demand for seamless, connected driving experiences, <a href="https://www.softserveinc.com/en-us">SoftServe</a>, a leading IT consulting and digital services provider, worked with <a href="https://www.continental.com/en/">Continental</a>, a leading German automotive technology company, to develop <a href="https://developer.nvidia.com/blog/spotlight-continental-and-softserve-deliver-generative-ai-powered-virtual-factory-solutions-with-openusd/">Industrial Co-Pilot</a>, a virtual agent powered by <a href="https://www.nvidia.com/en-us/glossary/generative-ai/">generative AI</a> that enables engineers to streamline maintenance workflows.</p>
<p>SoftServe helps manufacturers like Continental to further optimize their operations by integrating the Universal Scene Description, or <a href="https://www.nvidia.com/en-us/omniverse/usd/">OpenUSD</a>, framework into virtual factory solutions — such as Industrial Co-Pilot — developed on the <a href="https://www.nvidia.com/en-us/omniverse/">NVIDIA Omniverse</a> platform.</p>
<p>OpenUSD offers the flexibility and extensibility organizations need to harness the full potential of digital transformation, streamlining operations and driving efficiency. Omniverse is a platform of application programming interfaces, software development kits and services that enable developers to easily integrate OpenUSD and <a href="https://www.nvidia.com/en-us/design-visualization/technologies/rtx/">NVIDIA RTX</a> rendering technologies into existing software tools and simulation workflows.</p>
<h2><b>Realizing the Benefits of OpenUSD</b></h2>
<p>SoftServe and Continental’s Industrial Co-Pilot brings together generative AI and immersive 3D visualization to help factory teams increase productivity during equipment and production line maintenance. With the copilot, engineers can oversee production lines and monitor the performance of individual stations or the shop floor.</p>
<p>They can also interact with the copilot to conduct root cause analysis and receive step-by-step work instructions and recommendations, leading to reduced documentation processes and improved maintenance procedures. It’s expected that these advancements will contribute to increased productivity and a10% reduction in maintenance effort and downtime.</p>
<p><img loading="lazy" decoding="async" class="wp-image-71782 aligncenter" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2.png" alt="" width="578" height="324" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2.png 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2-400x224.png 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2-672x377.png 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2-768x431.png 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2-1536x861.png 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2-803x450.png 803w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2-384x215.png 384w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2-178x100.png 178w, https://blogs.nvidia.com/wp-content/uploads/2024/05/Copy-of-IndustrialCopilotDashboard2-1280x718.png 1280w" sizes="(max-width: 578px) 100vw, 578px" /></p>
<p>In a <a href="https://www.youtube.com/live/cqggH5skWH8?si=ZMUXPYIH7A0K5el4">recent Omniverse community livestream</a>, Benjamin Huber, who leads advanced automation and digitalization in the user experience business area at Continental, highlighted the significance of the company’s collaboration with SoftServe and its adoption of Omniverse.</p>
<p>The Omniverse platform equips Continental and SoftServe developers with the tools needed to build a new era of AI-enabled industrial applications and services. And by breaking down data silos and fostering multi-platform cooperation with OpenUSD, SoftServe and Continental developers enable engineers to work seamlessly across disciplines and systems, driving efficiency and innovation throughout their processes.</p>
<p>“Any engineer, no matter what tool they’re working with, can transform their data into OpenUSD and then interchange data from one discipline to another, and from one tool to another,” said Huber.</p>
<p>This sentiment was echoed by Vasyl Boliuk, senior lead and test automation engineer at SoftServe, who shared how OpenUSD and Omniverse — along with other NVIDIA technologies like <a href="https://www.nvidia.com/en-us/ai-data-science/products/riva/">NVIDIA Riva</a>, <a href="https://www.nvidia.com/en-us/ai-data-science/products/nemo/">NVIDIA NeMo</a> and <a href="https://developer.nvidia.com/blog/nvidia-nim-offers-optimized-inference-microservices-for-deploying-ai-models-at-scale/">NVIDIA NIM</a> microservices — enabled SoftServe and Continental teams to develop custom large language models and connect them to new 3D workflows.</p>
<p>“OpenUSD allows us to add any attribute or any piece of metadata we want to our applications,” he said.</p>
<p>Boliuk, Huber and other SoftServe and Continental representatives joined the livestream to share more about the potential unlocked from these OpenUSD-powered solutions. Watch the replay:</p>
<p><iframe loading="lazy" title="Generative AI-Powered Virtual Factory Solutions With OpenUSD" width="500" height="281" src="https://www.youtube.com/embed/cqggH5skWH8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<p>By embracing cutting-edge technologies and fostering collaboration, SoftServe and Continental are helping reshape automotive manufacturing.</p>
<h2><b>Get Plugged Into the World of OpenUSD</b></h2>
<p>Watch SoftServe and Continental’s on-demand NVIDIA GTC talks to learn more about their virtual factory solutions and experience developing on NVIDIA Omniverse with OpenUSD:</p>
<ul>
<li style="font-weight: 400;"><a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62919/">Transforming Factory Planning and Manufacturing Operations Within Digital Mega Plants</a></li>
<li style="font-weight: 400;"><a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s61799/">Getting Started With Generative AI and OpenUSD for Industrial Metaverse Applications</a></li>
</ul>
<p>Learn about the latest technologies driving the next industrial revolution by watching NVIDIA founder and CEO Jensen Huang’s <a href="https://www.nvidia.com/en-us/events/computex/">COMPUTEX keynote</a> on Sunday, June 2, at 7 p.m. Taiwan time.</p>
<p>Check out a new <a href="https://www.youtube.com/playlist?list=PL3jK4xNnlCVcUP08kj6eOzvCA82U_JKiy">video series</a> about how OpenUSD can improve 3D workflows. For more resources on OpenUSD, explore the Alliance for OpenUSD <a href="https://forum.aousd.org/">forum</a> and visit the <a href="https://aousd.org/">AOUSD website</a>.</p>
<p><i>Get started with NVIDIA Omniverse by downloading the standard license </i><a href="https://www.nvidia.com/en-us/omniverse/download/"><i>free</i></a><i>, access </i><a href="https://developer.nvidia.com/usd"><i>OpenUSD</i></a><i> resources and learn how </i><a href="https://www.nvidia.com/en-us/omniverse/enterprise/"><i>Omniverse Enterprise</i><i> can connect team</i></a><i>s. Follow Omniverse on </i><a href="https://www.instagram.com/nvidiaomniverse/"><i>Instagram</i></a><i>, </i><a href="https://medium.com/@nvidiaomniverse"><i>Medium</i></a><i> and </i><a href="https://twitter.com/nvidiaomniverse"><i>X</i></a><i>. For more, join the </i><a href="https://www.nvidia.com/en-us/omniverse/community/"><i>Omniverse community</i></a><i> on the </i><a href="https://forums.developer.nvidia.com/c/omniverse/300"><i>forums</i></a><i>, </i><a href="https://discord.com/invite/XWQNJDNuaC"><i>Discord server</i></a><i>, </i><a href="https://www.twitch.tv/nvidiaomniverse"><i>Twitch</i></a><i> and </i><a href="https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA"><i>YouTube</i></a><i> channels. </i></p>
<p><i>Featured image courtesy of SoftServe.</i></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/nv-ov-ito-1280x680_softserve_052024-1.png"
			type="image/png"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/nv-ov-ito-1280x680_softserve_052024-1-842x450.png"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Into the Omniverse: SoftServe and Continental Drive Digitalization With OpenUSD and Generative AI]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
		<item>
		<title>Senua’s Story Continues: GeForce NOW Brings ‘Senua’s Saga: Hellblade II’ to the Cloud</title>
		<link>https://blogs.nvidia.com/blog/geforce-now-thursday-senuas-saga-hellblade-2/</link>
		
		<dc:creator><![CDATA[GeForce NOW Community]]></dc:creator>
		<pubDate>Thu, 23 May 2024 13:00:05 +0000</pubDate>
				<category><![CDATA[Gaming]]></category>
		<category><![CDATA[Cloud Gaming]]></category>
		<category><![CDATA[GeForce NOW]]></category>
		<guid isPermaLink="false">https://blogs.nvidia.com/?p=71774</guid>

					<description><![CDATA[Every week, GFN Thursday brings new games to the cloud, featuring some of the latest and greatest titles for members to play. Leading the seven games joining GeForce NOW this week is the newest game in Ninja Theory’s Hellblade franchise, Senua’s Saga: Hellblade II. This day-and-date release expands the cloud gaming platform’s extensive library of	<a class="read-more" href="https://blogs.nvidia.com/blog/geforce-now-thursday-senuas-saga-hellblade-2/">
		Read Article		<span data-icon="y"></span>
	</a>
	]]></description>
										<content:encoded><![CDATA[<div id="bsf_rt_marker"></div><p>Every week, GFN Thursday brings new games to the cloud, featuring some of the latest and greatest titles for members to play.</p>
<p>Leading the seven games joining <a href="https://www.nvidia.com/en-us/geforce-now/">GeForce NOW</a> this week is the newest game in Ninja Theory’s <i>Hellblade</i> franchise, <i>Senua’s Saga: Hellblade II</i>. This day-and-date release expands the cloud gaming platform’s extensive library of over 1,900 games.</p>
<p>Members can also look forward to a new reward — a free in-game mount — for <i>The Elder Scrolls Online </i>starting Thursday, May 30. Get ready by opting into <a href="https://www.nvidia.com/en-us/geforce-now/rewards/">GeForce NOW’s Rewards program</a>.</p>
<h2><b>Senua Returns</b></h2>
<figure id="attachment_71778" aria-describedby="caption-attachment-71778" style="width: 672px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" class="size-large wp-image-71778" src="https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-672x368.jpg" alt="Senua's Saga: Hellblade II screen" width="672" height="368" srcset="https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-672x368.jpg 672w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-400x219.jpg 400w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-768x420.jpg 768w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-1536x840.jpg 1536w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-scaled.jpg 2048w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-823x450.jpg 823w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-393x215.jpg 393w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-183x100.jpg 183w, https://blogs.nvidia.com/wp-content/uploads/2024/05/GFN_Thursday-Senuas_Saga_Hellblade_II-1280x700.jpg 1280w" sizes="(max-width: 672px) 100vw, 672px" /><figcaption id="caption-attachment-71778" class="wp-caption-text">Head to the cloud to overcome the darkness.</figcaption></figure>
<p>In <i>Senua’s Saga: Hellblade II</i>, the sequel to the award-winning <i>Hellblade: Senua’s Sacrifice</i>, Senua returns in a brutal journey of survival through the myth and torment of Viking Iceland.</p>
<p>Intent on saving those who’ve fallen victim to the horrors of tyranny, Senua battles the forces of darkness within and without. Sink deep into the next chapter of Senua’s story, a crafted experience told through cinematic immersion, beautifully realized visuals and encapsulating sound.</p>
<p><a href="http://geforcenow.com">Priority and Ultimate members</a> can fully immerse themselves in Senua’s story with epic cinematic gameplay at higher resolutions and frame rates over free members. Ultimate members can stream at up to 4K 120 frames per second with exclusive access to GeForce RTX 4080 SuperPODs in the cloud, even on underpowered devices.</p>
<h2><b>Level Up With New Games</b></h2>
<p>Check out the full list of new games this week:</p>
<ul>
<li><i>Synergy </i>(New release on <a href="https://store.steampowered.com/app/1989070?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 21)</li>
<li><i>Senua’s Saga: Hellblade II</i> (New release on <a href="https://store.steampowered.com/app/2461850?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a> and <a href="https://www.xbox.com/games/store/senuas-saga-hellblade-ii/9pmbb7nghv95?utm_source=nvidia&amp;utm_campaign=geforce_now">Xbox</a>, available on PC Game Pass, May 21)</li>
<li><i>Crown Wars: The Black Prince </i>(New release on <a href="https://store.steampowered.com/app/1658920?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 23)</li>
<li><i>Serum</i> (New release on <a href="https://store.steampowered.com/app/1610520?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 23)</li>
<li><i>Ships at Sea</i> (New release on <a href="https://store.steampowered.com/app/1266540?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>, May 23)</li>
<li><i>Exo One </i>(<a href="https://store.steampowered.com/app/773370?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
<li><i>Phantom Brigade </i>(<a href="https://store.steampowered.com/app/553540?utm_source=nvidia&amp;utm_campaign=geforce_now">Steam</a>)</li>
</ul>
<p>What are you planning to play this weekend? Let us know on <a href="https://www.twitter.com/nvidiagfn">X</a> or in the comments below</p>
<blockquote class="twitter-tweet" data-width="500" data-dnt="true">
<p lang="en" dir="ltr">what&#39;s a life lesson you learned from a game?</p>
<p>&mdash; <img src="https://s.w.org/images/core/emoji/15.0.3/72x72/1f329.png" alt="🌩" class="wp-smiley" style="height: 1em; max-height: 1em;" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href="https://twitter.com/NVIDIAGFN/status/1793310854592491909?ref_src=twsrc%5Etfw">May 22, 2024</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
]]></content:encoded>
					
		
		
		
			<media:content
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-thursday-5-23-nv-blog-1280x680-no-copy.jpg"
			type="image/jpeg"
			width="1280"
			height="680"
			>
			<media:thumbnail
			url="https://blogs.nvidia.com/wp-content/uploads/2024/05/gfn-thursday-5-23-nv-blog-1280x680-no-copy-842x450.jpg"
			width="842"
			height="450"
			/>
			<media:title type="html"><![CDATA[Senua’s Story Continues: GeForce NOW Brings ‘Senua’s Saga: Hellblade II’ to the Cloud]]></media:title>
			<media:description type="html"></media:description>
			</media:content>
			</item>
	</channel>
</rss>
